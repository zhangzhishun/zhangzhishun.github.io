<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>NFT框架 OpenZeppelin ERC721源码分析</title>
      <link href="/2022/05/19/blockchain/nft/NFT%E6%A1%86%E6%9E%B6-OpenZeppelinERC721%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2022/05/19/blockchain/nft/NFT%E6%A1%86%E6%9E%B6-OpenZeppelinERC721%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h1><h2 id="1-代码版本"><a href="#1-代码版本" class="headerlink" title="1. 代码版本"></a>1. 代码版本</h2><p><a href="https://github.com/OpenZeppelin/openzeppelin-contracts/tree/release-v4.6">release-v4.6</a></p><h2 id="2-什么是ERC721？"><a href="#2-什么是ERC721？" class="headerlink" title="2. 什么是ERC721？"></a>2. 什么是ERC721？</h2><p>ERC-721 为 NFT 引入了一个标准，换言之， 这种类型的代币是独一无二的</p><h1 id="二、源码分析"><a href="#二、源码分析" class="headerlink" title="二、源码分析"></a>二、源码分析</h1><h2 id="ERC20涉及到的合约列表"><a href="#ERC20涉及到的合约列表" class="headerlink" title="ERC20涉及到的合约列表"></a>ERC20涉及到的合约列表</h2><ul><li>Context</li><li>ERC165</li><li>IERC721</li><li>IERC721Metadata</li></ul><h2 id="1-Context"><a href="#1-Context" class="headerlink" title="1. Context"></a>1. Context</h2><h2 id="2-IERC20"><a href="#2-IERC20" class="headerlink" title="2. IERC20"></a>2. IERC20</h2><p>EIP 中定义的 ERC20 标准的接口</p><pre><code class="javascript">// SPDX-License-Identifier: MIT// OpenZeppelin Contracts (last updated v4.6.0) (token/ERC20/IERC20.sol)pragma solidity ^0.8.0;/** * @dev Interface of the ERC20 standard as defined in the EIP. */interface IERC20 {    /**     * @dev 当 `value` 代币从一个账户 (`from`) 移动到另一个（`to`）触发此事件     *     * 请注意，`value` 可能为零     */    event Transfer(address indexed from, address indexed to, uint256 value);    /**     * @dev 当“owner”的“spender” token通过调用 {approve} 设置时触发此事件     * `value` 是新的津贴。     */    event Approval(address indexed owner, address indexed spender, uint256 value);    /**     * @dev 返回存在的token数量     */    function totalSupply() external view returns (uint256);    /**     * @dev 返回 `account` 拥有的token数量     */    function balanceOf(address account) external view returns (uint256);    /**     * @dev 将 `amount` 令牌从调用者的帐户移至 `to`。     *     * 返回一个布尔值，指示操作是否成功。     *     * 发出 {Transfer} 事件。     */    function transfer(address to, uint256 amount) external returns (bool);    /**     * @dev 返回允许“spender”通过 {transferFrom} 代表“owner”花费的token的剩余数量。默认为零。     *     * 当 {approve} 或 {transferFrom} 被调用时，这个值会改变。     */    function allowance(address owner, address spender) external view returns (uint256);    /**     * @dev Sets 将 `amount` 设置为 `spender` 在调用者代币上的限额。     * 返回一个布尔值，指示操作是否成功。     *      * 重要提示：请注意，使用此方法更改配额会带来风险     * 即有人可能会因不幸的交易排序而同时使用旧配额和新配额     * 缓解这种竞争条件的一种可能解决方案是首先将支出者的津贴减少到 0，然后设置所需的值：     * https://github.com/ethereum/EIPs/issues/20#issuecomment-263524729      *      * 发出 {Approval} 事件     */    function approve(address spender, uint256 amount) external returns (bool);    /**     * @dev 使用allowance机制将指定amount的token从“from”转移到“to”     * 然后从调用者的allowance中扣除“金额”     *      * 返回一个布尔值，该值指示操作是否成功     *      * 发出 {transferFrom} 事件     */    function transferFrom(        address from,        address to,        uint256 amount    ) external returns (bool);}</code></pre><h2 id="3-IERC20Metadata"><a href="#3-IERC20Metadata" class="headerlink" title="3. IERC20Metadata"></a>3. IERC20Metadata</h2><p>来自 ERC20 标准的可选metadata功能的接口</p><pre><code class="solidity">// SPDX-License-Identifier: MIT// OpenZeppelin Contracts v4.4.1 (token/ERC20/extensions/IERC20Metadata.sol)pragma solidity ^0.8.0;import "../IERC20.sol";/** * @dev Interface for the optional metadata functions from the ERC20 standard. * * _Available since v4.1._ */interface IERC20Metadata is IERC20 {    /**     * @dev 返回token名字     */    function name() external view returns (string memory);    /**     * @dev 返回token的标志     */    function symbol() external view returns (string memory);    /**     * @dev 返回token的小数点位数     */    function decimals() external view returns (uint8);}</code></pre><h2 id="4-ERC721"><a href="#4-ERC721" class="headerlink" title="4. ERC721"></a>4. ERC721</h2><p>ERC-721不可替代令牌标准的可选枚举扩展。</p><p>主要方法：</p><p>ERC721合约定义了基本的接口方法：</p><ul><li><p>safeTransferFrom：转移代币所有权</p></li><li><p>transferFrom：转移代币所有权</p></li><li><p>setApprovalForAll：授权operator具有所有代币的控制权</p></li><li><p>balanceOf：返回owner的代币数量</p></li><li><p>ownerOf：根据tokenId返回代币持有者address</p></li><li><p>getApproved：查询tokenId的授权人operator address</p></li><li><p>approve 授权tokenId给地址to</p></li><li><p>isApprovedForAll：查询一个地址是否为另一个地址的授权操作者。</p></li><li><p>totalSupply：返回由此契约跟踪的有效nft的计数（代币总量），其中每个nft都有一个分配的、可查询的所有者，且所有者不等于零地址</p></li><li><p>tokenByIndex：返回第index的NFT的tokenId。没有指定排序顺序。</p></li><li><p>tokenOfOwnerByIndex：返回分配给指定人的第index的NFT的tokenId。没有指定排序顺序</p></li></ul><p>源码：</p><pre><code class="solidity">// SPDX-License-Identifier: MIT// OpenZeppelin Contracts (last updated v4.6.0) (token/ERC721/ERC721.sol)pragma solidity ^0.8.0;import "./IERC721.sol";import "./IERC721Receiver.sol";import "./extensions/IERC721Metadata.sol";import "../../utils/Address.sol";import "../../utils/Context.sol";import "../../utils/Strings.sol";import "../../utils/introspection/ERC165.sol";/** * @dev Implementation of https://eips.ethereum.org/EIPS/eip-721[ERC721] Non-Fungible Token Standard, including * the Metadata extension, but not including the Enumerable extension, which is available separately as * {ERC721Enumerable}. */contract ERC721 is Context, ERC165, IERC721, IERC721Metadata {    using Address for address;    using Strings for uint256;    // Token name    string private _name;    // Token symbol    string private _symbol;    // Mapping from token ID to owner address    mapping(uint256 =&gt; address) private _owners;    // Mapping owner address to token count    mapping(address =&gt; uint256) private _balances;    // Mapping from token ID to approved address    mapping(uint256 =&gt; address) private _tokenApprovals;    // Mapping from owner to operator approvals    mapping(address =&gt; mapping(address =&gt; bool)) private _operatorApprovals;    /**     * @dev Initializes the contract by setting a `name` and a `symbol` to the token collection.     */    constructor(string memory name_, string memory symbol_) {        _name = name_;        _symbol = symbol_;    }    /**     * @dev See {IERC165-supportsInterface}.     */    function supportsInterface(bytes4 interfaceId) public view virtual override(ERC165, IERC165) returns (bool) {        return            interfaceId == type(IERC721).interfaceId ||            interfaceId == type(IERC721Metadata).interfaceId ||            super.supportsInterface(interfaceId);    }    /**     * @dev See {IERC721-balanceOf}.     */    function balanceOf(address owner) public view virtual override returns (uint256) {        require(owner != address(0), "ERC721: balance query for the zero address");        return _balances[owner];    }    /**     * @dev See {IERC721-ownerOf}.     */    function ownerOf(uint256 tokenId) public view virtual override returns (address) {        address owner = _owners[tokenId];        require(owner != address(0), "ERC721: owner query for nonexistent token");        return owner;    }    /**     * @dev See {IERC721Metadata-name}.     */    function name() public view virtual override returns (string memory) {        return _name;    }    /**     * @dev See {IERC721Metadata-symbol}.     */    function symbol() public view virtual override returns (string memory) {        return _symbol;    }    /**     * @dev See {IERC721Metadata-tokenURI}.     */    function tokenURI(uint256 tokenId) public view virtual override returns (string memory) {        require(_exists(tokenId), "ERC721Metadata: URI query for nonexistent token");        string memory baseURI = _baseURI();        return bytes(baseURI).length &gt; 0 ? string(abi.encodePacked(baseURI, tokenId.toString())) : "";    }    /**     * @dev Base URI for computing {tokenURI}. If set, the resulting URI for each     * token will be the concatenation of the `baseURI` and the `tokenId`. Empty     * by default, can be overridden in child contracts.     */    function _baseURI() internal view virtual returns (string memory) {        return "";    }    /**     * @dev See {IERC721-approve}.     */    function approve(address to, uint256 tokenId) public virtual override {        address owner = ERC721.ownerOf(tokenId);        require(to != owner, "ERC721: approval to current owner");        require(            _msgSender() == owner || isApprovedForAll(owner, _msgSender()),            "ERC721: approve caller is not owner nor approved for all"        );        _approve(to, tokenId);    }    /**     * @dev See {IERC721-getApproved}.     */    function getApproved(uint256 tokenId) public view virtual override returns (address) {        require(_exists(tokenId), "ERC721: approved query for nonexistent token");        return _tokenApprovals[tokenId];    }    /**     * @dev See {IERC721-setApprovalForAll}.     */    function setApprovalForAll(address operator, bool approved) public virtual override {        _setApprovalForAll(_msgSender(), operator, approved);    }    /**     * @dev See {IERC721-isApprovedForAll}.     */    function isApprovedForAll(address owner, address operator) public view virtual override returns (bool) {        return _operatorApprovals[owner][operator];    }    /**     * @dev See {IERC721-transferFrom}.     */    function transferFrom(        address from,        address to,        uint256 tokenId    ) public virtual override {        //solhint-disable-next-line max-line-length        require(_isApprovedOrOwner(_msgSender(), tokenId), "ERC721: transfer caller is not owner nor approved");        _transfer(from, to, tokenId);    }    /**     * @dev See {IERC721-safeTransferFrom}.     */    function safeTransferFrom(        address from,        address to,        uint256 tokenId    ) public virtual override {        safeTransferFrom(from, to, tokenId, "");    }    /**     * @dev See {IERC721-safeTransferFrom}.     */    function safeTransferFrom(        address from,        address to,        uint256 tokenId,        bytes memory data    ) public virtual override {        require(_isApprovedOrOwner(_msgSender(), tokenId), "ERC721: transfer caller is not owner nor approved");        _safeTransfer(from, to, tokenId, data);    }    /**     * @dev Safely transfers `tokenId` token from `from` to `to`, checking first that contract recipients     * are aware of the ERC721 protocol to prevent tokens from being forever locked.     *     * `data` is additional data, it has no specified format and it is sent in call to `to`.     *     * This internal function is equivalent to {safeTransferFrom}, and can be used to e.g.     * implement alternative mechanisms to perform token transfer, such as signature-based.     *     * Requirements:     *     * - `from` cannot be the zero address.     * - `to` cannot be the zero address.     * - `tokenId` token must exist and be owned by `from`.     * - If `to` refers to a smart contract, it must implement {IERC721Receiver-onERC721Received}, which is called upon a safe transfer.     *     * Emits a {Transfer} event.     */    function _safeTransfer(        address from,        address to,        uint256 tokenId,        bytes memory data    ) internal virtual {        _transfer(from, to, tokenId);        require(_checkOnERC721Received(from, to, tokenId, data), "ERC721: transfer to non ERC721Receiver implementer");    }    /**     * @dev Returns whether `tokenId` exists.     *     * Tokens can be managed by their owner or approved accounts via {approve} or {setApprovalForAll}.     *     * Tokens start existing when they are minted (`_mint`),     * and stop existing when they are burned (`_burn`).     */    function _exists(uint256 tokenId) internal view virtual returns (bool) {        return _owners[tokenId] != address(0);    }    /**     * @dev Returns whether `spender` is allowed to manage `tokenId`.     *     * Requirements:     *     * - `tokenId` must exist.     */    function _isApprovedOrOwner(address spender, uint256 tokenId) internal view virtual returns (bool) {        require(_exists(tokenId), "ERC721: operator query for nonexistent token");        address owner = ERC721.ownerOf(tokenId);        return (spender == owner || isApprovedForAll(owner, spender) || getApproved(tokenId) == spender);    }    /**     * @dev Safely mints `tokenId` and transfers it to `to`.     *     * Requirements:     *     * - `tokenId` must not exist.     * - If `to` refers to a smart contract, it must implement {IERC721Receiver-onERC721Received}, which is called upon a safe transfer.     *     * Emits a {Transfer} event.     */    function _safeMint(address to, uint256 tokenId) internal virtual {        _safeMint(to, tokenId, "");    }    /**     * @dev Same as {xref-ERC721-_safeMint-address-uint256-}[`_safeMint`], with an additional `data` parameter which is     * forwarded in {IERC721Receiver-onERC721Received} to contract recipients.     */    function _safeMint(        address to,        uint256 tokenId,        bytes memory data    ) internal virtual {        _mint(to, tokenId);        require(            _checkOnERC721Received(address(0), to, tokenId, data),            "ERC721: transfer to non ERC721Receiver implementer"        );    }    /**     * @dev Mints `tokenId` and transfers it to `to`.     *     * WARNING: Usage of this method is discouraged, use {_safeMint} whenever possible     *     * Requirements:     *     * - `tokenId` must not exist.     * - `to` cannot be the zero address.     *     * Emits a {Transfer} event.     */    function _mint(address to, uint256 tokenId) internal virtual {        require(to != address(0), "ERC721: mint to the zero address");        require(!_exists(tokenId), "ERC721: token already minted");        _beforeTokenTransfer(address(0), to, tokenId);        _balances[to] += 1;        _owners[tokenId] = to;        emit Transfer(address(0), to, tokenId);        _afterTokenTransfer(address(0), to, tokenId);    }    /**     * @dev Destroys `tokenId`.     * The approval is cleared when the token is burned.     *     * Requirements:     *     * - `tokenId` must exist.     *     * Emits a {Transfer} event.     */    function _burn(uint256 tokenId) internal virtual {        address owner = ERC721.ownerOf(tokenId);        _beforeTokenTransfer(owner, address(0), tokenId);        // Clear approvals        _approve(address(0), tokenId);        _balances[owner] -= 1;        delete _owners[tokenId];        emit Transfer(owner, address(0), tokenId);        _afterTokenTransfer(owner, address(0), tokenId);    }    /**     * @dev Transfers `tokenId` from `from` to `to`.     *  As opposed to {transferFrom}, this imposes no restrictions on msg.sender.     *     * Requirements:     *     * - `to` cannot be the zero address.     * - `tokenId` token must be owned by `from`.     *     * Emits a {Transfer} event.     */    function _transfer(        address from,        address to,        uint256 tokenId    ) internal virtual {        require(ERC721.ownerOf(tokenId) == from, "ERC721: transfer from incorrect owner");        require(to != address(0), "ERC721: transfer to the zero address");        _beforeTokenTransfer(from, to, tokenId);        // Clear approvals from the previous owner        _approve(address(0), tokenId);        _balances[from] -= 1;        _balances[to] += 1;        _owners[tokenId] = to;        emit Transfer(from, to, tokenId);        _afterTokenTransfer(from, to, tokenId);    }    /**     * @dev Approve `to` to operate on `tokenId`     *     * Emits an {Approval} event.     */    function _approve(address to, uint256 tokenId) internal virtual {        _tokenApprovals[tokenId] = to;        emit Approval(ERC721.ownerOf(tokenId), to, tokenId);    }    /**     * @dev Approve `operator` to operate on all of `owner` tokens     *     * Emits an {ApprovalForAll} event.     */    function _setApprovalForAll(        address owner,        address operator,        bool approved    ) internal virtual {        require(owner != operator, "ERC721: approve to caller");        _operatorApprovals[owner][operator] = approved;        emit ApprovalForAll(owner, operator, approved);    }    /**     * @dev Internal function to invoke {IERC721Receiver-onERC721Received} on a target address.     * The call is not executed if the target address is not a contract.     *     * @param from address representing the previous owner of the given token ID     * @param to target address that will receive the tokens     * @param tokenId uint256 ID of the token to be transferred     * @param data bytes optional data to send along with the call     * @return bool whether the call correctly returned the expected magic value     */    function _checkOnERC721Received(        address from,        address to,        uint256 tokenId,        bytes memory data    ) private returns (bool) {        if (to.isContract()) {            try IERC721Receiver(to).onERC721Received(_msgSender(), from, tokenId, data) returns (bytes4 retval) {                return retval == IERC721Receiver.onERC721Received.selector;            } catch (bytes memory reason) {                if (reason.length == 0) {                    revert("ERC721: transfer to non ERC721Receiver implementer");                } else {                    assembly {                        revert(add(32, reason), mload(reason))                    }                }            }        } else {            return true;        }    }    /**     * @dev Hook that is called before any token transfer. This includes minting     * and burning.     *     * Calling conditions:     *     * - When `from` and `to` are both non-zero, ``from``'s `tokenId` will be     * transferred to `to`.     * - When `from` is zero, `tokenId` will be minted for `to`.     * - When `to` is zero, ``from``'s `tokenId` will be burned.     * - `from` and `to` are never both zero.     *     * To learn more about hooks, head to xref:ROOT:extending-contracts.adoc#using-hooks[Using Hooks].     */    function _beforeTokenTransfer(        address from,        address to,        uint256 tokenId    ) internal virtual {}    /**     * @dev Hook that is called after any transfer of tokens. This includes     * minting and burning.     *     * Calling conditions:     *     * - when `from` and `to` are both non-zero.     * - `from` and `to` are never both zero.     *     * To learn more about hooks, head to xref:ROOT:extending-contracts.adoc#using-hooks[Using Hooks].     */    function _afterTokenTransfer(        address from,        address to,        uint256 tokenId    ) internal virtual {}}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
            <tag> NFT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NFT框架 OpenZeppelin ERC20源码分析</title>
      <link href="/2022/05/18/blockchain/nft/NFT%E6%A1%86%E6%9E%B6-OpenZeppelinERC20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2022/05/18/blockchain/nft/NFT%E6%A1%86%E6%9E%B6-OpenZeppelinERC20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h1><h2 id="1-代码版本"><a href="#1-代码版本" class="headerlink" title="1. 代码版本"></a>1. 代码版本</h2><p><a href="https://github.com/OpenZeppelin/openzeppelin-contracts/tree/release-v4.6">release-v4.6</a></p><h2 id="2-什么是ERC20？"><a href="#2-什么是ERC20？" class="headerlink" title="2. 什么是ERC20？"></a>2. 什么是ERC20？</h2><p>ERC20 代币合约跟踪可替代代币：</p><ul><li>任何一个代币都完全等同于任何其他代币</li><li>没有任何代币具有与之相关的特殊权利或行为</li></ul><p>这使得 ERC20 代币可用于交换货币、投票权、质押等媒介</p><h1 id="二、源码分析"><a href="#二、源码分析" class="headerlink" title="二、源码分析"></a>二、源码分析</h1><h2 id="ERC20涉及到的合约列表"><a href="#ERC20涉及到的合约列表" class="headerlink" title="ERC20涉及到的合约列表"></a>ERC20涉及到的合约列表</h2><ul><li>Context</li><li>IERC20</li><li>IERC20Metadata</li><li>ERC20</li></ul><h2 id="1-Context"><a href="#1-Context" class="headerlink" title="1. Context"></a>1. Context</h2><p>提供有关当前执行上下文的信息，包括交易的发送者及其数据，虽然可以通过 msg.sender 和 msg.data使用，但是不应直接访问它们，因为在处理元交易时，帐户发送和为执行付费可能不是实际的发送者（就应用程序而言被关注到）</p><pre><code class="solidity">// SPDX-License-Identifier: MIT// OpenZeppelin Contracts v4.4.1 (utils/Context.sol)pragma solidity ^0.8.0;/** * @dev Provides information about the current execution context, including the * sender of the transaction and its data. While these are generally available * via msg.sender and msg.data, they should not be accessed in such a direct * manner, since when dealing with meta-transactions the account sending and * paying for execution may not be the actual sender (as far as an application * is concerned). * * This contract is only required for intermediate, library-like contracts. */abstract contract Context {      /**       * 获取与当前合约交互的地址，该地址可能是用户地址，也可能是合约地址       */    function _msgSender() internal view virtual returns (address) {        return msg.sender;    }      /**       * 获取消息data       */    function _msgData() internal view virtual returns (bytes calldata) {        return msg.data;    }}</code></pre><h2 id="2-IERC20"><a href="#2-IERC20" class="headerlink" title="2. IERC20"></a>2. IERC20</h2><p>EIP 中定义的 ERC20 标准的接口</p><pre><code class="javascript">// SPDX-License-Identifier: MIT// OpenZeppelin Contracts (last updated v4.6.0) (token/ERC20/IERC20.sol)pragma solidity ^0.8.0;/** * @dev Interface of the ERC20 standard as defined in the EIP. */interface IERC20 {    /**     * @dev 当 `value` 代币从一个账户 (`from`) 移动到另一个（`to`）触发此事件     *     * 请注意，`value` 可能为零     */    event Transfer(address indexed from, address indexed to, uint256 value);    /**     * @dev 当“owner”的“spender” token通过调用 {approve} 设置时触发此事件     * `value` 是新的津贴。     */    event Approval(address indexed owner, address indexed spender, uint256 value);    /**     * @dev 返回存在的token数量     */    function totalSupply() external view returns (uint256);    /**     * @dev 返回 `account` 拥有的token数量     */    function balanceOf(address account) external view returns (uint256);    /**     * @dev 将 `amount` 令牌从调用者的帐户移至 `to`。     *     * 返回一个布尔值，指示操作是否成功。     *     * 发出 {Transfer} 事件。     */    function transfer(address to, uint256 amount) external returns (bool);    /**     * @dev 返回允许“spender”通过 {transferFrom} 代表“owner”花费的token的剩余数量。默认为零。     *     * 当 {approve} 或 {transferFrom} 被调用时，这个值会改变。     */    function allowance(address owner, address spender) external view returns (uint256);    /**     * @dev Sets 将 `amount` 设置为 `spender` 在调用者代币上的限额。     * 返回一个布尔值，指示操作是否成功。     *      * 重要提示：请注意，使用此方法更改配额会带来风险     * 即有人可能会因不幸的交易排序而同时使用旧配额和新配额     * 缓解这种竞争条件的一种可能解决方案是首先将支出者的津贴减少到 0，然后设置所需的值：     * https://github.com/ethereum/EIPs/issues/20#issuecomment-263524729      *      * 发出 {Approval} 事件     */    function approve(address spender, uint256 amount) external returns (bool);    /**     * @dev 使用allowance机制将指定amount的token从“from”转移到“to”     * 然后从调用者的allowance中扣除“金额”     *      * 返回一个布尔值，该值指示操作是否成功     *      * 发出 {transferFrom} 事件     */    function transferFrom(        address from,        address to,        uint256 amount    ) external returns (bool);}</code></pre><h2 id="3-IERC20Metadata"><a href="#3-IERC20Metadata" class="headerlink" title="3. IERC20Metadata"></a>3. IERC20Metadata</h2><p>来自 ERC20 标准的可选metadata功能的接口</p><pre><code class="solidity">// SPDX-License-Identifier: MIT// OpenZeppelin Contracts v4.4.1 (token/ERC20/extensions/IERC20Metadata.sol)pragma solidity ^0.8.0;import "../IERC20.sol";/** * @dev Interface for the optional metadata functions from the ERC20 standard. * * _Available since v4.1._ */interface IERC20Metadata is IERC20 {    /**     * @dev 返回token名字     */    function name() external view returns (string memory);    /**     * @dev 返回token的标志     */    function symbol() external view returns (string memory);    /**     * @dev 返回token的小数点位数     */    function decimals() external view returns (uint8);}</code></pre><h2 id="4-ERC20"><a href="#4-ERC20" class="headerlink" title="4. ERC20"></a>4. ERC20</h2><p>ERC-721不可替代令牌标准的可选枚举扩展。</p><p>主要方法：</p><p>ERC721合约定义了基本的接口方法：</p><ul><li><p>safeTransferFrom：转移代币所有权</p></li><li><p>transferFrom：转移代币所有权</p></li><li><p>setApprovalForAll：授权operator具有所有代币的控制权</p></li><li><p>balanceOf：返回owner的代币数量</p></li><li><p>ownerOf：根据tokenId返回代币持有者address</p></li><li><p>getApproved：查询tokenId的授权人operator address</p></li><li><p>approve 授权tokenId给地址to</p></li><li><p>isApprovedForAll：查询一个地址是否为另一个地址的授权操作者。</p></li><li><p>totalSupply：返回由此契约跟踪的有效nft的计数（代币总量），其中每个nft都有一个分配的、可查询的所有者，且所有者不等于零地址</p></li><li><p>tokenByIndex：返回第index的NFT的tokenId。没有指定排序顺序。</p></li><li><p>tokenOfOwnerByIndex：返回分配给指定人的第index的NFT的tokenId。没有指定排序顺序</p></li></ul><p>源码：</p><pre><code class="solidity">// SPDX-License-Identifier: MIT// OpenZeppelin Contracts (last updated v4.6.0) (token/ERC20/ERC20.sol)pragma solidity ^0.8.0;import "./IERC20.sol";import "./extensions/IERC20Metadata.sol";import "../../utils/Context.sol";/** * @dev {IERC20} 接口的实现 * * 此实现与创建令牌的方式无关 * 这意味着必须使用 {_mint} 在派生合约中添加供应机制。 * 有关通用机制，请参阅 {ERC20PresetMinterPauser} *  * 提示：有关详细说明，请参阅我们的指南 https://forum.zeppelin.solutions/t/how-to-implement-erc20-supply-mechanisms/226[如何实施供应机制] *  * 我们遵循了一般的 OpenZeppelin Contracts 指南： * 函数在失败时恢复而不是返回 `false`。这种行为仍然是传统的，并且与 ERC20 应用程序的期望不冲突 * 此外，在调用 {transferFrom} 时会发出 {Approval} 事件。这允许应用程序仅通过收听所述事件来重建所有帐户的限额。 EIP 的其他实现可能不会发出这些事件，因为规范没有要求。 * 最后，添加了非标准的 {decreaseAllowance} 和 {increaseAllowance} 函数，以缓解围绕设置限额的众所周知的问题。请参阅 {IERC20-approve} */contract ERC20 is Context, IERC20, IERC20Metadata {    mapping(address =&gt; uint256) private _balances;    mapping(address =&gt; mapping(address =&gt; uint256)) private _allowances;    uint256 private _totalSupply;    string private _name;    string private _symbol;    /**     * @dev 设置 {name} 和 {symbol}.     *     * {decimals} 的默认值为 18。要为 {decimals} 选择不同的值，应重载它     *      * 这两个值都是不可变的：只能在构造过程中设置一次     */    constructor(string memory name_, string memory symbol_) {        _name = name_;        _symbol = symbol_;    }    /**     * @dev 返回token的名字     */    function name() public view virtual override returns (string memory) {        return _name;    }    /**     * @dev 返回token的标志，通常是比名字短一点的缩写     */    function symbol() public view virtual override returns (string memory) {        return _symbol;    }    /**     * @dev 返回用于获取其用户表示的小数位数     * 例如，如果“decimals”等于“2”，则“505”代币的余额应显示为“5.05”（“505 / 10 ** 2”）     * 代币通常选择 18 的值，模仿 Ether 和 Wei 之间的关系。这是 {ERC20} 使用的值，除非此函数被覆盖；          * 注意：此信息仅用于_显示_目的：它绝不会影响合约的任何算术，包括 {IERC20-balanceOf} 和 {IERC20-transfer}     */    function decimals() public view virtual override returns (uint8) {        return 18;    }    /**     * @dev See {IERC20-totalSupply}.     */    function totalSupply() public view virtual override returns (uint256) {        return _totalSupply;    }    /**     * @dev See {IERC20-balanceOf}.     */    function balanceOf(address account) public view virtual override returns (uint256) {        return _balances[account];    }    /**     * @dev See {IERC20-transfer}.     *     * 规定:     *     * - `to` 不能是零地址.     * - 调用者至少有`amount`数量的token     */    function transfer(address to, uint256 amount) public virtual override returns (bool) {        address owner = _msgSender();        _transfer(owner, to, amount);        return true;    }    /**     * @dev See {IERC20-allowance}.     */    function allowance(address owner, address spender) public view virtual override returns (uint256) {        return _allowances[owner][spender];    }    /**     * @dev See {IERC20-approve}.     *     * 注意：如果 `amount` 是最大值 `uint256`，则不会在 `transferFrom` 上更新配额。这在语义上等同于无限批准     *     * 规定:     *     * - `spender` 不能是零地址.     */    function approve(address spender, uint256 amount) public virtual override returns (bool) {        address owner = _msgSender();        _approve(owner, spender, amount);        return true;    }    /**     * @dev See {IERC20-transferFrom}.     *     * 发出一个 {Approval} 事件，指示更新的配额     * EIP 不需要这样做。请参阅 {ERC20} 开头的注释     *      * 注意：如果当前allowance是最大的 `uint256`，则不会更新限额     *     * 规定:     *     * - `from` 和 `to` 不能是零地址.     * - `from` 至少有`amount`数量的token     * - 调用者从`from`获取到的allowance至少是`amount`.     */    function transferFrom(        address from,        address to,        uint256 amount    ) public virtual override returns (bool) {        address spender = _msgSender();        _spendAllowance(from, spender, amount);        _transfer(from, to, amount);        return true;    }    /**     * @dev 以原子方式增加调用者授予 `spender` 的allowance。     *     * 这是 {approve} 的替代方案，可用作缓解     * {IERC20-approve} 中描述的问题     *     * 发出一个 {Approval} 事件，指示更新的allowance     *      * 规定:     *     * - `spender` 不能是零地址.     */    function increaseAllowance(address spender, uint256 addedValue) public virtual returns (bool) {        address owner = _msgSender();        _approve(owner, spender, allowance(owner, spender) + addedValue);        return true;    }    /**     * @dev 以原子方式减少调用者授予 `spender` 的allowance。     *     * 这是 {approve} 的替代方案，可用作缓解     * {IERC20-approve} 中描述的问题。     *     * 发出一个 {Approval} 事件，指示更新的allowance。     *      * 规定:     *     * - `spender` 不能是零地址.     * - `spender` 至少有来自调用者授予的subtractedValue数量的allowance     */    function decreaseAllowance(address spender, uint256 subtractedValue) public virtual returns (bool) {        address owner = _msgSender();        uint256 currentAllowance = allowance(owner, spender);        require(currentAllowance &gt;= subtractedValue, "ERC20: decreased allowance below zero");        unchecked {            _approve(owner, spender, currentAllowance - subtractedValue);        }        return true;    }    /**     * @dev 将令牌的“数量”从“from”移动到“to”。     *     * 这个内部函数等价于{transfer}，可用于     * 例如实施自动代币费用，削减机制等。     *     * 发出 {Transfer} 事件     *     * 规定:     *     * - `from` 不能是零地址.     * - `to` 不能是零地址.     * - `from` 的余额至少 `amount`     */    function _transfer(        address from,        address to,        uint256 amount    ) internal virtual {        require(from != address(0), "ERC20: transfer from the zero address");        require(to != address(0), "ERC20: transfer to the zero address");        _beforeTokenTransfer(from, to, amount);        uint256 fromBalance = _balances[from];        require(fromBalance &gt;= amount, "ERC20: transfer amount exceeds balance");        unchecked {            _balances[from] = fromBalance - amount;        }        _balances[to] += amount;        emit Transfer(from, to, amount);        _afterTokenTransfer(from, to, amount);    }    /** @dev 创建 `amount` 代币并将它们分配给 `account`，增加总供应量。     *     * 发出一个 {Transfer} 事件，并将 `from` 设置为零地址。       *      * 规定:     *     * - `account` 不能是零地址.     */    function _mint(address account, uint256 amount) internal virtual {        require(account != address(0), "ERC20: mint to the zero address");        _beforeTokenTransfer(address(0), account, amount);        _totalSupply += amount;        _balances[account] += amount;        emit Transfer(address(0), account, amount);        _afterTokenTransfer(address(0), account, amount);    }    /**     * @dev 销毁 `account` 中的 `amount` 代币，减少总供应量。     *     * 发出一个 {Transfer} 事件，并将 `to` 设置为零地址。     Destroys `amount` tokens from `account`, reducing the     *     * 规定:     *     * - `account` 不能是零地址     * - `account` 至少有`amount`个token     */    function _burn(address account, uint256 amount) internal virtual {        require(account != address(0), "ERC20: burn from the zero address");        _beforeTokenTransfer(account, address(0), amount);        uint256 accountBalance = _balances[account];        require(accountBalance &gt;= amount, "ERC20: burn amount exceeds balance");        unchecked {            _balances[account] = accountBalance - amount;        }        _totalSupply -= amount;        emit Transfer(account, address(0), amount);        _afterTokenTransfer(account, address(0), amount);    }    /**     * @dev 将 `amount` 设置为 `spender` 在 `owner` 的代币上的限额。     *     * 这个内部函数相当于`approve`，可以用来     * 例如为某些子系统设置自动限额等。     *     * 发出 {Approval} 事件     *      * 规定:     *     * - `owner` 不能是零地址.     * - `spender` 不能是零地址.     */    function _approve(        address owner,        address spender,        uint256 amount    ) internal virtual {        require(owner != address(0), "ERC20: approve from the zero address");        require(spender != address(0), "ERC20: approve to the zero address");        _allowances[owner][spender] = amount;        emit Approval(owner, spender, amount);    }    /**     * @dev 根据花费的“amount”更新“owner”对“spender”的津贴     *     * 在无限津贴的情况下不更新津贴金额     * 如果没有足够的配额，请恢复     *     * 可能会发出 {Approval} 事件。     */    function _spendAllowance(        address owner,        address spender,        uint256 amount    ) internal virtual {        uint256 currentAllowance = allowance(owner, spender);        if (currentAllowance != type(uint256).max) {            require(currentAllowance &gt;= amount, "ERC20: insufficient allowance");            unchecked {                _approve(owner, spender, currentAllowance - amount);            }        }    }    /**     * @dev 在任何token转移之前调用的Hook     * 这包括mint和burn     *      * 调用条件:     *     * - 当 `from` 和 `to` 都非零时，`from` 的amount数量的token将被转移到`to`     * - 当 `from` 为零时，将为 `to` 铸造 `amount` 数量的token     * - 当 `to` 为 0 时，`from` 的`amount` 数量的token将被烧毁     * - `from` 和 `to` 永远不会都是零     *     * 要了解有关挂钩的更多信息，请访问：ROOT:extending-contracts.adoc#using-hooks[Using Hooks]     */    function _beforeTokenTransfer(        address from,        address to,        uint256 amount    ) internal virtual {}    /**     * @dev 在任何token转移后调用的Hook     * 这包括mint和burn     *     * 调用条件：     *     * - 当 `from` 和 `to` 都非零时，`from` 的`amount`数量的token已转移到`to`     * - 当 `from` 为零时，为 `to` 铸造 `amount` 数量的token     * - 当 `to` 为 0 时，`from` 的`amount`数量的token已被烧毁     * - `from` 和 `to` 永远不会都是零     *      * 要了解有关挂钩的更多信息，请访问：ROOT:extending-contracts.adoc#using-hooks[Using Hooks]     */    function _afterTokenTransfer(        address from,        address to,        uint256 amount    ) internal virtual {}}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
            <tag> NFT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Solidity学习笔记(攻击)</title>
      <link href="/2022/05/17/blockchain/ethereum/Solidity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E6%94%BB%E5%87%BB)/"/>
      <url>/2022/05/17/blockchain/ethereum/Solidity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E6%94%BB%E5%87%BB)/</url>
      
        <content type="html"><![CDATA[<h1 id="Solidity学习笔记-攻击"><a href="#Solidity学习笔记-攻击" class="headerlink" title="Solidity学习笔记(攻击)"></a>Solidity学习笔记(攻击)</h1><p>本文参考：<a href="https://solidity-by-example.org/">https://solidity-by-example.org/</a></p><p>推荐视频课程：<a href="https://www.bilibili.com/video/BV1St411a7Pk">https://www.bilibili.com/video/BV1St411a7Pk</a></p><h2 id="Re-Entrancy（重入）"><a href="#Re-Entrancy（重入）" class="headerlink" title="Re-Entrancy（重入）"></a>Re-Entrancy（重入）</h2><p>漏洞假设合约 A 调用合约 B</p><p>Reentracy 漏洞允许 B 在 A 完成执行之前回调 A</p><p><a href="https://solidity-by-example.org/hacks/re-entrancy">https://solidity-by-example.org/hacks/re-entrancy</a></p><p>预防技术：</p><ul><li>确保在调用外部合约之前发生所有状态更改</li><li>使用防止重新进入的函数修饰符这里是重新进入</li></ul><p>保护的示例：</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract ReEntrancyGuard {    bool internal locked;    modifier noReentrant() {        require(!locked, "No re-entrancy");        locked = true;        _;        locked = false;    }}</code></pre><h2 id="数值溢出"><a href="#数值溢出" class="headerlink" title="数值溢出"></a>数值溢出</h2><p>Solidity &lt; 0.8</p><p>Integers in Solidity 溢出/下溢没有任何错误</p><p>Solidity &gt;= 0.8 </p><p>Solidity 0.8 溢出/下溢的默认行为是抛出错误</p><p>预防技术：</p><ul><li>使用 SafeMath 来防止算术上溢和下溢</li><li>Solidity 0.8 默认为上溢/下溢引发错误</li></ul><h2 id="自毁"><a href="#自毁" class="headerlink" title="自毁"></a>自毁</h2><p>合约可以通过调用 selfdestruct 从区块链中删除</p><p>selfdestruct 将存储在合约中的所有剩余 Ether 发送到指定地址</p><p>恶意合约可以使用 selfdestruct 强制将 Ether 发送到任何合约</p><p>预防：不要依赖address(this).balance</p><p><a href="https://solidity-by-example.org/hacks/self-destruct">https://solidity-by-example.org/hacks/self-destruct</a></p><h2 id="访问私有数据"><a href="#访问私有数据" class="headerlink" title="访问私有数据"></a>访问私有数据</h2><p>攻击：智能合约上的所有数据都可以读取。让我们看看如何读取私有数据。在此过程中，您将了解 Solidity 如何存储状态变量。</p><p>预防：不要在区块链上存储敏感信息</p><h2 id="Delegatecall"><a href="#Delegatecall" class="headerlink" title="Delegatecall"></a>Delegatecall</h2><p>漏洞delegatecall 使用起来很棘手，错误的使用或不正确的理解会导致毁灭性的后果</p><p>使用delegatecall 时必须牢记两件事</p><ul><li>delegatecall 保留上下文（存储、调用者等）</li><li>合约调用 delegatecall 和合约被调用的存储布局必须相同</li></ul><p><a href="https://solidity-by-example.org/hacks/delegatecall">https://solidity-by-example.org/hacks/delegatecall</a></p><h2 id="Source-of-Randomness"><a href="#Source-of-Randomness" class="headerlink" title="Source of Randomness"></a>Source of Randomness</h2><p>漏洞blockhash和block.timestamp不是随机性的可靠来源</p><p>预防技术：不要使用 blockhash 和 block.timestamp 作为随机源</p><h2 id="Denial-of-Service"><a href="#Denial-of-Service" class="headerlink" title="Denial of Service"></a>Denial of Service</h2><p>漏洞有很多方法可以攻击智能合约使其无法使用</p><p>我们在这里介绍的一个漏洞是通过使发送以太币的功能失败来拒绝服务</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;/*The goal of KingOfEther is to become the king by sending more Ether thanthe previous king. Previous king will be refunded with the amount of Etherhe sent.*//*1. Deploy KingOfEther2. Alice becomes the king by sending 1 Ether to claimThrone().2. Bob becomes the king by sending 2 Ether to claimThrone().   Alice receives a refund of 1 Ether.3. Deploy Attack with address of KingOfEther.4. Call attack with 3 Ether.5. Current king is the Attack contract and no one can become the new king.What happened?Attack became the king. All new challenge to claim the throne will be rejectedsince Attack contract does not have a fallback function, denying to accept theEther sent from KingOfEther before the new king is set.*/contract KingOfEther {    address public king;    uint public balance;    function claimThrone() external payable {        require(msg.value &gt; balance, "Need to pay more to become the king");        (bool sent, ) = king.call{value: balance}("");        require(sent, "Failed to send Ether");        balance = msg.value;        king = msg.sender;    }}contract Attack {    KingOfEther kingOfEther;    constructor(KingOfEther _kingOfEther) {        kingOfEther = KingOfEther(_kingOfEther);    }    // You can also perform a DOS by consuming all gas using assert.    // This attack will work even if the calling contract does not check    // whether the call was successful or not.    //    // function () external payable {    //     assert(false);    // }    function attack() public payable {        kingOfEther.claimThrone{value: msg.value}();    }}</code></pre><p>预防技术：防止这种情况的一种方法是允许用户提取他们的以太币而不是发送它</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract KingOfEther {    address public king;    uint public balance;    mapping(address =&gt; uint) public balances;    function claimThrone() external payable {        require(msg.value &gt; balance, "Need to pay more to become the king");        balances[king] += balance;        balance = msg.value;        king = msg.sender;    }    function withdraw() public {        require(msg.sender != king, "Current king cannot withdraw");        uint amount = balances[msg.sender];        balances[msg.sender] = 0;        (bool sent, ) = msg.sender.call{value: amount}("");        require(sent, "Failed to send Ether");    }}</code></pre><h2 id="Phishing-with-tx-origin"><a href="#Phishing-with-tx-origin" class="headerlink" title="Phishing with tx.origin"></a>Phishing with tx.origin</h2><p>msg.sender 和 tx.origin 有什么区别？</p><p>如果合约 A 调用 B，B 调用 C，在 C 中 msg.sender 是 B，tx.origin 是 A</p><p>漏洞恶意合约可以欺骗合约所有者调用只有所有者才能调用的函数</p><p>预防技术：使用msg.sender 而不是 tx.origin</p><h2 id="用外部合约隐藏恶意代码"><a href="#用外部合约隐藏恶意代码" class="headerlink" title="用外部合约隐藏恶意代码"></a>用外部合约隐藏恶意代码</h2><p>在 Solidity 中，任何地址都可以被转换为特定的合约，即使该地址上的合约不是被转换的那个</p><p>这可以被利用来隐藏恶意代码。让我们看看如何</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;/*Let's say Alice can see the code of Foo and Bar but not Mal.It is obvious to Alice that Foo.callBar() executes the code inside Bar.log().However Eve deploys Foo with the address of Mal, so that calling Foo.callBar()will actually execute the code at Mal.*//*1. Eve deploys Mal2. Eve deploys Foo with the address of Mal3. Alice calls Foo.callBar() after reading the code and judging that it is   safe to call.4. Although Alice expected Bar.log() to be execute, Mal.log() was executed.*/contract Foo {    Bar bar;    constructor(address _bar) {        bar = Bar(_bar);    }    function callBar() public {        bar.log();    }}contract Bar {    event Log(string message);    function log() public {        emit Log("Bar was called");    }}// This code is hidden in a separate filecontract Mal {    event Log(string message);    // function () external {    //     emit Log("Mal was called");    // }    // Actually we can execute the same exploit even if this function does    // not exist by using the fallback    function log() public {        emit Log("Mal was called");    }}</code></pre><p>预防技巧：</p><ul><li><p>在构造函数内部初始化一个新合约</p></li><li><p>公开外部合约的地址，以便可以查看外部合约的代码</p></li></ul><pre><code class="solidity">Bar public bar;constructor() public {    bar = new Bar();}</code></pre><h2 id="Honeypot"><a href="#Honeypot" class="headerlink" title="Honeypot"></a>Honeypot</h2><p>Honeypot是捕捉黑客的陷阱</p><p>结合两个漏洞利用重入和隐藏恶意代码，我们可以构建一个捕捉恶意用户的合约</p><p><a href="https://solidity-by-example.org/hacks/honeypot">https://solidity-by-example.org/hacks/honeypot</a></p><h2 id="Front-Running"><a href="#Front-Running" class="headerlink" title="Front Running"></a>Front Running</h2><p>交易需要一些时间才能被挖掘，攻击者可以观察交易池并发送交易，将其包含在原始交易之前的块中。这种机制可以被滥用来对交易进行重新排序以使攻击者受益。</p><p>预防性技术：</p><ul><li>使用commit-reveal scheme</li><li>使用submarine send</li></ul><h2 id="Block-Timestamp-Manipulation"><a href="#Block-Timestamp-Manipulation" class="headerlink" title="Block Timestamp Manipulation"></a>Block Timestamp Manipulation</h2><p>block.timestamp 可以被矿工操纵，具有以下约束：</p><ul><li>它不能被标记为早于其父级的时间</li><li>它不能距离现在太远</li></ul><p>预防技术：</p><ul><li>不要使用 block.timestamp 作为entropy和随机数的来源</li></ul><h2 id="签名重播"><a href="#签名重播" class="headerlink" title="签名重播"></a>签名重播</h2><p>在链外签署消息并在执行函数之前签署需要签名的合约是一种有用的技术</p><p>例如，该技术用于：</p><ul><li>减少链上的交易数量</li><li>无气体交易，称为元交易</li></ul><p>漏洞：可以使用相同的签名多次执行一个功能，如果签名者的意图是批准一次交易，这可能是有害的</p><h2 id="绕过合约大小检查"><a href="#绕过合约大小检查" class="headerlink" title="绕过合约大小检查"></a>绕过合约大小检查</h2><p>如果一个地址是一个合约，那么该地址存储的代码大小将大于 0 对吗？</p><p>让我们看看如何创建一个由 extcodesize 返回的代码大小等于 0 的合约。</p><p><a href="https://solidity-by-example.org/hacks/contract-size">https://solidity-by-example.org/hacks/contract-size</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Solidity学习笔记(应用部分)</title>
      <link href="/2022/05/10/blockchain/ethereum/Solidity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E5%BA%94%E7%94%A8%E9%83%A8%E5%88%86)/"/>
      <url>/2022/05/10/blockchain/ethereum/Solidity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E5%BA%94%E7%94%A8%E9%83%A8%E5%88%86)/</url>
      
        <content type="html"><![CDATA[<h1 id="Solidity学习笔记-应用部分"><a href="#Solidity学习笔记-应用部分" class="headerlink" title="Solidity学习笔记(应用部分)"></a>Solidity学习笔记(应用部分)</h1><p>本文参考：<a href="https://solidity-by-example.org/">https://solidity-by-example.org/</a></p><p>推荐视频课程：<a href="https://www.bilibili.com/video/BV1St411a7Pk">https://www.bilibili.com/video/BV1St411a7Pk</a></p><h2 id="以太坊钱包"><a href="#以太坊钱包" class="headerlink" title="以太坊钱包"></a>以太坊钱包</h2><p>一个基本钱包的例子</p><ul><li>任何人都可以发送 ETH</li><li>只有所有者可以提款</li></ul><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract EtherWallet {    address payable public owner;    constructor() {        owner = payable(msg.sender);    }    receive() external payable {}    function withdraw(uint _amount) external {        require(msg.sender == owner, "caller is not owner");        payable(msg.sender).transfer(_amount);    }    function getBalance() external view returns (uint) {        return address(this).balance;    }}</code></pre><h2 id="多签名钱包"><a href="#多签名钱包" class="headerlink" title="多签名钱包"></a><font color="red">多签名钱包</font></h2><p>让我们创建一个多重签名钱包，以下是规范</p><p>钱包所有者可以</p><ul><li>提交交易</li><li>批准和撤销对待处理交易的批准</li><li>在足够多的所有者批准后，任何人都可以执行交易</li></ul><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract MultiSigWallet {    event Deposit(address indexed sender, uint amount, uint balance);    event SubmitTransaction(        address indexed owner,        uint indexed txIndex,        address indexed to,        uint value,        bytes data    );    event ConfirmTransaction(address indexed owner, uint indexed txIndex);    event RevokeConfirmation(address indexed owner, uint indexed txIndex);    event ExecuteTransaction(address indexed owner, uint indexed txIndex);    address[] public owners;    mapping(address =&gt; bool) public isOwner;    uint public numConfirmationsRequired;    struct Transaction {        address to;        uint value;        bytes data;        bool executed;        uint numConfirmations;    }    // mapping from tx index =&gt; owner =&gt; bool    mapping(uint =&gt; mapping(address =&gt; bool)) public isConfirmed;    Transaction[] public transactions;    modifier onlyOwner() {        require(isOwner[msg.sender], "not owner");        _;    }    modifier txExists(uint _txIndex) {        require(_txIndex &lt; transactions.length, "tx does not exist");        _;    }    modifier notExecuted(uint _txIndex) {        require(!transactions[_txIndex].executed, "tx already executed");        _;    }    modifier notConfirmed(uint _txIndex) {        require(!isConfirmed[_txIndex][msg.sender], "tx already confirmed");        _;    }    constructor(address[] memory _owners, uint _numConfirmationsRequired) {        require(_owners.length &gt; 0, "owners required");        require(            _numConfirmationsRequired &gt; 0 &amp;&amp;                _numConfirmationsRequired &lt;= _owners.length,            "invalid number of required confirmations"        );        for (uint i = 0; i &lt; _owners.length; i++) {            address owner = _owners[i];            require(owner != address(0), "invalid owner");            require(!isOwner[owner], "owner not unique");            isOwner[owner] = true;            owners.push(owner);        }        numConfirmationsRequired = _numConfirmationsRequired;    }    receive() external payable {        emit Deposit(msg.sender, msg.value, address(this).balance);    }    function submitTransaction(        address _to,        uint _value,        bytes memory _data    ) public onlyOwner {        uint txIndex = transactions.length;        transactions.push(            Transaction({                to: _to,                value: _value,                data: _data,                executed: false,                numConfirmations: 0            })        );        emit SubmitTransaction(msg.sender, txIndex, _to, _value, _data);    }    function confirmTransaction(uint _txIndex)        public        onlyOwner        txExists(_txIndex)        notExecuted(_txIndex)        notConfirmed(_txIndex)    {        Transaction storage transaction = transactions[_txIndex];        transaction.numConfirmations += 1;        isConfirmed[_txIndex][msg.sender] = true;        emit ConfirmTransaction(msg.sender, _txIndex);    }    function executeTransaction(uint _txIndex)        public        onlyOwner        txExists(_txIndex)        notExecuted(_txIndex)    {        Transaction storage transaction = transactions[_txIndex];        require(            transaction.numConfirmations &gt;= numConfirmationsRequired,            "cannot execute tx"        );        transaction.executed = true;        (bool success, ) = transaction.to.call{value: transaction.value}(            transaction.data        );        require(success, "tx failed");        emit ExecuteTransaction(msg.sender, _txIndex);    }    function revokeConfirmation(uint _txIndex)        public        onlyOwner        txExists(_txIndex)        notExecuted(_txIndex)    {        Transaction storage transaction = transactions[_txIndex];        require(isConfirmed[_txIndex][msg.sender], "tx not confirmed");        transaction.numConfirmations -= 1;        isConfirmed[_txIndex][msg.sender] = false;        emit RevokeConfirmation(msg.sender, _txIndex);    }    function getOwners() public view returns (address[] memory) {        return owners;    }    function getTransactionCount() public view returns (uint) {        return transactions.length;    }    function getTransaction(uint _txIndex)        public        view        returns (            address to,            uint value,            bytes memory data,            bool executed,            uint numConfirmations        )    {        Transaction storage transaction = transactions[_txIndex];        return (            transaction.to,            transaction.value,            transaction.data,            transaction.executed,            transaction.numConfirmations        );    }}</code></pre><p>这是一个测试从多重签名钱包发送交易的合约</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract TestContract {    uint public i;    function callMe(uint j) public {        i += j;    }    function getData() public pure returns (bytes memory) {        return abi.encodeWithSignature("callMe(uint256)", 123);    }}</code></pre><h2 id="默克尔树"><a href="#默克尔树" class="headerlink" title="默克尔树"></a>默克尔树</h2><p>Merkle 树允许您以密文方式证明一个元素包含在一个集合中，而不会泄露整个集合</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract MerkleProof {    function verify(        bytes32[] memory proof,        bytes32 root,        bytes32 leaf,        uint index    ) public pure returns (bool) {        bytes32 hash = leaf;        for (uint i = 0; i &lt; proof.length; i++) {            bytes32 proofElement = proof[i];            if (index % 2 == 0) {                hash = keccak256(abi.encodePacked(hash, proofElement));            } else {                hash = keccak256(abi.encodePacked(proofElement, hash));            }            index = index / 2;        }        return hash == root;    }}contract TestMerkleProof is MerkleProof {    bytes32[] public hashes;    constructor() {        string[4] memory transactions = [            "alice -&gt; bob",            "bob -&gt; dave",            "carol -&gt; alice",            "dave -&gt; bob"        ];        for (uint i = 0; i &lt; transactions.length; i++) {            hashes.push(keccak256(abi.encodePacked(transactions[i])));        }        uint n = transactions.length;        uint offset = 0;        while (n &gt; 0) {            for (uint i = 0; i &lt; n - 1; i += 2) {                hashes.push(                    keccak256(                        abi.encodePacked(hashes[offset + i], hashes[offset + i + 1])                    )                );            }            offset += n;            n = n / 2;        }    }    function getRoot() public view returns (bytes32) {        return hashes[hashes.length - 1];    }    /* verify    3rd leaf    0x1bbd78ae6188015c4a6772eb1526292b5985fc3272ead4c65002240fb9ae5d13    root    0x074b43252ffb4a469154df5fb7fe4ecce30953ba8b7095fe1e006185f017ad10    index    2    proof    0x948f90037b4ea787c14540d9feb1034d4a5bc251b9b5f8e57d81e4b470027af8    0x63ac1b92046d474f84be3aa0ee04ffe5600862228c81803cce07ac40484aee43    */}</code></pre><h2 id="遍历Map"><a href="#遍历Map" class="headerlink" title="遍历Map"></a>遍历Map</h2><p>您不能遍历映射</p><p>下面是一个如何创建可迭代映射的示例</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;library IterableMapping {    // Iterable mapping from address to uint;    struct Map {        address[] keys;        mapping(address =&gt; uint) values;        mapping(address =&gt; uint) indexOf;        mapping(address =&gt; bool) inserted;    }    function get(Map storage map, address key) public view returns (uint) {        return map.values[key];    }    function getKeyAtIndex(Map storage map, uint index) public view returns (address) {        return map.keys[index];    }    function size(Map storage map) public view returns (uint) {        return map.keys.length;    }    function set(        Map storage map,        address key,        uint val    ) public {        if (map.inserted[key]) {            map.values[key] = val;        } else {            map.inserted[key] = true;            map.values[key] = val;            map.indexOf[key] = map.keys.length;            map.keys.push(key);        }    }    function remove(Map storage map, address key) public {        if (!map.inserted[key]) {            return;        }        delete map.inserted[key];        delete map.values[key];        uint index = map.indexOf[key];        uint lastIndex = map.keys.length - 1;        address lastKey = map.keys[lastIndex];        map.indexOf[lastKey] = index;        delete map.indexOf[key];        map.keys[index] = lastKey;        map.keys.pop();    }}contract TestIterableMap {    using IterableMapping for IterableMapping.Map;    IterableMapping.Map private map;    function testIterableMap() public {        map.set(address(0), 0);        map.set(address(1), 100);        map.set(address(2), 200); // insert        map.set(address(2), 200); // update        map.set(address(3), 300);        for (uint i = 0; i &lt; map.size(); i++) {            address key = map.getKeyAtIndex(i);            assert(map.get(key) == i * 100);        }        map.remove(address(1));        // keys = [address(0), address(3), address(2)]        assert(map.size() == 3);        assert(map.getKeyAtIndex(0) == address(0));        assert(map.getKeyAtIndex(1) == address(3));        assert(map.getKeyAtIndex(2) == address(2));    }}</code></pre><h2 id="ERC20"><a href="#ERC20" class="headerlink" title="ERC20"></a>ERC20</h2><p>任何遵循 ERC20 标准的合约都是 ERC20 代币</p><p>ERC20 代币提供以下功能：</p><ul><li>转移代币</li><li>允许其他人代表代币持有者转移代币这里是 ERC20 的接口</li></ul><ol><li><p>创建一个ERC20 token</p><p>使用 Open Zeppelin 创建自己的 ERC20 代币很容易</p><p>这里是一个例子：</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;import "https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v4.0.0/contracts/token/ERC20/ERC20.sol";contract MyToken is ERC20 {    constructor(string memory name, string memory symbol) ERC20(name, symbol) {        // Mint 100 tokens to msg.sender        // Similar to how        // 1 dollar = 100 cents        // 1 token = 1 * (10 ** decimals)        _mint(msg.sender, 100 * 10**uint(decimals()));    }}</code></pre></li></ol><h2 id="ERC721"><a href="#ERC721" class="headerlink" title="ERC721"></a>ERC721</h2><p><a href="https://github.com/OpenZeppelin/openzeppelin-contracts/tree/master/contracts/token/ERC721">https://github.com/OpenZeppelin/openzeppelin-contracts/tree/master/contracts/token/ERC721</a></p><h2 id="Precompute-Contract-Address-with-Create2"><a href="#Precompute-Contract-Address-with-Create2" class="headerlink" title="Precompute Contract Address with Create2"></a><font style="color:red">Precompute Contract Address with Create2</font></h2><p>合约地址可以预先计算，在部署合约之前，使用 create2</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Factory {    // Returns the address of the newly deployed contract    function deploy(        address _owner,        uint _foo,        bytes32 _salt    ) public payable returns (address) {        // This syntax is a newer way to invoke create2 without assembly, you just need to pass salt        // https://docs.soliditylang.org/en/latest/control-structures.html#salted-contract-creations-create2        return address(new TestContract{salt: _salt}(_owner, _foo));    }}// This is the older way of doing it using assemblycontract FactoryAssembly {    event Deployed(address addr, uint salt);    // 1. Get bytecode of contract to be deployed    // NOTE: _owner and _foo are arguments of the TestContract's constructor    function getBytecode(address _owner, uint _foo) public pure returns (bytes memory) {        bytes memory bytecode = type(TestContract).creationCode;        return abi.encodePacked(bytecode, abi.encode(_owner, _foo));    }    // 2. Compute the address of the contract to be deployed    // NOTE: _salt is a random number used to create an address    function getAddress(bytes memory bytecode, uint _salt)        public        view        returns (address)    {        bytes32 hash = keccak256(            abi.encodePacked(bytes1(0xff), address(this), _salt, keccak256(bytecode))        );        // NOTE: cast last 20 bytes of hash to address        return address(uint160(uint(hash)));    }    // 3. Deploy the contract    // NOTE:    // Check the event log Deployed which contains the address of the deployed TestContract.    // The address in the log should equal the address computed from above.    function deploy(bytes memory bytecode, uint _salt) public payable {        address addr;        /*        NOTE: How to call create2        create2(v, p, n, s)        create new contract with code at memory p to p + n        and send v wei        and return the new address        where new address = first 20 bytes of keccak256(0xff + address(this) + s + keccak256(mem[p…(p+n)))              s = big-endian 256-bit value        */        assembly {            addr := create2(                callvalue(), // wei sent with current call                // Actual code starts after skipping the first 32 bytes                add(bytecode, 0x20),                mload(bytecode), // Load the size of code contained in the first 32 bytes                _salt // Salt from function arguments            )            if iszero(extcodesize(addr)) {                revert(0, 0)            }        }        emit Deployed(addr, _salt);    }}contract TestContract {    address public owner;    uint public foo;    constructor(address _owner, uint _foo) payable {        owner = _owner;        foo = _foo;    }    function getBalance() public view returns (uint) {        return address(this).balance;    }}</code></pre><h2 id="Minimal-Proxy-Contract"><a href="#Minimal-Proxy-Contract" class="headerlink" title="Minimal Proxy Contract"></a>Minimal Proxy Contract</h2><p>如果您有一个将被多次部署的合约，请使用Minimal Proxy Contract来廉价地部署它们</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;// original code// https://github.com/optionality/clone-factory/blob/master/contracts/CloneFactory.solcontract MinimalProxy {    function clone(address target) external returns (address result) {        // convert address to 20 bytes        bytes20 targetBytes = bytes20(target);        // actual code //        // 3d602d80600a3d3981f3363d3d373d3d3d363d73bebebebebebebebebebebebebebebebebebebebe5af43d82803e903d91602b57fd5bf3        // creation code //        // copy runtime code into memory and return it        // 3d602d80600a3d3981f3        // runtime code //        // code to delegatecall to address        // 363d3d373d3d3d363d73 address 5af43d82803e903d91602b57fd5bf3        assembly {            /*            reads the 32 bytes of memory starting at pointer stored in 0x40            In solidity, the 0x40 slot in memory is special: it contains the "free memory pointer"            which points to the end of the currently allocated memory.            */            let clone := mload(0x40)            // store 32 bytes to memory starting at "clone"            mstore(                clone,                0x3d602d80600a3d3981f3363d3d373d3d3d363d73000000000000000000000000            )            /*              |              20 bytes                |            0x3d602d80600a3d3981f3363d3d373d3d3d363d73000000000000000000000000                                                      ^                                                      pointer            */            // store 32 bytes to memory starting at "clone" + 20 bytes            // 0x14 = 20            mstore(add(clone, 0x14), targetBytes)            /*              |               20 bytes               |                 20 bytes              |            0x3d602d80600a3d3981f3363d3d373d3d3d363d73bebebebebebebebebebebebebebebebebebebebe                                                                                              ^                                                                                              pointer            */            // store 32 bytes to memory starting at "clone" + 40 bytes            // 0x28 = 40            mstore(                add(clone, 0x28),                0x5af43d82803e903d91602b57fd5bf30000000000000000000000000000000000            )            /*              |               20 bytes               |                 20 bytes              |           15 bytes          |            0x3d602d80600a3d3981f3363d3d373d3d3d363d73bebebebebebebebebebebebebebebebebebebebe5af43d82803e903d91602b57fd5bf3            */            // create new contract            // send 0 Ether            // code starts at pointer stored in "clone"            // code size 0x37 (55 bytes)            result := create(0, clone, 0x37)        }    }}</code></pre><h2 id="Upgradeable-Proxy"><a href="#Upgradeable-Proxy" class="headerlink" title="Upgradeable Proxy"></a>Upgradeable Proxy</h2><p>可升级代理合约的示例。永远不要在生产中使用它</p><p>这个例子展示了如何使用委托调用并在调用 fallback 时返回数据</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Proxy {    address public implementation;    function setImplementation(address _imp) external {        implementation = _imp;    }    function _delegate(address _imp) internal virtual {        assembly {            // calldatacopy(t, f, s)            // copy s bytes from calldata at position f to mem at position t            calldatacopy(0, 0, calldatasize())            // delegatecall(g, a, in, insize, out, outsize)            // - call contract at address a            // - with input mem[in…(in+insize))            // - providing g gas            // - and output area mem[out…(out+outsize))            // - returning 0 on error and 1 on success            let result := delegatecall(gas(), _imp, 0, calldatasize(), 0, 0)            // returndatacopy(t, f, s)            // copy s bytes from returndata at position f to mem at position t            returndatacopy(0, 0, returndatasize())            switch result            case 0 {                // revert(p, s)                // end execution, revert state changes, return data mem[p…(p+s))                revert(0, returndatasize())            }            default {                // return(p, s)                // end execution, return data mem[p…(p+s))                return(0, returndatasize())            }        }    }    fallback() external payable {        _delegate(implementation);    }}contract V1 {    address public implementation;    uint public x;    function inc() external {        x += 1;    }}contract V2 {    address public implementation;    uint public x;    function inc() external {        x += 1;    }    function dec() external {        x -= 1;    }}</code></pre><h2 id="Deploy-Any-Contract"><a href="#Deploy-Any-Contract" class="headerlink" title="Deploy Any Contract"></a>Deploy Any Contract</h2><p><a href="https://solidity-by-example.org/app/deploy-any-contract">https://solidity-by-example.org/app/deploy-any-contract</a></p><h2 id="Write-to-Any-Slot"><a href="#Write-to-Any-Slot" class="headerlink" title="Write to Any Slot"></a>Write to Any Slot</h2><p>Solidity 存储就像一个长度为 2^256 的数组。数组中的每个槽可以存储 32 个字节</p><p>状态变量定义了哪些槽将用于存储数据</p><p>但是使用汇编，您可以写入任何槽<br><a href="https://solidity-by-example.org/app/write-to-any-slot">https://solidity-by-example.org/app/write-to-any-slot</a></p><h2 id="单向支付通道"><a href="#单向支付通道" class="headerlink" title="单向支付通道"></a>单向支付通道</h2><p>支付渠道允许参与者反复将以太币从链下转移。</p><p>以下是该合约的使用方式：</p><ul><li>Alice 部署合约，用一些以太币为其提供资金</li><li>Alice 通过签署消息（链下）授权支付并将签名发送给 Bob</li><li>Bob 通过向智能合约提交签名消息来索取他的付款</li><li>如果 Bob 没有索取他的付款，Alice 在合同到期后取回她的 Ether </li></ul><p>这被称为单向支付通道，因为付款只能在一个从 Alice 到 Bob 的单向</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;import "github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.5/contracts/utils/cryptography/ECDSA.sol";import "github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.5/contracts/security/ReentrancyGuard.sol";contract UniDirectionalPaymentChannel is ReentrancyGuard {    using ECDSA for bytes32;    address payable public sender;    address payable public receiver;    uint private constant DURATION = 7 * 24 * 60 * 60;    uint public expiresAt;    constructor(address payable _receiver) payable {        require(_receiver != address(0), "receiver = zero address");        sender = payable(msg.sender);        receiver = _receiver;        expiresAt = block.timestamp + DURATION;    }    function _getHash(uint _amount) private view returns (bytes32) {        // NOTE: sign with address of this contract to protect agains        // replay attack on other contracts        return keccak256(abi.encodePacked(address(this), _amount));    }    function getHash(uint _amount) external view returns (bytes32) {        return _getHash(_amount);    }    function _getEthSignedHash(uint _amount) private view returns (bytes32) {        return _getHash(_amount).toEthSignedMessageHash();    }    function getEthSignedHash(uint _amount) external view returns (bytes32) {        return _getEthSignedHash(_amount);    }    function _verify(uint _amount, bytes memory _sig) private view returns (bool) {        return _getEthSignedHash(_amount).recover(_sig) == sender;    }    function verify(uint _amount, bytes memory _sig) external view returns (bool) {        return _verify(_amount, _sig);    }    function close(uint _amount, bytes memory _sig) external nonReentrant {        require(msg.sender == receiver, "!receiver");        require(_verify(_amount, _sig), "invalid sig");        (bool sent, ) = receiver.call{value: _amount}("");        require(sent, "Failed to send Ether");        selfdestruct(sender);    }    function cancel() external {        require(msg.sender == sender, "!sender");        require(block.timestamp &gt;= expiresAt, "!expired");        selfdestruct(sender);    }}</code></pre><h2 id="双向支付通道"><a href="#双向支付通道" class="headerlink" title="双向支付通道"></a>双向支付通道</h2><p>双向支付通道允许参与者 Alice 和 Bob 反复将以太币转移到链下</p><p>支付可以双向进行，Alice 支付 Bob，Bob 支付 Alice</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;pragma experimental ABIEncoderV2;/*Opening a channel1. Alice and Bob fund a multi-sig wallet2. Precompute payment channel address3. Alice and Bob exchanges signatures of initial balances4. Alice and Bob creates a transaction that can deploy a payment channel from   the multi-sig walletUpdate channel balances1. Repeat steps 1 - 3 from opening a channel2. From multi-sig wallet create a transaction that will   - delete the transaction that would have deployed the old payment channel   - and then create a transaction that can deploy a payment channel with the     new balancesClosing a channel when Alice and Bob agree on the final balance1. From multi-sig wallet create a transaction that will   - send payments to Alice and Bob   - and then delete the transaction that would have created the payment channelClosing a channel when Alice and Bob do not agree on the final balances1. Deploy payment channel from multi-sig2. call challengeExit() to start the process of closing a channel3. Alice and Bob can withdraw funds once the channel is expired*/import "github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.5/contracts/utils/math/SafeMath.sol";import "github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.5/contracts/utils/cryptography/ECDSA.sol";contract BiDirectionalPaymentChannel {    using SafeMath for uint;    using ECDSA for bytes32;    event ChallengeExit(address indexed sender, uint nonce);    event Withdraw(address indexed to, uint amount);    address payable[2] public users;    mapping(address =&gt; bool) public isUser;    mapping(address =&gt; uint) public balances;    uint public challengePeriod;    uint public expiresAt;    uint public nonce;    modifier checkBalances(uint[2] memory _balances) {        require(            address(this).balance &gt;= _balances[0].add(_balances[1]),            "balance of contract must be &gt;= to the total balance of users"        );        _;    }    // NOTE: deposit from multi-sig wallet    constructor(        address payable[2] memory _users,        uint[2] memory _balances,        uint _expiresAt,        uint _challengePeriod    ) payable checkBalances(_balances) {        require(_expiresAt &gt; block.timestamp, "Expiration must be &gt; now");        require(_challengePeriod &gt; 0, "Challenge period must be &gt; 0");        for (uint i = 0; i &lt; _users.length; i++) {            address payable user = _users[i];            require(!isUser[user], "user must be unique");            users[i] = user;            isUser[user] = true;            balances[user] = _balances[i];        }        expiresAt = _expiresAt;        challengePeriod = _challengePeriod;    }    function verify(        bytes[2] memory _signatures,        address _contract,        address[2] memory _signers,        uint[2] memory _balances,        uint _nonce    ) public pure returns (bool) {        for (uint i = 0; i &lt; _signatures.length; i++) {            /*            NOTE: sign with address of this contract to protect                  agains replay attack on other contracts            */            bool valid = _signers[i] ==                keccak256(abi.encodePacked(_contract, _balances, _nonce))                    .toEthSignedMessageHash()                    .recover(_signatures[i]);            if (!valid) {                return false;            }        }        return true;    }    modifier checkSignatures(        bytes[2] memory _signatures,        uint[2] memory _balances,        uint _nonce    ) {        // Note: copy storage array to memory        address[2] memory signers;        for (uint i = 0; i &lt; users.length; i++) {            signers[i] = users[i];        }        require(            verify(_signatures, address(this), signers, _balances, _nonce),            "Invalid signature"        );        _;    }    modifier onlyUser() {        require(isUser[msg.sender], "Not user");        _;    }    function challengeExit(        uint[2] memory _balances,        uint _nonce,        bytes[2] memory _signatures    )        public        onlyUser        checkSignatures(_signatures, _balances, _nonce)        checkBalances(_balances)    {        require(block.timestamp &lt; expiresAt, "Expired challenge period");        require(_nonce &gt; nonce, "Nonce must be greater than the current nonce");        for (uint i = 0; i &lt; _balances.length; i++) {            balances[users[i]] = _balances[i];        }        nonce = _nonce;        expiresAt = block.timestamp.add(challengePeriod);        emit ChallengeExit(msg.sender, nonce);    }    function withdraw() public onlyUser {        require(block.timestamp &gt;= expiresAt, "Challenge period has not expired yet");        uint amount = balances[msg.sender];        balances[msg.sender] = 0;        (bool sent, ) = msg.sender.call{value: amount}("");        require(sent, "Failed to send Ether");        emit Withdraw(msg.sender, amount);    }}</code></pre><h2 id="英式拍卖"><a href="#英式拍卖" class="headerlink" title="英式拍卖"></a>英式拍卖</h2><p>NFT的英式拍卖</p><p>拍卖：</p><ol><li>NFT的卖方部署此合同</li><li>拍卖持续 7 days</li><li>参与者可以通过存入高于当前最高出价者的 ETH 来出价</li><li>如果不是当前的最高出价，所有投标人都可以撤回他们的出价</li></ol><p>拍卖后：</p><ol><li>出价最高者成为 NFT的新所有者</li><li>卖家收到最高出价的 ETH</li></ol><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;interface IERC721 {    function safeTransferFrom(        address from,        address to,        uint tokenId    ) external;    function transferFrom(        address,        address,        uint    ) external;}contract EnglishAuction {    event Start();    event Bid(address indexed sender, uint amount);    event Withdraw(address indexed bidder, uint amount);    event End(address winner, uint amount);    IERC721 public nft;    uint public nftId;    address payable public seller;    uint public endAt;    bool public started;    bool public ended;    address public highestBidder;    uint public highestBid;    mapping(address =&gt; uint) public bids;    constructor(        address _nft,        uint _nftId,        uint _startingBid    ) {        nft = IERC721(_nft);        nftId = _nftId;        seller = payable(msg.sender);        highestBid = _startingBid;    }    function start() external {        require(!started, "started");        require(msg.sender == seller, "not seller");        nft.transferFrom(msg.sender, address(this), nftId);        started = true;        endAt = block.timestamp + 7 days;        emit Start();    }    function bid() external payable {        require(started, "not started");        require(block.timestamp &lt; endAt, "ended");        require(msg.value &gt; highestBid, "value &lt; highest");        if (highestBidder != address(0)) {            bids[highestBidder] += highestBid;        }        highestBidder = msg.sender;        highestBid = msg.value;        emit Bid(msg.sender, msg.value);    }    function withdraw() external {        uint bal = bids[msg.sender];        bids[msg.sender] = 0;        payable(msg.sender).transfer(bal);        emit Withdraw(msg.sender, bal);    }    function end() external {        require(started, "not started");        require(block.timestamp &gt;= endAt, "not ended");        require(!ended, "ended");        ended = true;        if (highestBidder != address(0)) {            nft.safeTransferFrom(address(this), highestBidder, nftId);            seller.transfer(highestBid);        } else {            nft.safeTransferFrom(address(this), seller, nftId);        }        emit End(highestBidder, highestBid);    }}</code></pre><h2 id="荷兰式拍卖"><a href="#荷兰式拍卖" class="headerlink" title="荷兰式拍卖"></a>荷兰式拍卖</h2><p>NFT的荷兰式拍卖</p><p>拍卖：</p><ol><li>NFT 卖方部署此合约，为 NFT设定起始价格</li><li>拍卖持续 7 days</li><li>NFT 的价格随着时间的推移而下降</li><li>参与者可以通过存入高于智能合约计算的当前价格的 ETH 来购买</li><li>当买家购买 NFT 时拍卖结束</li></ol><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;interface IERC721 {    function transferFrom(        address _from,        address _to,        uint _nftId    ) external;}contract DutchAuction {    uint private constant DURATION = 7 days;    IERC721 public immutable nft;    uint public immutable nftId;    address payable public immutable seller;    uint public immutable startingPrice;    uint public immutable startAt;    uint public immutable expiresAt;    uint public immutable discountRate;    constructor(        uint _startingPrice,        uint _discountRate,        address _nft,        uint _nftId    ) {        seller = payable(msg.sender);        startingPrice = _startingPrice;        startAt = block.timestamp;        expiresAt = block.timestamp + DURATION;        discountRate = _discountRate;        require(_startingPrice &gt;= _discountRate * DURATION, "starting price &lt; min");        nft = IERC721(_nft);        nftId = _nftId;    }    function getPrice() public view returns (uint) {        uint timeElapsed = block.timestamp - startAt;        uint discount = discountRate * timeElapsed;        return startingPrice - discount;    }    function buy() external payable {        require(block.timestamp &lt; expiresAt, "auction expired");        uint price = getPrice();        require(msg.value &gt;= price, "ETH &lt; price");        nft.transferFrom(seller, msg.sender, nftId);        uint refund = msg.value - price;        if (refund &gt; 0) {            payable(msg.sender).transfer(refund);        }        selfdestruct(seller);    }}</code></pre><h2 id="众筹"><a href="#众筹" class="headerlink" title="众筹"></a>众筹</h2><p><a href="https://solidity-by-example.org/app/crowd-fund">https://solidity-by-example.org/app/crowd-fund</a></p><h2 id="Multi-Call"><a href="#Multi-Call" class="headerlink" title="Multi Call"></a>Multi Call</h2><p><a href="https://solidity-by-example.org/app/multi-call">https://solidity-by-example.org/app/multi-call</a></p><h2 id="Multi-Delegatecall"><a href="#Multi-Delegatecall" class="headerlink" title="Multi Delegatecall"></a>Multi Delegatecall</h2><p><a href="https://solidity-by-example.org/app/multi-delegatecall">https://solidity-by-example.org/app/multi-delegatecall</a></p><h2 id="时间锁"><a href="#时间锁" class="headerlink" title="时间锁"></a>时间锁</h2><p>TimeLock 是一种合约，用于发布未来要执行的交易。在最短的等待时间之后，可以执行事务</p><p>时间锁通常用于 DAO</p><p><a href="https://solidity-by-example.org/app/time-lock">https://solidity-by-example.org/app/time-lock</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Solidity学习笔记(基础部分)</title>
      <link href="/2022/05/05/blockchain/ethereum/Solidity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86)/"/>
      <url>/2022/05/05/blockchain/ethereum/Solidity%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86)/</url>
      
        <content type="html"><![CDATA[<h1 id="Solidity学习笔记-基础部分"><a href="#Solidity学习笔记-基础部分" class="headerlink" title="Solidity学习笔记(基础部分)"></a>Solidity学习笔记(基础部分)</h1><p>本文参考：<a href="https://solidity-by-example.org/">https://solidity-by-example.org/</a></p><p>推荐视频课程：<a href="https://www.bilibili.com/video/BV1St411a7Pk">https://www.bilibili.com/video/BV1St411a7Pk</a></p><h2 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello World"></a>Hello World</h2><pre><code class="solidity">// SPDX-License-Identifier: MIT// compiler version must be greater than or equal to 0.8.13 and less than 0.9.0pragma solidity ^0.8.13;contract HelloWorld {    string public greet = "Hello World!";}</code></pre><h2 id="第一个程序"><a href="#第一个程序" class="headerlink" title="第一个程序"></a>第一个程序</h2><p>这是一个简单的合约，用于获取、增加、减少账户余额</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Counter {    uint public count;    // Function to get the current count    function get() public view returns (uint) {        return count;    }    // Function to increment count by 1    function inc() public {        count += 1;    }    // Function to decrement count by 1    function dec() public {        // This function will fail if count = 0        count -= 1;    }}</code></pre><h2 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h2><p>在这里介绍四种数据类型：</p><ul><li>boolean</li><li>uint</li><li>int</li><li>address</li></ul><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Primitives {    bool public boo = true;    /*    uint stands for unsigned integer, meaning non negative integers    different sizes are available        uint8   ranges from 0 to 2 ** 8 - 1        uint16  ranges from 0 to 2 ** 16 - 1        ...        uint256 ranges from 0 to 2 ** 256 - 1    */    uint8 public u8 = 1;    uint public u256 = 456;    uint public u = 123; // uint is an alias for uint256    /*    Negative numbers are allowed for int types.    Like uint, different ranges are available from int8 to int256        int256 ranges from -2 ** 255 to 2 ** 255 - 1    int128 ranges from -2 ** 127 to 2 ** 127 - 1    */    int8 public i8 = -1;    int public i256 = 456;    int public i = -123; // int is same as int256    // minimum and maximum of int    int public minInt = type(int).min;    int public maxInt = type(int).max;    address public addr = 0xCA35b7d915458EF540aDe6068dFe2F44E8fa733c;    /*    In Solidity, the data type byte represent a sequence of bytes.     Solidity presents two type of bytes types :     - fixed-sized byte arrays     - dynamically-sized byte arrays.          The term bytes in Solidity represents a dynamic array of bytes.      It’s a shorthand for byte[] .    */    bytes1 a = 0xb5; //  [10110101]    bytes1 b = 0x56; //  [01010110]    // Default values    // Unassigned variables have a default value    bool public defaultBoo; // false    uint public defaultUint; // 0    int public defaultInt; // 0    address public defaultAddr; // 0x0000000000000000000000000000000000000000}</code></pre><h2 id="变量类型"><a href="#变量类型" class="headerlink" title="变量类型"></a>变量类型</h2><p>Solidity 中有 3 种类型的变量</p><ul><li>local<ul><li>函数内定义</li><li>不存储在区块链</li></ul></li><li>state<ul><li>函数外定义</li><li>存储在区块链</li></ul></li><li>global (保存区块链的信息)</li></ul><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Variables {    // State variables are stored on the blockchain.    string public text = "Hello";    uint public num = 123;    function doSomething() public {        // Local variables are not saved to the blockchain.        uint i = 456;        // Here are some global variables        uint timestamp = block.timestamp; // Current block timestamp        address sender = msg.sender; // address of the caller    }}</code></pre><h2 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h2><p>常量是不能被修改的</p><p>它们的值是硬编码的，使用常量可以节省 gas 成本</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Constants {    // coding convention to uppercase constant variables    address public constant MY_ADDRESS = 0x777788889999AaAAbBbbCcccddDdeeeEfFFfCcCc;    uint public constant MY_UINT = 123;}</code></pre><h2 id="不可变变量"><a href="#不可变变量" class="headerlink" title="不可变变量"></a>不可变变量</h2><p>不可变变量就像常量。不可变变量的值可以在构造函数中设置，但之后不能修改。</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Immutable {    // coding convention to uppercase constant variables    address public immutable MY_ADDRESS;    uint public immutable MY_UINT;    constructor(uint _myUint) {        MY_ADDRESS = msg.sender;        MY_UINT = _myUint;    }}</code></pre><h2 id="读取和写入状态变量"><a href="#读取和写入状态变量" class="headerlink" title="读取和写入状态变量"></a>读取和写入状态变量</h2><p>要写入或更新状态变量，您需要发送交易</p><p>但是您可以免费读取状态变量，无需任何交易费用</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract SimpleStorage {    // State variable to store a number    uint public num;    // You need to send a transaction to write to a state variable.    function set(uint _num) public {        num = _num;    }    // You can read from a state variable without sending a transaction.    function get() public view returns (uint) {        return num;    }}</code></pre><h2 id="以太坊单位：Ether-and-Wei"><a href="#以太坊单位：Ether-and-Wei" class="headerlink" title="以太坊单位：Ether and Wei"></a>以太坊单位：Ether and Wei</h2><p>交易使用以太币支付，类似于一美元等于 100 美分，1eth等于 10^18wei</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract EtherUnits {    uint public oneWei = 1 wei;    // 1 wei is equal to 1    bool public isOneWei = 1 wei == 1;    uint public oneEther = 1 ether;    // 1 ether is equal to 10^18 wei    bool public isOneEther = 1 ether == 1e18;}</code></pre><h2 id="Gas"><a href="#Gas" class="headerlink" title="Gas"></a>Gas</h2><ol><li><p>一次交易需要支付多少eth？</p><p>您支付的 gas spent * gas price 的eth数量，其中：</p><ul><li>gas是一个计算单位</li><li>gas花费是交易中使用的 gas 总量</li><li>gas price是您愿意为每 gas 支付多少 ether </li></ul><p>具有更高 gas 价格的交易有更高的优先级被包含在一个块中，未使用的Gas将被退还</p></li><li><p>Gas限制</p><p>您可以花费的 gas 量有 2 个上限：</p><ul><li>gas limit（您愿意为交易使用的最大 gas 量，由您设置）</li><li>块 gas 限制（一个块中允许的最大 gas 量，由区块链网络设置）</li></ul></li></ol><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Gas {    uint public i = 0;    // Using up all of the gas that you send causes your transaction to fail.    // State changes are undone.    // Gas spent are not refunded.    function forever() public {        // Here we run a loop until all of the gas are spent        // and the transaction fails        while (true) {            i += 1;        }    }}</code></pre><h2 id="If-Else"><a href="#If-Else" class="headerlink" title="If / Else"></a>If / Else</h2><p>Solidity 支持条件语句 if、else if 和 else</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract IfElse {    function foo(uint x) public pure returns (uint) {        if (x &lt; 10) {            return 0;        } else if (x &lt; 20) {            return 1;        } else {            return 2;        }    }    function ternary(uint _x) public pure returns (uint) {        // if (_x &lt; 10) {        //     return 1;        // }        // return 2;        // shorthand way to write if / else statement        return _x &lt; 10 ? 1 : 2;    }}</code></pre><h2 id="For、While循环"><a href="#For、While循环" class="headerlink" title="For、While循环"></a>For、While循环</h2><p>Solidity 支持 for、while 和 do while 循环，不要编写无界循环，因为这可能会达到 gas 限制，导致您的交易失败</p><p>由于上述原因，很少使用 while 和 do while 循环</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Loop {    function loop() public {        // for loop        for (uint i = 0; i &lt; 10; i++) {            if (i == 3) {                // Skip to next iteration with continue                continue;            }            if (i == 5) {                // Exit loop with break                break;            }        }        // while loop        uint j;        while (j &lt; 10) {            j++;        }    }}</code></pre><h2 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a>Mapping</h2><p>Mapping是使用语法映射（keyType =&gt; valueType）创建的</p><p>keyType可以是任何内置值类型、字节、字符串或合约地址</p><p>valueType可以是任何类型，包括另一个Mapping或数组</p><p>Mappings不可迭代</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Mapping {    // Mapping from address to uint    mapping(address =&gt; uint) public myMap;    function get(address _addr) public view returns (uint) {        // Mapping always returns a value.        // If the value was never set, it will return the default value.        return myMap[_addr];    }    function set(address _addr, uint _i) public {        // Update the value at this address        myMap[_addr] = _i;    }    function remove(address _addr) public {        // Reset the value to the default value.        delete myMap[_addr];    }}contract NestedMapping {    // Nested mapping (mapping from address to another mapping)    mapping(address =&gt; mapping(uint =&gt; bool)) public nested;    function get(address _addr1, uint _i) public view returns (bool) {        // You can get values from a nested mapping        // even when it is not initialized        return nested[_addr1][_i];    }    function set(        address _addr1,        uint _i,        bool _boo    ) public {        nested[_addr1][_i] = _boo;    }    function remove(address _addr1, uint _i) public {        delete nested[_addr1][_i];    }}</code></pre><h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><p>数组可以具有编译时固定大小或动态大小</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Array {    // Several ways to initialize an array    uint[] public arr;    uint[] public arr2 = [1, 2, 3];    // Fixed sized array, all elements initialize to 0    uint[10] public myFixedSizeArr;    function get(uint i) public view returns (uint) {        return arr[i];    }    // Solidity can return the entire array.    // But this function should be avoided for    // arrays that can grow indefinitely in length.    function getArr() public view returns (uint[] memory) {        return arr;    }    function push(uint i) public {        // Append to array        // This will increase the array length by 1.        arr.push(i);    }    function pop() public {        // Remove last element from array        // This will decrease the array length by 1        arr.pop();    }    function getLength() public view returns (uint) {        return arr.length;    }    function remove(uint index) public {        // Delete does not change the array length.        // It resets the value at index to it's default value,        // in this case 0        delete arr[index];    }    function examples() external {        // create array in memory, only fixed size can be created        uint[] memory a = new uint[](5);    }}</code></pre><h2 id="Enum"><a href="#Enum" class="headerlink" title="Enum"></a>Enum</h2><p>Solidity 支持枚举，它们对于跟踪状态很有用。枚举可以在合约之外声明</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Enum {    // Enum representing shipping status    enum Status {        Pending,        Shipped,        Accepted,        Rejected,        Canceled    }    // Default value is the first element listed in    // definition of the type, in this case "Pending"    Status public status;    // Returns uint    // Pending  - 0    // Shipped  - 1    // Accepted - 2    // Rejected - 3    // Canceled - 4    function get() public view returns (Status) {        return status;    }    // Update status by passing uint into input    function set(Status _status) public {        status = _status;    }    // You can update to a specific enum like this    function cancel() public {        status = Status.Canceled;    }    // delete resets the enum to its first value, 0    function reset() public {        delete status;    }}</code></pre><h2 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h2><p>您可以通过创建结构体来定义自己的类型</p><p>它们对于将相关数据组合在一起很有用</p><p>结构体可以在合约之外声明并在另一个合约中导入</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Todos {    struct Todo {        string text;        bool completed;    }    // An array of 'Todo' structs    Todo[] public todos;    function create(string memory _text) public {        // 3 ways to initialize a struct        // - calling it like a function        todos.push(Todo(_text, false));        // key value mapping        todos.push(Todo({text: _text, completed: false}));        // initialize an empty struct and then update it        Todo memory todo;        todo.text = _text;        // todo.completed initialized to false        todos.push(todo);    }    // Solidity automatically created a getter for 'todos' so    // you don't actually need this function.    function get(uint _index) public view returns (string memory text, bool completed) {        Todo storage todo = todos[_index];        return (todo.text, todo.completed);    }    // update text    function update(uint _index, string memory _text) public {        Todo storage todo = todos[_index];        todo.text = _text;    }    // update completed    function toggleCompleted(uint _index) public {        Todo storage todo = todos[_index];        todo.completed = !todo.completed;    }}</code></pre><h2 id="数据存储位置"><a href="#数据存储位置" class="headerlink" title="数据存储位置"></a>数据存储位置</h2><p>变量被声明为 storage、memory 或 calldata 以明确指定数据的位置：</p><ul><li>storage：变量是状态变量（存储在区块链上）</li><li>memory：变量在内存中，在调用函数时存在，在声明要存储在内存中（临时）的变量（函数参数以及函数内部的逻辑）时应使用memory</li><li>calldata：一个不可修改、非持久性的区域，用于存储函数参数。在声明外部函数的动态参数时必须使用 calldata，calldata 是存储函数参数的不可修改、非持久性区域</li></ul><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract DataLocations {    uint[] public arr;    mapping(uint =&gt; address) map;    struct MyStruct {        uint foo;    }    mapping(uint =&gt; MyStruct) myStructs;    function f() public {        // call _f with state variables        _f(arr, map, myStructs[1]);        // get a struct from a mapping        MyStruct storage myStruct = myStructs[1];        // create a struct in memory        MyStruct memory myMemStruct = MyStruct(0);    }    function _f(        uint[] storage _arr,        mapping(uint =&gt; address) storage _map,        MyStruct storage _myStruct    ) internal {        // do something with storage variables    }    // You can return memory variables    function g(uint[] memory _arr) public returns (uint[] memory) {        // do something with memory array    }    function h(uint[] calldata _arr) external {        // do something with calldata array    }}</code></pre><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>有几种方法可以从函数中输出</p><p>公共函数不能接受某些数据类型作为输入或输出(例如Mapping)</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Function {    // Functions can return multiple values.    function returnMany()        public        pure        returns (            uint,            bool,            uint        )    {        return (1, true, 2);    }    // Return values can be named.    function named()        public        pure        returns (            uint x,            bool b,            uint y        )    {        return (1, true, 2);    }    // Return values can be assigned to their name.    // In this case the return statement can be omitted.    function assigned()        public        pure        returns (            uint x,            bool b,            uint y        )    {        x = 1;        b = true;        y = 2;    }    // Use destructuring assignment when calling another    // function that returns multiple values.    function destructuringAssignments()        public        pure        returns (            uint,            bool,            uint,            uint,            uint        )    {        (uint i, bool b, uint j) = returnMany();        // Values can be left out.        (uint x, , uint y) = (4, 5, 6);        return (i, b, j, x, y);    }    // Cannot use map for either input or output    // Can use array for input    function arrayInput(uint[] memory _arr) public {}    // Can use array for output    uint[] public arr;    function arrayOutput() public view returns (uint[] memory) {        return arr;    }}</code></pre><h2 id="View、Pure修饰函数"><a href="#View、Pure修饰函数" class="headerlink" title="View、Pure修饰函数"></a>View、Pure修饰函数</h2><p>Getter功能的函数可以声明为 view 或 pure</p><p>View 函数声明不会更改状态</p><p>Pure 函数声明不会更改或读取任何状态变量</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract ViewAndPure {    uint public x = 1;    // Promise not to modify the state.    function addToX(uint y) public view returns (uint) {        return x + y;    }    // Promise not to modify or read from the state.    function add(uint i, uint j) public pure returns (uint) {        return i + j;    }}</code></pre><h2 id="Error异常"><a href="#Error异常" class="headerlink" title="Error异常"></a>Error异常</h2><p>Error异常将撤消事务期间对状态所做的所有更改</p><p>您可以通过调用 require、revert 或 assert 来抛出异常</p><ul><li><p>require用于在执行之前验证输入和条件</p></li><li><p>revert 类似于 require，有关详细信息，请参阅下面的代码</p></li><li><p>assert 用于检查不应为假的代码。断言失败可能意味着存在Bug</p></li></ul><p>使用自定义错误来节省Gas</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Error {    function testRequire(uint _i) public pure {        // Require should be used to validate conditions such as:        // - inputs        // - conditions before execution        // - return values from calls to other functions        require(_i &gt; 10, "Input must be greater than 10");    }    function testRevert(uint _i) public pure {        // Revert is useful when the condition to check is complex.        // This code does the exact same thing as the example above        if (_i &lt;= 10) {            revert("Input must be greater than 10");        }    }    uint public num;    function testAssert() public view {        // Assert should only be used to test for internal errors,        // and to check invariants.        // Here we assert that num is always equal to 0        // since it is impossible to update the value of num        assert(num == 0);    }    // custom error    error InsufficientBalance(uint balance, uint withdrawAmount);    function testCustomError(uint _withdrawAmount) public view {        uint bal = address(this).balance;        if (bal &lt; _withdrawAmount) {            revert InsufficientBalance({balance: bal, withdrawAmount: _withdrawAmount});        }    }}</code></pre><h2 id="Modifier函数"><a href="#Modifier函数" class="headerlink" title="Modifier函数"></a>Modifier函数</h2><p>Modifier是可以在函数调用之前和/或之后运行的代码</p><p>Modifier可用于：</p><ul><li>限制访问</li><li>验证输入</li><li>防止重入黑客攻击</li></ul><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract FunctionModifier {    // We will use these variables to demonstrate how to use    // modifiers.    address public owner;    uint public x = 10;    bool public locked;    constructor() {        // Set the transaction sender as the owner of the contract.        owner = msg.sender;    }    // Modifier to check that the caller is the owner of    // the contract.    modifier onlyOwner() {        require(msg.sender == owner, "Not owner");        // Underscore is a special character only used inside        // a function modifier and it tells Solidity to        // execute the rest of the code.        _;    }    // Modifiers can take inputs. This modifier checks that the    // address passed in is not the zero address.    modifier validAddress(address _addr) {        require(_addr != address(0), "Not valid address");        _;    }    function changeOwner(address _newOwner) public onlyOwner validAddress(_newOwner) {        owner = _newOwner;    }    // Modifiers can be called before and / or after a function.    // This modifier prevents a function from being called while    // it is still executing.    modifier noReentrancy() {        require(!locked, "No reentrancy");        locked = true;        _;        locked = false;    }    function decrement(uint i) public noReentrancy {        x -= i;        if (i &gt; 1) {            decrement(i - 1);        }    }}</code></pre><h2 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h2><p>事件允许记录日志到以太坊区块链</p><p>事件的一些用例是：</p><ul><li>监听事件和更新用户界面</li><li>一种廉价的存储形式</li></ul><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Event {    // Event declaration    // Up to 3 parameters can be indexed.    // Indexed parameters helps you filter the logs by the indexed parameter    event Log(address indexed sender, string message);    event AnotherLog();    function test() public {        emit Log(msg.sender, "Hello World!");        emit Log(msg.sender, "Hello EVM!");        emit AnotherLog();    }}</code></pre><h2 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h2><p>构造函数是在创建合约时执行的可选函数</p><p>以下是如何将参数传递给构造函数的示例</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;// Base contract Xcontract X {    string public name;    constructor(string memory _name) {        name = _name;    }}// Base contract Ycontract Y {    string public text;    constructor(string memory _text) {        text = _text;    }}// There are 2 ways to initialize parent contract with parameters.// Pass the parameters here in the inheritance list.contract B is X("Input to X"), Y("Input to Y") {}contract C is X, Y {    // Pass the parameters here in the constructor,    // similar to function modifiers.    constructor(string memory _name, string memory _text) X(_name) Y(_text) {}}// Parent constructors are always called in the order of inheritance// regardless of the order of parent contracts listed in the// constructor of the child contract.// Order of constructors called:// 1. X// 2. Y// 3. Dcontract D is X, Y {    constructor() X("X was called") Y("Y was called") {}}// Order of constructors called:// 1. X// 2. Y// 3. Econtract E is X, Y {    constructor() Y("Y was called") X("X was called") {}}</code></pre><h2 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h2><p>Solidity 支持多重继承</p><p>合约可以使用is关键字继承其他合约</p><p>要被子合约覆盖的函数必须声明为virtual</p><p>要覆盖父函数的函数必须使用关键字override</p><p>继承的顺序很重要</p><p>你必须按照从“最基础”到“最衍生”（“most base-like” to “most derived”）的顺序列出父合约</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;/* Graph of inheritance    A   / \  B   C / \ /F  D,E*/contract A {    function foo() public pure virtual returns (string memory) {        return "A";    }}// Contracts inherit other contracts by using the keyword 'is'.contract B is A {    // Override A.foo()    function foo() public pure virtual override returns (string memory) {        return "B";    }}contract C is A {    // Override A.foo()    function foo() public pure virtual override returns (string memory) {        return "C";    }}// Contracts can inherit from multiple parent contracts.// When a function is called that is defined multiple times in// different contracts, parent contracts are searched from// right to left, and in depth-first manner.contract D is B, C {    // D.foo() returns "C"    // since C is the right most parent contract with function foo()    function foo() public pure override(B, C) returns (string memory) {        return super.foo();    }}contract E is C, B {    // E.foo() returns "B"    // since B is the right most parent contract with function foo()    function foo() public pure override(C, B) returns (string memory) {        return super.foo();    }}// Inheritance must be ordered from “most base-like” to “most derived”.// Swapping the order of A and B will throw a compilation error.contract F is A, B {    function foo() public pure override(A, B) returns (string memory) {        return super.foo();    }}</code></pre><h2 id="覆盖继承的合约状态变量"><a href="#覆盖继承的合约状态变量" class="headerlink" title="覆盖继承的合约状态变量"></a>覆盖继承的合约状态变量</h2><p>与函数不同，状态变量不能通过在子合约中重新声明来覆盖</p><p>让我们学习如何正确覆盖继承的状态变量</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract A {    string public name = "Contract A";    function getName() public view returns (string memory) {        return name;    }}// Shadowing is disallowed in Solidity 0.6// This will not compile// contract B is A {//     string public name = "Contract B";// }contract C is A {    // This is the correct way to override inherited state variables.    constructor() {        name = "Contract C";    }    // C.getName returns "Contract C"}</code></pre><h2 id="调用父合约"><a href="#调用父合约" class="headerlink" title="调用父合约"></a>调用父合约</h2><p>可以直接调用父合约，也可以使用关键字 super 调用</p><p>使用关键字 super 会调用所有的直接父合约</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;/* Inheritance tree   A /  \B   C \ /  D*/contract A {    // This is called an event. You can emit events from your function    // and they are logged into the transaction log.    // In our case, this will be useful for tracing function calls.    event Log(string message);    function foo() public virtual {        emit Log("A.foo called");    }    function bar() public virtual {        emit Log("A.bar called");    }}contract B is A {    function foo() public virtual override {        emit Log("B.foo called");        A.foo();    }    function bar() public virtual override {        emit Log("B.bar called");        super.bar();    }}contract C is A {    function foo() public virtual override {        emit Log("C.foo called");        A.foo();    }    function bar() public virtual override {        emit Log("C.bar called");        super.bar();    }}contract D is B, C {    // Try:    // - Call D.foo and check the transaction logs.    //   Although D inherits A, B and C, it only called C and then A.    // - Call D.bar and check the transaction logs    //   D called C, then B, and finally A.    //   Although super was called twice (by B and C) it only called A once.    function foo() public override(B, C) {        super.foo();    }    function bar() public override(B, C) {        super.bar();    }}</code></pre><h2 id="变量可见约束"><a href="#变量可见约束" class="headerlink" title="变量可见约束"></a>变量可见约束</h2><p>函数和状态变量必须声明它们是否可以被其他合约访问</p><p>函数可以声明为：</p><ul><li><p>public：任何合约和账户都可以调用</p></li><li><p>private：只在定义函数的合约内部</p></li><li><p>internal：仅继承内部函数的内部合约</p></li><li><p>external：只有其他合约和账户可以调用</p></li></ul><p>状态变量可以声明为公共的、私有的或内部的，但不能声明为外部的</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Base {    // Private function can only be called    // - inside this contract    // Contracts that inherit this contract cannot call this function.    function privateFunc() private pure returns (string memory) {        return "private function called";    }    function testPrivateFunc() public pure returns (string memory) {        return privateFunc();    }    // Internal function can be called    // - inside this contract    // - inside contracts that inherit this contract    function internalFunc() internal pure returns (string memory) {        return "internal function called";    }    function testInternalFunc() public pure virtual returns (string memory) {        return internalFunc();    }    // Public functions can be called    // - inside this contract    // - inside contracts that inherit this contract    // - by other contracts and accounts    function publicFunc() public pure returns (string memory) {        return "public function called";    }    // External functions can only be called    // - by other contracts and accounts    function externalFunc() external pure returns (string memory) {        return "external function called";    }    // This function will not compile since we're trying to call    // an external function here.    // function testExternalFunc() public pure returns (string memory) {    //     return externalFunc();    // }    // State variables    string private privateVar = "my private variable";    string internal internalVar = "my internal variable";    string public publicVar = "my public variable";    // State variables cannot be external so this code won't compile.    // string external externalVar = "my external variable";}contract Child is Base {    // Inherited contracts do not have access to private functions    // and state variables.    // function testPrivateFunc() public pure returns (string memory) {    //     return privateFunc();    // }    // Internal function call be called inside child contracts.    function testInternalFunc() public pure override returns (string memory) {        return internalFunc();    }}</code></pre><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>您可以通过声明接口与其他合约交互</p><p>接口：</p><ul><li>不能实现任何函数</li><li>可以从其他接口继承</li><li>所有声明的函数必须是外部的</li><li>不能声明构造函数</li><li>不能声明状态变量</li></ul><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Counter {    uint public count;    function increment() external {        count += 1;    }}interface ICounter {    function count() external view returns (uint);    function increment() external;}contract MyContract {    function incrementCounter(address _counter) external {        ICounter(_counter).increment();    }    function getCount(address _counter) external view returns (uint) {        return ICounter(_counter).count();    }}// Uniswap exampleinterface UniswapV2Factory {    function getPair(address tokenA, address tokenB)        external        view        returns (address pair);}interface UniswapV2Pair {    function getReserves()        external        view        returns (            uint112 reserve0,            uint112 reserve1,            uint32 blockTimestampLast        );}contract UniswapExample {    address private factory = 0x5C69bEe701ef814a2B6a3EDD4B1652CB9cc5aA6f;    address private dai = 0x6B175474E89094C44Da98b954EedeAC495271d0F;    address private weth = 0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2;    function getTokenReserves() external view returns (uint, uint) {        address pair = UniswapV2Factory(factory).getPair(dai, weth);        (uint reserve0, uint reserve1, ) = UniswapV2Pair(pair).getReserves();        return (reserve0, reserve1);    }}</code></pre><h2 id="Payable关键字"><a href="#Payable关键字" class="headerlink" title="Payable关键字"></a>Payable关键字</h2><p>声明为Payable的函数和地址可以在合约中接收以太币</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Payable {    // Payable address can receive Ether    address payable public owner;    // Payable constructor can receive Ether    constructor() payable {        owner = payable(msg.sender);    }    // Function to deposit Ether into this contract.    // Call this function along with some Ether.    // The balance of this contract will be automatically updated.    function deposit() public payable {}    // Call this function along with some Ether.    // The function will throw an error since this function is not payable.    function notPayable() public {}    // Function to withdraw all Ether from this contract.    function withdraw() public {        // get the amount of Ether stored in this contract        uint amount = address(this).balance;        // send all Ether to owner        // Owner can receive Ether since the address of owner is payable        (bool success, ) = owner.call{value: amount}("");        require(success, "Failed to send Ether");    }    // Function to transfer Ether from this contract to address from input    function transfer(address payable _to, uint _amount) public {        // Note that "to" is declared as payable        (bool success, ) = _to.call{value: _amount}("");        require(success, "Failed to send Ether");    }}</code></pre><h2 id="发送Ether-transfer-send-call"><a href="#发送Ether-transfer-send-call" class="headerlink" title="发送Ether(transfer, send, call)"></a>发送Ether(transfer, send, call)</h2><ol><li><p>如何发送Ether？</p><p>你可以使用以下方法发送Ether给其他合约：</p><ul><li>transfer (2300 gas, 抛出异常)</li><li>send (2300 gas, 返回bool)</li><li>call (转发所有gas或设置的gas, 返回bool)</li></ul></li><li><p>如何接收Ether？</p><p>接收Ether的合约必须至少具有以下函数之一：</p><ul><li>receive() external payable</li><li>fallback() external payable</li></ul></li><li><p>你应该使用哪个函数？</p><p>在 2019 年 12 月之后，建议使用与可重入保护结合的调用方法</p><p>通过以下方式防止重入：</p><ul><li>在调用其他合约之前进行所有状态更改</li><li>使用可重入保护修饰符</li></ul></li></ol><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract ReceiveEther {    /*    Which function is called, fallback() or receive()?           send Ether               |         msg.data is empty?              / \            yes  no            /     \receive() exists?  fallback()         /   \        yes   no        /      \    receive()   fallback()    */    // Function to receive Ether. msg.data must be empty    receive() external payable {}    // Fallback function is called when msg.data is not empty    fallback() external payable {}    function getBalance() public view returns (uint) {        return address(this).balance;    }}contract SendEther {    function sendViaTransfer(address payable _to) public payable {        // This function is no longer recommended for sending Ether.        _to.transfer(msg.value);    }    function sendViaSend(address payable _to) public payable {        // Send returns a boolean value indicating success or failure.        // This function is not recommended for sending Ether.        bool sent = _to.send(msg.value);        require(sent, "Failed to send Ether");    }    function sendViaCall(address payable _to) public payable {        // Call returns a boolean value indicating success or failure.        // This is the current recommended method to use.        (bool sent, bytes memory data) = _to.call{value: msg.value}("");        require(sent, "Failed to send Ether");    }}</code></pre><h2 id="Fallback"><a href="#Fallback" class="headerlink" title="Fallback"></a>Fallback</h2><p>fallback是一个不接受任何参数且不返回任何内容的函数。</p><p>它在以下情况下执行： </p><ul><li>调用不存在的函数</li><li>将 Ether 直接发送到合约但 receive() 不存在或 msg.data 不为空</li></ul><p>fallback 在通过 transfer 或 send 调用时有 2300 gas 限制</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Fallback {    event Log(uint gas);    // Fallback function must be declared as external.    fallback() external payable {        // send / transfer (forwards 2300 gas to this fallback function)        // call (forwards all of the gas)        emit Log(gasleft());    }    // Helper function to check the balance of this contract    function getBalance() public view returns (uint) {        return address(this).balance;    }}contract SendToFallback {    function transferToFallback(address payable _to) public payable {        _to.transfer(msg.value);    }    function callFallback(address payable _to) public payable {        (bool sent, ) = _to.call{value: msg.value}("");        require(sent, "Failed to send Ether");    }}</code></pre><h2 id="Call"><a href="#Call" class="headerlink" title="Call"></a>Call</h2><p>call 是与其他合约交互的低级函数</p><p>这是您通过调用 fallback 函数发送 Ether 时推荐使用的方法</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Receiver {    event Received(address caller, uint amount, string message);    fallback() external payable {        emit Received(msg.sender, msg.value, "Fallback was called");    }    function foo(string memory _message, uint _x) public payable returns (uint) {        emit Received(msg.sender, msg.value, _message);        return _x + 1;    }}contract Caller {    event Response(bool success, bytes data);    // Let's imagine that contract B does not have the source code for    // contract A, but we do know the address of A and the function to call.    function testCallFoo(address payable _addr) public payable {        // You can send ether and specify a custom gas amount        (bool success, bytes memory data) = _addr.call{value: msg.value, gas: 5000}(            abi.encodeWithSignature("foo(string,uint256)", "call foo", 123)        );        emit Response(success, data);    }    // Calling a function that does not exist triggers the fallback function.    function testCallDoesNotExist(address _addr) public {        (bool success, bytes memory data) = _addr.call(            abi.encodeWithSignature("doesNotExist()")        );        emit Response(success, data);    }}</code></pre><h2 id="Delegatecall"><a href="#Delegatecall" class="headerlink" title="Delegatecall"></a>Delegatecall</h2><p>delegatecall 是一个类似于call 的底层函数</p><p>当合约A 对合约B 执行delegatecall 时，B 的代码与合约A 的存储、msg.sender 和msg.value 一起执行。</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;// NOTE: Deploy this contract firstcontract B {    // NOTE: storage layout must be the same as contract A    uint public num;    address public sender;    uint public value;    function setVars(uint _num) public payable {        num = _num;        sender = msg.sender;        value = msg.value;    }}contract A {    uint public num;    address public sender;    uint public value;    function setVars(address _contract, uint _num) public payable {        // A's storage is set, B is not modified.        (bool success, bytes memory data) = _contract.delegatecall(            abi.encodeWithSignature("setVars(uint256)", _num)        );    }}</code></pre><h2 id="Function-Selector"><a href="#Function-Selector" class="headerlink" title="Function Selector"></a>Function Selector</h2><p>调用函数时，calldata的前4个字节指定调用哪个函数。这4个字节称为函数选择器。</p><p>以下面这段代码为例。它使用 call 在地址 addr 上执行合约的transfer</p><pre><code class="solidity">addr.call(abi.encodeWithSignature("transfer(address,uint256)", 0xSomeAddress, 123))</code></pre><p>从 abi.encodeWithSignature(….) 返回的前 4 个字节是函数选择器</p><p>如果您在代码中预先计算并内联函数选择器，也许可以节省少量的gas？</p><p>以下是函数选择器的计算方式</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract FunctionSelector {    /*    "transfer(address,uint256)"    0xa9059cbb    "transferFrom(address,address,uint256)"    0x23b872dd    */    function getSelector(string calldata _func) external pure returns (bytes4) {        return bytes4(keccak256(bytes(_func)));    }}</code></pre><h2 id="调用其他合约"><a href="#调用其他合约" class="headerlink" title="调用其他合约"></a>调用其他合约</h2><p>合约可以通过两种方式调用其他合约</p><p>最简单的方法是直接调用它，比如 A.foo(x, y, z)</p><p>调用其他合约的另一种方法是使用低级调用</p><p>这种方法不是推荐</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Callee {    uint public x;    uint public value;    function setX(uint _x) public returns (uint) {        x = _x;        return x;    }    function setXandSendEther(uint _x) public payable returns (uint, uint) {        x = _x;        value = msg.value;        return (x, value);    }}contract Caller {    function setX(Callee _callee, uint _x) public {        uint x = _callee.setX(_x);    }    function setXFromAddress(address _addr, uint _x) public {        Callee callee = Callee(_addr);        callee.setX(_x);    }    function setXandSendEther(Callee _callee, uint _x) public payable {        (uint x, uint value) = _callee.setXandSendEther{value: msg.value}(_x);    }}</code></pre><h2 id="合约中常见其他合约"><a href="#合约中常见其他合约" class="headerlink" title="合约中常见其他合约"></a>合约中常见其他合约</h2><p>其他合约可以使用 new 关键字创建合约</p><p>从 0.8.0 开始，new 关键字通过指定 salt 选项来支持 create2 功能</p><p>创建合约时，合约地址是由 创建者地址 以及 全局的已创建合约的计数器 计算得到，但是如果创建时指定了 salt 选项，则合约地址的生成机制变得不一样。是由创建者地址、给定的 salt 值、目标合约的创建字节码以及合约的构造函数的参数 计算得到，这种 salt 方式创建合约的好处是，你可以根据 salt 和合约参数推断出合约的地址，一般可以将 salt 设置为 <code>keccak256(abi.encodePacked(arg0, arg1))</code> ，这样的话，合约的参数决定了 salt，那么合约的参数就直接决定了合约的地址。</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract Car {    address public owner;    string public model;    address public carAddr;    constructor(address _owner, string memory _model) payable {        owner = _owner;        model = _model;        carAddr = address(this);    }}contract CarFactory {    Car[] public cars;    function create(address _owner, string memory _model) public {        Car car = new Car(_owner, _model);        cars.push(car);    }    function createAndSendEther(address _owner, string memory _model) public payable {        Car car = (new Car){value: msg.value}(_owner, _model);        cars.push(car);    }    function create2(        address _owner,        string memory _model,        bytes32 _salt    ) public {        Car car = (new Car){salt: _salt}(_owner, _model);        cars.push(car);    }    function create2AndSendEther(        address _owner,        string memory _model,        bytes32 _salt    ) public payable {        Car car = (new Car){value: msg.value, salt: _salt}(_owner, _model);        cars.push(car);    }    function getCar(uint _index)        public        view        returns (            address owner,            string memory model,            address carAddr,            uint balance        )    {        Car car = cars[_index];        return (car.owner(), car.model(), car.carAddr(), address(car).balance);    }}</code></pre><h2 id="Try-Catch"><a href="#Try-Catch" class="headerlink" title="Try Catch"></a>Try Catch</h2><p>try / catch 只能从外部函数调用和合约创建中捕获错误</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;// External contract used for try / catch examplescontract Foo {    address public owner;    constructor(address _owner) {        require(_owner != address(0), "invalid address");        assert(_owner != 0x0000000000000000000000000000000000000001);        owner = _owner;    }    function myFunc(uint x) public pure returns (string memory) {        require(x != 0, "require failed");        return "my func was called";    }}contract Bar {    event Log(string message);    event LogBytes(bytes data);    Foo public foo;    constructor() {        // This Foo contract is used for example of try catch with external call        foo = new Foo(msg.sender);    }    // Example of try / catch with external call    // tryCatchExternalCall(0) =&gt; Log("external call failed")    // tryCatchExternalCall(1) =&gt; Log("my func was called")    function tryCatchExternalCall(uint _i) public {        try foo.myFunc(_i) returns (string memory result) {            emit Log(result);        } catch {            emit Log("external call failed");        }    }    // Example of try / catch with contract creation    // tryCatchNewContract(0x0000000000000000000000000000000000000000) =&gt; Log("invalid address")    // tryCatchNewContract(0x0000000000000000000000000000000000000001) =&gt; LogBytes("")    // tryCatchNewContract(0x0000000000000000000000000000000000000002) =&gt; Log("Foo created")    function tryCatchNewContract(address _owner) public {        try new Foo(_owner) returns (Foo foo) {            // you can use variable foo here            emit Log("Foo created");        } catch Error(string memory reason) {            // catch failing revert() and require()            emit Log(reason);        } catch (bytes memory reason) {            // catch failing assert()            emit LogBytes(reason);        }    }}</code></pre><h2 id="导入文件"><a href="#导入文件" class="headerlink" title="导入文件"></a>导入文件</h2><p>您可以在 Solidity 中导入本地和外部文件</p><ol><li><p>本地文件</p><p>这是我们的文件夹结构：</p><pre><code>├── Import.sol└── Foo.sol</code></pre><p>Foo.sol</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;struct Point {    uint x;    uint y;}error Unauthorized(address caller);function add(uint x, uint y) pure returns (uint) {    return x + y;}contract Foo {    string public name = "Foo";}</code></pre><p>Import.sol</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;// import Foo.sol from current directoryimport "./Foo.sol";// import {symbol1 as alias, symbol2} from "filename";import {Unauthorized, add as func, Point} from "./Foo.sol";contract Import {    // Initialize Foo.sol    Foo public foo = new Foo();    // Test Foo.sol by getting it's name.    function getFooName() public view returns (string memory) {        return foo.name();    }}</code></pre></li><li><p>外部文件</p><p>您也可以通过简单地复制 url 从 GitHub 导入</p><pre><code class="solidity">// https://github.com/owner/repo/blob/branch/path/to/Contract.solimport "https://github.com/owner/repo/blob/branch/path/to/Contract.sol";// Example import ECDSA.sol from openzeppelin-contract repo, release-v4.5 branch// https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.5/contracts/utils/cryptography/ECDSA.solimport "https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.5/contracts/utils/cryptography/ECDSA.sol";</code></pre></li></ol><h2 id="Library"><a href="#Library" class="headerlink" title="Library"></a>Library</h2><p>库类似于合约，但不能声明任何状态变量，也不能发送以太币</p><p>如果所有库函数都是内部的，则库被嵌入到合约中</p><p>否则必须在合约之前部署并链接库部署</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;library SafeMath {    function add(uint x, uint y) internal pure returns (uint) {        uint z = x + y;        require(z &gt;= x, "uint overflow");        return z;    }}library Math {    function sqrt(uint y) internal pure returns (uint z) {        if (y &gt; 3) {            z = y;            uint x = y / 2 + 1;            while (x &lt; z) {                z = x;                x = (y / x + x) / 2;            }        } else if (y != 0) {            z = 1;        }        // else z = 0 (default value)    }}contract TestSafeMath {    using SafeMath for uint;    uint public MAX_UINT = 2**256 - 1;    function testAdd(uint x, uint y) public pure returns (uint) {        return x.add(y);    }    function testSquareRoot(uint x) public pure returns (uint) {        return Math.sqrt(x);    }}// Array function to delete element at index and re-organize the array// so that their are no gaps between the elements.library Array {    function remove(uint[] storage arr, uint index) public {        // Move the last element into the place to delete        require(arr.length &gt; 0, "Can't remove from empty array");        arr[index] = arr[arr.length - 1];        arr.pop();    }}contract TestArray {    using Array for uint[];    uint[] public arr;    function testArrayRemove() public {        for (uint i = 0; i &lt; 3; i++) {            arr.push(i);        }        arr.remove(1);        assert(arr.length == 2);        assert(arr[0] == 0);        assert(arr[1] == 2);    }}</code></pre><h2 id="ABI解码"><a href="#ABI解码" class="headerlink" title="ABI解码"></a>ABI解码</h2><p>abi.encode 将数据编码为字节</p><p>abi.decode 将字节解码回数据</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract AbiDecode {    struct MyStruct {        string name;        uint[2] nums;    }    function encode(        uint x,        address addr,        uint[] calldata arr,        MyStruct calldata myStruct    ) external pure returns (bytes memory) {        return abi.encode(x, addr, arr, myStruct);    }    function decode(bytes calldata data)        external        pure        returns (            uint x,            address addr,            uint[] memory arr,            MyStruct memory myStruct        )    {        // (uint x, address addr, uint[] memory arr, MyStruct myStruct) = ...        (x, addr, arr, myStruct) = abi.decode(data, (uint, address, uint[], MyStruct));    }}</code></pre><h2 id="Keccak256"><a href="#Keccak256" class="headerlink" title="Keccak256"></a>Keccak256</h2><p>keccak256 计算输入的 Keccak-256 散列</p><p>一些用例包括：</p><ul><li>从输入创建确定性唯一 ID</li><li>Commit-Reveal 方案</li><li>简化的加密签名（通过签名hash而不是更大的输入）</li></ul><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;contract HashFunction {    function hash(        string memory _text,        uint _num,        address _addr    ) public pure returns (bytes32) {        return keccak256(abi.encodePacked(_text, _num, _addr));    }    // Example of hash collision    // Hash collision can occur when you pass more than one dynamic data type    // to abi.encodePacked. In such case, you should use abi.encode instead.    function collision(string memory _text, string memory _anotherText)        public        pure        returns (bytes32)    {        // encodePacked(AAA, BBB) -&gt; AAABBB        // encodePacked(AA, ABBB) -&gt; AAABBB        return keccak256(abi.encodePacked(_text, _anotherText));    }}contract GuessTheMagicWord {    bytes32 public answer =        0x60298f78cc0b47170ba79c10aa3851d7648bd96f2f8e46a19dbc777c36fb0c00;    // Magic word is "Solidity"    function guess(string memory _word) public view returns (bool) {        return keccak256(abi.encodePacked(_word)) == answer;    }}</code></pre><h2 id="验证签名"><a href="#验证签名" class="headerlink" title="验证签名"></a>验证签名</h2><p>消息可以在链下签名，然后使用智能合约在链上进行验证</p><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;/* Signature VerificationHow to Sign and Verify# Signing1. Create message to sign2. Hash the message3. Sign the hash (off chain, keep your private key secret)# Verify1. Recreate hash from the original message2. Recover signer from signature and hash3. Compare recovered signer to claimed signer*/contract VerifySignature {    /* 1. Unlock MetaMask account    ethereum.enable()    */    /* 2. Get message hash to sign    getMessageHash(        0x14723A09ACff6D2A60DcdF7aA4AFf308FDDC160C,        123,        "coffee and donuts",        1    )    hash = "0xcf36ac4f97dc10d91fc2cbb20d718e94a8cbfe0f82eaedc6a4aa38946fb797cd"    */    function getMessageHash(        address _to,        uint _amount,        string memory _message,        uint _nonce    ) public pure returns (bytes32) {        return keccak256(abi.encodePacked(_to, _amount, _message, _nonce));    }    /* 3. Sign message hash    # using browser    account = "copy paste account of signer here"    ethereum.request({ method: "personal_sign", params: [account, hash]}).then(console.log)    # using web3    web3.personal.sign(hash, web3.eth.defaultAccount, console.log)    Signature will be different for different accounts    0x993dab3dd91f5c6dc28e17439be475478f5635c92a56e17e82349d3fb2f166196f466c0b4e0c146f285204f0dcb13e5ae67bc33f4b888ec32dfe0a063e8f3f781b    */    function getEthSignedMessageHash(bytes32 _messageHash)        public        pure        returns (bytes32)    {        /*        Signature is produced by signing a keccak256 hash with the following format:        "\x19Ethereum Signed Message\n" + len(msg) + msg        */        return            keccak256(                abi.encodePacked("\x19Ethereum Signed Message:\n32", _messageHash)            );    }    /* 4. Verify signature    signer = 0xB273216C05A8c0D4F0a4Dd0d7Bae1D2EfFE636dd    to = 0x14723A09ACff6D2A60DcdF7aA4AFf308FDDC160C    amount = 123    message = "coffee and donuts"    nonce = 1    signature =        0x993dab3dd91f5c6dc28e17439be475478f5635c92a56e17e82349d3fb2f166196f466c0b4e0c146f285204f0dcb13e5ae67bc33f4b888ec32dfe0a063e8f3f781b    */    function verify(        address _signer,        address _to,        uint _amount,        string memory _message,        uint _nonce,        bytes memory signature    ) public pure returns (bool) {        bytes32 messageHash = getMessageHash(_to, _amount, _message, _nonce);        bytes32 ethSignedMessageHash = getEthSignedMessageHash(messageHash);        return recoverSigner(ethSignedMessageHash, signature) == _signer;    }    function recoverSigner(bytes32 _ethSignedMessageHash, bytes memory _signature)        public        pure        returns (address)    {        (bytes32 r, bytes32 s, uint8 v) = splitSignature(_signature);        return ecrecover(_ethSignedMessageHash, v, r, s);    }    function splitSignature(bytes memory sig)        public        pure        returns (            bytes32 r,            bytes32 s,            uint8 v        )    {        require(sig.length == 65, "invalid signature length");        assembly {            /*            First 32 bytes stores the length of the signature            add(sig, 32) = pointer of sig + 32            effectively, skips first 32 bytes of signature            mload(p) loads next 32 bytes starting at the memory address p into memory            */            // first 32 bytes, after the length prefix            r := mload(add(sig, 32))            // second 32 bytes            s := mload(add(sig, 64))            // final byte (first byte of the next 32 bytes)            v := byte(0, mload(add(sig, 96)))        }        // implicitly return (r, s, v)    }}</code></pre><h2 id="节省Gas方法"><a href="#节省Gas方法" class="headerlink" title="节省Gas方法"></a>节省Gas方法</h2><p>节省Gas的方法：</p><ul><li>用 calldata 替换memory</li><li>将状态变量加载到memory</li><li>将 for 循环 i++ 替换为 ++i</li><li>缓存数组元素</li><li>short circuit</li></ul><pre><code class="solidity">// SPDX-License-Identifier: MITpragma solidity ^0.8.13;// gas golfcontract GasGolf {    // start - 50908 gas    // use calldata - 49163 gas    // load state variables to memory - 48952 gas    // short circuit - 48634 gas    // loop increments - 48244 gas    // cache array length - 48209 gas    // load array elements to memory - 48047 gas    uint public total;    // start - not gas optimized    // function sumIfEvenAndLessThan99(uint[] memory nums) external {    //     for (uint i = 0; i &lt; nums.length; i += 1) {    //         bool isEven = nums[i] % 2 == 0;    //         bool isLessThan99 = nums[i] &lt; 99;    //         if (isEven &amp;&amp; isLessThan99) {    //             total += nums[i];    //         }    //     }    // }    // gas optimized    // [1, 2, 3, 4, 5, 100]    function sumIfEvenAndLessThan99(uint[] calldata nums) external {        uint _total = total;        uint len = nums.length;        for (uint i = 0; i &lt; len; ++i) {            uint num = nums[i];            if (num % 2 == 0 &amp;&amp; num &lt; 99) {                _total += num;            }        }        total = _total;    }}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IPFS and Friends: A Qualitative Comparison of Next Generation Peer-to-Peer Data Networks</title>
      <link href="/2022/04/28/distributed_storage/IPFS%20and%20Friends:%20A%20Qualitative%20Comparison%20of%20Next%20Generation%20Peer-to-Peer%20Data%20Networks/"/>
      <url>/2022/04/28/distributed_storage/IPFS%20and%20Friends:%20A%20Qualitative%20Comparison%20of%20Next%20Generation%20Peer-to-Peer%20Data%20Networks/</url>
      
        <content type="html"><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在本文中，我们将对下一代数据网络进行技术概述。我们使用选定的数据网络来介绍一般概念和强调新的发展。具体来说，我们提供了IPFS的更深层次的概述，以及Swarm、Hypercore Protocol、SAFE、Storj和Arweave的总体概述。我们确定常见的构建模块，并提供定性比较。从概述中，我们得出了未来关于数据网络的挑战和研究目标。</p><h2 id="I-概述"><a href="#I-概述" class="headerlink" title="I. 概述"></a>I. 概述</h2><p>集中式控制和治理会导致数据孤岛，这可能会影响可访问性、可用性和机密性。例如，数据访问可能会受到审查。与此同时，数据孤岛为数据泄露和数据出售提供了一个有价值的目标，这可能会危及安全和隐私。一般来说，用户会失去自己的控制权，并将其委托给云提供商。</p><p>打破数据竖井和减少信任假设的一个方向是点对点数据网络。这个术语概括了建立在点对点(P2P)网络之上的一系列数据存储方法，包括数据存储、复制、分发和交换等方面。作为典型的P2P网络，对等点可以直接交互，建立覆盖网络，共享资源，并可以做出自治的本地决策。因此，P2P数据网络努力共同管理和共享存储。虽然P2P网络的主要目标和原则在过去二十年中没有改变，但P2P网络随着时间的推移不断发展，提高了可用性和功能。在图1中，我们展示了从第一代到下一代数据网络的发展。</p><p><img src="/images/distributed_storage/image-20220428142211126.png" alt="image-20220428142211126"></p><p>图1 下一代P2P数据网络的先驱技术</p><h3 id="A-第一代数据网络"><a href="#A-第一代数据网络" class="headerlink" title="A. 第一代数据网络"></a>A. 第一代数据网络</h3><p>还有许多不同的旧P2P网络也可以归类为数据网络。1999年随着音频文件共享网络Napster的出现，P2P技术开始流行起来，紧随其后的是Gnutella，它可以共享所有类型的文件。Napster和Gnutella标志着P2P网络的开始，随后出现了许多专注于特定应用领域或新颖网络结构的P2P网络。例如Freenet实现了匿名存储和检索。Chord， CAN和Pastry提供了维护结构化覆盖网络拓扑的协议。特别是BitTorrent受到了用户和研究社区的广泛关注。BitTorrent引入了激励机制来实现帕累托效率，试图提高网络利用率，实现更高水平的鲁棒性。我们认为Napster、Gnutella、Freenet、BitTorrent等网络是第一代P2P数据网络，主要关注文件共享。</p><p>Androutsellis Theotokis和Spinellis提供了P2P内容分发技术的2004年发展概况——提供了对上一代技术的广泛概述。以前的其他工作也提供了对上一代的更仔细的研究，更密切地关注特定的P2P数据网络(例如，FreeNet和Past)或一般的分布式文件系统(例如，Google FS和Hadoop Distributed FS)。</p><p>P2P技术的进步和第一代数据网络的普及，影响了分布式文件系统和内容分发技术的领域。这种趋势也属于一般的数据网络，特别是P2P数据网络。</p><h3 id="B-Transistion阶段"><a href="#B-Transistion阶段" class="headerlink" title="B. Transistion阶段"></a>B. Transistion阶段</h3><p>在P2P文件共享系统中似乎缺失的一个组件是改善文件的长期存储和可用性的方法。随着2008年比特币的引入，P2P思想，特别是联合数据复制得到了新的关注。分布式分类账技术在分布式系统中提供可用性、完整性和复杂的容错能力。特别是，加密货币显示了其在去中心化环境中作为货币激励机制的潜力。这些以及其他的趋势和发展，例如Kademlia和信息中心网络，导致了我们称之为下一代P2P数据网络的发明。</p><h3 id="C-下一代数据网络"><a href="#C-下一代数据网络" class="headerlink" title="C.下一代数据网络"></a>C.下一代数据网络</h3><p>从2014年IPFS的引入开始，我们将下一代数据网络定义为分散共享和存储数据的系统和概念，这是在过去十年中出现的。我们提供下一代P2P数据网络的技术概述。与现有文献相比，我们提供了下一代数据网络，即P2P数据网络的比较概述。我们主要关注独立于区块链的使用的存储和内容共享。<br>在本文中，我们将展示这些新系统是如何构建的，它们如何利用从以前的系统中获得的知识，以及过去十年中新的发展和进步。我们确定这些系统的构建模块、相似性和趋势。虽然有些系统本身是其他应用程序的构建块，例如去中心化应用程序(DApps)，但我们主要关注系统的两个方面:内容分发和分布式存储。此外，我们还提供了激励机制的见解，用于检索或存储文件，或两者兼而有之。由于许多新的数据网络被开发，我们不能提供所有数据网络的全面概述。相反，我们将重点关注几个精选的系统，它们具有复杂或独特的机制、不同的用例以及不同程度的内容和用户隐私。我们的概述侧重于概念和实现细节的抽象，以提取一般的见解。然而，应该指出的是，由于正在进行的开发，系统很容易发生变化。我们的调查论文使用了广泛的来源，包括同行评议的论文、白皮书以及文档、规范和源代码。<br>具体来说，我们关注IPFS、Swarm、Hypercore Protocol、SAFE、Storj和Arweave。特别是IPFS(InterPlanetary File System, IPFS)作为区块链的存储层已经得到了广泛的应用，并成为了一系列研究的对象。此外，我们将这些系统的概述放在前面的系统和研究方向，即BitTorrent、信息中心网络和区块链。通过对比先驱系统，我们概述了数据网络的演变，并能够深入讨论下一代的进展。<br>在此基础上，我们提取了P2P数据网络的构建块和一些独特的方面。虽然所有的系统都允许分布式内容共享和存储，但它们似乎只关注其中的一个方面。也就是说，每个系统的目标都是服务于具有不同需求和关注点的略有不同的目的。这导致了在网络组织、文件查找、分散程度、冗余和隐私方面的不同设计决策。例如，Storj的目标是分布式云存储，而Hypercore协议则专注于分布式大型数据集。同样，IPFS的目标是取代web的客户端-服务器结构，因此需要比BitTorrent更关注数据查找，因为BitTorrent主要是每个文件都位于自己的覆盖网络中。同时，我们在构建数据网络的方法上发现了许多相似之处，例如，使用Kademlia来构建网络或寻找对等点，将文件分割成块，或激励不同的任务来增加功能。<br>其他关于下一代数据网络的研究尤其关注与区块链的交互。Huang等人主要涵盖了IPFS和Swarm, Benisi等人讨论了这些技术，更侧重于区块链方面。Casino等人仔细研究了去中心化存储的不变性及其后果和可能的威胁。然而，由于可伸缩性或延迟问题，一些数据网络明确决定不使用区块链。因此，在我们的调查论文中，我们对数据网络采取了更广泛的视角，着眼于区块链以外的数据网络的设计决策。<br>Naik和Keshavamurthy对最近的P2P网络给出了一个更普遍的观点。他们描述了下一个层次的P2P网络，像BitTorrent和Chord这样的经典网络的演变，并讨论了动荡下的性能方面。值得注意的是，他们对下一级网络的定义与我们的下一代网络的定义不同，因为他们将IPFS定义为“经典的P2P网络”。相反，我们认为，P2P数据网络是随着时间的推移而演变的，融合了新建立的领域的想法，例如，明确的激励机制。</p><h2 id="II-技术介绍"><a href="#II-技术介绍" class="headerlink" title="II. 技术介绍"></a>II. 技术介绍</h2><p>自P2P数据网络首次出现以来，已经过去了20多年。在此期间，这项技术不断发展，并影响了新网络的发展。我们观察到，基本上有三个“时代”的P2P数据网络:它开始于1999-2002年的P2P文件共享和网络，如BitTorrent和Kademlia，我们认为这是第一代。这个时代之后是一个“过渡阶段”，以信息为中心的网络和加密货币等新想法出现了。大约自2014年IPFS的发明以来，我们看到了新一代P2P数据网络的发展。为了更好地理解和欣赏这些影响，我们介绍了奠定基础的重要“先驱”技术，即BitTorrent、Kademlia、Information-Centric Networking、Self-Certifying Names和区块链。</p><h3 id="A-BitTorrent"><a href="#A-BitTorrent" class="headerlink" title="A. BitTorrent"></a>A. BitTorrent</h3><p>BitTorrent协议[6]是一种P2P文件共享协议。它有一个激励结构来控制下载行为，试图实现资源的公平消耗。BitTorrent的目标是提供一种比使用单一服务器更有效的方式来分发文件。这是通过在每次下载时复制文件这一事实实现的，从而使文件分发具有自伸缩性(self-scalable)。<br>文件以种子形式交换。一般来说，每个种子是一个P2P覆盖网络负责一个文件。为了用BitTorrent协议交换文件，需要创建一个.torrent类型的文件，其中包含文件的元数据和一个跟踪器(tracker)。也可以在一个.torrent文件中定义多个文件。种子文件需要被提供，例如，在网络服务器上，文件可以被共享。跟踪器作为种子的引导节点。具有完整文件的对等点称为种子点。仍然没有命中数据块的节点被称为leechers。leecher请求数据块，并同时作为已经下载的块的下载点。<br>BitTorrent如何处理文件的概念概述见图2。角色和他们的交互如下:一个对等体获得.torrent文件，联系.torrent文件中列出的tracker 𝑇，获得一个对等体列表，连接到对等体，成为一个leecher。在图中，对等体𝑆0作为文件的种子，而对等体𝐿𝑖代表请求不同块的leecher。如.torrent文件所示，该文件被分割为𝑐𝑗块。当leecher成功地获得了所有的块后，它就变成了一颗新的种子。Seed𝑆0和leechers为文件建立了torrent网络。其他文件分布在不同的种子网络与可能不同的对等。</p><p><img src="/images/distributed_storage/image-20220428145010491.png" alt="image-20220428145010491">除了集中呈现的跟踪器，还有无跟踪的种子(trackerless torrents)。在无跟踪torrent中，种子是通过一个分布式哈希表(DHT)找到的。客户端从torrent文件中获取密钥，DHT返回可用的torrent对等点列表。BitTorrent客户端可以使用预先确定的节点或由torrent文件提供的节点来引导DHT。<br>使BitTorrent独一无二(可能是成功的)的特性是明确激励对等点交换数据，这是在文件共享策略中最稀有的部分首先和tit-for-tat实现的。最稀有的部分首先描述了BitTorrent的区块选择。它确保了块重叠的最小化，使文件交换对于节点变动更加健壮。最好选择网络中最不常见的块进行下载。针锋相对描述了带宽资源分配机制。在BitTorrent对等点决定谁他们上传数据基于下载的数据从对等点。这应该防止leecher只下载而不提供任何资源给别人。<br>BitTorrent得到了很好的研究，并证明了它的时间考验。尽管它已经很老了，但仍有数百万人在积极地使用[45]来共享文件，并为较新的点对点文件分发系统提供了一个榜样。此外，BitTorrent基金会和Tron基金会开发了BitTorrent Token (BTT)，作为基于区块链的激励层，以增加文件的可用性和持久性。新的激励结构通过收购数据扩大了针锋相对的竞争。报价数据(bid data)决定了对等端为持续服务满足的BTT/byte速率。作为支付的交换，对端被解除阻塞并有资格接收数据。令牌的交换由支付通道处理。</p><h3 id="B-Kademlia"><a href="#B-Kademlia" class="headerlink" title="B. Kademlia"></a>B. Kademlia</h3><p>从今天的角度来看，Kademlia可能是使用最广泛的DHT。正如我们稍后将看到的，大多数P2P数据网络都以某种方式构建在Kademlia之上。Kademlia还影响了P2P文件交换协议，如BitTorrent，它通过使用基于Kademlia的DHT支持无跟踪的torrent。<br>一般来说，Kademlia可以被归类为结构化的覆盖网络，它规定了如何构造和维护P2P网络。为此，对等体被分配一个身份，这个身份决定了它的位置，进而决定了它的邻居。对于邻居选择，使用异或度量。异或度规的优点是它是对称的和单向的。根据它们的XOR距离，节点被分类为𝑘-buckets。bucket被排列成二叉树，其中最短的前缀决定了bucket。如果一个新节点属于一个包含𝑘个节点(包括它自己)的桶，那么这个桶将被分成更小的桶，否则这个新节点将被丢弃。具有8位标识符的示例性Kademlia树如图3所示。</p><p><img src="/images/distributed_storage/image-20220428145024512.png" alt="image-20220428145024512"></p><h3 id="C-Information-Centric-Networking"><a href="#C-Information-Centric-Networking" class="headerlink" title="C. Information-Centric Networking"></a>C. Information-Centric Networking</h3><p>另一个值得一提的前身是信息中心网络(ICN)。尽管ICN不是一个P2P数据网络，但它的一些想法和概念至少与某些数据网络相似。与P2P数据网络不同，ICN提出改变网络层。包的路由和流应该从点对点位置搜索更改为直接从网络请求内容。举个例子，让我们假设我们想要检索一些数据，例如，一个网站，并且我们知道这个网站在example.com是可用的。首先，我们通过DNS请求站点主机的位置，即IP地址。然后，我们建立一个连接来检索网站。在ICN中，我们将直接请求数据，而不会寻址数据所在的主机。任何存储网站的节点都可以立即提供数据。<br>Jacobson等人提出了以内容为中心的网络，其中这些内容请求是interest packet。内容的所有者可以直接用包含该内容的数据包回答感兴趣的数据包。这就需要在基础设施级别上实现流量控制、路由和安全的其他机制。对interest packet进行广播，对数据感兴趣的对等体可以共享资源。目前有多个处理ICN的项目，例如命名数据网络(NDN)。对于Ntorrent，Mastorakis等人提出了一个NDN的扩展，在NDN中实现了一个类似bittorrent的机制。关于ICN的更多一般信息可在中找到。由于数据网络以内容为中心的性质，它们可以被广泛地解释为ICN的覆盖实现。</p><h3 id="D-Self-Certifying-Names"><a href="#D-Self-Certifying-Names" class="headerlink" title="D .Self-Certifying Names"></a>D .Self-Certifying Names</h3><p>从以主机为中心的通信到以内容为中心的通信的变化引入了新的安全问题。此外，当缓存成为网络的主要特征时，需要考虑特定的威胁，例如缓存中毒或针对缓存的拒绝服务攻击。更广泛地说，ICN的安全问题一般包括内容认证、授权和访问控制以及隐私。<br>目前，安全研究的主要焦点在于认证。由于缓存的广泛使用，数据提供者不再一定是对象的原始源(数据所有者)。这需要使接收者能够评估对象的有效性(完整性)、来源(内容来源)和相关性的机制。<br>确保有效性和相关性的一种方法是自我认证名称。可以使用散列指针(或更通用的内容散列)来引用内容，从而启用自认证名称。文件的内容被用作加密哈希函数的输入，例如SHA-3。得到的摘要可以用来识别内容，客户机可以在本地验证文件的完整性。哈希函数的加密特性，最重要的是预图像和抗碰撞，确保没有人可以在不改变摘要的情况下替换或修改输入数据。在这种情况下，名称提供了完整性和相关性，但是，谁负责验证对象，例如，客户端和/或中间端，仍然是值得怀疑的。此外，自我证明的名称本身不能提供出处或证明物体的来源。加密签名可以保证对象来源的真实性，但需要公钥基础设施或信任网络来验证签名。虽然这允许验证对象来源的真实性，但仍然可能发送格式不正确的对象，因此需要确保完整性的机制。通过缓存的内容的寿命需要谨慎的密钥管理，以防止加密凭据被破坏。<br>访问控制也有类似的问题:一旦数据发布，就很难限制访问或撤销发布。加密可能会限制访问，但可能需要带外密钥分发。关于ICN的安全、隐私、访问控制和其他挑战的进一步见解见[53,54]。</p><h3 id="E-区块链"><a href="#E-区块链" class="headerlink" title="E. 区块链"></a>E. 区块链</h3><p>2008年比特币的引入为分布式应用提供了新的可能性。比特币是一种巧妙而复杂的组合，它结合了来自链接时间领域的各种想法——加密、数字现金、P2P网络、拜占庭容错和密码学。比特币带来的关键创新之一是一种开放的共识算法，它可以积极激励同行遵守规则。因此，它使用了在这个过程中生成的硬币的概念，即挖矿。<br>虽然术语区块链通常指整个系统及其协议，但它也指类似于哈希链或哈希树的特定数据结构。也就是说，区块链使用加密散列对链接到其前任的块进行排序。这种链接的数据结构确保了区块链数据(例如事务)的完整性。区块链的一致性由共识算法保证，例如比特币中的Nakamoto共识。有关比特币和区块链的更多细节，请参阅。<br>由于区块链受到诸如可伸缩性等问题的困扰，人们开发了不同的设计来缓解这些问题。不同的设计开辟了一个新的类别，称为分布式分类账技术(DLT)。dlt提供分布式、拜占庭式容错、不可变和有序的日志。不幸的是，由于一系列的可扩展性问题和链上存储容量有限，纯粹基于DLT的数据网络的可行性有限[57,58]。此外，在被设计为交换和价值存储媒介的区块链(即比特币等加密货币)中存储大量数据会导致高额的交易费用。然而，dlt的研究和开发表明了基于区块链的数据网络的可行性，例如Arweave(参见第4 - e节)。<br>然而，一般来说，允许去中心化支付的加密货币可以作为一种激励结构在P2P数据网络中使用。正如我们将在下文中阐述的，这种激励结构可以增加数据网络的健壮性和可用性，从而解决前几代人的弱点。</p><h2 id="III-INTERPLANETARY-FILE-SYSTEM-IPFS"><a href="#III-INTERPLANETARY-FILE-SYSTEM-IPFS" class="headerlink" title="III. INTERPLANETARY FILE SYSTEM (IPFS)"></a>III. INTERPLANETARY FILE SYSTEM (IPFS)</h2><h2 id="IV-RELATED-P2P-DATA-NETWORKS"><a href="#IV-RELATED-P2P-DATA-NETWORKS" class="headerlink" title="IV. RELATED P2P DATA NETWORKS"></a>IV. RELATED P2P DATA NETWORKS</h2><h3 id="A-Swarm"><a href="#A-Swarm" class="headerlink" title="A. Swarm"></a>A. Swarm</h3><p>Swarm是一个由以太坊基金会开发的用于存储和交付内容的P2P分布式平台。它通过不允许任何删除，以及上传和忘记属性来抵抗审查。群是为以太坊构建的，因此在某些方面依赖并共享以太坊的设计方面。Swarm的目标是为web3栈提供去中心化的存储和流媒体功能，这是一个用于共享互动内容的去中心化的、抵制审查的环境。以太坊基金会将Swarm设想为“世界计算机的硬盘”。<br>与IPFS类似的是Swarm使用基于内容的寻址。与IPFS相反的是Swarm中基于内容的寻址也决定了存储位置。为了确保可用性，群控引入了职责范围。责任区域是节点的近邻。责任区域中的节点应该提供块冗余。通过版本控制支持可变性，保持文件的每个版本。提要、专门构造和寻址的块以及以太坊名称服务(ENS)用于查找变异文件。ENS是以太坊改进提案137中定义的标准。它提供了将地址转换为人类可读名称的能力。与IPNS不同，ENS是作为以太坊区块链上的智能合约来实现的。</p><p>图6是云计算的概念概述，我们继续使用作者和审稿人之间交换的调查论文作为运行例子。Swarm会将一个文件分割，也就是将调查分成一些块，这些块被安排在一个所谓的Swarm hash中。Swarm哈希是排列在Merkle树中的块的组合，其中叶节点代表输入数据，中间节点是子节点的引用组合。得到的数据块被上传到网络。群采用Kademlia拓扑结构，邻居由它们的标识距离决定。需要注意的是，除了桶的连接外，Swarm还依赖于一个最近的邻居集合，即该邻居的剩余节点。一个邻居基本上是包含至少三个其他对等节点的桶数量最少的桶。这个最近的邻居集负责复制，并且不一定是对称的。例如，在图6中，𝑁3的最近邻居是𝑁2，𝑁1和𝑁0，而𝑁12的邻居是𝑁8，𝑁9，𝑁10和𝑁11(参见图3)。上传的块被中继，存储和复制在最近的地址。要检索调查，必须使用群根哈希。网络根据内容地址转发请求。</p><p><img src="/images/distributed_storage/image-20220428151148330.png" alt="image-20220428151148330"></p><p>为了保证确保节点行为，Swarm提供了一个激励层。其激励机制基于SWAP、SWEAR和SWINDLE。SWAP (SWarm Accounting Proto- col)处理节点间数据交换的均衡。各节点维护本地计费信息。对等点基本上是在没有利息的情况下从服务节点购买一大块。区块的价格可以在同行之间协商。请求会被处理到某个不平衡的阈值，即块被不平衡地处理，债务变得过高。在达到第一个阈值后，节点希望得到债务的结清以进行进一步的服务。如果达到第二个阈值，则由于未清偿债务，节点断开连接。债务可以用支票结算，支票可以被理解为一种简单的单向支付渠道。SWarm Enforcement And Registration (SWEAR)和Secured With INsurance Deposit Litigation And Escrow (SWINDLE)将确保内容的持久性。此外，Swarm的激励机制有邮票，它提供了一种机制来防止垃圾上传，也提供了一种彩票机制来激励块的持续存储。<br>邮票可通过智能合约批量获取。邮票被附在上传的区块上，并由邮票所有者签名。这可以作为上传区块的付款凭证。只能通过中继或存储节点监控戳记的使用情况。这允许重复使用/过度使用邮票。为了减少过度使用戳记的风险，戳记只用于某些前缀冲突，将戳记限制为特定存储区域中的块。<br>邮票被用于抽奖。彩票为块提供了价值，以防止块的早期删除。通过抽签，存储节点可以获得邮票的部分初始成本。在彩票中选择一个地址区域。临近区域的节点可以申请奖励。通过应用，节点可以证明该区域内块的所有权。节点定义了存储块的价格。在证明拥有这些块之后，拥有最便宜奖品的节点获得奖励。讨论:群提供了复杂的激励概念。与依赖区块链交易相比，用支票结算不平衡检索提供了一种更快、更便宜的结算差异的方法。与彩票一起发行的邮票为储存大块的数据提供了额外的激励。此外，虽然上传内容需要花费成本，但节点可以通过主动为参与者提供块来赚取成本。然而，邮票可以将用户链接到上传的内容。虽然群集提供了一定程度的发送者匿名性，但上传的匿名性可能会限制可用的内容。<br>考虑到分布式块不可变存储(DISC)所确定的存储位置，网络可能面临存储问题。提要可以在网络中提供用户定义的空间，以恢复提要和固定的形式，可能能够减轻这些缺点。<br>总的来说，Swarm显然依赖于以太坊生态系统。虽然这有利于激励结构，但由于以太坊发展积极，用户基础广泛，这也需要用户对以太坊的依赖。虽然有这么庞大的潜在用户群，但对用例或Swarm机制的研究却很少。Swarm和以太坊的连接可能是缺乏研究的一个原因，因为Swarm似乎没有IPFS那么完整，而以太坊本身仍然保留着许多研究机会。</p><h3 id="B-Hypercore-Protocol-Dat"><a href="#B-Hypercore-Protocol-Dat" class="headerlink" title="B. Hypercore Protocol/Dat"></a>B. Hypercore Protocol/Dat</h3><p>Hypercore Protocol(以前的Dat Protocol)支持类似Git的内容和元数据的增量版本。Hypercore协议由多个子组件组成。严格地说，Hypercore是子组件之一，为了简单起见，我们使用这个术语来泛指Hypercore协议。在Hypercore中，数据存储在一个类似于BitTorrent结构的目录中，每个目录处理自己的网络。该协议支持不同的存储模式，每个节点可以决定目录中的哪些数据以及需要存储哪些版本的数据。此外，该协议支持订阅目录中所有/任何文件的实时更改。协议中的所有通信都是加密的。为了查找和读取数据，需要知道一个特定的读键。<br>该协议旨在共享大量可变数据。创建该协议的动机是为了防止科学文献的链接腐烂和内容漂移。该协议只允许随机访问部分数据。<br>Hypercore可以理解为共享一个文件夹。可以对文件夹中的文件进行修改、添加和删除操作。这也包括并允许可变文件。<br>Hypercore的概念概述如图7所示。对于对等发现，Hypercore使用Hyperswarm，一种基于Kademlia的DHT。如果作者想使用Hypercore协议共享调查结果，需要创建Hypercore并添加调查结果。要想被超perswarm发现，就必须加入超perswarm覆盖网络。通过共享公钥𝐾𝑃𝑢𝑏，审阅者可以计算发现密钥𝐾𝐷，并在找到对等点并加入数据网络后解密消息。一旦另一个覆盖网络加入，非结构化的志愿者网络就可以共享数据，调查可以被检索。<br>讨论:Hypercore允许通过交换公钥来共享数据。可以获取特定版本和特定区域的数据。这使得它变得简单，特别是对于大型数据集，并且允许可变数据。该协议专注于共享文件集合，这扩大了协议的可用性。<br>由于加密和发现密钥，该协议确保了机密性。公钥允许计算发现密钥，但不可能逆转公钥。这将阻止其他人读取数据。Hypercore的一个缺点是缺乏公钥以外的其他身份验证机制，这阻止了额外的细粒度访问控制。此外，它仍然泄漏元数据，因为发现密钥只是一个假名。<br>Hypercore没有复制数据的激励机制，数据的持久性依赖于参与者。利用或分析Hypercore/Dat的研究很少。虽然该协议似乎开发得很好，而且可用，但研究似乎侧重于IPFS。</p><h3 id="C-Secure-Access-For-Everyone-SAFE"><a href="#C-Secure-Access-For-Everyone-SAFE" class="headerlink" title="C. Secure Access For Everyone(SAFE)"></a>C. Secure Access For Everyone(SAFE)</h3><p>人人安全访问(SAFE)网络[17,81]被设计为一个完全自主的分散数据和通信网络。甚至认证也遵循自我认证[82]机制，它不依赖于任何集中组件。SAFE的主要目标是提供一个网络，每个人都可以加入并使用它来存储、查看和发布数据，而不会在机器上留下他们活动的痕迹。这将允许参与者以较低的迫害风险发布内容。<br>SAFE支持三种不同的数据类型:Map、Sequence和Blob。数据可以进一步分为公共数据和私有数据。Map和sequence是无冲突的复制数据类型，这对于确保可变数据的一致性很重要。Blob用于不可变数据。SAFE网络中的所有数据都是加密的，包括公共数据。使用的加密算法是自加密[83]，使用文件本身对文件进行加密。也就是说，一个文件被分割成至少三个固定大小的块。每个块使用前一个块的散列和加密，即𝑛−1，其中𝑛是当前块。之后，加密的块会被原始块的串接哈希值混淆。对于SAFE，混淆后的块存储在网络中。对于解密，在加密过程中会创建一个数据映射。数据映射包含关于文件的信息，并将模糊块的散列映射到真实块的散列。对于公共数据，解密密钥由网络提供。私人数据可以删除，而公共数据应该是永久的。因此，可变数据只能是私有的。名称解析系统允许人类可读的地址来检索数据。<br>网络本身是根据基于卡德米利亚的DHT由异或地址组织的。此外，网络被分成几个部分。当一个新的保险库想要加入网络时，新的保险库需要证明它可以提供所需的资源，然后被随机分配一个XOR地址，从而分配给一个节。这些部分是动态维护的。根据网络中保险库的数量，分区并将保险库重新分配到新的分区。对于长得太小的节，可以通过获取新节点或请求重新定位节点来平衡节的大小。更改section会增加保险库的节点年龄。节点年龄是信任的衡量标准，可以失去，然后必须重新赢得。在一个section中，只有一定数量的节点可以做出决策，即长者。长者是该区域中最古老的节点。由长老投票决定是否接受分区内的事件，经一定人数的长老同意并集体签字后生效。网络段中的事件是，例如，加入/离开一个节点或存储一个块。长者的真实性由SectionProofChain保证，SectionProofChain包含长者的群组签名，是证明一个区段有效性的公钥序列。每当长者组发生变化时，序列就会更新和签名。<br>SAFE网络的概念概述如图8所示。考虑到我们正在运行的示例，调查被划分为自加密的块，并用于生成数据地图。在完成自我认证过程后，向网络发送一个PUT请求。当负责存储块的区域中的长者同意后，数据就被存储。下载文件时，需要数据图。数据映射用于GET请求，以获取经过模糊处理的加密块。下载公共数据不需要认证。在获得这些块之后，可以在数据映射的帮助下重新创建文件。<br>在SAFE网络中，存储数据需要使用该网络自身的货币，即Safecoin。客户的安全币平衡由客户经理监控，并在外管局的共识机制的帮助下被批准/拒绝。节点可以通过耕种(即向请求者提供内容)赚取Safecoin。<br>讨论:自我认证、自我加密和网络组织给了用户对其数据的高度控制。中心组件的缺失减少了单点故障。此外，隐私和在一定程度上匿名是SAFE网络的关键特征。网络中仅存储数据时需要鉴权。检索数据通过客户端选择的代理进行中介，该代理提供了匿名通信。Safecoin旨在提供一个激励层，确保网络的可用性和可靠性。<br>Paul等人[84]在2014年首次对SAFE进行了安全分析，涉及机密性、完整性和可用性以及可能的攻击。2015年，Jacob等人[85]从真实性、完整性、保密性、可用性和匿名性等方面分析了网络的安全性。作者解释了如何利用自我认证和去中心化特性来揭示单个实体的个人数据。</p><h3 id="D-Storj"><a href="#D-Storj" class="headerlink" title="D. Storj"></a>D. Storj</h3><p>Storj[18]是一个P2P存储网络。下面我们引用的是3.0版本。它专注于数据的高持久性、低延迟以及存储数据的高安全性和私密性。支持对通信、文件位置和文件进行端到端加密。为了文件的高持久性或换句话说，文件在网络中更好的可用性，Storj使用了擦除码。此外，低带宽消耗也是设计的主要目标之一。该协议假设对象大小为4𝑀𝐵或更多，虽然支持较小的对象大小，但存储过程的效率可能较低。在Storj中，去中心化被解释为没有一个操作者单独负责系统的操作。在一个分散的系统中，信任和拜占庭式的失败假设是重要的。Storj假设没有利他的，总是表现良好的节点，大多数理性节点，只有在盈利时表现出恶意，还有少数拜占庭式恶意节点。<br>Storj的目标是成为去中心化的云存储。Storj Labs Inc.希望为集中式存储提供商提供另一种选择。为此，Storj提供了与Amazon S3应用程序编程接口的兼容性，以提高总体接受度并简化新用户的迁移。由于Storj提供了云存储，用户可以存储和检索数据，以及删除、移动和复制数据。<br>Storj网络由三种节点类型组成:卫星节点、存储节点和上行节点。卫星节点管理文件的存储过程和维护。对元数据甚至文件路径的加密增加了对元数据的额外保护。上行节点是终端用户，需要存储和访问文件。存储节点用于存储数据。存储和上行节点选择与哪些卫星节点合作。这导致了一个类似于BitTorrent的网络，其中卫星成为中心部分。<br>Storj的概念概述如图9所示。为了上传调查论文，作者需要将其分割成片段，然后对片段进行加密。作者要求卫星存储一个片段。卫星检查存储节点的容量并返回足够的候选存储列表。然后，片段被分割成条状，这些条状被擦除编码并排列成片段。然后，这些片段被并行上传至存储节点。</p><p>对于擦除编码，Storj使用Reed-Solomon擦除码[86]。对于erasure code，数据编码为(𝑘，𝑛)erasure code。这意味着，一个对象被编码为𝑛片段，以这种方式只需要𝑘片段就可以重新创建对象。Storj为每个对象选择四个值:𝑘、𝑚、𝑜和𝑛。𝑘表示重建数据所需的最小块数，𝑚是用于修复的缓冲区，𝑜是用于churn的缓冲区，𝑛是总块数。与多次存储数据块相比，Erasure code提供了更高的冗余，开销更小。此外，由于检索文件只需要𝑘片段，因此可以减少文件可用前的延迟。<br>上传完成后，一个包含片段元数据的指针(例如片段的哈希值、存储位置、擦除编码方案)被返回给卫星。对每个部分重复这个步骤，最后一个部分包含关于调查的额外元数据。如需下载调查报告，请提供各部分的指针。这些片段是由存储节点并行请求的。一旦收集到足够多的片段，就可以阅读调查报告了。<br>为了保证理性节点之间的合作，Storj提供了激励机制。奖励系统奖励存储节点存储和提供内容。通过审计和声誉系统对节点进行监控和评估。Storj的一个目标是低延迟，从而避免依赖区块链的激励机制。<br>讨论:与其他P2P数据网络相比，Storj使用了一些独特的概念。特别是，Amazon S3的兼容性可能会促进Storj成为去中心化的存储系统。擦除码增加了存储文件的开销，但在检索文件时，只需要下载必要数量的片段。通过擦除码的存储去中心化，以及足够的存储节点选择和声誉系统的帮助，增加了对数据泄露的保护。<br>卫星节点是网络的重要组成部分，并对网络进行分区，因为在一颗卫星上可用的文件在另一颗卫星上不可用。这促进了卫星形式的集中化。虽然由于加密，卫星无法与可能的第三方共享元数据，但仍然有可能泄露访问模式。<br>虽然已经部署了Storj，并且确实可以使用，但关于该主题的应用程序和研究相当少。De Figueiredo等人[87]分析了Storj网络，并将卫星节点识别为拒绝服务攻击的可能向量。他们修改了存储节点连接处理的实现，在测试环境中成功拿下了一个卫星节点，使得支付和文件检索在一段时间内无法实现。但是，生产系统应该能够抵抗这种攻击。另一项研究也显示了对数据网络的另一种攻击。Zhang等人[88]指出，在Storj v2.0中，可以将未加密的数据上传到存储节点，用于框架存储节点的所有者。尽管如此，Storj提供了隐私保障、弹性、可获取的元数据或每个人都可以部署不同节点的可能性，这些都可以为云存储提供有价值的见解。</p><h3 id="E-Arweave"><a href="#E-Arweave" class="headerlink" title="E. Arweave"></a>E. Arweave</h3><p>Arweave协议[19]利用了一种类似区块链的结构(称为blockweave)，为永久的链上数据存储以及存储支付提供了一种机制。在块组织中，一个块指向直接前一个块和召回块，召回块是基于前一个块的信息确定地选择的。虽然编织是不可改变的，并提供了对其数据的审查阻力，但每个节点都可以决定拒绝接受内容。通过足够多的节点拒绝内容可以防止包含不需要的内容。<br>Arweave使用了一种类似于BitTorrent的“tit-for-tat”的协议Wildfire来为同行排名。通过Wildfire，每个节点维护一个节点列表，并根据节点的响应能力(如响应请求或发送事务)进行评分和排名。这个分数基本上是由最近请求的平均每秒接收字节数决定的。级别高(因此性能最好)的对等点首先并行地接收消息，然后依次接收其余的消息。定期修剪连接到低等级对等体的连接。这激励节点自身高度响应，以尽可能快的速度接收消息。优化节点的资源利用率，减少通信时间。<br>Arweave的核心是基于区块链的网络。虽然野火引入了一个有利于某些连接的排名，但它仍然是一个非结构化的P2P网络。图10给出了Arweave的概念概述以及如何归档/检索文件。为了在Arweave中存档调查论文，有必要将交易发送到网络上。对等点通过将该交易包含在一个块中来确认该交易。如果有人想要阅读调查，网络被要求。如果一个对等点存储了包含调查的块，它可以被返回，调查可以被读取。</p><p><img src="/images/distributed_storage/image-20220428173237462.png" alt="image-20220428173237462">Arweave的目标是提供数据的永久存储，以一种不可变的方式保存和时间戳信息。数据存储在区块组织的链上，因此，是不可变的，只有通过分叉组织才能移除。blockweave为永久网络提供了去中心化存储。<br>blockweave及其数据的存储和维护通过Arweave的加密货币:Arweave代币来确保。代币用于奖励矿工和支付发送交易。<br>讨论:Arweave协议在类似区块链的结构上提供链上存储。这使得存储具有与区块链类似的优点和缺点。Arweave提供时间戳、透明度、激励机制和不可变存储。数据是通过提供匿名数据作者的事务存储的。<br>区块链最大的问题之一是可扩展性。Arweave试图通过区块阴影(一种类似于紧凑块的机制，在比特币改进提案152[89]中有解释)和野火(用于快速块传播，减少分叉概率)来减少这些问题。此外，使用块哈希列表和钱包列表可以降低初始参与成本。在2.0版本中，Arweave引入了一个硬分叉来提高可伸缩性，将数据与事务分离。在事务中不包括数据，而是包括数据的Merkle根。这提高了事务传播速度，因为转发事务不再需要数据。<br>由于存在伪随机召回块，为了使挖掘收益最大化，节点被激励存储大量的块。这增加了数据的复制。然而，并不是每个节点都必须存储每个块或内容，每个节点根据内容过滤器为自己决定存储哪些数据。请求内容可能会变得复杂，因为节点是随机请求的，希望它们存储内容。<br>对Arweave的直接研究很少。然而，这可以解释为新兴的基于区块链的协议的广泛范围和区块链的研究至少可以部分应用于Arweave。</p><h3 id="F-Honorable-Mentions-and-Related-Concepts"><a href="#F-Honorable-Mentions-and-Related-Concepts" class="headerlink" title="F. Honorable Mentions and Related Concepts"></a>F. Honorable Mentions and Related Concepts</h3><p>在我们对选定的P2P数据网络的详细概述之后，我们提供了有关当前一代P2P数据网络的其他系统和概念的其他文献。特别是，一些论文概念为P2P内容共享提供了不同的、复杂的想法。<br>Sia[90]的目标是成为去中心化的云存储平台。一个文件被分割成多个块，这些块被加密，然后通过擦除编码存储在多个存储节点上。块的位置存储为元数据。Sia使用区块链来激励数据的存储和检索。数据存储的条件和持续时间在存储合同中是固定的。数据所有者负责文件运行状况。<br>OSN (Open Storage Network)[91]是一个用于传输和共享研究数据的分布式网络。它可以与专注于大量研究数据的分布式云服务相媲美。数据存储在中央监控和维护的吊舱中。这些OSN吊舱是专门配置的服务器机架，需要高带宽互联网连接。想要为这个网络做出贡献的机构可以安置豆荚。因此，研究人员可以在OSN网络中存储和共享他们的研究数据。OSN吊舱的连接性应保证数据的快速访问。数据可以与选定的参与者共享，也可以通过开放获取。对pods的集中管理和严格的条件将OSN与现有的其他数据网络区分开来，分散和任意参与是这些数据网络的一个关键特征。<br>Fukumitsu等人[92]提出了一种点对点类型的存储系统，在该系统中，即使是重构所存储文件所需的元数据也存储在网络中，可以通过ID、密码和时间戳来检索。作者假设一个非结构化的P2P网络，其中每个节点可以提供不同的服务。节点定期广播有关自身的必要信息，例如提供的服务及其IP地址。该方案的一个重要组成部分是存储在区块链上的存储节点列表。存储节点列表是随机选取的提供存储服务的节点列表。数据按部分存储，存储过程分为两个阶段:存储用户数据和存储重构用户数据所需的数据。用户数据被加密，分成部分，存储在当前可用的存储节点中选择的节点上。可以使用恢复键请求部件。为了重构用户数据，需要解密密钥、存储节点对和恢复密钥。因此，需要将数据复制到其他节点。用户创建ID、密码对，并选择存储列表。数据通过ID、密码和存储列表的散列进行加密。存储节点是从存储列表中确定选择的。部件的恢复键是存储列表的散列和块索引的散列，即ID和密码。该方案允许获取数据，而无需将信息存储在用户设备上。<br>Jia等人[93]提出了一种实现健忘RAM隐藏数据访问模式的机制——oblvp2p。虽然作者提到他们的机制适用于其他点对点系统，但他们关注的是带有跟踪器的类似BitTorrent的系统。<br>Qian等人[94]提出了Garlic Cast，一种改善覆盖网络中匿名性的机制。对等点不直接请求和搜索内容。相反，对等体搜索代理，代理交换和请求内容。对等体及其代理之间的消息是通过安全增强的信息分散算法(IDA)交换的。rda是一种擦除编码形式，其中𝑘的𝑛片段足以重建对象。安全增强的IDA首先对消息进行加密，使用𝑘-threshold IDA将消息和密钥分割为𝑛片段，然后发送cloves，即包含密钥和消息片段的消息。通过随机游走发现代理:丁香被发送给它的邻居，请求对等点作为一个具有随机丁香序列号的代理，每个邻居随机转发丁香，并维护继承者和前任的状态。具有两个具有相同序列号的丁香的对等体可以恢复请求，如果它自愿成为对等体，它将返回一个回复给请求者。<br>其他论文概念利用区块链进行访问控制，并存储数据位置，而不是作为激励机制的补充，如Blockstack[95]，它在区块链上维护元数据，并依赖外部数据存储来实际存储数据。也有使用分布式账本技术进行访问控制的概念。<br>Calypso[96]，它使用基于跳链的身份和访问管理，允许可审计的数据共享。然而，这些系统和仅集中于通过区块链出售数据的系统不在本次调查的范围之内。</p><h2 id="V-DISCUSSION-OF-BUILDING-BLOCKS"><a href="#V-DISCUSSION-OF-BUILDING-BLOCKS" class="headerlink" title="V. DISCUSSION OF BUILDING BLOCKS"></a>V. DISCUSSION OF BUILDING BLOCKS</h2><p><img src="/images/distributed_storage/image-20220428171303982.png" alt="image-20220428171303982"></p><h3 id="A-Performance"><a href="#A-Performance" class="headerlink" title="A. Performance"></a>A. Performance</h3><p>系统性能的研究已经成为一些研究者所追求的研究方向。通过模拟或测试来调查性能、读/写时间、存储开销、文件查找、抗churn阻力，可以用来识别新的用例，并巩固一个系统可能取代集中式系统的断言。IPFS开发人员开发了“Testground”[103]，用于大规模测试和基准测试P2P系统。从这个意义上说，Testground的性能及其对真实系统的复制能力也是一个值得研究的领域。也有其他分析IPFS性能的研究，如读写时延[28,31]，使用IPFS集群进行物联网数据共享[29]，改进系统[30,36]，或分析网络[34,35,37]。Heinisuo等人[32]表明，由于高网络流量消耗电池，IPFS需要改进才能在移动设备上使用。关于IPFS竞争对手的研究还很缺乏。此外，Naik和Keshavamurthy[41]关注的主题是P2P网络的流失。此外，考虑到研究数据的增加，需要研究在Tera-和Petabytes范围内建立大型单一数据集的数据网络的可行性。</p><h3 id="B-Confidentiality-and-Access-Control"><a href="#B-Confidentiality-and-Access-Control" class="headerlink" title="B. Confidentiality and Access Control"></a>B. Confidentiality and Access Control</h3><p>过去和现在的数据网络提供了一些机密性和访问控制，但这些系统是为公共数据而不是为私有数据设计的。需要研究节点在存储数据时所获得的知识。这不仅涉及数据内容的信息，还涉及元数据(如访问模式)。现有的访问控制系统的安全性有待进一步研究。有研究建议使用区块链进行访问控制[22 - 25,64]，但区块链的不变性使得这对于私人和个人数据来说存在问题。关于私有数据的另一个方面是删除数据。虽然防止删除数据有助于抵制审查，但删除个人、恶意或非法数据的可能性可能提高对数据网络的接受程度。例如，Politou等人[102]提出了一种IPFS中删除内容的机制。调查和改进现有系统可以增加对数据网络的信任。增强对机密性的信任和防止未经授权的访问可以打开这些系统来存储私人和个人数据。</p><h3 id="C-Security"><a href="#C-Security" class="headerlink" title="C. Security"></a>C. Security</h3><p>对于安全研究来说，这一领域的工作通常是在发现和修复新的漏洞之间反复进行。此外，研究还涉及利用P2P数据网络与恶意软件交换数据的恶意活动<br>在安全漏洞方面，Prünster等人[33]披露了对IPFS的eclipse攻击，De Figueiredo等人[87]披露了对Storj的测试网络的拒绝服务攻击。此外，不仅需要研究已知的攻击向量，还需要研究新的攻击向量的存在。例如，Storj承认存在“Honest Geppetto”攻击的可能性，即攻击者(诚实地)长时间地操作许多存储节点，有效地控制大部分存储能力。这种控制允许将数据作为“人质”或一般地取下数据，使数据网络无法操作。另一个例子是Frameup[88]，其中未加密的数据存储在存储节点上，这可能会导致法律问题。存储任意数据也可能给存储设备带来风险。安全是研究领域，我们观察IPFS以外的研究。</p><h3 id="D-Anonymity"><a href="#D-Anonymity" class="headerlink" title="D. Anonymity"></a>D. Anonymity</h3><p>除涉及数据安全和隐私的机密性外，保护个人隐私是另一个相关的方面;特别是匿名性，它描述的是无法在一群个体中识别一个个体，即不可链接性[104]。<br>在匿名方面，数据网络中可以保护各种实体:内容创建者、存储节点和请求内容的用户。在上一代数据网络中，特别是Freenet[2]和GNUnet[105]着重于保护不同实体的身份。Balduf等人[70]已经表明，IPFS通过监控数据请求识别内容请求者，从而继续存在隐私问题。<br>由于激励机制和由此产生的个人指控，很难保证匿名，因为至少需要假名。一旦使用了激励机制，有关请求者的信息就得到了。记录交易的分布式分类账，例如Filecoin、Ethereum Swarm、Arweave，可以揭示额外的信息，因此参与者是匿名的。当一个中心组件授权请求和处理激励时，例如Storj中的卫星节点，请求者、存储节点和中心组件相互认识。在激励请求的情况下，显示请求节点和存储节点。请求者的身份可以通过转发策略或代理(如Swarm、SAFE)部分地得到保护。<br>第一代有像Freenet这样的系统，旨在匿名和抵制审查。这一代的匿名性似乎落后于第一代。尽管使用mixnet或Tor进行匿名通信取得了进展[106]，但还没有数据网络提供强匿名性。总之，提供的匿名保证和进一步的增强需要调查。这包括匿名实用程序的权衡和对不同攻击者模型的分析。匿名不仅对保护个人隐私很重要，而且对保证声称的抵制审查也很重要。如果可以很容易地推断出存储节点的身份，那么即使网络保护不被删除，执法部门也有可能执行<br>审查。这是一个值得关注的问题，特别是对于像Swarm这样的系统，存储块的位置是预先确定的，节点身份是与以太坊假名相连的</p><h3 id="E-Naming"><a href="#E-Naming" class="headerlink" title="E. Naming"></a>E. Naming</h3><p>命名，特别是在分布式系统中提供人类可读的名称，是一个已知的挑战。Zooko ‘s Triangle[107]捕捉到了这个问题及其邻近的挑战。它描述了构建分布式命名空间的困难，分布式命名空间是分布式的(没有中央权威)、安全的(清晰的解析)和人类可读的。<br>在所有系统中，数据的寻址要么缺乏分布性(基于跟踪器的BitTorrent和Storj)，要么缺乏人类可读性(无跟踪器的BitTorrent、Hypercore、IPFS、Swarm和SAFE)。BitTorrent是一个很好的例子，跟踪器是一个中央权威，在无跟踪的BitTorrent的情况下，人类可读的种子是用不太可读的信息哈希(种子的哈希)解决的。在Storj的3.0版本中，卫星是一个中心组件。<br>缺乏可读性是自认证数据的结果，其中数据决定了数据的地址或名称。数据变更后，地址也随之变更。因此，通过不同的机制(独立于内容的命名)来支持人类的可读性。Hy- percore是一个例外。在Hypercore中，数据组被绑定到公钥，并且通过版本控制来保护组内的可变性。<br>提供人类可读性的一个解决方案是名称解析。名称解析允许将密钥映射到自我认证的内容。名称解析可以提供人类的可读性，并提供对文件版本控制的支持。然而，由于更新值的可能性和传播的延迟，即使密钥是唯一的，人们也会认为安全性被破坏了。名称解析独立于Zooko ‘s Triangle，宣布内容，并给出模棱两可的字符串含义，应该只用于公共数据，除非名称解析提供访问控制。<br>为此，IPFS、Swarm和SAFE提供了某种命名服务。实际上，IPFS提供了两种命名服务:IPNS和DNSLink，用于不同的目的。IPNS用于将公钥的哈希映射到IPFS CID，允许可变数据。DNSLink使用DNS TXT记录实现域名到IPFS地址的映射。<br>Swarm还提供了两种命名系统:single-owner chunk和ENS[79]。单所有者块提供了基于所有者和标识符的数据标识，提供了一个安全的、非人类可读的键和一个可更新的值。以太坊名称系统类似于DNS，其中一条记录被映射到一个地址。<br>Swartz[108]认为，基于区块链的名称服务提供了Zooko三角形的所有三个属性。任何人都可以在提供去中心化的区块链上注册名称，名称可以是任何提供人类可读性的名称，而防篡改分类帐确保提供安全性的唯一名称。根据这一论点，像Name- coin、Blockstack[95]和ENS这样的系统被开发出来，它们采用了基于区块链的名称系统的思想。虽然这些系统的存在，除了带有ENS的群系统，似乎没有一个系统能解决Zooko的三角形问题。然而，由于缺乏交易最终性和可能的区块链分叉，可以认为基于区块链的系统违反了强大的安全方面，只提供最终安全性。</p><h2 id="VII-CONCLUSION-AND-LESSONS-LEARNED"><a href="#VII-CONCLUSION-AND-LESSONS-LEARNED" class="headerlink" title="VII. CONCLUSION AND LESSONS LEARNED"></a>VII. CONCLUSION AND LESSONS LEARNED</h2><p>第一代P2P数据网络告诉我们，P2P驱动的文件交换是可行的，并且有一些主要的优势，例如，自扩展性。这项技术持续存在的另一个指标是BitTorrent的持续存在和广泛的用户基础。然而，第一代也教会了我们弱点，例如，缺乏长期可用性。下一代数据网络建立在上一代数据网络的基础上并加以改进，利用技术进步和概念来解决弱点。</p><p>在这篇调查论文中，我们研究了新兴的新一代P2P数据网络。特别地，我们调查了新的发展和技术构件。从我们的定性比较中，我们可以得出结论，除了覆盖结构之外，各种数据网络在文件管理、可用性和激励方面探索了不同的解决方案。最值得注意的是，显性激励机制，如使用加密货币或某种代币，似乎无处不在，以确保长期可用性和参与者的参与。我们还看到了不同的度量方法，以确保在面对拒绝服务攻击或超越激励机制的流失时的可用性，即复制、擦除码，甚至两者的结合。此外，由于许多系统在分布式体系结构中结合了命名服务和内容寻址，它们有可能像Zooko的三角形那样协调人类的可读性、安全性和分散性等系统属性。<br>现在一个重要的开放任务是调查和评估各种构建块。特别是，激励机制的设计是出了名的困难。在某种程度上，我们可以将P2P数据网络的不同部署视为一个大型现场测试，在那里我们可以观察某些设计决策的影响。总的来说，无论是作为其他应用的基础，还是作为研究对象本身，P2P数据网络已经成为研究议程的一部分。<br>然而，许多挑战和开放的研究问题仍然存在，例如，调查匿名性，参与者的隐私和访问控制，开放P2P数据网络到更广泛的可能的用例。因此，我们相信新一代的P2P数据网络为未来的研究提供了许多令人兴奋的机会。</p><p>推荐阅读：</p><ol><li><a href="https://www.youtube.com/watch?v=jp0bF9Qu2Jw">Vol 075 别再问我什么叫 BT 种子</a></li><li>原论文链接：<a href="https://ieeexplore.ieee.org/abstract/document/9684521">https://ieeexplore.ieee.org/abstract/document/9684521</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Distributed Storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Ubuntu20.04搭建单机Fabric2.3.0Raft共识测试网络</title>
      <link href="/2022/04/17/blockchain/fabric/%E5%9F%BA%E4%BA%8ERaft%E5%85%B1%E8%AF%86%E6%90%AD%E5%BB%BA%E5%8D%95%E6%9C%BAFabric2.3%E7%BD%91%E7%BB%9C/"/>
      <url>/2022/04/17/blockchain/fabric/%E5%9F%BA%E4%BA%8ERaft%E5%85%B1%E8%AF%86%E6%90%AD%E5%BB%BA%E5%8D%95%E6%9C%BAFabric2.3%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="PRIVATE FILE">    <label for="pass">PRIVATE FILE</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 部署文档 </tag>
            
            <tag> Fabric </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Arweave – 一种类区块链的区块编织结构（Lightpaper）</title>
      <link href="/2022/04/12/blockchain/arweave/Arweave_%E4%B8%80%E7%A7%8D%E7%B1%BB%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9A%84%E5%8C%BA%E5%9D%97%E7%BC%96%E7%BB%87%E7%BB%93%E6%9E%84(Lightpaper)/"/>
      <url>/2022/04/12/blockchain/arweave/Arweave_%E4%B8%80%E7%A7%8D%E7%B1%BB%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9A%84%E5%8C%BA%E5%9D%97%E7%BC%96%E7%BB%87%E7%BB%93%E6%9E%84(Lightpaper)/</url>
      
        <content type="html"><![CDATA[<p>转载：<a href="http://ipfsdrop.com/docs/whitepaper/arweave-lightpaper/">http://ipfsdrop.com/docs/whitepaper/arweave-lightpaper/</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>经典的区块链在数据存储方面存在几个众所周知的主要问题。这些问题需要将新的第三方协议集成到现有区块链的上层，因为费用太高，无法进行链上存储。因此，对于经典的区块链来说，访问内容始终会产生成本，而且内容永远不会永久存储­。随着对数据存储的需求呈指数增长，对可扩展的分布式低成本数据存储协议的需求是必要的。</p><p>在这项工作中，我们介绍Arweave——一种类区块链的区块编织结构。区块编织是一个平台­，致力于首次以经济高效的方式提供可扩展的链上存储。随着系统中存储的数据量的增加，达成共识所需的哈希值减少，从而降低了存储数据的成本。该协议现有的REST API使得在区块编织上层构建去中心化的应用程序­十分简单，反映了Arweave对开发者社区的关注及其推动采用新兴和新颖协议的能力。</p><p>在本文中，我们还介绍了新颖的概念­诸如「区块阴影（block-shadowing）」——一种灵活的交易区块分配算法——­改进了其他区块链的现有“分片”技术­优化网络拓扑，并带来新的共识机制，称为访问证明（Proof of Access）。</p><h2 id="1-导语（Introduction）"><a href="#1-导语（Introduction）" class="headerlink" title="1. 导语（Introduction）"></a>1. 导语（Introduction）</h2><p>在这个信息时代，我们常常屈服于一种幻想，即信息被读取­可用，它永远不会被更改或丢失。从根本上讲这是不正确的[7]。在互联网上，我们建立了一个巨大的去中心化信息传播系统­信息，我们还没有建立一个对应的­永久知识存储系统。现代历史有非常多的例子——­从图书馆和档案馆的大火[9，10，3，8]到专制国家的书籍燃烧（焚书坑儒）[12，11]，重要信息的构建和丢失。当我们在互联网上查询信息时­，我们依赖于被允许访问被集中存储的该数据。­拥有此信息的服务器的访问­所有者可以随时撤消该许可。同样，由于在Internet上提供信息需要支付服务器费用和维护费用，因此当资金不足时，网站通常会轻易地消失。</p><p>更进一步，许多政府正在采取越来越多的步骤来审查和删除对互联网上政治敏感信息的访问[13、5、4]。与媒体和新闻机构一样，我们曾经拥有实体和不可撤销的副本，现在我们­单纯地访问信息，然后将其丢弃。随着时间的推移，媒体组织更新其文章的内容已变得司空见惯。虽然这提供了一些­与以前的系统相比，它具有许多优点，最显着的是，它可以传播有关展开情况的实时更新，还可以使重要的上下文丢失或变得模糊。</p><h2 id="2-背景（Background）"><a href="#2-背景（Background）" class="headerlink" title="2. 背景（Background）"></a>2. 背景（Background）</h2><p>所有区块链创新都站在巨人的肩膀上，包括比特币本身，数据结构交响曲，分布式网络工作和密码学。我们也试图扩大空间，解决现有区块链网络的特定缺点，即存储，并采用一种新颖的交易速度方法。如今，大多数区块链技术都坚持认为，“全节点”必须维护整个区块链的副本以验证未来的交易，而使之成为可能的Merkle数据结构本身就是一项了不起的壮举，并增加了无与伦比的安全性，我们认为围绕此过程的一些性能增强可以减轻整个节点的同步负担，在第4节中介绍了解决块，节点和钱包同步的几种技术。</p><p>当涉及到存储数据时，完整的区块链要求可能甚至是现有区块链技术的障碍。在以太坊（一种去中心化的世界计算机）的情况下，使用其本机令牌的存储成本令人难以置信。 Arweave的主要动机是以与以太坊中表示的方式相同的方式实现永久，不变的存储。但是，高昂的费用使这种存储变得越来越不切实际。虽然可以在以太坊上存储数据，但是由于数据存储成本，先前的尝试是不切实际的。</p><p>其他区块链技术专注于改善节点之间的共识算法，特别是Stellar Lumens和APo和Neo等dPos架构。尽管这可以提高事务处理速度，但存储负担仍然是许多此类网络将面临的长期障碍。通过首先专注于解决存储问题，我们体验了一些性能增强功能，这些性能增强功能可用于促进高吞吐量货币交易。</p><h2 id="3-激励（Motivation）"><a href="#3-激励（Motivation）" class="headerlink" title="3. 激励（Motivation）"></a>3. 激励（Motivation）</h2><p>我们已经设计并实现了一个区块链网络，其中永久性的低成本存储已成为现实。将存储访问权纳入共识，并结合新颖的交易捆绑方法和任意大小的块，可创建高吞吐量的加密货币，该加密货币将比其他加密货币（如比特币[10]和以太坊[12]）有所改善。过去，档案（互联网或其他方式）通常由单个机构（甚至是个人）维护，因此容易受到两种主要形式的操纵。首先是通过在文档存储过程中修改文档[2]。第二个问题是，文档在进入存储之前可能已经被伪造或修改过[1]。例如，许多归因于苏格拉底的作品被认为是他的门徒们写的[6]。 Arweave解决了这两个问题。一旦将文档存储在组织上，就将其与组织上的每个其他块加密链接。这确保了任何尝试更改文档内容的尝试都会被网络检测到并拒绝。以这种方式，不可能破坏组织上的信息。 Arweave是Internet上可浏览的姊妹网络，可提供Internet迫切需要但目前缺乏的长期，永久数据存储功能。</p><p>Arweave系统的关键组件旨在让开发人员轻松构建与网络数据交互，创建和使用的应用程序。这些使用与语言无关的REST API构建的应用程序将充当网络中侦听网络的节点。这些应用程序的功能将是广泛而多样的，从分散和不变的社交网络到讨论网站和新闻聚合器。为了向编织提交信息，将需要少量令牌。这些代币将用于支付矿工在维护组织和网络方面的工作，以及抑制垃圾邮件的传播。这代表了对典型集中式存储系统的极大改进。同样，它使个人有能力确保自己关心的信息能够长期存在。随着网络和文档将增强令牌的价值，维持织法的动机也会增加。随着这些影响的加剧，我们期望Arweave代币将成为信息时代的宝贵资产。与大量重要文件密不可分且内在联系。</p><h2 id="4-技术（Technology）"><a href="#4-技术（Technology）" class="headerlink" title="4. 技术（Technology）"></a>4. 技术（Technology）</h2><p>Arweave建立在四项核心技术的基础上，这些技术可以共同在新的区块链上创建低成本，高吞吐量的永久存储。 这些创新是：</p><ul><li>区块编织（Blockweave）</li><li>访问证明（Proof of Access）</li><li>野火（Wildfire）</li><li>区块阴影（Blockshadows）</li></ul><p>虽然这些技术相互交织，但是每种技术在创建适用于快速事务处理和低成本永久性存储的新型网络方面都发挥着关键作用。</p><h3 id="4-1-区块编织（Blockweave）"><a href="#4-1-区块编织（Blockweave）" class="headerlink" title="4.1 区块编织（Blockweave）"></a>4.1 区块编织（Blockweave）</h3><p>大多数区块链的一个众所周知的特性是，必须存储每个区块以作为“完整节点”参与验证交易。 Arweave并非如此。</p><p>取而代之的是，Arweave引入了两个新概念，这些概念允许节点在不拥有整个链条的情况下完成关键的网络功能。这些概念中的第一个是块哈希列表，它是所有先前块的哈希的列表。这样可以验证旧块，并有效评估潜在的新块。这些概念的第二个是钱包列表，这是系统中所有活动钱包的列表。这样就可以在不占用最后一次交易使用的区块的情况下验证交易。使用这些由网络同步并可以由矿工下载的区块链列表和钱包列表，节点几乎可以立即加入网络并参与对组织的挖掘。</p><p>此外，Arweave使用“持续验证”系统，而不是让每个矿工在进入网络时都验证从基因块到当前块的整个块结构。当矿工加入Arweave网络时，他们将下载当前区块并从当前区块中检索区块哈希和钱包列表。由于这些区块链和钱包列表已通过每个区块的持续进行进行了连续验证，因此新矿工可以立即开始参与，而无需验证整个组织。当然，完全编织验证可用于希望执行该验证的任何节点。通过这种方式，矿工无需查找与钱包相关联的先前交易即可验证新交易。取而代之的是，矿工将只需要验证交易是否已由钱包拥有者的私钥正确签名。为了防止召回块伪造攻击，块哈希表的哈希将与每个新块一起分发。</p><p>Arweave - 一种类区块链的区块编织结构（Lightpaper）</p><p><img src="/images/arweave/image-20220412232151857.png" alt="image-20220412232151857">图1：blockweave数据结构的示意图，展示了到前一个区块和回调区块的链接。</p><h3 id="4-2-访问证明（Proof-of-Access）"><a href="#4-2-访问证明（Proof-of-Access）" class="headerlink" title="4.2 访问证明（Proof of Access）"></a>4.2 访问证明（Proof of Access）</h3><p>Arweaves共识机制基于访问证明（PoA）和工作证明（PoW）。虽然典型的PoW系统仅依赖于前一个块才能生成每个连续的块，但PoA算法会合并来自随机选择的前一个块的数据。结合区块编织数据结构，矿工不需要存储所有区块（形成一个区块链），而是可以存储任何先前的区块（由PoA和野火推动），从而形成区块编织，即区块编织。通过获取当前块的哈希值并计算其相对于当前块高度的模数，可以选择要合并到下一个块中的“调用块”。</p><p>调用块中的事务与在当前块中找到的事务一起进行哈希处理，以生成下一个块。当矿工找到合适的哈希后，他们会将新块与回调区块一起分发给网络的其他成员。这使网络的其他成员，即使没有自己的回调区块副本的那些成员，也可以独立地验证新块是否有效。</p><h3 id="4-3-野火（Wildfire）"><a href="#4-3-野火（Wildfire）" class="headerlink" title="4.3 野火（Wildfire）"></a>4.3 野火（Wildfire）</h3><p>作为数据存储系统，Arweave不仅需要存储大量信息的能力，而且还需要以最方便的方式提供对该数据的访问。此外，Arweave系统的重要组成部分是在请求时对数据进行无成本的访问。随后，Arweave增加了一层激励措施，以鼓励矿工自由共享数据。</p><p>Wildfire是一种系统，它通过使网络上数据请求的快速满足成为参与的必要部分，从而解决了分散式网络中数据共享的问题。 Wildfire通过在每个节点本地创建一个排名系统来进行工作，该排名系统确定新块和事务向对等对象分发的速度如何，基于它们对请求进行响应并接受来自其他对象的数据的速度。对等体按其等级顺序服务，而性能不佳的对等体则被从网络中黑名单中删除。从经济上激励同伴，使他们在彼此的排名中保持良好的位置，以便他们可以花费最大的时间进行有效的挖掘。</p><p>Arweave - 一种类区块链的区块编织结构（Lightpaper）</p><p><img src="/images/arweave/image-20220412232319579.png" alt="image-20220412232319579"></p><p>图2：野火系统示意图。 每个节点根据这些对等点之前对它们的表现进行评估，对其对等点进行排名。<br>这极大地鼓励系统中的节点以对其他对等方尽可能最友好的方式运行，而不会给正在接收数据的人，甚至可能是一次性请求的那些人带来代价。 更进一步，它创建了一种网络拓扑，该拓扑适合于最有效的全局路由，因为首选了允许在系统中快速传输新数据的连接。 实际上，野火机制构建了一个网络拓扑，该拓扑映射了Internet的底层物理连接基础，以适应其架构随时间的变化。 总体而言，野火系统可确保新块的高速分发，并以较短的延迟保持数据可用。</p><h3 id="4-4-区块阴影（Blockshadows）"><a href="#4-4-区块阴影（Blockshadows）" class="headerlink" title="4.4 区块阴影（Blockshadows）"></a>4.4 区块阴影（Blockshadows）</h3><p>在传统的区块链系统中，当挖掘一个新块时，无论一个节点已经拥有多少块数据，每个完整的块都会分配到网络中的每个节点。这不仅浪费大量数据，而且极大地降低了网络就块达成共识的速度。因此，Arweave引入了一种新技术，即块影子，它不仅可以最大程度地减少数据浪费，而且可以实现快速的块共识和巨大的事务吞吐量。</p><p>Blockshadowing的工作原理是部分取消来自块的事务，并且仅在节点之间发送最小的块“影子”，该影子允许对等方重建完整的块，而不是传输完整的块本身。这些区块影子专门包含钱包列表和哈希列表的哈希，并且代替区块内的交易，仅包含交易哈希的列表。根据这一信息（可能只有几千字节），一个已经在该区块中拥有所有交易的节点以及一个最新的哈希和钱包列表可以重建几乎任意大小的整个区块。为了促进这一点，节点还将立即彼此共享事务，但是只有在它们高度确定网络中的其他节点也具有事务处理后，才尝试将事务放置在一个块中。</p><p>这个区块集散系统的结果是一个快速，灵活的区块分配系统，该系统可以使交易以尽可能快的速度在网络上分布，并且可以以接近网络的速度达成共识。此外，该系统可确保当网络使用率很高时，交易费用不会显着增加，并且乐观的100mbps网络上的交易吞吐量的理论限制为每秒约5000笔交易。</p><h3 id="4-5-民主内容政策（Democratic-Content-Policy）"><a href="#4-5-民主内容政策（Democratic-Content-Policy）" class="headerlink" title="4.5 民主内容政策（Democratic Content Policy）"></a>4.5 民主内容政策（Democratic Content Policy）</h3><p>为了支持网络中各个参与者的自由以控制他们存储的内容，并允许整个网络以民主方式拒绝受到广泛谴责的内容，Arweave软件提供了一个黑名单系统。每个节点主节点都有一个（可选）黑名单，其中包含例如它不希望存储的某些数据的哈希值或子字符串，并且永远不会写入与此匹配的磁盘内容。这些黑名单可以由个人建立，也可以通过协作建立，也可以从其他来源导入。</p><p>在本地级别，这些黑名单允许节点控制自己的内容，但是这些本地拒绝的总和也会创建网络范围的内容拒绝。超过一半以上的网络拒绝的内容不仅会被这些单个节点中的每一个拒绝，而且还将被整个网络整体拒绝。这创建了一个民主的全网络内容拒绝系统，该系统可以将各种文化和观点中的黑名单合并为一个普遍删除的微小的特定内容黑名单。这个接近普遍，民主的黑名单使网络不受少数行为者的干扰，同时仍允许其以民主方式保护自己的自由。</p><h2 id="4-6-讨论（Discussion）"><a href="#4-6-讨论（Discussion）" class="headerlink" title="4.6 讨论（Discussion）"></a>4.6 讨论（Discussion）</h2><h3 id="4-6-1-存储池（Storage-Pools）"><a href="#4-6-1-存储池（Storage-Pools）" class="headerlink" title="4.6.1 存储池（Storage Pools）"></a>4.6.1 存储池（Storage Pools）</h3><p>对Arweave的一种潜在的理论攻击已经变得非常大，那就是矿工可能会合作维护一个组织的单个副本，他们都可以使用这些副本来检索召回块。 虽然这种行为乍看起来似乎是问题，但事实并非如此。 如果此类“存储池”被大部分矿工雇用，那么其他矿工存储稀有矿块的动机就会增加。 这是因为，如果集中存储区不可用，则当将来该稀有块成为撤回块时，具有稀有块副本的矿工将很可能获得奖励。 这种自私的行为为网络提供了风险抵销功能，该功能会随着数据丢失（由集中存储池引起）的可能性增长而扩展。</p><h2 id="5-构建App（Building-Apps）"><a href="#5-构建App（Building-Apps）" class="headerlink" title="5. 构建App（Building Apps）"></a>5. 构建App（Building Apps）</h2><p>可以使用简单的REST API构建使用组织的应用程序。 REST端点是HTTP，可以直接访问网络，因此任何Arweave钱包都可以读取和写入数据。 客户只需要通过Chrome扩展程序或具有Arweave钱包集成功能的本机应用程序将其Arweave钱包带入网站，即可从网络读取数据或向网络写入数据。 可以在组织之上构建几种体系结构。</p><h3 id="5-1-客户端-服务器架构（Client-Server-Architecture）"><a href="#5-1-客户端-服务器架构（Client-Server-Architecture）" class="headerlink" title="5.1 客户端-服务器架构（Client-Server Architecture）"></a>5.1 客户端-服务器架构（Client-Server Architecture）</h3><p>传统的Web或本机应用程序具有客户端-服务器体系结构。在云上运行的服务器将被“启用Arweave”，与一个或多个Arweave节点进行交互，代表客户端读取和写入数据。这些服务可以是将客户端作为访问者的网站，也可以是将客户端请求传递给开发人员操作的服务器的本机应用程序。这些服务器将需要维护AR令牌的浮动，以确保可以处理写入数据的请求。使用该架构从编织读取数据仍然是免费的。</p><p>该架构的获利潜力很简单。开发人员将需要通过广告，每月订阅或直接付款来获得更大的价值，而不是使用其为存储提供动力的AR令牌数量。永久性不可变存储有许多应用。例如，存储抗量子，加密的法律案例文件，身份或医疗记录。尽管某些法规需要适应敏感信息的存储，地理范围和被遗忘的权利，但也可以通过加密和密钥管理来缓解这种情况。几个创收模型可以在组织的顶部分层，其主要价值主张是链上永久不可变的存储。</p><h3 id="5-2-无服务器架构（Serverless-Architecture）"><a href="#5-2-无服务器架构（Serverless-Architecture）" class="headerlink" title="5.2 无服务器架构（Serverless Architecture）"></a>5.2 无服务器架构（Serverless Architecture）</h3><p>客户端可以通过启用Arweave的浏览器访问应用程序，而应用程序可以自身运行。由于浏览器的普及和Web技术的普及，使用HTML / CSS / JS将这些应用程序存储为标准前端Web应用程序是最有意义的。但是，如果客户端的本机应用程序包含针对不同语言（例如LLVM字节码）或脚本语言（如Python）的解释器/解析器，则它们可以在客户端上运行，并且可能会受益于Web应用程序中的相同可升级性。</p><p>开发人员不仅可以将无服务器的应用程序部署到Arweave，而且这些应用程序还可以将持久性和可证明状态写入网络。由于Arweave没有施加特定的数据结构，因此开发人员可以自由地以对他们来说最有意义的格式存储数据。如果该应用程序最好通过高度优化的Merkle结构（例如以太坊虚拟机（EVM）中找到的结构）来满足，则可以轻松地将其实现。如果开发人员正在寻找更多的文本Blob样式存储，那么这也是微不足道的。</p><p>无服务器应用程序非常有趣，因为它们可以写入自己的数据。例如，基于分布式计算将允许训练神经网络存储其结果，并可能与其他网络共享其结果模型。</p><h3 id="5-3-基于事件的（Event-Based）"><a href="#5-3-基于事件的（Event-Based）" class="headerlink" title="5.3 基于事件的（Event Based）"></a>5.3 基于事件的（Event Based）</h3><p>在Twitter成立之初，便有了蓬勃发展的家庭手工业应用程序生态系统，而开发人员则在“ firehost” API的基础上开发，这些API将推文流化为任何愿意付费访问的人。 情况已不再如此，在Facebook Cambridge Analytica惨败之后，这些向客户提供数据分析的服务的许多“可信赖的合作伙伴”都被任意关闭。</p><p>Arweave是一个分散的公共数据网络，因此，除了被民主拒绝的内容外，它永远不会审查数据访问或数据本身。 这意味着开发人员可以自由地在Arweave之上进行构建，并且可以使用REST API侦听传入的数据。 触发事件后，侦听器将触发订阅了这些事件的客户端的相应函数调用。 开发人员不必担心会受到限制或关闭，因为网络受到激励以向他们提供对数据馈送的可靠访问。</p><h3 id="5-4-无信任和可证明（Trustless-and-Provable）"><a href="#5-4-无信任和可证明（Trustless-and-Provable）" class="headerlink" title="5.4 无信任和可证明（Trustless and Provable）"></a>5.4 无信任和可证明（Trustless and Provable）</h3><p>可以对应用程序体系结构进行设计，以便轻松实现需要存储并保证防篡改的信息。 此外，可证明公平的运行时代码可以存储在组织上，并由客户端直接解释。 客户端使用内容的事务ID，可以在计算之前验证编织中的有效负载，并确保它们运行的代码既不受信任又可以证明是公平的，即与其他客户端运行的代码相同。 这为服务于其他区块链网络的无信任随机数生成器和其他基于oracle的服务开辟了有趣的可能性。</p><h2 id="6-用例（Use-Cases）"><a href="#6-用例（Use-Cases）" class="headerlink" title="6. 用例（Use Cases）"></a>6. 用例（Use Cases）</h2><p>永久存储有几个用例。 具体而言，法规要求将文件存档长达一定年限。 可证明的媒体报道，学术研究和不变的记录在我们回声室和假新闻泛滥的现代世界中变得越来越重要。</p><h3 id="6-1-真实性（Authenticity）"><a href="#6-1-真实性（Authenticity）" class="headerlink" title="6.1 真实性（Authenticity）"></a>6.1 真实性（Authenticity）</h3><p>法律体系常常与文件真实性的诉讼纠缠在一起。 Arweave通过提供来自作者的任何数字内容的不确定且可验证的存储来解决此问题。 2017年，特拉华州裁定在法院诉讼程序中可以接受区块链证据。 这些记录可能会大大加快有关艺术归属和知识财产之争的争议。 对于创意经济而言，效果是双重的，使艺术家可以将自己的作品立即转让给他人，并避免琐碎的诉讼。</p><h2 id="7-结论（Conclusion）"><a href="#7-结论（Conclusion）" class="headerlink" title="7. 结论（Conclusion）"></a>7. 结论（Conclusion）</h2><p>我们提出了一个新的区块链网络，该网络支持低成本的不可变数据存储和高吞吐量的加密货币。通过使用一种称为blockweave的类似于区块链的新数据结构，可以实现Arweave协议。通过区块隐藏灵活的大小交易区块分配；一种新的共识机制，即减少对工作证明的依赖度，称为访问证明；以及称为Wildfire的自我优化网络拓扑。就像比特币网络一样，我们在隔离方面的技术进步并不是十分复杂。但是，当结合起来形成整个网络时，紧急行为非常强大。从测试网的结果可以看出，在公共的，无许可的和分散的网络协议上，安全，可靠和不变的数据存储是可能的。除了数据存储期限外，任意大小的块都使安全的高吞吐量加密货币成为可能，而无需诉诸复杂的共识机制，例如dBFT或dPoS。</p><p>Arweave通过其REST API紧密地连接到Internet的结构中，并且正在使用Arweave主网建立一些创收业务。 Arweave与其他流行的加密货币之间的桥梁，安全的计算和智能合约协议将使低成本和永久性的数据存储轻松集成到分散式应用程序的技术堆栈中。一个全面全球化的信息和金融交流世界需要永久记录。通过结合加密技术和分布式系统，我们为这些永久记录提供了基础。我们希望Arweave将成为现有互联网协议（例如，万维网）的必要伴侣。与他人合作，建立更加开放和透明的未来。</p><h2 id="8-引用（Reference）"><a href="#8-引用（Reference）" class="headerlink" title="8. 引用（Reference）"></a>8. 引用（Reference）</h2><ol><li>Aweave白皮书地址：<a href="https://www.arweave.org/files/arweave-lightpaper.pdf">https://www.arweave.org/files/arweave-lightpaper.pdf</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Arweave </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用密码学库</title>
      <link href="/2022/03/28/cryptography/%E5%AF%86%E7%A0%81%E5%AD%A6%E5%BA%93%E6%80%BB%E7%BB%93/"/>
      <url>/2022/03/28/cryptography/%E5%AF%86%E7%A0%81%E5%AD%A6%E5%BA%93%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="PRIVATE FILE">    <label for="pass">PRIVATE FILE</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">U2FsdGVkX1+S84OPuFs/1vLvQqrgH4CQN/Tgb81EzWSjeZ+Xfvgmr9zn9wXkob60GyjXJZ9JWZuRZYwCQU1yCXB6RXHmYbcP9VNwxC5zLcYHGyN6/IrbgNJMkTcQY/v8Jlbu/mWmLn6JmDiZErbj8GqM34qHKKuq7i91R07Ey9F2oV3VfEE7nVWFtF5wKN9MPcMk99VyEQTeDEO0Pyid2RIrCCxqCLsHoGVo6K6qR4UepNvsiam/aWwPR7KDhWIm8Q+UQO4GakpdRKjE5uYIdsej1gBkuxub8INUCYo3HTJMfKdFhqH1P5rBxr4xmCPPLbHYEhdtVr40ME+iozFioFXfjMTmam6kCe5Qhqle1SHyRYOp3ig86S9PKNjRHSQVbpReczy1vkc3gI4Fw+0S15qAbcTQ53shSfRUV2aePP7kNjaucJhKWJAWgsO0t+E+nP/gdn8AZqnSruG/L1ZZxSQnPpVQmco6N9gBwC7J3SNs1FjDrNGqcarfXxC3L1jn+kljsKop5gEvcSLHg6hBZOiWB5LhSG/HY9XyI2kHLJ4OgVyU8LdUePluMrEqi7idmZc+wV5KGx1haH17wZsGJnn8vlzWB7yXsYtNXm4hywI8QR5poximrSQBhtXWsghFuzcj1pya6JUti14+zFoxteqRlU40ZaCwY3GDQATvyG3DoFxJDQiIFkhYyC1e4SIWpW3EtYLBlCFbO9pMELA9gcUlUDRmhmzAFIed5b7fx/KOWcItCgQoCOBpKd+D9hyTm2dvcl5yV9UaYoNzcP8ydyfSO5MkGDySGkqk+XHgNl5DzbsJ0vQ8FzovTBtVFWhMvIBqXHRHUhsxDbFOH1lkNBW3a/ZW7NvttkmTX/CNBhm26Tt7m30SVHxcjkeR75fyNV+UrMvJ6DI42L9YJC936oSG/g9K9g8r6JoH8Ue9LQSffpIjCIMuBsrWJfNasup2Nk0Slv7uS9oYeXAQ23xQyjz/rhr5gchVTW+P5iRlDB2CmBJTNWisStHARqezCGxsIkoOuVJ3VxgHzzQ7r71PwxALqA7FJXzg3emfy+5KlmEEqLW65dEjONX2QznknvZRBbu17JRvXBJPK4xs/t0u7q+oDYIknqT7bUcNE+uIFTyehsEeOwNQ6iv4MVQ7DT4UD6ZOFDi+eu/3eM9j0Zsp/Ruvt4T7LuG3fOIEvUMLuoYXwqXUX9q9yRaMvZx9kqJCF+R8tfOFf2Nb+iQEI0LFztlt3uRlLToRJE9ybwO7LJdlY7TLBadtN/7H1A+DAwfRF5bP/hYXjU2Gx1B6ae38SGWPTVf6RyF5JUK/6ICi+7rgg+avy7sJ0I4xdcyBzlYHr8ydHDrnudEOFTbBwep8S2gWbKwSeaF45bRPjtR2kc7fYgvD7pyv6JkfzzTlzzxG/T6OhBL9id5Abygp3UxP7rQG0Z7R8R3koMSYDLJFq+ox5fKuReHEt7g5HwOaKW9B2k+Ut72GAYcSeqjbE140YpkuTiIEf+OJQeLsXKvEeXr+9GmrEJeamA1ODE1paOExdxixWkZ2sY0rTQA8q8jUGtEl9hJ+IM1VIKB3OF0oj+mgByyjZ57PMXkg8WeskNGnGZBTADB11edJDAjyku4uK8exlAqznV5fQxhQU+dPiJF746dK0w08ezjjL6I3IetEPWJiMZAsfP1OsZ3sDA/7Z4r8/c/zkf8mJF3ttmQiVLGcd9bVfGlpmHVO5I1UReRDXcFK+LnMfbsZA6VsJRFL7Xk70nx4MVJWZF9GQJcYYUcISx6ID1b4sMe0PNeJcqjeixr04SvJshqowtnrlqN1Decfa7l+ynk8tzimwXE5gCRmKUpmg2pe9Fv6PBhVxKRCHrg5aHqhKnVNnSg9Qse/Cg==</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 密码学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>30分钟创建一条区块链(二)</title>
      <link href="/2022/03/05/blockchain/other/30%E5%88%86%E9%92%9F%E5%88%9B%E5%BB%BA%E4%B8%80%E6%9D%A1%E5%8C%BA%E5%9D%97%E9%93%BE(%E4%BA%8C)/"/>
      <url>/2022/03/05/blockchain/other/30%E5%88%86%E9%92%9F%E5%88%9B%E5%BB%BA%E4%B8%80%E6%9D%A1%E5%8C%BA%E5%9D%97%E9%93%BE(%E4%BA%8C)/</url>
      
        <content type="html"><![CDATA[<h2 id="将区块链API化"><a href="#将区块链API化" class="headerlink" title="将区块链API化"></a>将区块链API化</h2><p>在这个区块链中，我们想要实现三个API，分别是</p><ul><li>/api/mine：节点使用这个方法来挖掘新的区块</li><li>/api/transactions/new: 账户使用这个方法来建立新的交易</li><li>/api/chain: 返回当前的区块链</li></ul><p>为了复用我们在上篇写好的代码，我们首先安装express.js，并创建一个新文件 app.js。express是一个基于node的http框架，它可以允许我们接受通过http协议传输的节点信息。我们还需要body-parser帮助我们解码节点发送过来的信息。</p><h2 id="实现分布式共识"><a href="#实现分布式共识" class="headerlink" title="实现分布式共识"></a>实现分布式共识</h2><p>以上我们已经实现了一个单机版的区块链了，但区块链之所以有用，是因为它能被部署到多个节点上去，并且所有节点都能够相互更新，实现分布式的共识。这样的机制保证了我们能够抵御double spending attack以及确保只有一条区块链在运行。</p><p>为了实现我们的分布式共识，我们首先需要知道网络上其他的节点在哪里。仿照Ethereum的 Node Discovery Protocol，我们可以做一个类似的搜索节点的功能和节点注册功能</p><pre><code class="javascript">_app.post('/api/nodes/register', (req, res) =&gt; {    // 注册节点    let newNode = _.pick(req.body, ['ip', 'port']);    neighbors.push(newNode);    console.log('new node detected. Node info: ' + JSON.stringify(newNode));    res.send({        message: 'Node ' + newNode.ip + ':' + newNode.port + ' is added to my network'    });});</code></pre><h3 id="共识实现-解决冲突链"><a href="#共识实现-解决冲突链" class="headerlink" title="共识实现: 解决冲突链"></a>共识实现: 解决冲突链</h3><p>知道了附近的节点在哪，我们就可以开始实现我们的共识算法。共识算法的第一部分需要我们能够辨别出最长且有效的链，我们可以通过在之前写的区块链模型里加入新的函数实现。</p><p>在 <code>app.js</code>中，我们可以在每次挖矿之后都向附近的节点广播，以解决冲突链。首先我们需要建立一个新的端点 <code>/api/nodes/resolve</code>。建立好端点之后我们需要在挖矿之后对所有的邻居进行广播。</p><p>这样setup之后，我们的节点在每一次挖矿的时候都会对附近的邻居进行广播并寻求consensus。当然，我们还可以设定定时任务来更高频的进行广播。另外，我们也没有对收到的chain进行电子验证，没有动态化的寻找相邻节点，没有将每一个transaction广播，以及一系列可以完善的地方，不过在这篇教程当中我们就不继续下去了。</p><pre><code class="javascript">_app.get('/api/mine', (req, res) =&gt; {    // 挖矿    myChain.createBlock();    let p = new Promise((resolve) =&gt; resolve());    for (let i of neighbors) {        let resolveUri = 'http://' + i.ip + ':' + i.port + '/api/nodes/resolve';        console.log("send resolve to: " + resolveUri);        p.then(() =&gt; rp({            uri: resolveUri,            method: 'POST',            json: true,            body: {'chain': myChain}        })).then((res) =&gt; {            // 同步最长链            myChain.resolveChain(JSON.parse(res.body)["chain"]);        });    }    p.then(() =&gt; {        res.send({            message: 'A new block is mined, and conflict is resolved',            content: myChain.lastBlock()        });    });});</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上我们实现了一个简单的区块链，虽然这个区块链简陋且不安全，但是我们能够成功将它部署到多个节点上，实现了最基本的区块链的功能。</p><p>完整代码：<a href="https://github.com/zhangzhishun/sugar-blockchain-js">代码</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://mp.weixin.qq.com/s/6jwIj_m86dpGk62biEJyIA">30分钟自己写一条区块链(一)</a></li><li><a href="https://mp.weixin.qq.com/s/UbLx2mHEb9OyPeJBwP2bvg">30分钟自己写一条区块链(二)</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 部署文档 </tag>
            
            <tag> Other </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>30分钟创建一条区块链(一)</title>
      <link href="/2022/02/28/blockchain/other/30%E5%88%86%E9%92%9F%E5%88%9B%E5%BB%BA%E4%B8%80%E6%9D%A1%E5%8C%BA%E5%9D%97%E9%93%BE(%E4%B8%80)/"/>
      <url>/2022/02/28/blockchain/other/30%E5%88%86%E9%92%9F%E5%88%9B%E5%BB%BA%E4%B8%80%E6%9D%A1%E5%8C%BA%E5%9D%97%E9%93%BE(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<p>如何从技术上实现一条区块链？<br>首先，这里假定读者有基本的编程能力，虽然本文用了Javascript来写，但掌握任意一门编程语言的读者阅读起来应该不会有任何难度。</p><h2 id="开发准备"><a href="#开发准备" class="headerlink" title="开发准备"></a>开发准备</h2><p>我们首先需要安装最新版的Node.js</p><h2 id="第一步，搭建区块链模型"><a href="#第一步，搭建区块链模型" class="headerlink" title="第一步，搭建区块链模型"></a>第一步，搭建区块链模型</h2><p>我们首先来搭一个能够新建区块，创建交易的区块链的模型。</p><pre><code class="javascript">'use strict';//定义一个class，叫BlockChain，每一个区块链都是这个class的实例class BlockChain {    constructor() {        this.chain = []; // 储存所有区块        this.difficulty = 4; // 挖矿的难度    }    isProofValid(tentativeBlock) {        // 这里我们判断newProof是不是一个合法的proof的方法是    }    createBlock(transaction, previousHash = undefined) {        // 创造一个新区块    }    createTransaction(sender, receiver, value) {        // 创建一个交易    }    static hash(block) {        // 对一个区块进行哈希:    }    lastBlock() {        // 取得链上的最后一个区块    }    miner() {        // 挖矿程序    }}</code></pre><p>这里要解释一下区块(block)和交易(transaction)各自长什么样，虽然不同区块链的区块模型有很大差异，但最基本的一些元素都是相通的。一个最基本的区块大概长下面这样：</p><pre><code class="javascript">var block = {       timestamp: 1516245715528,     id: 0,    proof: 786453290000,    previousBlockHash: "12f79cda4fb3f084531de2034e6b4acf",    transactions: [{        sender: "0xca35b7d915458ef540ade6068dfe2f44e8fa733c",        receiver: "0x14723a09acff6d2a60dcdf7aa4aff308fddc160c",        value: 100    }]}</code></pre><p>可以看到，一个区块包含了它被挖出来的时间戳(timestamp)，它在区块链里的位置(id)，它的证明(proof, 更多的会在之后讲到)，前一个区块的整体哈希值(previousBlockHash)，包含的交易(transactions)。 作为一个最基本的交易模型，每一个交易只包含了发送者的地址(sender)，接受者的地址(receiver)，以及这次交易的价值(value)。</p><h2 id="第二步，实现基本功能"><a href="#第二步，实现基本功能" class="headerlink" title="第二步，实现基本功能"></a>第二步，实现基本功能</h2><p>工具函数<br>这里我们首先实现一个工具函数Hash(block), 它会帮助我们将一个区块进行哈希。这个函数会在我们进行挖矿(发掘新区块)的时候用到。</p><pre><code class="javascript">static hash(block) {    // 对一个区块进行哈希:    // 现将block 转换成base64    // 将得到的结果进行SHA哈希    const blockStr = JSON.stringify(block);    const blockB64 = new Buffer(blockStr).toString("base64");    const newHash = crypto.createHash("sha256");    newHash.update(blockB64);    return newHash.digest("hex");}</code></pre><p>这个函数将一个区块，也就是一个Javascript object，哈希成一段字符串。我们使用了crypto这个工具，在最新版的Node.js里面已经是内置了，所以我们并不需要安装它。</p><p>创建一个新交易<br>下一步，我们实现创建新交易的方法。</p><pre><code class="javascript">createTransaction(sender, receiver, value) {    // 创建一个交易    // 根据提供的sender, receiver地址，以及转账的价值，建立一个交易    // 并把它加入到我们的区块链里    const transaction = {        sender: sender,        receiver: receiver,        value: value    };    this._packTransactions.push(transaction);    return this.miner();}</code></pre><p>非常直观，我们只是创建了一个object，加入到区块链里并返回而已。</p><p>创建一个新区块<br>我们现在来实现创建一个区块的代码。当我们的区块链连一个区块也没有的时候，我们需要建立第一个区块(genesis block)，这一点我们在constructor里面实现。</p><pre><code class="javascript">constructor() {    this.chain = []; // 储存所有区块    this.difficulty = 4; // 挖矿的难度    this.createBlock(["Genesis Block"], 1); // 创建第一个区块    this._packTransactions = []; // 当前需要打包的数据}createBlock(transaction, previousHash = undefined) {    // 创造一个新区块    // 一开始的proof是0，不一定是有效的，所以我们需要mineProof来找到有效的proof    let block = {        timestamp: Date.now(),        id: this.chain.length,        proof: 0,        previousBlockHash: previousHash || this.constructor.hash(this.lastBlock()),        transactions: transaction    };    const hash = this.mineProof(block);    this.chain.push(block);    return hash;}</code></pre><p>在创建一个新区块的时候，我们用了当前时间的时间戳，以现在区块链的长度作为id，初始的proof设置为0(proof会在下一步详细讲到)，并将上一个区块整体进行哈希并赋值给previousBlockHash。在创建genesis 区块的时候，我们将previousBlockHash设置为1。 为了便于理解，我们建立新区块的时候没有附上任何交易，实际的情况是矿工可以自主选择包含哪些交易，并需要对这些交易进行处理得到一个默克尔树。</p><h2 id="理解挖矿：找到有效的Proof"><a href="#理解挖矿：找到有效的Proof" class="headerlink" title="理解挖矿：找到有效的Proof"></a>理解挖矿：找到有效的Proof</h2><p>读者朋友们应该都听说过工作量证明(Proof of Work)，POW是区块链中用来创造区块的核心算法或者机制。POW本身的目的是为了找到一个数字来解决一个数学问题，而找到这个数字的难度是越来越高的，但一旦找到之后，要证明它解决了这个数学问题又是非常容易的，任何人都能很快做到。 当然除了Proof of Work之外，我们还有Proof of Space, Proof of Stake，在代码里我们就用proof来代表找到的这个数字。 那么这个数学问题到底是什么呢？我们用一个例子来回答。</p><p>给定一个数字A，我们想找到数字B，使得Hash(A<em>B)的结果C的最后1位等于0。也就是说，C可以是Hash(A</em>B)=2ba83…6d0，因为它的最后一位是0。</p><h2 id="实现挖矿"><a href="#实现挖矿" class="headerlink" title="实现挖矿"></a>实现挖矿</h2><p>知道了如何挖矿之后，我们将上面的代码融合到我们的区块链模型里。</p><pre><code class="javascript">    isProofValid(tentativeBlock) {        // 这里我们判断newProof是不是一个合法的proof的方法是        // 将整个区块进行哈希        // 如果得到的散列值指的最后n位都是0，那么这是一个valid proof        // 其中，n = difficulty        const result = this.constructor.hash(tentativeBlock);        return result.substr(result.length - this.difficulty) === '0'.repeat(this.difficulty);    }    mineProof(tentativeBlock) {        console.log("miner block start: " + JSON.stringify(tentativeBlock));        while (!this.isProofValid(tentativeBlock)) {            tentativeBlock.proof += 1; // 如果不是可用的proof，我们就接着枚举        }        const hash = this.constructor.hash(tentativeBlock);        console.log("miner block success. Hash: " + hash);        return hash;    }    createBlock(transaction, previousHash = undefined) {        // 创造一个新区块        // 一开始的proof是0，不一定是有效的，所以我们需要mineProof来找到有效的proof        let block = {            timestamp: Date.now(),            id: this.chain.length,            proof: 0,            previousBlockHash: previousHash || this.constructor.hash(this.lastBlock()),            transactions: transaction        };        const hash = this.mineProof(block);        this.chain.push(block);        return hash;    }    miner() {        // 挖矿程序        if (this._packTransactions.length &gt; 0) {            const hash = this.createBlock([this._packTransactions[this._packTransactions.length - 1]]);            if (hash) {                this._packTransactions.pop();                return hash            }        }    }</code></pre><p>完整代码：<a href="https://github.com/zhangzhishun/sugar-blockchain-js/blob/master/blockchain.js">blockchain</a></p><p>参考：</p><ol><li><a href="https://mp.weixin.qq.com/s/6jwIj_m86dpGk62biEJyIA">30分钟自己写一条区块链(一)</a></li><li><a href="https://mp.weixin.qq.com/s/UbLx2mHEb9OyPeJBwP2bvg">30分钟自己写一条区块链(二)</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 部署文档 </tag>
            
            <tag> Other </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NFT框架 0xcert ERC721源码分析</title>
      <link href="/2022/02/26/blockchain/nft/NFT%E6%A1%86%E6%9E%B6-0xcert-ERC721%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2022/02/26/blockchain/nft/NFT%E6%A1%86%E6%9E%B6-0xcert-ERC721%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>ERC721官方简介是：A standard interface for non-fungible tokens, also known as deeds.也叫非同质代币，或者不可置换代币（NFTs）。提到ERC721，一个好理解的例子就是<a href="https://link.segmentfault.com/?enc=C1N3804jiPfa4j/kbVqQeA==.qKJ3FJzSnC5Qcs2rB15IvrOOttPxdU0dtue8Pk75gJ0=">CryptoKitties迷恋猫</a> ,每一只猫都是独一无二的拥有不同基因，有收藏价值属性。ERC721对于虚拟资产收藏品领域会有很好的应用价值和市场需求。</p><p>ERC721是以太坊和 Wanchain 区块链的<a href="https://github.com/ethereum/EIPs/blob/master/EIPS/eip-721.md">ERC-721不可替代令牌标准的完整参考实现。</a>它还与其他 EVM 兼容链兼容，如 Binance Smart Chain (BSC)、Avalanche (AVAX) 等。这是一个开源项目，完成了<a href="https://hardhat.org/">Hardhat</a>测试。</p><p>此项目的目的是为任何想要在以太坊和 Wanchain 区块链上使用和开发不可替代代币的人提供一个良好的起点。您可以使用经过多次审核的代码，而不是自己重新实现 ERC-721，此实现比 ERC-721 标准更具限制性，因为它不支持<code>payable</code>开箱即用的函数调用。但是，您可以自己添加它。</p><p>合约列表：</p><ul><li><a href="https://github.com/nibbstack/erc721/blob/2.6.1/src/contracts/tokens/nf-token.sol"><code>nf-token.sol</code></a>：这是基本的 ERC-721 token实现（支持 ERC-165）。</li><li><a href="https://github.com/nibbstack/erc721/blob/2.6.1/src/contracts/tokens/nf-token-metadata.sol"><code>nf-token-metadata.sol</code></a>：这为代币合约实现了可选的 ERC-721 元数据功能。它实现了一个token名称、一个符号和一个指向公开暴露的 ERC-721 JSON 元数据文件的不同 URI。</li><li><a href="https://github.com/nibbstack/erc721/blob/2.6.1/src/contracts/tokens/nf-token-enumerable.sol"><code>nf-token-enumerable.sol</code></a>：这实现了对枚举的可选 ERC-721 支持。如果您想知道代币的总供应量、按索引查询代币等，这很有用</li></ul><p>合约类、接口之间的继承关系：</p><p><img src="/images/open-zeppelin-erc721/image-20220226171652608.png" alt="image-20220226171652608"></p><h2 id="1-SupportsInterface"><a href="#1-SupportsInterface" class="headerlink" title="1. SupportsInterface"></a>1. <a href="https://github.com/nibbstack/erc721/blob/2.6.1/src/contracts/utils/supports-interface.sol">SupportsInterface</a></h2><p>实现检测智能合约接口的标准。</p><p>例如在合约的构造函数定义如下内容指定检测标准：</p><pre><code class="javascript">supportedInterfaces[0x01ffc9a7] = true; // ERC165supportedInterfaces[0x780e9d63] = true; // ERC721EnumerablesupportedInterfaces[0x5b5e139f] = true; // ERC721MetadatasupportedInterfaces[0x80ac58cd] = true; // ERC721</code></pre><p>源码：</p><pre><code class="javascript">// SPDX-License-Identifier: MITpragma solidity ^0.8.0;import "./erc165.sol";/** * @dev Implementation of standard for detect smart contract interfaces. */contract SupportsInterface is  ERC165{  /**   * @dev Mapping of supported intefraces. You must not set element 0xffffffff to true.   */  mapping(bytes4 =&gt; bool) internal supportedInterfaces;  /**   * @dev Contract constructor.   */  constructor()  {    supportedInterfaces[0x01ffc9a7] = true; // ERC165  }  /**   * @dev Function to check which interfaces are suported by this contract.   * @param _interfaceID Id of the interface.   * @return True if _interfaceID is supported, false otherwise.   */  function supportsInterface(    bytes4 _interfaceID  )    external    override    view    returns (bool)  {    return supportedInterfaces[_interfaceID];  }}</code></pre><h2 id="2-ERC721"><a href="#2-ERC721" class="headerlink" title="2. ERC721"></a>2. <a href="https://github.com/nibbstack/erc721/blob/2.6.1/src/contracts/tokens/erc721.sol">ERC721</a></h2><p>ERC721合约定义了基本的接口方法：</p><ul><li><p>safeTransferFrom：转移代币所有权</p></li><li><p>transferFrom：转移代币所有权</p></li><li><p>setApprovalForAll：授权operator具有所有代币的控制权</p></li><li><p>balanceOf：返回owner的代币数量</p></li><li><p>ownerOf：根据tokenId返回代币持有者address</p></li><li><p>getApproved：查询tokenId的授权人operator address</p></li><li><p>approve 授权tokenId给地址to</p></li><li><p>isApprovedForAll：查询一个地址是否为另一个地址的授权操作者。</p></li></ul><p>源码：</p><pre><code class="javascript">// SPDX-License-Identifier: MITpragma solidity ^0.8.0;/** * @dev ERC-721 non-fungible token standard. * See https://github.com/ethereum/EIPs/blob/master/EIPS/eip-721.md. */interface ERC721{  /**   * @dev Emits when ownership of any NFT changes by any mechanism. This event emits when NFTs are   * created (`from` == 0) and destroyed (`to` == 0). Exception: during contract creation, any   * number of NFTs may be created and assigned without emitting Transfer. At the time of any   * transfer, the approved address for that NFT (if any) is reset to none.   */  event Transfer(    address indexed _from,    address indexed _to,    uint256 indexed _tokenId  );  /**   * @dev This emits when the approved address for an NFT is changed or reaffirmed. The zero   * address indicates there is no approved address. When a Transfer event emits, this also   * indicates that the approved address for that NFT (if any) is reset to none.   */  event Approval(    address indexed _owner,    address indexed _approved,    uint256 indexed _tokenId  );  /**   * @dev This emits when an operator is enabled or disabled for an owner. The operator can manage   * all NFTs of the owner.   */  event ApprovalForAll(    address indexed _owner,    address indexed _operator,    bool _approved  );  /**   * @notice Throws unless `msg.sender` is the current owner, an authorized operator, or the   * approved address for this NFT. Throws if `_from` is not the current owner. Throws if `_to` is   * the zero address. Throws if `_tokenId` is not a valid NFT. When transfer is complete, this   * function checks if `_to` is a smart contract (code size &gt; 0). If so, it calls   * `onERC721Received` on `_to` and throws if the return value is not   * `bytes4(keccak256("onERC721Received(address,uint256,bytes)"))`.   * @dev Transfers the ownership of an NFT from one address to another address. This function can   * be changed to payable.   * @param _from The current owner of the NFT.   * @param _to The new owner.   * @param _tokenId The NFT to transfer.   * @param _data Additional data with no specified format, sent in call to `_to`.   */  function safeTransferFrom(    address _from,    address _to,    uint256 _tokenId,    bytes calldata _data  )    external;  /**   * @notice This works identically to the other function with an extra data parameter, except this   * function just sets data to ""   * @dev Transfers the ownership of an NFT from one address to another address. This function can   * be changed to payable.   * @param _from The current owner of the NFT.   * @param _to The new owner.   * @param _tokenId The NFT to transfer.   */  function safeTransferFrom(    address _from,    address _to,    uint256 _tokenId  )    external;  /**   * @notice The caller is responsible to confirm that `_to` is capable of receiving NFTs or else   * they may be permanently lost.   * @dev Throws unless `msg.sender` is the current owner, an authorized operator, or the approved   * address for this NFT. Throws if `_from` is not the current owner. Throws if `_to` is the zero   * address. Throws if `_tokenId` is not a valid NFT.  This function can be changed to payable.   * @param _from The current owner of the NFT.   * @param _to The new owner.   * @param _tokenId The NFT to transfer.   */  function transferFrom(    address _from,    address _to,    uint256 _tokenId  )    external;  /**   * @notice The zero address indicates there is no approved address. Throws unless `msg.sender` is   * the current NFT owner, or an authorized operator of the current owner.   * @param _approved The new approved NFT controller.   * @dev Set or reaffirm the approved address for an NFT. This function can be changed to payable.   * @param _tokenId The NFT to approve.   */  function approve(    address _approved,    uint256 _tokenId  )    external;  /**   * @notice The contract MUST allow multiple operators per owner.   * @dev Enables or disables approval for a third party ("operator") to manage all of   * `msg.sender`'s assets. It also emits the ApprovalForAll event.   * @param _operator Address to add to the set of authorized operators.   * @param _approved True if the operators is approved, false to revoke approval.   */  function setApprovalForAll(    address _operator,    bool _approved  )    external;  /**   * @dev Returns the number of NFTs owned by `_owner`. NFTs assigned to the zero address are   * considered invalid, and this function throws for queries about the zero address.   * @notice Count all NFTs assigned to an owner.   * @param _owner Address for whom to query the balance.   * @return Balance of _owner.   */  function balanceOf(    address _owner  )    external    view    returns (uint256);  /**   * @notice Find the owner of an NFT.   * @dev Returns the address of the owner of the NFT. NFTs assigned to the zero address are   * considered invalid, and queries about them do throw.   * @param _tokenId The identifier for an NFT.   * @return Address of _tokenId owner.   */  function ownerOf(    uint256 _tokenId  )    external    view    returns (address);  /**   * @notice Throws if `_tokenId` is not a valid NFT.   * @dev Get the approved address for a single NFT.   * @param _tokenId The NFT to find the approved address for.   * @return Address that _tokenId is approved for.   */  function getApproved(    uint256 _tokenId  )    external    view    returns (address);  /**   * @notice Query if an address is an authorized operator for another address.   * @dev Returns true if `_operator` is an approved operator for `_owner`, false otherwise.   * @param _owner The address that owns the NFTs.   * @param _operator The address that acts on behalf of the owner.   * @return True if approved for all, false otherwise.   */  function isApprovedForAll(    address _owner,    address _operator  )    external    view    returns (bool);}</code></pre><h2 id="3-ERC721Metadata"><a href="#3-ERC721Metadata" class="headerlink" title="3. ERC721Metadata"></a>3. <a href="https://github.com/nibbstack/erc721/blob/2.6.1/src/contracts/tokens/erc721-metadata.sol">ERC721Metadata</a></h2><p>ERC-721不可替代令牌标准的可选元数据扩展。</p><p>主要方法：</p><ul><li>name：返回NFT的描述性名称</li><li>symbol：返回NFT的缩写名称</li><li>tokenURI：返回_tokenId对应的资源URI</li></ul><pre><code class="javascript">// SPDX-License-Identifier: MITpragma solidity ^0.8.0;/** * @dev Optional metadata extension for ERC-721 non-fungible token standard. * See https://github.com/ethereum/EIPs/blob/master/EIPS/eip-721.md. */interface ERC721Metadata{  /**   * @dev Returns a descriptive name for a collection of NFTs in this contract.   * @return _name Representing name.   */  function name()    external    view    returns (string memory _name);  /**   * @dev Returns a abbreviated name for a collection of NFTs in this contract.   * @return _symbol Representing symbol.   */  function symbol()    external    view    returns (string memory _symbol);  /**   * @dev Returns a distinct Uniform Resource Identifier (URI) for a given asset. It Throws if   * `_tokenId` is not a valid NFT. URIs are defined in RFC3986. The URI may point to a JSON file   * that conforms to the "ERC721 Metadata JSON Schema".   * @return URI of _tokenId.   */  function tokenURI(uint256 _tokenId)    external    view    returns (string memory);}</code></pre><h2 id="4-ERC721Enumerable"><a href="#4-ERC721Enumerable" class="headerlink" title="4. ERC721Enumerable"></a>4. <a href="https://github.com/nibbstack/erc721/blob/2.6.1/src/contracts/tokens/erc721-enumerable.sol">ERC721Enumerable</a></h2><p>ERC-721不可替代令牌标准的可选枚举扩展。</p><p>主要方法：</p><ul><li>totalSupply：返回由此契约跟踪的有效nft的计数（代币总量），其中每个nft都有一个分配的、可查询的所有者，且所有者不等于零地址</li><li>tokenByIndex：返回第index的NFT的tokenId。没有指定排序顺序。</li><li>tokenOfOwnerByIndex：返回分配给指定人的第index的NFT的tokenId。没有指定排序顺序</li></ul><p>源码：</p><pre><code class="javascript">// SPDX-License-Identifier: MITpragma solidity ^0.8.0;/** * @dev Optional enumeration extension for ERC-721 non-fungible token standard. * See https://github.com/ethereum/EIPs/blob/master/EIPS/eip-721.md. */interface ERC721Enumerable{  /**   * @dev Returns a count of valid NFTs tracked by this contract, where each one of them has an   * assigned and queryable owner not equal to the zero address.   * @return Total supply of NFTs.   */  function totalSupply()    external    view    returns (uint256);  /**   * @dev Returns the token identifier for the `_index`th NFT. Sort order is not specified.   * @param _index A counter less than `totalSupply()`.   * @return Token id.   */  function tokenByIndex(    uint256 _index  )    external    view    returns (uint256);  /**   * @dev Returns the token identifier for the `_index`th NFT assigned to `_owner`. Sort order is   * not specified. It throws if `_index` &gt;= `balanceOf(_owner)` or if `_owner` is the zero address,   * representing invalid NFTs.   * @param _owner An address where we are interested in NFTs owned by them.   * @param _index A counter less than `balanceOf(_owner)`.   * @return Token id.   */  function tokenOfOwnerByIndex(    address _owner,    uint256 _index  )    external    view    returns (uint256);}</code></pre><h2 id="5-NFToken"><a href="#5-NFToken" class="headerlink" title="5. NFToken"></a>5. <a href="https://github.com/nibbstack/erc721/blob/2.6.1/src/contracts/tokens/nf-token.sol">NFToken</a></h2><p>ERC721 标准基本实现</p><p>主要方法：</p><ul><li>safeTransferFrom：将NFT的所有权从一个地址转移到另一个地址。此功能可更改为payable</li><li>transferFrom：将指定的token所有权转移给另外一个地址，不鼓励使用这个方法，尽量使用<code>safeTransferFrom</code></li><li>approve：批准另一个人address来交易指定的代币，0 address 表示没有授权的地址，给定的时间内，一个token只能有一个批准的地址，只有token的持有者或者授权的操作人才可以调用。此功能可更改为payable</li><li>setApprovalForAll：设置或者取消对操作人的授权，一个操作人可以代表他们转让发送者的所有token</li><li>balanceOf：获取持有者的代币总数</li><li>ownerOf：根据token ID获取持有者</li><li>getApproved：获取token被授权的地址，如果没有设置地址则为0</li><li>isApprovedForAll：查询是否操作人被指定的持有者授权，要查询的授权人地址，要查询的授权操作人地址</li></ul><pre><code class="javascript">// SPDX-License-Identifier: MITpragma solidity ^0.8.0;import "./erc721.sol";import "./erc721-token-receiver.sol";import "../utils/supports-interface.sol";import "../utils/address-utils.sol";/** * @dev Implementation of ERC-721 non-fungible token standard. */contract NFToken is  ERC721,  SupportsInterface{  using AddressUtils for address;  /**   * @dev List of revert message codes. Implementing dApp should handle showing the correct message.   * Based on 0xcert framework error codes.   */  string constant ZERO_ADDRESS = "003001";  string constant NOT_VALID_NFT = "003002";  string constant NOT_OWNER_OR_OPERATOR = "003003";  string constant NOT_OWNER_APPROVED_OR_OPERATOR = "003004";  string constant NOT_ABLE_TO_RECEIVE_NFT = "003005";  string constant NFT_ALREADY_EXISTS = "003006";  string constant NOT_OWNER = "003007";  string constant IS_OWNER = "003008";  /**   * @dev Magic value of a smart contract that can receive NFT.   * Equal to: bytes4(keccak256("onERC721Received(address,address,uint256,bytes)")).   */  bytes4 internal constant MAGIC_ON_ERC721_RECEIVED = 0x150b7a02;  /**   * @dev A mapping from NFT ID to the address that owns it.   */  mapping (uint256 =&gt; address) internal idToOwner;  /**   * @dev Mapping from NFT ID to approved address.   */  mapping (uint256 =&gt; address) internal idToApproval;   /**   * @dev Mapping from owner address to count of their tokens.   */  mapping (address =&gt; uint256) private ownerToNFTokenCount;  /**   * @dev Mapping from owner address to mapping of operator addresses.   */  mapping (address =&gt; mapping (address =&gt; bool)) internal ownerToOperators;  /**   * @dev Guarantees that the msg.sender is an owner or operator of the given NFT.   * @param _tokenId ID of the NFT to validate.   */  modifier canOperate(    uint256 _tokenId  )  {    address tokenOwner = idToOwner[_tokenId];    require(      tokenOwner == msg.sender || ownerToOperators[tokenOwner][msg.sender],      NOT_OWNER_OR_OPERATOR    );    _;  }  /**   * @dev Guarantees that the msg.sender is allowed to transfer NFT.   * @param _tokenId ID of the NFT to transfer.   */  modifier canTransfer(    uint256 _tokenId  )  {    address tokenOwner = idToOwner[_tokenId];    require(      tokenOwner == msg.sender      || idToApproval[_tokenId] == msg.sender      || ownerToOperators[tokenOwner][msg.sender],      NOT_OWNER_APPROVED_OR_OPERATOR    );    _;  }  /**   * @dev Guarantees that _tokenId is a valid Token.   * @param _tokenId ID of the NFT to validate.   */  modifier validNFToken(    uint256 _tokenId  )  {    require(idToOwner[_tokenId] != address(0), NOT_VALID_NFT);    _;  }  /**   * @dev Contract constructor.   */  constructor()  {    supportedInterfaces[0x80ac58cd] = true; // ERC721  }  /**   * @notice Throws unless `msg.sender` is the current owner, an authorized operator, or the   * approved address for this NFT. Throws if `_from` is not the current owner. Throws if `_to` is   * the zero address. Throws if `_tokenId` is not a valid NFT. When transfer is complete, this   * function checks if `_to` is a smart contract (code size &gt; 0). If so, it calls   * `onERC721Received` on `_to` and throws if the return value is not   * `bytes4(keccak256("onERC721Received(address,uint256,bytes)"))`.   * @dev Transfers the ownership of an NFT from one address to another address. This function can   * be changed to payable.   * @param _from The current owner of the NFT.   * @param _to The new owner.   * @param _tokenId The NFT to transfer.   * @param _data Additional data with no specified format, sent in call to `_to`.   */  function safeTransferFrom(    address _from,    address _to,    uint256 _tokenId,    bytes calldata _data  )    external    override  {    _safeTransferFrom(_from, _to, _tokenId, _data);  }  /**   * @notice This works identically to the other function with an extra data parameter, except this   * function just sets data to "".   * @dev Transfers the ownership of an NFT from one address to another address. This function can   * be changed to payable.   * @param _from The current owner of the NFT.   * @param _to The new owner.   * @param _tokenId The NFT to transfer.   */  function safeTransferFrom(    address _from,    address _to,    uint256 _tokenId  )    external    override  {    _safeTransferFrom(_from, _to, _tokenId, "");  }  /**   * @notice The caller is responsible to confirm that `_to` is capable of receiving NFTs or else   * they may be permanently lost.   * @dev Throws unless `msg.sender` is the current owner, an authorized operator, or the approved   * address for this NFT. Throws if `_from` is not the current owner. Throws if `_to` is the zero   * address. Throws if `_tokenId` is not a valid NFT. This function can be changed to payable.   * @param _from The current owner of the NFT.   * @param _to The new owner.   * @param _tokenId The NFT to transfer.   */  function transferFrom(    address _from,    address _to,    uint256 _tokenId  )    external    override    canTransfer(_tokenId)    validNFToken(_tokenId)  {    address tokenOwner = idToOwner[_tokenId];    require(tokenOwner == _from, NOT_OWNER);    require(_to != address(0), ZERO_ADDRESS);    _transfer(_to, _tokenId);  }  /**   * @notice The zero address indicates there is no approved address. Throws unless `msg.sender` is   * the current NFT owner, or an authorized operator of the current owner.   * @dev Set or reaffirm the approved address for an NFT. This function can be changed to payable.   * @param _approved Address to be approved for the given NFT ID.   * @param _tokenId ID of the token to be approved.   */  function approve(    address _approved,    uint256 _tokenId  )    external    override    canOperate(_tokenId)    validNFToken(_tokenId)  {    address tokenOwner = idToOwner[_tokenId];    require(_approved != tokenOwner, IS_OWNER);    idToApproval[_tokenId] = _approved;    emit Approval(tokenOwner, _approved, _tokenId);  }  /**   * @notice This works even if sender doesn't own any tokens at the time.   * @dev Enables or disables approval for a third party ("operator") to manage all of   * `msg.sender`'s assets. It also emits the ApprovalForAll event.   * @param _operator Address to add to the set of authorized operators.   * @param _approved True if the operators is approved, false to revoke approval.   */  function setApprovalForAll(    address _operator,    bool _approved  )    external    override  {    ownerToOperators[msg.sender][_operator] = _approved;    emit ApprovalForAll(msg.sender, _operator, _approved);  }  /**   * @dev Returns the number of NFTs owned by `_owner`. NFTs assigned to the zero address are   * considered invalid, and this function throws for queries about the zero address.   * @param _owner Address for whom to query the balance.   * @return Balance of _owner.   */  function balanceOf(    address _owner  )    external    override    view    returns (uint256)  {    require(_owner != address(0), ZERO_ADDRESS);    return _getOwnerNFTCount(_owner);  }  /**   * @dev Returns the address of the owner of the NFT. NFTs assigned to the zero address are   * considered invalid, and queries about them do throw.   * @param _tokenId The identifier for an NFT.   * @return _owner Address of _tokenId owner.   */  function ownerOf(    uint256 _tokenId  )    external    override    view    returns (address _owner)  {    _owner = idToOwner[_tokenId];    require(_owner != address(0), NOT_VALID_NFT);  }  /**   * @notice Throws if `_tokenId` is not a valid NFT.   * @dev Get the approved address for a single NFT.   * @param _tokenId ID of the NFT to query the approval of.   * @return Address that _tokenId is approved for.   */  function getApproved(    uint256 _tokenId  )    external    override    view    validNFToken(_tokenId)    returns (address)  {    return idToApproval[_tokenId];  }  /**   * @dev Checks if `_operator` is an approved operator for `_owner`.   * @param _owner The address that owns the NFTs.   * @param _operator The address that acts on behalf of the owner.   * @return True if approved for all, false otherwise.   */  function isApprovedForAll(    address _owner,    address _operator  )    external    override    view    returns (bool)  {    return ownerToOperators[_owner][_operator];  }  /**   * @notice Does NO checks.   * @dev Actually performs the transfer.   * @param _to Address of a new owner.   * @param _tokenId The NFT that is being transferred.   */  function _transfer(    address _to,    uint256 _tokenId  )    internal    virtual  {    address from = idToOwner[_tokenId];    _clearApproval(_tokenId);    _removeNFToken(from, _tokenId);    _addNFToken(_to, _tokenId);    emit Transfer(from, _to, _tokenId);  }  /**   * @notice This is an internal function which should be called from user-implemented external   * mint function. Its purpose is to show and properly initialize data structures when using this   * implementation.   * @dev Mints a new NFT.   * @param _to The address that will own the minted NFT.   * @param _tokenId of the NFT to be minted by the msg.sender.   */  function _mint(    address _to,    uint256 _tokenId  )    internal    virtual  {    require(_to != address(0), ZERO_ADDRESS);    require(idToOwner[_tokenId] == address(0), NFT_ALREADY_EXISTS);    _addNFToken(_to, _tokenId);    emit Transfer(address(0), _to, _tokenId);  }  /**   * @notice This is an internal function which should be called from user-implemented external burn   * function. Its purpose is to show and properly initialize data structures when using this   * implementation. Also, note that this burn implementation allows the minter to re-mint a burned   * NFT.   * @dev Burns a NFT.   * @param _tokenId ID of the NFT to be burned.   */  function _burn(    uint256 _tokenId  )    internal    virtual    validNFToken(_tokenId)  {    address tokenOwner = idToOwner[_tokenId];    _clearApproval(_tokenId);    _removeNFToken(tokenOwner, _tokenId);    emit Transfer(tokenOwner, address(0), _tokenId);  }  /**   * @notice Use and override this function with caution. Wrong usage can have serious consequences.   * @dev Removes a NFT from owner.   * @param _from Address from which we want to remove the NFT.   * @param _tokenId Which NFT we want to remove.   */  function _removeNFToken(    address _from,    uint256 _tokenId  )    internal    virtual  {    require(idToOwner[_tokenId] == _from, NOT_OWNER);    ownerToNFTokenCount[_from] -= 1;    delete idToOwner[_tokenId];  }  /**   * @notice Use and override this function with caution. Wrong usage can have serious consequences.   * @dev Assigns a new NFT to owner.   * @param _to Address to which we want to add the NFT.   * @param _tokenId Which NFT we want to add.   */  function _addNFToken(    address _to,    uint256 _tokenId  )    internal    virtual  {    require(idToOwner[_tokenId] == address(0), NFT_ALREADY_EXISTS);    idToOwner[_tokenId] = _to;    ownerToNFTokenCount[_to] += 1;  }  /**   *&nbsp;@dev Helper function that gets NFT count of owner. This is needed for overriding in enumerable   * extension to remove double storage (gas optimization) of owner NFT count.   * @param _owner Address for whom to query the count.   * @return Number of _owner NFTs.   */  function _getOwnerNFTCount(    address _owner  )    internal    virtual    view    returns (uint256)  {    return ownerToNFTokenCount[_owner];  }  /**   * @dev Actually perform the safeTransferFrom.   * @param _from The current owner of the NFT.   * @param _to The new owner.   * @param _tokenId The NFT to transfer.   * @param _data Additional data with no specified format, sent in call to `_to`.   */  function _safeTransferFrom(    address _from,    address _to,    uint256 _tokenId,    bytes memory _data  )    private    canTransfer(_tokenId)    validNFToken(_tokenId)  {    address tokenOwner = idToOwner[_tokenId];    require(tokenOwner == _from, NOT_OWNER);    require(_to != address(0), ZERO_ADDRESS);    _transfer(_to, _tokenId);    if (_to.isContract())    {      bytes4 retval = ERC721TokenReceiver(_to).onERC721Received(msg.sender, _from, _tokenId, _data);      require(retval == MAGIC_ON_ERC721_RECEIVED, NOT_ABLE_TO_RECEIVE_NFT);    }  }  /**   * @dev Clears the current approval of a given NFT ID.   * @param _tokenId ID of the NFT to be transferred.   */  function _clearApproval(    uint256 _tokenId  )    private  {    delete idToApproval[_tokenId];  }}</code></pre><h2 id="6-NFTokenMetadata"><a href="#6-NFTokenMetadata" class="headerlink" title="6. NFTokenMetadata"></a>6. <a href="https://github.com/nibbstack/erc721/blob/2.6.1/src/contracts/tokens/nf-token-metadata.sol">NFTokenMetadata</a></h2><p>ERC-721不可替代令牌标准的可选元数据实现，继承NFToken并实现了ERC721Metadata接口</p><pre><code class="javascript">// SPDX-License-Identifier: MITpragma solidity ^0.8.0;import "./nf-token.sol";import "./erc721-metadata.sol";/** * @dev Optional metadata implementation for ERC-721 non-fungible token standard. */contract NFTokenMetadata is  NFToken,  ERC721Metadata{  /**   * @dev A descriptive name for a collection of NFTs.   */  string internal nftName;  /**   * @dev An abbreviated name for NFTokens.   */  string internal nftSymbol;  /**   * @dev Mapping from NFT ID to metadata uri.   */  mapping (uint256 =&gt; string) internal idToUri;  /**   * @notice When implementing this contract don't forget to set nftName and nftSymbol.   * @dev Contract constructor.   */  constructor()  {    supportedInterfaces[0x5b5e139f] = true; // ERC721Metadata  }  /**   * @dev Returns a descriptive name for a collection of NFTokens.   * @return _name Representing name.   */  function name()    external    override    view    returns (string memory _name)  {    _name = nftName;  }  /**   * @dev Returns an abbreviated name for NFTokens.   * @return _symbol Representing symbol.   */  function symbol()    external    override    view    returns (string memory _symbol)  {    _symbol = nftSymbol;  }  /**   * @dev A distinct URI (RFC 3986) for a given NFT.   * @param _tokenId Id for which we want uri.   * @return URI of _tokenId.   */  function tokenURI(    uint256 _tokenId  )    external    override    view    validNFToken(_tokenId)    returns (string memory)  {    return _tokenURI(_tokenId);  }  /**   * @notice This is an internal function that can be overriden if you want to implement a different   * way to generate token URI.   * @param _tokenId Id for which we want uri.   * @return URI of _tokenId.   */  function _tokenURI(    uint256 _tokenId  )    internal    virtual    view    returns (string memory)  {    return idToUri[_tokenId];  }  /**   * @notice This is an internal function which should be called from user-implemented external   * burn function. Its purpose is to show and properly initialize data structures when using this   * implementation. Also, note that this burn implementation allows the minter to re-mint a burned   * NFT.   * @dev Burns a NFT.   * @param _tokenId ID of the NFT to be burned.   */  function _burn(    uint256 _tokenId  )    internal    override    virtual  {    super._burn(_tokenId);    delete idToUri[_tokenId];  }  /**   * @notice This is an internal function which should be called from user-implemented external   * function. Its purpose is to show and properly initialize data structures when using this   * implementation.   * @dev Set a distinct URI (RFC 3986) for a given NFT ID.   * @param _tokenId Id for which we want URI.   * @param _uri String representing RFC 3986 URI.   */  function _setTokenUri(    uint256 _tokenId,    string memory _uri  )    internal    validNFToken(_tokenId)  {    idToUri[_tokenId] = _uri;  }}</code></pre><h2 id="7-NFTokenEnumerable"><a href="#7-NFTokenEnumerable" class="headerlink" title="7. NFTokenEnumerable"></a>7. <a href="https://github.com/nibbstack/erc721/blob/2.6.1/src/contracts/tokens/nf-token-enumerable.sol">NFTokenEnumerable</a></h2><p>ERC-721不可替代令牌标准的可选枚举实现，继承NFToken并实现了ERC721Enumerable接口</p><pre><code class="javascript">// SPDX-License-Identifier: MITpragma solidity ^0.8.0;import "./nf-token.sol";import "./erc721-enumerable.sol";/** * @dev Optional enumeration implementation for ERC-721 non-fungible token standard. */contract NFTokenEnumerable is  NFToken,  ERC721Enumerable{  /**   * @dev List of revert message codes. Implementing dApp should handle showing the correct message.   * Based on 0xcert framework error codes.   */  string constant INVALID_INDEX = "005007";  /**   * @dev Array of all NFT IDs.   */  uint256[] internal tokens;  /**   * @dev Mapping from token ID to its index in global tokens array.   */  mapping(uint256 =&gt; uint256) internal idToIndex;  /**   * @dev Mapping from owner to list of owned NFT IDs.   */  mapping(address =&gt; uint256[]) internal ownerToIds;  /**   * @dev Mapping from NFT ID to its index in the owner tokens list.   */  mapping(uint256 =&gt; uint256) internal idToOwnerIndex;  /**   * @dev Contract constructor.   */  constructor()  {    supportedInterfaces[0x780e9d63] = true; // ERC721Enumerable  }  /**   * @dev Returns the count of all existing NFTokens.   * @return Total supply of NFTs.   */  function totalSupply()    external    override    view    returns (uint256)  {    return tokens.length;  }  /**   * @dev Returns NFT ID by its index.   * @param _index A counter less than `totalSupply()`.   * @return Token id.   */  function tokenByIndex(    uint256 _index  )    external    override    view    returns (uint256)  {    require(_index &lt; tokens.length, INVALID_INDEX);    return tokens[_index];  }  /**   * @dev returns the n-th NFT ID from a list of owner's tokens.   * @param _owner Token owner's address.   * @param _index Index number representing n-th token in owner's list of tokens.   * @return Token id.   */  function tokenOfOwnerByIndex(    address _owner,    uint256 _index  )    external    override    view    returns (uint256)  {    require(_index &lt; ownerToIds[_owner].length, INVALID_INDEX);    return ownerToIds[_owner][_index];  }  /**   * @notice This is an internal function which should be called from user-implemented external   * mint function. Its purpose is to show and properly initialize data structures when using this   * implementation.   * @dev Mints a new NFT.   * @param _to The address that will own the minted NFT.   * @param _tokenId of the NFT to be minted by the msg.sender.   */  function _mint(    address _to,    uint256 _tokenId  )    internal    override    virtual  {    super._mint(_to, _tokenId);    tokens.push(_tokenId);    idToIndex[_tokenId] = tokens.length - 1;  }  /**   * @notice This is an internal function which should be called from user-implemented external   * burn function. Its purpose is to show and properly initialize data structures when using this   * implementation. Also, note that this burn implementation allows the minter to re-mint a burned   * NFT.   * @dev Burns a NFT.   * @param _tokenId ID of the NFT to be burned.   */  function _burn(    uint256 _tokenId  )    internal    override    virtual  {    super._burn(_tokenId);    uint256 tokenIndex = idToIndex[_tokenId];    uint256 lastTokenIndex = tokens.length - 1;    uint256 lastToken = tokens[lastTokenIndex];    tokens[tokenIndex] = lastToken;    tokens.pop();    // This wastes gas if you are burning the last token but saves a little gas if you are not.    idToIndex[lastToken] = tokenIndex;    idToIndex[_tokenId] = 0;  }  /**   * @notice Use and override this function with caution. Wrong usage can have serious consequences.   * @dev Removes a NFT from an address.   * @param _from Address from wich we want to remove the NFT.   * @param _tokenId Which NFT we want to remove.   */  function _removeNFToken(    address _from,    uint256 _tokenId  )    internal    override    virtual  {    require(idToOwner[_tokenId] == _from, NOT_OWNER);    delete idToOwner[_tokenId];    uint256 tokenToRemoveIndex = idToOwnerIndex[_tokenId];    uint256 lastTokenIndex = ownerToIds[_from].length - 1;    if (lastTokenIndex != tokenToRemoveIndex)    {      uint256 lastToken = ownerToIds[_from][lastTokenIndex];      ownerToIds[_from][tokenToRemoveIndex] = lastToken;      idToOwnerIndex[lastToken] = tokenToRemoveIndex;    }    ownerToIds[_from].pop();  }  /**   * @notice Use and override this function with caution. Wrong usage can have serious consequences.   * @dev Assigns a new NFT to an address.   * @param _to Address to wich we want to add the NFT.   * @param _tokenId Which NFT we want to add.   */  function _addNFToken(    address _to,    uint256 _tokenId  )    internal    override    virtual  {    require(idToOwner[_tokenId] == address(0), NFT_ALREADY_EXISTS);    idToOwner[_tokenId] = _to;    ownerToIds[_to].push(_tokenId);    idToOwnerIndex[_tokenId] = ownerToIds[_to].length - 1;  }  /**   *&nbsp;@dev Helper function that gets NFT count of owner. This is needed for overriding in enumerable   * extension to remove double storage(gas optimization) of owner NFT count.   * @param _owner Address for whom to query the count.   * @return Number of _owner NFTs.   */  function _getOwnerNFTCount(    address _owner  )    internal    override    virtual    view    returns (uint256)  {    return ownerToIds[_owner].length;  }}</code></pre><h2 id="8-Ownable"><a href="#8-Ownable" class="headerlink" title="8. Ownable"></a>8. <a href="https://github.com/nibbstack/erc721/blob/master/src/contracts/ownership/ownable.sol">Ownable</a></h2><p>合同有一个所有者地址，并提供基本的授权控制，简化了用户权限的实现。此合同基于以下源代码: <a href="https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v4.5.0/contracts/access/Ownable.sol">https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v4.5.0/contracts/access/Ownable.sol</a></p><pre><code class="javascriptscript">// SPDX-License-Identifier: MITpragma solidity ^0.8.0;/** * @dev The contract has an owner address, and provides basic authorization control whitch * simplifies the implementation of user permissions. This contract is based on the source code at: * https://github.com/OpenZeppelin/openzeppelin-solidity/blob/master/contracts/ownership/Ownable.sol */contract Ownable{  /**   * @dev Error constants.   */  string public constant NOT_CURRENT_OWNER = "018001";  string public constant CANNOT_TRANSFER_TO_ZERO_ADDRESS = "018002";  /**   * @dev Current owner address.   */  address public owner;  /**   * @dev An event which is triggered when the owner is changed.   * @param previousOwner The address of the previous owner.   * @param newOwner The address of the new owner.   */  event OwnershipTransferred(    address indexed previousOwner,    address indexed newOwner  );  /**   * @dev The constructor sets the original `owner` of the contract to the sender account.   */  constructor()  {    owner = msg.sender;  }  /**   * @dev Throws if called by any account other than the owner.   */  modifier onlyOwner()  {    require(msg.sender == owner, NOT_CURRENT_OWNER);    _;  }  /**   * @dev Allows the current owner to transfer control of the contract to a newOwner.   * @param _newOwner The address to transfer ownership to.   */  function transferOwnership(    address _newOwner  )    public    onlyOwner  {    require(_newOwner != address(0), CANNOT_TRANSFER_TO_ZERO_ADDRESS);    emit OwnershipTransferred(owner, _newOwner);    owner = _newOwner;  }}</code></pre><p>OpenZeppelin ERC721源码分析到这里就结束了。</p><p>参考：</p><ol><li><a href="https://github.com/nibbstack/erc721/tree/2.6.1">ERC721源码v2.6.1</a></li><li><a href="https://segmentfault.com/a/1190000016070774">ERC721源码分析</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
            <tag> NFT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于以太坊的战艇游戏(Layer2)源码解析</title>
      <link href="/2022/02/24/blockchain/layer2/%E5%9F%BA%E4%BA%8E%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%9A%84%E6%88%98%E8%89%87%E6%B8%B8%E6%88%8F(Layer2)/"/>
      <url>/2022/02/24/blockchain/layer2/%E5%9F%BA%E4%BA%8E%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%9A%84%E6%88%98%E8%89%87%E6%B8%B8%E6%88%8F(Layer2)/</url>
      
        <content type="html"><![CDATA[<h1 id="基于以太坊的战艇游戏-Layer2-源码解析"><a href="#基于以太坊的战艇游戏-Layer2-源码解析" class="headerlink" title="基于以太坊的战艇游戏(Layer2)源码解析"></a>基于以太坊的战艇游戏(Layer2)源码解析</h1><h2 id="一、游戏介绍"><a href="#一、游戏介绍" class="headerlink" title="一、游戏介绍"></a>一、游戏介绍</h2><p>每一个玩家都可以看到上图所示的页面。该页面分为两部分，下面部分表示当前玩家的棋盘信息，开始的时候，该玩家随机选择两个格子，用于放置两个战舰；上面部分显示对方玩家的棋盘信息，除了对方玩家的战舰位置。开始的时候，上面部分的棋盘是空的。游戏开始之后，两个玩家轮流猜测对方的战舰的位置，每一次只能猜一个方格。如果对方的战舰不在所猜测的方格中，那么就会在对应位置显示一个水花的图像；反之，则出现一团火的图像。因为双方看不到对方的棋盘，因此，每一次都需要对方玩家回复“所猜测的方格是否有战舰”（我们可以采用密码学的技术检测出对方是否撒谎）。当某一个玩家率先猜中了对方两个战舰的位置，该玩家就赢了，并可以收取自己和对方的赌注。</p><h2 id="二、涉及技术"><a href="#二、涉及技术" class="headerlink" title="二、涉及技术"></a>二、涉及技术</h2><p>使用的编程技术有：</p><ul><li>HTML； Javascript; CCS; (网页前端)</li><li>Web3 （提供了调用智能合约的js接口）</li><li>ganache-cli （在本地模拟以太坊节点）</li><li>remix （以太坊智能合约的IDE）</li><li>Solidity （智能合约编程语言）</li></ul><h2 id="三、技术概括"><a href="#三、技术概括" class="headerlink" title="三、技术概括"></a>三、技术概括</h2><p>下图显示，如果使用layer1的区块链技术，每走一步棋都需要向区块链发布一个交易。</p><p><img src="/images/battle-ship-layer2/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpYW5neWlodWFp,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述"></p><p>下图所示的正是我们使用的方式。</p><p><img src="/images/battle-ship-layer2/watermark,type_W5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpYW5neWlodWFp,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述"></p><p>一个问题：如何检测对方玩家撒谎？<br>具体为，每一个玩家在游戏开始前都需要随机指定两个格子，表示两个战舰的位置，如果某玩家中途变卦，不承认自己所指定的那两个格子呢？再者，当前玩家猜测对方玩家战舰所在的方格位置，对方玩家需要回复该方格下是否有战舰，如果对方玩家不诚信呢？我们使用了Merkle<br>tree进行commit（承诺）。介绍merkle tree（形如下图）不属于本文的范围。</p><p>根据密码学中的hash函数的特点，任意一个节点的变化都会导致根节点变化。并且，我们能够很容易证明某一个节点是否属于该merkle tree。</p><p><img src="/images/battle-ship-layer2/watermark,type_oZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpYW5neWlodWFp,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述"></p><p>这里，我们对两位玩家的所有的游戏方格分别生成两棵merkle tree，叶子节点表示方格的编号。这里为了保密性，在编号后面合并一个随机数（合并后的数据作为hash函数的输入）。</p><p>因此，解决方法是，在玩家指定两个战舰的位置之后，需要生成一棵merkle<br>tree，并向对方发送根节点。该根节点便是对方的承诺，且它不会泄露战舰的位置信息。在游戏过程中，如果要揭露某一个方格下是否存在战舰，需要将对应编号的叶子节点和从该节点到根节点的路径信息发送给对方。若对方能够构造出相同的根节点，证明该玩家是诚信的。（这里涉及到了密码学hash函数的知识）。</p><p>另一个问题：如果一个玩家a中途离开，怎么办？ 当前实现的功能：需要玩家b向智能合约中提交一个控告。为了回应该控告，玩家a要在一分钟之内调用智能合约，取消掉该控告。如果一分钟之后玩家a不回复，那么玩家b就可以取走所有的赌注。</p><h2 id="四、区块链和智能合约的作用"><a href="#四、区块链和智能合约的作用" class="headerlink" title="四、区块链和智能合约的作用"></a>四、区块链和智能合约的作用</h2><p>在这个游戏中，智能合约充当了裁判的角色：若某个玩家撒谎或者中途离开，那么智能合约就会把赌注给另一个玩家。因此，本质上区块链中的智能合约解决了信用问题，并且，重要的是，不需要依赖任何可信的第三方。游戏玩家不需要相信任何人：不用担心对方不诚信，不用担心游戏平台和对方玩家勾结；不用担心自己的赌注莫名奇妙就被取走；不用担心游戏平台宕机。</p><p>下图表示的是智能合约的fields，也即是智能合约需要保存的数据。我们保存了两个玩家的地址，赌注的数量，游戏状态，最终赢家的地址，两个merkle tree的跟节点，超时不回复的数据等等。</p><p>该项目还实现了下述功能：</p><ul><li>Forfeit Game，表示当前玩家放弃该游戏，包括赌注。（已实现）</li><li>Claim Win，在当前玩家猜中对方两个战舰之后，点击该按钮就可以取走所有的赌注。（已实现）</li><li>Accuse<br>Cheating，原本的功能是当发现对方玩家撒谎时，将撒谎的数据发布到智能合约中，让智能合约裁决。如果读者想要实现该功能，需要注意，某一个玩家在向对方发送数据前，需要对该数据签名，以避免耍赖。因此，当某一个玩家要求智能合约裁决时，智能合约需要验证相关签名。（未实现）</li><li>Accuse Timeout，控告对方玩家中途离开；（已实现）</li><li>Respond to Accusation， 当当前玩家被控告时，该玩家需要在一分钟内点击该按钮，表示自己在线，来回复控告。（已实现）</li><li>claim timeout winnings，如果被告人没有在一分钟之内回复，就可以点击该按钮来取走所有的赌注。（已实现）</li></ul><h2 id="五、源码分析"><a href="#五、源码分析" class="headerlink" title="五、源码分析"></a>五、源码分析</h2><h3 id="1-构造Merkle树"><a href="#1-构造Merkle树" class="headerlink" title="1. 构造Merkle树"></a>1. 构造Merkle树</h3><p>使用JavaScript代码实现构造树，首先计算每个位置否存在舰艇+随机数组合后取sha3，作为每个位置的hash，然后每两个页节点取一次hash，循环最终形成一个根节点。</p><p><img src="/images/battle-ship-layer2/merkle.png" alt="img"></p><p>最终构造后的merkle树为5层，每层节点数为1、2、4、8、16</p><p>内容如下：</p><p><img src="/images/battle-ship-layer2/image-20220223205315073.png" alt="image-20220223205315073"></p><p>JS代码：</p><pre><code class="javascript">/* build_merkle  builds a Merkle Tree from the given initial_board and nonces  \args:    initial_board - [[]] - 初始化甲板作为矩阵传递，二维数组，对应横纵坐标，值为是否含有舰艇（bool）    nonces - [[Uint32]] - 随机值矩阵*/function build_merkle(initial_board, nonces) {    check_correct_sizes(initial_board, nonces);    let merkle = [[]];    // add all leaf nodes    for (let i = 0; i &lt; BOARD_LEN; i++) {        for (let j = 0; j &lt; BOARD_LEN; j++) {            merkle[0].push(                web3.utils.keccak256(                    web3.utils.fromAscii(JSON.stringify(initial_board[i][j]) + JSON.stringify(nonces[i][j]))                )            );        }    }    // build tree from leaves    // while, current level of merkle has length &gt; 1, add more levels    let curr_level = 0;    while (merkle[curr_level].length &gt; 1) {        merkle.push([]);        curr_level += 1;        // build new layer of tree        for (let i = 0; i + 1 &lt; merkle[curr_level - 1].length; i += 2) {            // have new_node represent another node in the Merkle tree            let new_node = web3.utils.keccak256(merkle[curr_level - 1][i] + merkle[curr_level - 1][i + 1].substring(2), {encoding: 'hex'});            // finalize finally computes the hash for every argument passed in update            merkle[curr_level].push(new_node);        }        // if this most recent merkle level has an odd length, we need        // to just hoist the last element into the next level        if (merkle[curr_level - 1].length % 2 !== 0) {            merkle[curr_level].push(merkle[curr_level - 1][merkle[curr_level - 1].length - 1]);        }    }    return merkle;}</code></pre><h3 id="2-猜测舰艇位置"><a href="#2-猜测舰艇位置" class="headerlink" title="2. 猜测舰艇位置"></a>2. 猜测舰艇位置</h3><p>首先发送猜测给对手，对手回应是否猜中，如果猜中了猜测者发起合约验证。</p><p>JS代码：</p><pre><code class="javascript">// function called when a user guesses a squareasync function guess_square(i, j, player, opponent, callback) {    // 签名    let signed_guess = await player.build_guess(i, j);    // 发送签名和猜测给对手获取对手回应是否猜中、随机数、merkle验证使用的节点数组    let [opening, nonce, proof] = await opponent.respond_to_guess(i, j, signed_guess);    // 更新页面    $('#' + opponent.my_name + ' &gt; .my-board #' + i + '-' + j)        .css('background-image', 'url(' + (opening ? EXPLOSION_IMG : SPLASH_IMG) + ')');    // interpret response    await player.receive_response_to_guess(i, j, [opening, nonce, proof]);    // return if the guess hit a ship    callback(opening);}</code></pre><p>respond_to_guess方法获取nonce, proof方法，JS代码：</p><pre><code class="javascript">/* 获取零知识证明需要的节点hash  /args:    initial_board - matrix representing my-board state    nonces - nonces for your board    guess - [i, j] - guess building proof for*/function get_proof_for_board_guess(initial_board, nonces, guess) {    let merkle_tree = build_merkle(initial_board, nonces);    let index_in_merkle = guess[0] * BOARD_LEN + guess[1];    let proof = [];    for (let i = 0; i &lt; merkle_tree.length - 1; i++) {        let merkle_group = Math.floor(index_in_merkle / Math.pow(2, i)); // goodod        let index_in_group = merkle_group % 2;        let sibling = Math.min(merkle_group - index_in_group + (index_in_group + 1) % 2, merkle_tree[i].length - 1);        if (sibling == merkle_group) continue;        proof.push(merkle_tree[i][sibling]);    }    return proof;}</code></pre><p>验证是否击中，Solidity代码：</p><pre><code class="solidity">// 验证单个单板上的单个点的证明// args:// - opening_nonce - 对应于web3.utils.fromAscii(JSON.stringify(open) + JSON.stringify(nonce)));// - proof - sha256哈希表，对应于 get_proof_for_board_guess()的输出// - guess - [i, j] - guess开口对应（guess that opening corresponds to）// - commit - board的默克尔根function verify_opening(bytes memory opening_nonce, bytes32[] memory proof, uint guess_leaf_index, bytes32 commit) public pure returns (bool result) {    bytes32 curr_commit = keccak256(opening_nonce); // see if this changes hash    uint index_in_leaves = guess_leaf_index;    uint curr_proof_index = 0;    uint i = 0;    while (curr_proof_index &lt; proof.length) {        // 对于默克尔树的当前层级，猜测的节点在哪个组的索引(相当于默克尔树下一层级parent的索引)        // index of which group the guess is in for the current level of Merkle tree        // (equivalent to index of parent in next level of Merkle tree)        uint group_in_level_of_merkle = index_in_leaves / (2**i);        // Merkle分组（两个为一组分组）索引数，只有(0, 1)        uint index_in_group = group_in_level_of_merkle % 2;        // 当前默克尔层级的最大节点索引        uint max_node_index = ((BOARD_LEN * BOARD_LEN + (2**i) - 1) / (2**i)) - 1;        // curr_commit的同级索引        uint sibling = group_in_level_of_merkle - index_in_group + (index_in_group + 1) % 2;        i++;        if (sibling &gt; max_node_index) continue;        if (index_in_group % 2 == 0) {            curr_commit = keccak256(merge_bytes32(curr_commit, proof[curr_proof_index]));            curr_proof_index++;        } else {            curr_commit = keccak256(merge_bytes32(proof[curr_proof_index], curr_commit));            curr_proof_index++;        }    }    return (curr_commit == commit);}</code></pre><h3 id="3-判定赢"><a href="#3-判定赢" class="headerlink" title="3. 判定赢"></a>3. 判定赢</h3><p>leaf_index_check_p2中记录着已经击中了多少舰艇</p><p>Solidity代码：</p><pre><code class="solidity">// 宣布你赢了比赛// 如果你击中了2个舰艇，然后这个函数会转移赢钱给你和结束游戏。function claim_win() public{    assert(msg.sender == p1 || msg.sender == p2);    bool    isP1Win = true;    if (msg.sender == p2) {        isP1Win = false;    }    if (isP1Win) {        require(leaf_index_check_p2.length &gt;= 2);        winner = p1;    } else {        require(leaf_index_check_p1.length &gt;= 2);        winner = p2;    }    // transfer all the tokens from this contract to the winner (i.e., msg sender)    msg.sender.transfer(address(this).balance);    state = 2;}</code></pre><h3 id="4-控告对手作弊"><a href="#4-控告对手作弊" class="headerlink" title="4. 控告对手作弊"></a>4. 控告对手作弊</h3><p>调用上面的verify_opening方法验证是否满足Merkle树，不满足说明对方作弊。</p><p>Solidity代码：</p><pre><code class="solidity">// 控告对手作弊 — 如果是真的，你就赢了。// opening_nonce - 对应于JS中的web3.utils.fromAscii(JSON.stringify(opening) + JSON.stringify(nonce))// proof - 一个sha256哈希列表，你可以从get_proof_for_board_guess(这是发送者认为是一个谎言)// guess_leaf_index - 猜测船只位置的索引// owner - 这艘船所在的board的所有者的地址function accuse_cheating (    bytes memory opening_nonce,    bytes32[] memory proof,    uint256 guess_leaf_index,    address owner) public returns (bool result) {    assert((msg.sender == p1 &amp;&amp; owner == p2) || (msg.sender == p2 &amp;&amp; owner == p1));    bytes32 com = merkle_root_p1;    if(owner == p2){        com = merkle_root_p2;    }    if(!verify_opening(opening_nonce, proof, guess_leaf_index, com)){        msg.sender.transfer(address(this).balance);        state = 2;        winner = msg.sender;        return true;    }    return false;}</code></pre><h2 id="六、参考链接"><a href="#六、参考链接" class="headerlink" title="六、参考链接"></a>六、参考链接</h2><ol><li>源代码提供：<a href="https://blog.csdn.net/liangyihuai/article/details/116459829">https://blog.csdn.net/liangyihuai/article/details/116459829</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
            <tag> Layer2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>雪崩共识</title>
      <link href="/2022/02/08/blockchain/avalanche/%E9%9B%AA%E5%B4%A9%E5%85%B1%E8%AF%86/"/>
      <url>/2022/02/08/blockchain/avalanche/%E9%9B%AA%E5%B4%A9%E5%85%B1%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<p><strong>1.引言</strong></p><p>Avalanche主网正式上线，OKEx也已经上架Avalanche原生代币AVAX，曾获得“共识协议3.0”之称的Avalanche重回大众视野，为何Avalanche一举一动受到如此大的市场关注？</p><p>这一切要从2015年5月说起，康奈尔大学出现了一篇《从“雪花”到“雪崩”：一种新型的亚稳态共识协议族》的论文，在市场上引发了雪崩式的迅速反响，成为可以和中本聪的PoW机制、以太坊智能合约相媲美的颠覆性技术创新。</p><p><strong>2.结合早期协议优点并改进缺点</strong></p><p>正如康奈尔大学教授埃米·冈·瑟勒（Emin Gun Sirer）所言：“Avalanche描述了一种新的共识协议，它将中本聪共识协议与经典共识协议相结合，这是一次重大的突破”。在此之前，经典共识协议和中本聪共识协议是早期两类解决分布式系统拜占庭问题的主要共识协议。</p><p>分布式系统中的共识问题一直是计算机科学领域的重要话题，而拜占庭将军问题则是重中之重。战争时期，在军队可能有叛徒和间谍的情况下忠诚的将军如何达成一致的意见，这便是拜占庭将军问题。经典共识协议由图灵奖得主兰伯特提出，具有强一致性、高效的特点，但也有通信成本高、节点无法自由进出的缺点。</p><p><strong>图1：经典共识协议（PBFT）工作原理</strong></p><p><img src="https://hx24.huoxing24.com/image/crawler/2020/09/28/1601261161638216.jpg" alt="拜占庭">资料来源：《区块链技术指南》，OKEx Research</p><p>而著名的中本聪共识协议则创造性地用概率保证实际运行的共识，解决了节点无法自由进出的问题，但是成本高昂问题仍未被解决。</p><p><strong>图2：中本聪共识协议工作原理</strong></p><p><img src="https://hx24.huoxing24.com/image/crawler/2020/09/28/1601261161662703.jpg" alt="拜占庭">资料来源：OKEx Research</p><p>Avalanche共识协议则结合了两类协议的优点：借鉴了中本聪协议概率性安全保障的设计，同时加入了BFT属性，增加系统的效率和安全性。</p><p><strong>3.Avalanche原理：“雪花”到“雪崩”的层层完善</strong></p><p>正如Avalanche白皮书提到的“雪花”到“雪崩”过程，Avalanche的4个子协议组成正是从最简单的Slush协议，到Snowflake、Snowball 和 Avalanch，逐步完善，形成了“雪花”到“雪崩”的质变。</p><p><strong>3.1. “雪泥”Slush 协议：万物之初</strong></p><p>Slush协议是最基础的“雪泥”，通过多次随机抽样来达成共识。为便于理解，这里我们以投票确认颜色为例。节点达成共识的步骤如下：</p><p>（1）初始状态时所有的节点均未着色；</p><p>（2）当节点A收到信息时，未着色的节点将信息颜色设为自己的颜色，并询问其他节点的颜色；</p><p>（3）未着色的节点B收到询问，将自己染成相同颜色并回复；已着色的节点C收到询问会回复自己的颜色；</p><p>（4）节点A收到多个响应后，如果大多数颜色和自己的一直，则不改变颜色，否则改变颜色，即以大多数其他节点的颜色反馈来校正自己的颜色。</p><p>Slush协议就已经解决了经典共识协议通讯成本高的问题，还用部分抽样等方式避免了中本聪共识协议高能耗的问题。后续协议的改进主要为了提升共识协议安全性。</p><p><strong>3.2. “雪花”Snowflake协议：初步改善</strong></p><p>在拜占庭节点存在的情况下，Slush不能提供强大的安全保证。为此，Snowflake作为升级版协议引入了计数器（Counter）来增加系统的安全性。</p><p>具体而言，网络中的攻击节点故意散播错误的颜色，可能导致Slush某一轮统计得到错误的颜色，而Snowflake的计数器统计了某种颜色连续出现的次数，只有某种颜色连续出现多次，节点才会改变自己的颜色。如此避免了拜占庭节点带来的干扰，确保了系统的安全性和活跃度。</p><p><strong>3.3. “雪球”Snowball协议：深入升级</strong></p><p>Snowball在Snowflake的基础上更进一步地。引入了类似信誉积分的制度——信任度，以提高安全性。</p><p>具体而言，Snowflake协议的改进如下：</p><p>（1）每成功查询一次，节点就为该颜色的信任度加1分；</p><p>（2）节点会切换为信任度较高的颜色。</p><p>Snowball协议不仅比Snowflake更难遭受攻击，而且更容易推广到多命令协议。</p><p><strong>3.4. “雪崩”Avalanche协议：量变到质变</strong></p><p>终极Boss“雪崩”——Avalanche又在Snowball的基础上增加了有向无循环图（DAG）来记录所有的交易状态。在DAG中，如果想给从创世点到某节点路径上的所有节点都投票只需要给该节点投票，大大提高了效率。其次，DAG有着类似于区块链的链式结构记录交易信息，使得过去的交易信息很难被篡改，进一步提升了安全性。</p><p>图3：DAG示意图</p><p><img src="https://hx24.huoxing24.com/image/crawler/2020/09/28/1601261161723758.jpg" alt="拜占庭">资料来源：《区块链新共识算法 Snowflake to Avalanche》，OKEx Research</p><p><strong>3.5. Avalanche协议：集前期协议之大成</strong></p><p>吸取了早期两个共识协议的优点，并经过4个协议层次递进、逐步改善，Avalanche协议具有许多优良特性。</p><p>（1）高效的可扩展性：轻量级，可扩展，低延迟；</p><p>（2）高拜占庭容错：即使网络中有超过50%的节点是拜占庭节点，网络依然是安全的;</p><p>（3）静态绿色：与PoW机制不同，Avalanche协议不会浪费任何资源;</p><p>（4）低通信成本：Avalanche协议比传统共识协议的通讯复杂度更低。</p><p><strong>4. 零确认交易与Avalanche协议</strong></p><p>Avalanche刚面世时，人们还没有发现Avalanche协议与零确认交易之间有什么关系。然而在2018年12月左右，BCH社区的技术人员Chris Pacia发表一篇文章，认为可以使用Avalanche协议来保证零确认交易的安全性，一时起千层浪，引发了市场的广泛兴趣。</p><p>Avalanche协议的确认需要多次抽样，为缩短确认时间，则抽样次数必须受到限制，这意味着，恶意节点超过一定比例后，在有限抽样里诚实节点无法达成共识。为此，Chris Pacia认为可以引入PoW机制来保护网络的安全，防止黑客的攻击节点数量太多。</p><p><strong>5. Avalanche现状：众望所归</strong></p><p>自2018年Avalanche白皮书发布以来，受到了广泛的首肯心折，许多VC相竞为之折腰。2019 年，雪崩协议Ava获得了 a16z、Polychain Capital 等机构 600 万美元融资。2020年6月，AVA Lab又完成了一笔1200万美元的代币私募融资，同年7月，又获得IOSG Ventures的战略投资，并就中国市场未来发展达成独家战略合作协议。根据最新消息，AVA的公募于7月8日开启。</p><p><strong>6. 结语</strong></p><p>Avalanche结合了早期两种共识协议的优点并改进其缺点，具有高拓展性、静态绿色以及低通信成本的优点。同时，从Slush到Avalanche层层递进、逐步完善，引入计数器、可信度、DAG等，日臻完善。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://www.avalabs.org/whitepapers">Avalanche writepaper</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Avalanche </tag>
            
            <tag> 共识算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>What&#39;s Avalanche?</title>
      <link href="/2022/02/07/blockchain/avalanche/What&#39;s%20Avalanche/"/>
      <url>/2022/02/07/blockchain/avalanche/What&#39;s%20Avalanche/</url>
      
        <content type="html"><![CDATA[<h1 id="What-is-Avalanche"><a href="#What-is-Avalanche" class="headerlink" title="What is Avalanche?"></a>What is Avalanche?</h1><p>Avalanche is an open-source platform for launching decentralized applications and enterprise blockchain deployments in one interoperable, highly scalable ecosystem. Avalanche is the first decentralized smart contracts platform built for the scale of global finance, with near-instant transaction finality. Ethereum developers can quickly build on Avalanche as Solidity works out-of-the-box.</p><p>A key difference between Avalanche and other decentralized networks is the <font color="red">consensus protocol</font>. Over time, people have come to a false understanding that blockchains have to be slow and not scalable. The Avalanche protocol employs a novel approach to consensus to achieve its <font color="red">strong safety guarantees, quick finality, and high-throughput</font> without compromising decentralization.</p><h1 id="Consensus-protocol"><a href="#Consensus-protocol" class="headerlink" title="Consensus protocol"></a>Consensus protocol</h1><p><img src="https://docs.avax.network/assets/images/Consensus-protocol-comparison-aa555b20f36947d6a5ff869d8758fa6e.png" alt="image"></p><p>Protocols in the Avalanche family operate through repeated sub-sampled voting. When a <a href="http://support.avalabs.org/en/articles/4064704-what-is-a-blockchain-validator">validator</a> is determining whether a <a href="http://support.avalabs.org/en/articles/4587384-what-is-a-transaction">transaction</a> should be accepted or rejected, it asks a small, random subset of validators whether they think the transaction should be accepted or rejected. If the queried validator thinks the transaction is invalid, has already rejected the transaction, or prefers a conflicting transaction, it replies that it thinks the transaction should be rejected. Otherwise, it replies that it thinks the transaction should be accepted.</p><p>If a sufficiently large portion (<em>alpha</em> α) of the validators sampled reply that they think the transaction should be accepted, the validator prefers to accept the transaction. That is, when it is queried about the transaction in the future, it will reply that it thinks the transaction should be accepted. Similarly, the validator will prefer to reject the transaction if a sufficiently large portion of the validators replies that they think the transaction should be rejected.</p><p>The validator repeats this sampling process until <em>alpha</em> of the validators queried reply the same way (accept or reject) for <em>beta</em> β consecutive rounds.</p><p>In the common case when a transaction has no conflicts, finalization happens very quickly. When conflicts exist, honest validators quickly cluster around conflicting transactions, entering a positive feedback loop until all correct validators prefer that transaction. This leads to the acceptance of non-conflicting transactions and the rejection of conflicting transactions.</p><p><img src="https://docs.avax.network/assets/images/howavalancheconsensusworks-a37dc2bdf67c7c2997dcbfd01ee28e64.png" alt="image"></p><p>It is guaranteed (with high probability based on system parameters) that if any honest validator accepts or rejects a transaction, all honest validators will accept or reject that transaction.</p><h2 id="Key-Features"><a href="#Key-Features" class="headerlink" title="Key Features"></a>Key Features</h2><h3 id="Speed"><a href="#Speed" class="headerlink" title="Speed"></a>Speed</h3><p>Uses a novel consensus protocol, developed by a team of Cornell computer scientists, and is able to permanently confirm transactions in under <font color="red">1 second</font>.</p><h3 id="Scalability"><a href="#Scalability" class="headerlink" title="Scalability"></a>Scalability</h3><p>Capable of <font color="red">4,500 transactions per second</font>–an order of magnitude greater than existing blockchains.</p><h3 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h3><p><font color="red">Ensures stronger security guarantees well</font>-above the 51% standard of other networks.</p><h3 id="Flexibility"><a href="#Flexibility" class="headerlink" title="Flexibility"></a>Flexibility</h3><p><font color="red">Easily</font> create custom blockchains and decentralized apps that contain almost any arbitrary logic.</p><h3 id="Sustainability"><a href="#Sustainability" class="headerlink" title="Sustainability"></a>Sustainability</h3><p>Uses energy-efficient <font color="red">proof-of-stake</font> consensus algorithm rather than proof-of-work.</p><h3 id="Smart-Contract-Support"><a href="#Smart-Contract-Support" class="headerlink" title="Smart Contract Support"></a>Smart Contract Support</h3><p>Supports the creation of <font color="red">Solidity smart contracts</font> and your favorite Ethereum tools like Remix, Metamask, Truffle, and more.</p><h3 id="Private-and-Public-Blockchains"><a href="#Private-and-Public-Blockchains" class="headerlink" title="Private and Public Blockchains"></a>Private and Public Blockchains</h3><p>Create your own public or private blockchains.</p><h3 id="Designed-for-Finance"><a href="#Designed-for-Finance" class="headerlink" title="Designed for Finance"></a>Designed for Finance</h3><p>Native support for easily creating and trading <font color="red">digital smart assets</font> with complex, custom rulesets.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><p><a href="https://docs.avax.network/">Avalanche website</a></p></li><li><p><a href="https://github.com/ava-labs/avalanchego">Avalanche source code</a></p></li><li><p><a href="https://academy.binance.com/zh/articles/what-is-avalanche-avax">What’s is Avalanche?</a></p></li><li><p><a href="https://www.avalabs.org/whitepapers">Avalanche writepaper</a></p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Avalanche </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker方式搭建以太坊网络-私有链</title>
      <link href="/2022/01/29/blockchain/ethereum/Docker%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%A4%AA%E5%9D%8A---%E7%A7%81%E6%9C%89%E9%93%BE/"/>
      <url>/2022/01/29/blockchain/ethereum/Docker%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%A4%AA%E5%9D%8A---%E7%A7%81%E6%9C%89%E9%93%BE/</url>
      
        <content type="html"><![CDATA[<p>本文涉及的知识和技术有：</p><ul><li>Docker：一种时下流行的容器</li><li>geth：以太坊客户端的go实现</li><li>truffle：以太坊合约部署工具</li></ul><h2 id="主机配置"><a href="#主机配置" class="headerlink" title="主机配置"></a>主机配置</h2><p>此处需要补充一点的是，如果您使用的是虚拟机、云主机或者老破小机器，需要确保分配给主机的内存至少2GB。因为以太坊为了抵御比特大陆这样的ASIC矿机对算力的垄断，采用了和比特币完全不同的PoW算法——ethash。该算法的特点是算力不敏感，内存敏感。该算法目前需要在内存创建大约1GB的DAG用来做PoW运算，且DAG会随着区块的增加呈阶梯状增长，因此建议至少给挖矿节点的宿主机器分配至少2GB的内存，且保留扩大内存容量的灵活性。</p><h2 id="获取geth镜像"><a href="#获取geth镜像" class="headerlink" title="获取geth镜像"></a>获取geth镜像</h2><p>docker hub上有现成的geth镜像。直接获取：</p><pre><code class="bash">docker pull ethereum/client-go:v1.8.12</code></pre><h2 id="创建Docker网络"><a href="#创建Docker网络" class="headerlink" title="创建Docker网络"></a>创建Docker网络</h2><p>旧版本的docker容器相互之间是依靠link建立关系。<br>新版本docker推荐创建自有网路，再将需要互联的容器配置到相同的网络中。<br>于是，我们创建一个名为“ethnet“的网络。该网络配置如下：</p><ul><li>子网172.19.0.0/16<ul><li>IP段172.19.0.0</li><li>掩码255.255.0.0</li><li>IP范围172.19.0.1~172.19.255.254</li><li>IP广播172.19.255.255</li></ul></li></ul><pre><code class="bash">docker network create -d bridge --subnet=172.19.0.0/16 ethnetdocker network ls</code></pre><h1 id="配置以太坊网络"><a href="#配置以太坊网络" class="headerlink" title="配置以太坊网络"></a>配置以太坊网络</h1><p>运行如下命令进入一个容器：</p><pre><code class="bash">docker run -it --rm --network ethnet --ip 172.19.0.50 -v /opt/docker-project/eth/workspace:/workspace --entrypoint /bin/sh ethereum/client-go:v1.8.12</code></pre><blockquote><p>–network ethnet参数指定了该容器加入刚才创建的ethnet网络<br> –ip 172.19.0.50指定了一个固定IP给该容器。</p></blockquote><h2 id="创建账户"><a href="#创建账户" class="headerlink" title="创建账户"></a>创建账户</h2><p>首先，在容器内的/workspace目录创建目录和文件</p><p>执行以下命令：</p><pre><code class="bash">mkdir -p /workspacedappmkdir -p /workspace/dapp/minermkdir -p /workspace/dapp/datatouch /workspace/dapp/genesis.json</code></pre><p>然后运行如下命令创建账户：</p><pre><code class="bash">geth -datadir /workspace/dapp/miner/data account new</code></pre><p>输入两次password，获得地址。将地址记录下来，后面要用到。</p><blockquote><p>重复如上步骤可以创建多个账户。</p></blockquote><h2 id="创建创世区块"><a href="#创建创世区块" class="headerlink" title="创建创世区块"></a>创建创世区块</h2><p>编辑刚才创建的文件</p><pre><code class="bash">vi /workspace/dapp/data/genesis.json</code></pre><p>文件内容：</p><pre><code class="json">{  "config": {    "chainId": 88,    "homesteadBlock": 0,    "eip155Block": 0,    "eip158Block": 0  },  "alloc"      : {    "b126d89780d2221ceffe5c94efd9ca6a005a9f0c": {"balance": "100000000000000000000"},    "93415bb68da6816c581537a4fa74727ddf6f4f4d": {"balance": "1000000000000000000"},    "fa5773a704ee9e91e60ffb8fe4207e934f70619f": {"balance": "1000000000000000000"}  },  "coinbase"   : "0x0000000000000000000000000000000000000000",  "difficulty" : "0x400",  "extraData"  : "",  "gasLimit"   : "0x2fefd8",  "nonce"      : "0x0000000000000000",  "mixhash"    :  "0x0000000000000000000000000000000000000000000000000000000000000000",  "parentHash" :  "0x0000000000000000000000000000000000000000000000000000000000000000",  "timestamp"  : "0x00"}</code></pre><ul><li>genesis.json是用来创建创世区块的配置文件</li><li>加入同一私链的节点必须使用同一配置文件</li><li>chainid是私链网络的标识，可以是任意数字。</li><li>即使chainid相同，如果genesis.json配置不一样，也将是两个不兼容的网络</li><li>alloc下面列举了4个账户地址，分别是上一步创建并记录下来的地址。</li><li>balance是创世区块为每个账户分配的初始以太币。这里看似分配了很多，其实单位是wei。1eth=10^18wei。也就是除了第一个账户给了100eth外，其它几个账户分别只拥有1eth。这里给第一个账户多分点，是因为我们之后需要用它来部署合约。</li></ul><h2 id="完成以太坊网络配置"><a href="#完成以太坊网络配置" class="headerlink" title="完成以太坊网络配置"></a>完成以太坊网络配置</h2><p>此时可以退出刚才的容器。由于我们运行容器是加了–rm参数，刚才的容器会被删除，但宿主机的/workspace下的文件会被保存下来。</p><h1 id="挖矿"><a href="#挖矿" class="headerlink" title="挖矿"></a>挖矿</h1><p>上述步骤只是配置好了一个以太坊私有网络，并没有真正创建网络。我们知道，以太坊网络是一个分布式的网络，有了矿工，才有的网络。于是，我们首先得有一个矿工。</p><h2 id="创建“主”矿工节点"><a href="#创建“主”矿工节点" class="headerlink" title="创建“主”矿工节点"></a>创建“主”矿工节点</h2><p>我们接下来打算创建的矿工节点，成为“主”矿工，因为它需要拥有如下特性：</p><ul><li>它是一个容器，并且是持久的容器</li><li>它会自动读取genesis.json文件，并初始化以太坊网络</li><li>它能够连接其它节点（容器）</li><li>它能够接受各种rpc调用，并能够部署合约</li><li>它已经配置好挖矿账户，可以一键挖矿</li></ul><p>于是，我们按照这个要求，开始一步步创建矿工节点。</p><h3 id="创建entrypoint脚本"><a href="#创建entrypoint脚本" class="headerlink" title="创建entrypoint脚本"></a>创建entrypoint脚本</h3><p>创建一个文件：</p><pre><code class="bash">vi /opt/docker-project/eth/workspace/dapp/init.sh</code></pre><p> 文件内容如下：</p><pre><code class="bash">#!/bin/shgeth -datadir ~/data/ init /workspace/dapp/data/genesis.jsonif [  $# -lt 1 ]; then   exec "/bin/sh"else  exec /bin/sh -c "$@"fi</code></pre><blockquote><p>该脚本的功能是让以太坊节点（容器）自动初始化以太坊网络，并且接受一个自动运行脚本作为输入。</p></blockquote><h3 id="创建自动运行脚本"><a href="#创建自动运行脚本" class="headerlink" title="创建自动运行脚本"></a>创建自动运行脚本</h3><p>创建一个文件：</p><pre><code class="bash">vi /opt/docker-project/eth/workspace/dapp/mine.sh</code></pre><p>内容如下：</p><pre><code class="bash">#!/bin/shaccount='b126d89780d2221ceffe5c94efd9ca6a005a9f0c'cp -r /workspace/dapp/miner/data/keystore/* ~/data/keystore/geth -datadir ~/data/ --networkid 88 --rpc --rpcaddr "172.19.0.50" --rpcapi admin,eth,miner,web3,personal,net,txpool --unlock ${account} --etherbase ${account} console</code></pre><ul><li>第一行命令是将刚才生成的账户私钥文件拷贝到容器的home目录下。因为/workspace是宿主目录挂载的，并不是linux文件系统，直接将datadir指定到该目录会导致geth报错。</li><li>第二行命令是启动以太坊节点的命令。<ul><li>–networkid 88指定了networkid，这个必须与genesis.json内设置保持一致</li><li>–rpc –rpcaddr “172.19.0.50” –rpcapi …. 这些参数表示该节点接受rpc，并且指定了rpc的协议</li><li>–unlock “0x…” 加入该参数会需要用户输入账户密码。密码校验后会解锁该账户。账户解锁后，该节点就能使用此账户的私钥进行签名加密等动作，用以进行交易、发布合约等。</li><li>–etherbase 参数指定了挖矿收益账户</li></ul></li></ul><h3 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h3><pre><code class="bash">chmod +x /opt/docker-project/eth/workspace/dapp/init.shchmod +x /opt/docker-project/eth/workspace/dapp/mine.shdocker run -it --name=miner --network ethnet --ip 172.19.0.50 --hostname node -v /opt/docker-project/eth/workspace:/workspace --entrypoint /workspace/dapp/init.sh ethereum/client-go:v1.8.12 /workspace/dapp/mine.sh</code></pre><blockquote><p>该命令会创建一个持久化的容器。容器的entrypoint和自动运行脚本指定为我们刚创建的那两个脚本。</p></blockquote><p>如果报错：</p><pre><code class="bash">Fatal: Failed to unlock account (no key for given address or file)</code></pre><p>可能原因是没有修改上面的mine.sh脚本的account参数为第一个账户地址</p><h2 id="创建“从”矿工节点"><a href="#创建“从”矿工节点" class="headerlink" title="创建“从”矿工节点"></a>创建“从”矿工节点</h2><p>只有一个节点的网络，怎么看都不像“分布式”网络。所以我们需要创建更多的节点来形成一个“分布式网络”。我们称这些节点叫做“从”矿工。<br> 这类矿工不需要交易，不需要发布合约，因此不需要unlock账户，也不需要接受rpc。它们只知道埋头挖矿。</p><h3 id="创建自动运行脚本-1"><a href="#创建自动运行脚本-1" class="headerlink" title="创建自动运行脚本"></a>创建自动运行脚本</h3><p>“从”矿工节点和“主”矿工节点共享entrypoint，以保证它们创建出完全相同的网络。<br> 只有自动运行脚本不太一样，</p><pre><code class="bash">vi /opt/docker-project/eth/workspace/dapp/node.sh</code></pre><p>文件内容：</p><pre><code class="bash">#!/bin/shcp -r /workspace/dapp/miner/data/keystore/* ~/data/keystore/geth -datadir ~/data/ --networkid 88 console </code></pre><p>创建容器:</p><pre><code class="bash">chmod +x /opt/docker-project/eth/workspace/dapp/node.shdocker run -it --name=node1 --network ethnet --ip 172.19.0.51 --hostname node1 -v /opt/docker-project/eth/workspace:/workspace --entrypoint /workspace/dapp/init.sh ethereum/client-go:v1.8.12 /workspace/dapp/node.sh</code></pre><h1 id="操作节点"><a href="#操作节点" class="headerlink" title="操作节点"></a>操作节点</h1><p>以上创建出了多个以太坊节点，运行在同一网络下。每个节点都可以执行如下操作。供参考。</p><h2 id="节点发现"><a href="#节点发现" class="headerlink" title="节点发现"></a>节点发现</h2><h3 id="查看节点信息"><a href="#查看节点信息" class="headerlink" title="查看节点信息"></a>查看节点信息</h3><pre><code class="bash">geth -datadir ~/data/ --networkid 88 console&gt;admin.nodeInfo.enode# 输出"enode://708b66364c83af2d3725c309f2bdc0e7d4e395c6ac7310e1a1147b9dfe084649e6c6a3ce6c483c51ab6e924f6abade647246c2b57ecc49d9a573cea896cdf0e6@[::]:30303"</code></pre><h3 id="配置静态节点文件"><a href="#配置静态节点文件" class="headerlink" title="配置静态节点文件"></a>配置静态节点文件</h3><p>~/data/geth/static-nodes.json</p><pre><code class="json">[    "enode://&lt;node public key&gt;@&lt;node IP address&gt;:&lt;node port&gt;"]</code></pre><h3 id="查看连接上的节点"><a href="#查看连接上的节点" class="headerlink" title="查看连接上的节点"></a>查看连接上的节点</h3><pre><code class="bash">geth -datadir ~/data/ --networkid 88 console&gt;admin.peers</code></pre><h3 id="动态添加节点"><a href="#动态添加节点" class="headerlink" title="动态添加节点"></a>动态添加节点</h3><pre><code class="bash">&gt;admin.addPeer("enode://&lt;node public key&gt;@&lt;node IP address&gt;:&lt;node port&gt;")</code></pre><h2 id="挖矿-1"><a href="#挖矿-1" class="headerlink" title="挖矿"></a>挖矿</h2><p>启动miner容器</p><pre><code class="bash">&gt;miner.start(1)</code></pre><ul><li>参数1指定了挖矿的线程数。</li><li>首次启动节点会消耗大约20~30分钟产生DAG</li><li>某开始挖矿后，其它节点将会收到新区块并打印</li></ul><h1 id="部署合约"><a href="#部署合约" class="headerlink" title="部署合约"></a>部署合约</h1><h2 id="创建truffle镜像"><a href="#创建truffle镜像" class="headerlink" title="创建truffle镜像"></a>创建truffle镜像</h2><p>由于没有找到好用的truffle镜像，我自己创建了一个。Dockerfile内容如下：</p><pre><code class="ruby">FROM alpine:3.8MAINTAINER Cary Tan hbuzzs@163.comENV PS1='[truffle@docker $PWD]\$ 'RUN echo "http://mirrors.tuna.tsinghua.edu.cn/alpine/v3.8/main" &gt; /etc/apk/repositories \      &amp;&amp; echo "http://mirrors.tuna.tsinghua.edu.cn/alpine/v3.8/community" &gt;&gt; /etc/apk/repositories \      &amp;&amp; apk update \          &amp;&amp; apk add curl \      &amp;&amp; apk add npm \      &amp;&amp; apk add git \      &amp;&amp; mkdir -p /workspace \      &amp;&amp; npm config set registry https://registry.npm.taobao.org \      &amp;&amp; npm install -g truffleWORKDIR /workspaceCMD /bin/sh</code></pre><p>也可使用他人上传的镜像：</p><pre><code class="bash">docker pull txcary/truffle:180806# 这个镜像没有curl 需要安装apk add curl</code></pre><h2 id="新建truffle工程"><a href="#新建truffle工程" class="headerlink" title="新建truffle工程"></a>新建truffle工程</h2><pre><code class="bash">mkdir -p /opt/docker-project/truffle/workspace/VanTokencd /opt/docker-project/truffle/workspace/VanTokengit clone https://github.com/trufflesuite/truffle-init-bare.git</code></pre><h2 id="启动truffle容器"><a href="#启动truffle容器" class="headerlink" title="启动truffle容器"></a>启动truffle容器</h2><pre><code class="bash">docker run -it --rm -v /opt/docker-project/truffle/workspace:/workspace --network ethnet txcary/truffle:180806</code></pre><h3 id="测试节点RPC"><a href="#测试节点RPC" class="headerlink" title="测试节点RPC"></a>测试节点RPC</h3><pre><code class="bash">curl 172.19.0.50:8545 -X POST --data '{"id":1,"jsonrpc":"2.0","method":"eth_accounts", "params":[]}' -H "Content-Type: application/json"curl 172.19.0.50:8545 -X POST --data '{"id":1,"jsonrpc":"2.0","method":"eth_getBalance", "params":["0x4c283287839fd441b8c8d18771321bc06a81edae","latest"]}' -H "Content-Type: application/json"</code></pre><ul><li>第一条命令获取节点上的账户</li><li>第二条命令获取账户余额</li><li>如果这两条命令成功了，说明以太坊私有网络搭建成功，并且节点rpc调用成功</li></ul><h3 id="修改truffle-js"><a href="#修改truffle-js" class="headerlink" title="修改truffle.js"></a>修改truffle.js</h3><pre><code class="javascript">module.exports = {        networks: {            development: {                host: "172.19.0.50",                port: 8545,                network_id: 88,                gas: 2900000,                gasPrice: 10000000000            }        }};</code></pre><ul><li>gas使用默认值会导致超限错误，研究半天不知道为什么。要是搞明白的可以给我留言，谢谢！</li><li>gasPrice为默认值</li></ul><h2 id="编写合约Migrations-sol（truffle内置）"><a href="#编写合约Migrations-sol（truffle内置）" class="headerlink" title="编写合约Migrations.sol（truffle内置）"></a>编写合约Migrations.sol（truffle内置）</h2><pre><code class="solidity">pragma solidity &gt;=0.4.22 &lt;0.6.0;contract Migrations {    address public owner;    uint public lastCompletedMigration;    modifier restricted() {        if (msg.sender == owner) _;    }    constructor() public {        owner = msg.sender;    }    function setCompleted(uint completed) public restricted {        lastCompletedMigration = completed;    }    function upgrade(address newAddress) public restricted {        Migrations upgraded = Migrations(newAddress);        upgraded.setCompleted(lastCompletedMigration);    }}</code></pre><h2 id="新建部署脚本"><a href="#新建部署脚本" class="headerlink" title="新建部署脚本"></a>新建部署脚本</h2><p>deploy_contracts.js</p><pre><code class="javascript">var contractsName = artifacts.require("./Storage.sol");module.exports = function(deployer) {  deployer.deploy(contractsName);};</code></pre><h2 id="编译合约"><a href="#编译合约" class="headerlink" title="编译合约"></a>编译合约</h2><pre><code class="bash">truffle compile</code></pre><h2 id="部署合约-1"><a href="#部署合约-1" class="headerlink" title="部署合约"></a>部署合约</h2><pre><code class="bash">truffle migrate --network development --verbose-rpc</code></pre><p>部署成功</p><p><img src="/images/eth_network_set_up/image-20220204103544178.png" alt="image-20220204103544178"></p><h1 id="参考链接："><a href="#参考链接：" class="headerlink" title="参考链接："></a>参考链接：</h1><ul><li><a href="https://www.jianshu.com/p/7994db7a2b89?from=singlemessage">https://www.jianshu.com/p/7994db7a2b89?from=singlemessage</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 部署文档 </tag>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法分析</title>
      <link href="/2022/01/18/data_struct_algorithm/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/"/>
      <url>/2022/01/18/data_struct_algorithm/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="数据结构与算法分析"><a href="#数据结构与算法分析" class="headerlink" title="数据结构与算法分析"></a>数据结构与算法分析</h1><h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><ul><li>了解算法分析方法（第二章-13）</li><li>精通表、栈和队列（第三章-27）、树（第四章-40）、散列（第五章-36）、优先队列、堆（第六章-28）、排序（第七章-50）、不相交集类（第八章-17）</li><li>精通图论（第九章-38）、算法设计技巧（第十章-50）、红黑树（第十二章第二节-5）</li></ul><h1 id="第-2-章-算法分析方法"><a href="#第-2-章-算法分析方法" class="headerlink" title="第 2 章 算法分析方法"></a>第 2 章 算法分析方法</h1><h2 id="2-4-运行时间计算"><a href="#2-4-运行时间计算" class="headerlink" title="2.4 运行时间计算"></a>2.4 运行时间计算</h2><h3 id="2-4-1-一般法则"><a href="#2-4-1-一般法则" class="headerlink" title="2.4.1 一般法则"></a>2.4.1 一般法则</h3><ol><li>法则1 —— for循环</li></ol><p>一个for循环的运行时间至多是该for循环内部那些语句（包括测试）的运行时间乘以迭代的次数</p><ol><li>法则2 —— 嵌套的for循环</li></ol><p>在一组嵌套循环内部的一条语句的运行时间为该语句的运行时间乘以该组所有的for循环的大小的乘积</p><ol><li>法则3 —— 顺序语句</li></ol><p>将各个语句的运行时间求和即可。这意味着其中的最大值就是所得的运行时间。</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled.png" alt="Untitled"></p><ol><li>法则4 —— if/else语句</li></ol><p>一个if/else语句的运行时间从不超过判断的运行时间再加上S1和S2中运行时间长者的总的运行时间。</p><h1 id="第-3-章-表、栈和队列"><a href="#第-3-章-表、栈和队列" class="headerlink" title="第 3 章 表、栈和队列"></a>第 3 章 表、栈和队列</h1><h2 id="3-1-抽象数据类型"><a href="#3-1-抽象数据类型" class="headerlink" title="3.1 抽象数据类型"></a>3.1 抽象数据类型</h2><p>抽象数据类型（ADT）是带有一组操作的一些对象的集合。</p><h2 id="3-2-表ADT"><a href="#3-2-表ADT" class="headerlink" title="3.2 表ADT"></a>3.2 表ADT</h2><p>我们称形如$A_0$$,A_1,A_2,…,A_{N-1}$的为表，该表大小为N</p><h3 id="3-2-1-表的简单数组实现"><a href="#3-2-1-表的简单数组实现" class="headerlink" title="3.2.1 表的简单数组实现"></a>3.2.1 表的简单数组实现</h3><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%201.png" alt="Untitled"></p><h3 id="3-2-2-简单链表"><a href="#3-2-2-简单链表" class="headerlink" title="3.2.2 简单链表"></a>3.2.2 简单链表</h3><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%202.png" alt="Untitled"></p><h2 id="3-6-栈ADT"><a href="#3-6-栈ADT" class="headerlink" title="3.6 栈ADT"></a>3.6 栈ADT</h2><h3 id="3-6-1-栈模型"><a href="#3-6-1-栈模型" class="headerlink" title="3.6.1 栈模型"></a>3.6.1 栈模型</h3><p>栈是限制插入和删除只能在一个位置上进行的表，该位置是表的末端，叫做站的顶（top）。</p><p>栈的基本操作有push（进栈）、pop（出栈）</p><p>栈有时又叫LIFO（后进先出）表</p><h3 id="3-6-3-应用"><a href="#3-6-3-应用" class="headerlink" title="3.6.3 应用"></a>3.6.3 应用</h3><ul><li>平衡符号</li><li>后缀表达式</li><li>方法调用</li></ul><h2 id="3-7-队列ADT"><a href="#3-7-队列ADT" class="headerlink" title="3.7 队列ADT"></a>3.7 队列ADT</h2><h3 id="3-7-1-队列模型"><a href="#3-7-1-队列模型" class="headerlink" title="3.7.1 队列模型"></a>3.7.1 队列模型</h3><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%203.png" alt="Untitled"></p><h1 id="第-4-章-树"><a href="#第-4-章-树" class="headerlink" title="第 4 章 树"></a>第 4 章 树</h1><h2 id="4-1-预备知识"><a href="#4-1-预备知识" class="headerlink" title="4.1 预备知识"></a>4.1 预备知识</h2><h2 id="4-2-二叉树"><a href="#4-2-二叉树" class="headerlink" title="4.2 二叉树"></a>4.2 二叉树</h2><h2 id="4-3-查找树ADT-——-二叉查找树"><a href="#4-3-查找树ADT-——-二叉查找树" class="headerlink" title="4.3 查找树ADT ——  二叉查找树"></a>4.3 查找树ADT ——  二叉查找树</h2><h2 id="4-4-AVL树"><a href="#4-4-AVL树" class="headerlink" title="4.4 AVL树"></a>4.4 AVL树</h2><p>AVL树是带有平衡条件的二叉查找树</p><p>特点：</p><ul><li>本身首先是一棵二叉搜索树。</li><li>每个节点的左右子树的高度之差的绝对值（平衡因子）最多为1</li></ul><h3 id="4-4-1-单旋转"><a href="#4-4-1-单旋转" class="headerlink" title="4.4.1 单旋转"></a>4.4.1 单旋转</h3><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%204.png" alt="Untitled"></p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%205.png" alt="Untitled"></p><h3 id="4-4-2-双旋转"><a href="#4-4-2-双旋转" class="headerlink" title="4.4.2 双旋转"></a>4.4.2 双旋转</h3><h2 id="4-5-伸展树"><a href="#4-5-伸展树" class="headerlink" title="4.5 伸展树"></a>4.5 伸展树</h2><p>伸展树保证从空树开始连续M次对树的操作最多花费*O(M log N)*时间</p><p>伸展树基于这样的事实：对于二叉查找树来说，每次操作最坏情形时间*O(N)*并不坏，只要它相对不常发生就行。</p><h2 id="4-6-树的遍历"><a href="#4-6-树的遍历" class="headerlink" title="4.6 树的遍历"></a>4.6 树的遍历</h2><ul><li>先序遍历</li><li>中序遍历</li><li>后序遍历</li><li>层序遍历</li></ul><h2 id="4-7-B-树"><a href="#4-7-B-树" class="headerlink" title="4.7 B+树**"></a>4.7 B+树**</h2><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%206.png" alt="Untitled"></p><p>阶为M的B+树的特性：</p><ul><li>数据项存储在树叶上</li><li>非叶子节点存储直到M-1个关键字以指示搜索的方向；关键字i代表子树i+1中的最小的关键字</li><li>树的根或者是一片树叶，或者其儿子数在2和M之间</li><li>除根外，所有非树叶节点的儿子数在<code>⌈M/2⌉</code>和<code>M</code>之间</li><li>所有的树叶都在相同的深度上并有<code>⌈L/2⌉</code>和<code>L</code> 之间个数据项</li></ul><p>B树与B+树不同点：</p><ul><li>单一节点存储的元素更多，使得查询的IO次数更少，所以也就使得它更适合做为数据库MySQL的底层数据结构了。</li><li>所有的查询都要查找到叶子节点，查询性能是稳定的，而B树，每个节点都可以查找到数据，所以不稳定。</li><li>所有的叶子节点形成了一个有序链表，更加便于查找。</li></ul><h1 id="第-5-章-散列"><a href="#第-5-章-散列" class="headerlink" title="第 5 章 散列"></a>第 5 章 散列</h1><h2 id="5-1-一般想法"><a href="#5-1-一般想法" class="headerlink" title="5.1 一般想法"></a>5.1 一般想法</h2><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%207.png" alt="Untitled"></p><h2 id="5-2-散列函数"><a href="#5-2-散列函数" class="headerlink" title="5.2 散列函数"></a>5.2 散列函数</h2><p>如果关键字是整数一般合理的方法就是直接返回<em>key mod Tablesize</em></p><p>如果关键字是字符串，</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%208.png" alt="Untitled"></p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%209.png" alt="Untitled"></p><h2 id="5-3-分离链接法"><a href="#5-3-分离链接法" class="headerlink" title="5.3 分离链接法"></a>5.3 分离链接法</h2><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2010.png" alt="Untitled"></p><p>分离链接法：其做法是将散列到同一个值的所有元素保留到一个表中</p><h2 id="5-4-不同链表的散列表"><a href="#5-4-不同链表的散列表" class="headerlink" title="5.4 不同链表的散列表"></a>5.4 不同链表的散列表</h2><h3 id="5-4-1-线性探测法"><a href="#5-4-1-线性探测法" class="headerlink" title="5.4.1 线性探测法"></a>5.4.1 线性探测法</h3><p>在线性探测法中，函数f是i的线性函数，典型情形是$f(i) = i$</p><h3 id="5-4-2-平方探测法"><a href="#5-4-2-平方探测法" class="headerlink" title="5.4.2 平方探测法"></a>5.4.2 平方探测法</h3><p>平方探测是消除线性探测中一次聚集问题的冲突解决方法。</p><p>平方探测就是冲突函数为二次的探测方法，流行的选择是$f(i)=i^2$</p><p>定理：如果使用平方探测，且表的大小是素数，那么当表至少有一半是空的时候总能够插入一个新元素</p><h3 id="5-4-3-双散列"><a href="#5-4-3-双散列" class="headerlink" title="5.4.3 双散列"></a>5.4.3 双散列</h3><p>对于双散列，一种流行的选择是$f(i)=i*hash_2(x)$</p><h2 id="5-5-再散列"><a href="#5-5-再散列" class="headerlink" title="5.5 再散列"></a>5.5 再散列</h2><p>建立另外一个大约两倍大的表（而且使用一个相关的新散列函数），扫描整个原始散列表，计算每个（未删除的）元素的新散列值并将其插入到新表中</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2011.png" alt="Untitled"></p><h2 id="5-6-标准库中的散列表"><a href="#5-6-标准库中的散列表" class="headerlink" title="5.6 标准库中的散列表"></a>5.6 标准库中的散列表</h2><h2 id="5-7-最坏情形下O-1-访问的散列表"><a href="#5-7-最坏情形下O-1-访问的散列表" class="headerlink" title="5.7 最坏情形下O(1)访问的散列表"></a>5.7 最坏情形下O(1)访问的散列表</h2><h3 id="5-7-1-完美散列"><a href="#5-7-1-完美散列" class="headerlink" title="5.7.1 完美散列"></a>5.7.1 完美散列</h3><h3 id="5-7-2-布谷鸟散列"><a href="#5-7-2-布谷鸟散列" class="headerlink" title="5.7.2 布谷鸟散列"></a>5.7.2 布谷鸟散列</h3><p>在布谷鸟散列中，假设有N个项。我们维护两个分别超过半空的表，且有两个独立的散列函数，可以把每个项分配到每个表中的一个位置。布谷鸟散列保持不变的是一个项总会被存储在这两个位置之一。</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2012.png" alt="Untitled"></p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2013.png" alt="Untitled"></p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2014.png" alt="Untitled"></p><h3 id="5-7-3-跳房子散列"><a href="#5-7-3-跳房子散列" class="headerlink" title="5.7.3 跳房子散列"></a>5.7.3 跳房子散列</h3><p>跳房子散列的思路是用事先确定的、对计算机的底层体系结构而言是最优的一个常数，给探测序列的最大长度加个上界。这样做可以给出常数集的最坏查询时间，并且与布谷鸟散列一样，查询可以并行化，以同时检查可用位置的有限集。</p><h2 id="5-8-通用散列法"><a href="#5-8-通用散列法" class="headerlink" title="5.8 通用散列法"></a>5.8 通用散列法</h2><h1 id="第-6-章-优先队列（堆）"><a href="#第-6-章-优先队列（堆）" class="headerlink" title="第 6 章 优先队列（堆）"></a>第 6 章 优先队列（堆）</h1><h2 id="6-1-模型"><a href="#6-1-模型" class="headerlink" title="6.1 模型"></a>6.1 模型</h2><p>优先队列是允许至少下列两种操作的数据结构：插入和删除最小者。</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2015.png" alt="Untitled"></p><h2 id="6-2-一些简单的实现"><a href="#6-2-一些简单的实现" class="headerlink" title="6.2 一些简单的实现"></a>6.2 一些简单的实现</h2><ol><li>使用简单链表</li><li>使用二叉查找树</li></ol><h2 id="6-3-二叉堆"><a href="#6-3-二叉堆" class="headerlink" title="6.3 二叉堆"></a>6.3 二叉堆</h2><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2016.png" alt="Untitled"></p><h3 id="6-3-1-结构性质"><a href="#6-3-1-结构性质" class="headerlink" title="6.3.1 结构性质"></a>6.3.1 结构性质</h3><p>堆是一个完全二叉树</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2017.png" alt="Untitled"></p><ol><li>插入</li></ol><p>为将一个元素X插入到堆中，我们在一个可用位置创建一个空穴，否则该堆将不是完全熟，如果可以放在该空穴中而不破坏堆的序，那么插入完成。否则我们把空穴的父节点上的元素移入该空穴中，这样空穴就朝着根的方向上冒一步。继续该过程直到X能被放入空穴中为止。</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2018.png" alt="Untitled"></p><ol><li>删除最小元</li></ol><p>删除最小元以类似于插入的方式处理。当删除一个最小元时，要在跟节点建立一个空穴。由于现在堆少了一个元素，因此堆中最后一个元素X必须移动到该堆的某个地方。如果X可以被放倒空穴中，那么deleteMin完成，否则我们将空穴的两个儿子中较小者移入空穴，这样就把空穴向下推了一层，重复该步骤直到X可以被放入空穴中。</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2019.png" alt="Untitled"></p><h2 id="6-4-优先队列的应用"><a href="#6-4-优先队列的应用" class="headerlink" title="6.4 优先队列的应用"></a>6.4 优先队列的应用</h2><h2 id="6-5-d-堆"><a href="#6-5-d-堆" class="headerlink" title="6.5 d-堆"></a>6.5 d-堆</h2><p>d-堆是二叉堆的简单推广，就像一个二叉堆，只是所有的节点都有d个儿子（因此，二叉堆是2-堆）</p><h2 id="6-6-左式堆"><a href="#6-6-左式堆" class="headerlink" title="6.6 左式堆"></a>6.6 左式堆</h2><p>左式堆像二叉堆那样也具有结构性和有序性。左式堆具有相同的堆序性质，左式堆也是二叉树，左式堆和叉二树唯一的区别是：左式堆不是理想平衡的，而实际上趋向于非常不平衡。</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2020.png" alt="Untitled"></p><h2 id="6-7-斜堆"><a href="#6-7-斜堆" class="headerlink" title="6.7 斜堆"></a>6.7 斜堆</h2><p>斜堆是左式堆的自调节形式，实现起来极其简单。</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2021.png" alt="Untitled"></p><h2 id="6-8-二项队列"><a href="#6-8-二项队列" class="headerlink" title="6.8 二项队列"></a>6.8 二项队列</h2><h3 id="6-8-1-二项队列结构"><a href="#6-8-1-二项队列结构" class="headerlink" title="6.8.1 二项队列结构"></a>6.8.1 二项队列结构</h3><p>一个二项队列不是一颗堆序的树，而是堆序的树的集合，称为森林。</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2022.png" alt="Untitled"></p><h1 id="第-7-章-排序"><a href="#第-7-章-排序" class="headerlink" title="第 7 章 排序"></a>第 7 章 排序</h1><h2 id="7-2-插入排序"><a href="#7-2-插入排序" class="headerlink" title="7.2 插入排序"></a>7.2 插入排序</h2><p>插入排序由N-1趟排序组成。对于p=1到N-1趟，插入排序保证从位置0到位置p上的元素为已排序状态。</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2023.png" alt="Untitled"></p><p>时间复杂度：$O(N^2)$</p><p>定理：通过交换相邻元素进行排序的任何算法平均都需要$Ω(N^2)$时间</p><h2 id="7-4-希尔排序"><a href="#7-4-希尔排序" class="headerlink" title="7.4 希尔排序"></a>7.4 希尔排序</h2><p>定理：使用希尔排序最坏情形运行时间为$O(N^2)$</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2024.png" alt="Untitled"></p><h2 id="7-5-堆排序"><a href="#7-5-堆排序" class="headerlink" title="7.5 堆排序"></a>7.5 堆排序</h2><p>优先队列可以用以$O(NlogN)$时间的排序。基于该思想的算法叫做堆排序。</p><h2 id="7-6-归并排序"><a href="#7-6-归并排序" class="headerlink" title="7.6 归并排序"></a>7.6 归并排序</h2><p>归并排序以O(NlogN)最坏情形时间运行。它是递归算法一个好的实例。</p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2025.png" alt="Untitled"></p><h2 id="7-7-快速排序"><a href="#7-7-快速排序" class="headerlink" title="7.7 快速排序"></a>7.7 快速排序</h2><p>快速排序是事件中一种快速的排序算法，在C++或对Java基本类型的排序汇总特别有用。平均运行时间是$O(NlogN)$。</p><h1 id="第-9-章-图论"><a href="#第-9-章-图论" class="headerlink" title="第 9 章 图论"></a>第 9 章 图论</h1><h2 id="9-1-定义"><a href="#9-1-定义" class="headerlink" title="9.1 定义"></a>9.1 定义</h2><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2026.png" alt="Untitled"></p><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2027.png" alt="Untitled"></p><h2 id="9-2-拓扑排序"><a href="#9-2-拓扑排序" class="headerlink" title="9.2 拓扑排序"></a>9.2 拓扑排序</h2><h2 id="9-3-最短路径算法"><a href="#9-3-最短路径算法" class="headerlink" title="9.3 最短路径算法"></a>9.3 最短路径算法</h2><h3 id="9-3-1-无权最短路径"><a href="#9-3-1-无权最短路径" class="headerlink" title="9.3.1 无权最短路径"></a>9.3.1 无权最短路径</h3><p><img src="/images/data_structures_and_algorithms_analysis/Untitled%2028.png" alt="Untitled"></p><h2 id="未完"><a href="#未完" class="headerlink" title="未完"></a>未完</h2><h1 id="第-9-章-算法设计技巧"><a href="#第-9-章-算法设计技巧" class="headerlink" title="第 9 章 算法设计技巧"></a>第 9 章 算法设计技巧</h1><h2 id="10-1-贪婪算法"><a href="#10-1-贪婪算法" class="headerlink" title="10.1 贪婪算法"></a>10.1 贪婪算法</h2><p>贪婪算法分阶段地工作，在每一个阶段可以认为所做决定是好的。而不考虑将来的后果。</p><h2 id="10-2-分治算法"><a href="#10-2-分治算法" class="headerlink" title="10.2 分治算法"></a>10.2 分治算法</h2><p>分治算法由两部分组成：</p><ul><li>分：递归解决较小的问题</li><li>治：然后从子问题的解构建原问题的解</li></ul><h2 id="10-3-动态规划"><a href="#10-3-动态规划" class="headerlink" title="10.3 动态规划"></a>10.3 动态规划</h2><p>将递归算法重新写成非递归算法，让后者把那些子问题的答案系统第记录在一个表内，利用这种方法的一种技巧叫做动态规划</p><h2 id="10-4-随机数算法"><a href="#10-4-随机数算法" class="headerlink" title="10.4 随机数算法"></a>10.4 随机数算法</h2><h2 id="10-5-回溯算法"><a href="#10-5-回溯算法" class="headerlink" title="10.5 回溯算法"></a>10.5 回溯算法</h2><h1 id="第-12-章-高级数据结构及其实现"><a href="#第-12-章-高级数据结构及其实现" class="headerlink" title="第 12 章 高级数据结构及其实现"></a>第 12 章 高级数据结构及其实现</h1><h2 id="12-2-红黑树"><a href="#12-2-红黑树" class="headerlink" title="12.2 红黑树"></a>12.2 红黑树</h2><p>对红黑树的操作在最坏情形下花费O(logN)时间</p><p>红黑树是具有下列着色性质的二叉查找树：</p><ul><li>每一个节点或者着成红色，或者着成黑色</li><li>根是黑色的</li><li>如果一个节点是红色，那么它的子节点必须是黑色的</li><li>从一个节点到一个null引用的每一条路径必须包含相同数目的黑色节点</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构与算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IPFS原理深入分析</title>
      <link href="/2022/01/18/distributed_storage/IPFS%E5%8E%9F%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/"/>
      <url>/2022/01/18/distributed_storage/IPFS%E5%8E%9F%E7%90%86%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="〇、目标"><a href="#〇、目标" class="headerlink" title="〇、目标"></a>〇、目标</h1><ol><li>熟悉IPFS概念</li><li>熟悉IPFS上传文件、下载文件过程</li></ol><h1 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h1><h2 id="2-BACKGROUND"><a href="#2-BACKGROUND" class="headerlink" title="2. BACKGROUND"></a>2. BACKGROUND</h2><h3 id="Distributed-Hash-Tables-DHTs"><a href="#Distributed-Hash-Tables-DHTs" class="headerlink" title="Distributed Hash Tables(DHTs)"></a>Distributed Hash Tables(DHTs)</h3><ol><li><p>Kademlia DHT</p><p> 优点</p><ul><li>【通信性能】通过大规模网络高效查找:查询平均需要通信$log_2(n)$向上取整节点。(例如，一个由10,000,000个节点组成的网络需要20个跳数)</li><li>【通信性能】低协调开销:优化了发送给其他节点的控制消息的数量</li><li>【安全】通过选择长期存在的节点来抵抗各种攻击</li><li>【应用】在对等应用程序中广泛使用，包括Gnutella和BitTorrent，形成了超过2000万个节点的网络。</li></ul></li><li><p>Coral DSHT</p><p> 优点</p><ul><li>【通信性能】Kademlia将值存储在id与键最接近(使用XOR-distance)的节点中。这并不考虑应用程序数据的局域性，忽略可能已经拥有数据的远节点，并不管最近节点是否需要这份数据而去强制它们存储数据。这浪费了大量的存储和带宽。相反，Coral在能够提供数据块的对等节点存储地址信息</li><li>【通信性能】Coral将DHT API从get_value(key)放宽为get_any_values(key) (DSHT中的“sloppy”)。这仍然工作直到Coral用户只需要一个(工作)peer，而不是完整的列表。作为交换，Coral只能将值的子集分发到最近的节点，从而避免了热点(当一个键变得流行时，会重载所有最近的节点)</li><li>【通信性能】Coral根据区域和大小组织了一个称为簇的独立DSHT层次结构。这使得节点可以首先查询其区域内的对等节点，在不查询远处节点的情况下查找附近的数据，大大减少了查找的延迟</li></ul></li><li><p>S/Kademlia DHT</p><p>S/Kademlia扩展了Kademlia以两种特别重要的方式来抵御恶意攻击:</p><ul><li>【安全】S/Kademlia提供了安全的NodeId生成方案，并防止女巫攻击。它要求节点创建一个PKI密钥对，从密钥对中获得自己的身份，并对彼此的消息进行签名。一种方案包括一个工作证明加密谜题，以使生成女巫攻击的成本很高</li><li>【安全】S/Kademlia节点在不相交的路径上查找值，以确保在网络中存在大量对手的情况下，诚实的节点可以相互连接。即使对抗分数高达一半的节点S/Kademlia实现了0.85的成功率，</li></ul></li></ol><h3 id="Block-Exchanges-BitTorrentc"><a href="#Block-Exchanges-BitTorrentc" class="headerlink" title="Block Exchanges - BitTorrentc"></a>Block Exchanges - BitTorrentc</h3><p>BitTorrent（简称BT）是一个文件分发协议，每个下载者在下载的同时不断向其他下载者上传已下载的数据。</p><p>BitTorrent是一个广泛成功的点对点文件处理系统，它成功地协调了互不信任的点(群)网络，在相互分发文件的过程中进行合作。BitTorrent及其生态系统中IPFS设计的关键特性包括:</p><ol><li>BitTorrent的数据交换协议使用了一种类似于tit-for-tat的策略，奖励那些相互贡献的节点，惩罚那些只窃取别人资源的节点</li><li>BitTorrent同行跟踪文件片段的可用性，优先发送最罕见的片段。这减轻了种子的负担，使非种子同伴能够相互交易</li><li>BitTorrent标准的tit-for-tat易受某些利用带宽共享策略的攻击。PropShare是一种不同的对等带宽分配策略，它能更好地抵抗利用策略，并提高群的性能</li></ol><h3 id="Version-Control-Systems-Git"><a href="#Version-Control-Systems-Git" class="headerlink" title="Version Control Systems - Git"></a>Version Control Systems - Git</h3><p>版本控制系统提供了对随时间变化的文件建模的工具，并有效地分发不同的版本。流行的版本控制系统Git提供了一个功能强大的Merkle dag对象模型，它以分布式友好的方式捕获对文件系统树的更改。</p><ol><li>不可变对象代表Files (blob)、Directories (tree)和Changes (commit)</li><li>对象是内容寻址的，通过其内容的加密散列</li><li>与其他物体的链接被嵌入，形成一个默克尔DAG。这提供了许多有用的完整性和工作流属性</li><li>大多数版本化元数据(分支、标签等)都是简单的指针引用，因此创建和更新的成本很低</li><li>版本更改仅更新引用或添加对象</li><li>将版本更改分发给其他用户只是简单地传输对象和更新远程引用</li></ol><h3 id="Self-Certified-Filesystems-SFS"><a href="#Self-Certified-Filesystems-SFS" class="headerlink" title="Self-Certified Filesystems - SFS"></a>Self-Certified Filesystems - SFS</h3><p>SFS[12,11]提出了两种引人注目的实现：</p><ul><li>分布式信任链</li><li>平等共享的全局命名空间</li></ul><p>SFS引入了一种用于构建自认证文件系统的技术:</p><p>使用以下scheme：</p><p><code>/sfs/&lt;Location&gt;:&lt;HostID&gt;</code></p><p>其中Location是服务器的网络地址，并且:HostID = hash(public_key || Location)</p><p>因此SFS文件系统的名称证明了它的服务器。用户可以验证服务器提供的公钥，协商共享密钥，并确保所有流量的安全。所有SFS实例共享一个全局命名空间，其中的名称分配是加密的，不受任何集中主体的限制。</p><h2 id="3-IPFS-DESIGN"><a href="#3-IPFS-DESIGN" class="headerlink" title="3. IPFS DESIGN"></a>3. IPFS DESIGN</h2><p>IPFS协议被划分为负责不同功能的子协议堆栈</p><h3 id="3-1-身份——管理节点身份的生成和更新"><a href="#3-1-身份——管理节点身份的生成和更新" class="headerlink" title="3.1 身份——管理节点身份的生成和更新"></a>3.1 身份——管理节点身份的生成和更新</h3><p>节点由一个NodeId标识，这是一个公钥的加密哈希，是用S/Kademlia的静态加密谜题创建的。节点存储它们的公钥和私钥(使用密码短语加密)。用户可以在每次启动时自由实例化一个新的节点标识，尽管这样会损失已积累的网络利益。节点被激励保持不变</p><h3 id="3-2-网络——管理与其他对等体的连接，使用各种底层网络协议。可配置的"><a href="#3-2-网络——管理与其他对等体的连接，使用各种底层网络协议。可配置的" class="headerlink" title="3.2 网络——管理与其他对等体的连接，使用各种底层网络协议。可配置的"></a>3.2 网络——管理与其他对等体的连接，使用各种底层网络协议。可配置的</h3><p>IPFS网络栈特性:</p><ul><li>传输:IPFS可以使用任何传输协议，最适合于WebRTC数据通道(用于浏览器连接)或uTP(LEDBAT)</li><li>可靠性:如果底层网络不提供，IPFS可以使用uTP (LEDBAT[14])或SCTP[15]提供可靠性</li><li>连通性:IPFS也使用ICE NAT穿越技术</li><li>完整性:可选地使用哈希校验和检查消息的完整性</li><li>真实性:可选地检查mes- sage的真实性，通过使用发送方的特权密钥进行数字签名。</li></ul><h3 id="3-3-路由——维护定位特定对等体和对象的信息。响应本地和远程查询。默认为DHT，但可切换"><a href="#3-3-路由——维护定位特定对等体和对象的信息。响应本地和远程查询。默认为DHT，但可切换" class="headerlink" title="3.3 路由——维护定位特定对等体和对象的信息。响应本地和远程查询。默认为DHT，但可切换"></a>3.3 路由——维护定位特定对等体和对象的信息。响应本地和远程查询。默认为DHT，但可切换</h3><p>IPFS节点需要一个路由系统，它可以找到其他节点的网络地址，以及可以为特定对象服务的节点。IPFS使用S/Kademlia和Coral DSHT实现这一点。IPFS的对象大小和使用模式类似于Coral和Mainline，因此IPFS DHT根据其大小对存储的值进行区分。小值(等于或小于1KB)直接存储在DHT上。对于较大的值，DHT存储引用，这些引用是可以为块提供服务的节点的nodeid</p><h3 id="3-4-块交换——一个新的块交换协议-BitSwap-，它管理有效的块分配。以市场为模型，对数据复制的激励很弱。可切换的贸易策略"><a href="#3-4-块交换——一个新的块交换协议-BitSwap-，它管理有效的块分配。以市场为模型，对数据复制的激励很弱。可切换的贸易策略" class="headerlink" title="3.4 块交换——一个新的块交换协议(BitSwap)，它管理有效的块分配。以市场为模型，对数据复制的激励很弱。可切换的贸易策略"></a>3.4 块交换——一个新的块交换协议(BitSwap)，它管理有效的块分配。以市场为模型，对数据复制的激励很弱。可切换的贸易策略</h3><p>在IPFS中，数据分发是通过使用BitTorrent启发的协议BitSwap与对等点交换块来实现的。像BitTorrent一样，BitSwap对等体正在寻找一组块(want_list)，并有另一组块交换(have_list)。与BitTorrent不同，BitSwap并不局限于一个torrent中的区块。BitSwap操作是一个持久的市场，节点可以获取他们需要的块，而不管这些块是什么文件的一部分。这些块可以来自文件系统中完全不相关的文件。节点聚集在一起进行交易。</p><h3 id="3-5-对象——一个Merkle-DAG，由具有链接的内容定位的不可变对象组成。用于表示任意的数据结构，例如文件层次结构和通信系统"><a href="#3-5-对象——一个Merkle-DAG，由具有链接的内容定位的不可变对象组成。用于表示任意的数据结构，例如文件层次结构和通信系统" class="headerlink" title="3.5 对象——一个Merkle DAG，由具有链接的内容定位的不可变对象组成。用于表示任意的数据结构，例如文件层次结构和通信系统"></a>3.5 对象——一个Merkle DAG，由具有链接的内容定位的不可变对象组成。用于表示任意的数据结构，例如文件层次结构和通信系统</h3><p>DHT和BitSwap允许IPFS形成一个大规模的点对点系统，用于快速、可靠地存储和分发块。在这些之上，IPFS构建了一个Merkle DAG，一个有向无环图，其中对象之间的链接是嵌入源中的目标的加密散列。这是Git数据结构的一般化。</p><p>默克尔DAG为IPFS提供了许多有用的属性：</p><ol><li>内容寻址:所有内容由其多哈希校验和唯一标识，包括链接</li><li>抗篡改:所有内容都通过校验和进行验证。如果数据被篡改或损坏，IPFS会检测到它</li><li>重复数据删除:所有包含相同内容的对象都是相同的，且只存储一次。对于索引对象，如git树和提交，或数据的公共部分，这尤其有用。</li></ol><h3 id="3-6-文件——受Git启发的文件版本的文件系统层次结构"><a href="#3-6-文件——受Git启发的文件版本的文件系统层次结构" class="headerlink" title="3.6 文件——受Git启发的文件版本的文件系统层次结构"></a>3.6 文件——受Git启发的文件版本的文件系统层次结构</h3><p>IPFS还定义了一组对象，用于在Merkle DAG之上对版本化的文件系统建模。该对象模型类似于Git s:</p><ol><li>块:一个可变大小的数据块</li><li>列表:块或其他列表的集合</li><li>树:块、列表或其他树的集合</li><li>提交:树版本历史中的快照。</li></ol><h3 id="3-7-命名——一个自认证的可变名称系统"><a href="#3-7-命名——一个自认证的可变名称系统" class="headerlink" title="3.7 命名——一个自认证的可变名称系统"></a>3.7 命名——一个自认证的可变名称系统</h3><p>到目前为止，IPFS堆栈形成了一个点对点块交换，构造了一个对象的内容寻址DAG。它用于发布和检索不可变对象。它甚至可以跟踪这些对象的版本历史。但是，缺少一个关键组件:可变命名。没有它，所有新内容的通信都必须在带外进行，发送IPFS链接。需要的是在同一路径上检索可变状态的某种方法。值得说明的是，如果可变数据是必要的，我们最终努力建立一个不可变的默克尔DAG。考虑一下来自Merkle DAG的IPFS属性:对象可以(a)通过其散列检索，(b)完整性检查，(c)链接到其他对象，以及(d)无限期缓存。在某种意义上:对象是永久的。这些是高性能分布式系统的关键属性，在分布式系统中，数据跨网络链路移动的代价很高。对象内容寻址构建了一个具有(a)显著带宽优化、(b)不可信内容服务、(c)永久链接和(d)对任何对象及其引用进行完全永久备份的能力的web。Merkle DAG(不可变的内容寻址对象)和命名(指向Merkle DAG的可变指针)瞬时出现在许多成功的分布式系统中。这包括Git版本控制系统，它有不可变对象和可变引用;和Plan， UNIX的分布式继承者，及其可变的Fossil和不可变的Venti文件系统。LBFS也使用可变索引和不可变块。</p><h2 id="4-IPFS共识"><a href="#4-IPFS共识" class="headerlink" title="4. IPFS共识"></a>4. IPFS共识</h2><p>IPFS创新的采用了一种混合共识机制——复制证明（PoRep）+时空证明（PoSt）+ 预期共识(EC)</p><ol><li>复制证明：共识机制中的核心因素，尽管IPFS的网络协议、共识、其他算法都基本定型，但是复制证明仍然处于不断完善的方案中。</li><li>时空证明:（PoSt)提出了证明链（proof-chain）的数据结构，证明链把一些的挑战（challenge）和证明（proof）链接起来形成。在证明链的基础上添加上时间段，这样就得到了一段时间内的矿工存储数据的证明，这就是时空证明（Proof of Spacetime，PoSt）。PoSt可以证明在该段时间内矿工存储了特定的数据，并且利用时间戳锚定这些证明链，这样即使验证者（verifier）不在线，也可以在未来的某个时间内利用时空证明去验证该矿工生成了证明链，PoSt会被提交到链上用来产生新的Block。</li><li>预期共识:（Expected Consensus，EC）是在每一轮里面选举出来一名或者多名矿工来创建新的区块，矿工赢得选举的可能性跟矿工当前的有效存储（算力）成正比。IPFS把矿工在网络中的当前存储数据相对于整个网络的存储比例转化为矿工投票权（voting power of the miner）。无论在该周期里，选举出来的是一名还是多名矿工，被选举出来的矿工都需要创建新的区块，并把新的区块对网络进行广播。 尽管链中的区块是线性的，但是IPFS的区块数据结构采用的DAG（有向无环图），可以在同一时间产生多个区块（所以Filecoin的交易要比BTC的有效的多，这也是为什么把Filecoin叫做“可能的blockchain 3.0”的原因） </li></ol><p>Filecoin首创的混合共识机制，从根本上定义了Filecoin是一个合理高效、去中心化的系统，并体现出Filecoin的公平性、保密性和公开可验证性</p><h1 id="二、上传文件"><a href="#二、上传文件" class="headerlink" title="二、上传文件"></a>二、上传文件</h1><p><img src="/images/ipfs/upload_file.png" alt="img.png"></p><h2 id="1-生成默克尔DAG的结构"><a href="#1-生成默克尔DAG的结构" class="headerlink" title="1. 生成默克尔DAG的结构"></a>1. 生成默克尔DAG的结构</h2><p>生成的结构有两种Layout：balanced和trickle的。这里介绍默认的balanced结构，首先生成root作为根节点，然后将文件分割，默认按照256KB大小读取一个chunk，生成叶子节点，依次生成node1，node2，root节点会有Link指向挂在root节点的叶子节点node1和node2。root节点下面能够Link的叶子节点数量是有限的，IPFS中默认设置的是174个（定义的Link的总的大小是8KB，每个Link的大小是34 + 8 + 5【sha256 multihash + size + no name + protobuf framing】，默认的Link的个数为8192/47约等于174）。</p><p><img src="/images/ipfs/image-1.png" alt="/images/ipfs/image-1.png"></p><p>如下图所示，超过174个后则会新创建一个new root节点，并Link到old root，新的chunk作为node3（这里用node3简约了，实际上是第175个节点）被new root直接Link。</p><p><img src="/images/ipfs/image-4.png" alt="/images/ipfs/image-4.png"></p><p>当继续有新的chunk添加时，则会生成node34作为node3和node4的父节点，node34含有两个Link分别链接到node3和node4。</p><p><img src="/images/ipfs/image-5.png" alt="/images/ipfs/image-5.png"></p><p>IPFS在init的时候会生成.ipfs目录，如下图所示，其中blocks则为文件块存储的目录，datastore为leveldb数据库，其中存储了文件系统的根哈希等，存储相关的配置关联在.ipfs目录下面的config文件。</p><p><img src="/images/ipfs/image-6.png" alt="/images/ipfs/image-6.png"></p><h2 id="2-对块进行存储"><a href="#2-对块进行存储" class="headerlink" title="2. 对块进行存储"></a>2. 对块进行存储</h2><ul><li>如下图所示，一个Block存储时，首先由dagService（实现了DAGService接口）调用Add进行添加；</li><li>之后由blockService（实现了BlockService接口）调用AddBlock添加该Block；</li><li>再调用arccache的Put，arccache是对存储的Block做arc策略的缓存；</li><li>再之后由VerifBS调用Put进行存储，VerifyBS主要对CID的合法性进行校验，合法则进行Put；</li><li>接着blockstore（实现了Blockstore接口）调用Put进行存储，Put函数中会对CID进行转化，调用dshelp的CidToDsKey方法将CID转化成存储的Key；</li><li>再接着调用keytransform.Datastore的Put，Put函数中会将前缀拼上，这时Key加上了前缀/blocks；</li><li>然后调用measure的Put函数，measure是对mount的封装；</li><li>之后调用mount的Put函数，mount和IPFS的config配置文件中结构对应，根据key去查找对应的datastore，由于前缀是/blocks则可以找到对应的measure；</li><li>调用该measure的Put函数；</li><li>最后调用flatfs的Put函数，由Put函数调用doPut最终调用encode函数将完整的block写入的目录指定为/home/test/.ipfs/blocks/WD，其中WD来自于blocks/CIQFSQATUBIEIFDECKTNGHOKPOEE7WUPM5NNNSJCCDROMM6YHEKTWDY中的倒数第三第二个字符。这样该Block则写入了该目录下面的文件中。</li></ul><p><img src="/images/ipfs/image-7.png" alt="/images/ipfs/image-7.png"></p><p><img src="/images/ipfs/image-9.png" alt="/images/ipfs/image-9.png"></p><h1 id="三、下载文件"><a href="#三、下载文件" class="headerlink" title="三、下载文件"></a>三、下载文件</h1><p><img src="/images/ipfs/download_file.png" alt="img.png"></p><ol><li>检查本地的blockstore中是否存在请求的数据，如果存在则直接从本地返回；否则会向对等节点发送block hash列表；</li><li>对等节点通过DHT和路由层算法，找到每个block hash所在的节点，将文件返回来；</li><li>本地节点在接收block文件的同时缓存一份到本地的blockstore中</li><li>更新DHT</li><li>组装block文件，返回至用户端</li></ol><h1 id="附：资料"><a href="#附：资料" class="headerlink" title="附：资料"></a>附：资料</h1><ol><li>IPFS白皮书：<a href="https://github.com/ipfs/papers/raw/master/ipfs-cap2pfs/ipfs-p2p-file-system.pdf">https://github.com/ipfs/papers/raw/master/ipfs-cap2pfs/ipfs-p2p-file-system.pdf</a></li><li>上传/下载文件过程：<ul><li><a href="https://www.jianshu.com/p/9eb1e5f83e13">https://www.jianshu.com/p/9eb1e5f83e13</a></li><li><a href="https://www.chaindesk.cn/witbook/24/449">https://www.chaindesk.cn/witbook/24/449</a></li></ul></li><li><a href="https://www.jiabaotz.com/finance/79470.html">IPFS/Filecoin的共识机制有哪些特点？</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Distributed Storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go语言核心编程</title>
      <link href="/2022/01/17/go/Go%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/"/>
      <url>/2022/01/17/go/Go%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="Go-Core-Programming"><a href="#Go-Core-Programming" class="headerlink" title="Go Core Programming"></a>Go Core Programming</h1><h1 id="第-1-章-基础知识"><a href="#第-1-章-基础知识" class="headerlink" title="第 1 章 基础知识"></a>第 1 章 基础知识</h1><h2 id="1-1-语言简介"><a href="#1-1-语言简介" class="headerlink" title="1.1 语言简介"></a>1.1 语言简介</h2><h3 id="1-1-1-Go语言的诞生背景"><a href="#1-1-1-Go语言的诞生背景" class="headerlink" title="1.1.1 Go语言的诞生背景"></a>1.1.1 Go语言的诞生背景</h3><ul><li><strong>当前编程语言对并发的支持不是很好</strong>，不能很好地发挥多核CPU的威力</li><li>程序规模越来越大，<strong>编译速度越来越慢</strong></li><li>现有的<strong>编程语言设计越来越复杂</strong>，某些特性的实现不怎么优雅</li></ul><h3 id="1-1-3-Go语言的特性"><a href="#1-1-3-Go语言的特性" class="headerlink" title="1.1.3 Go语言的特性"></a>1.1.3 Go语言的特性</h3><p><img src="/images/go_core_programming/Untitled.png" alt="Untitled"></p><p><img src="/images/go_core_programming/Untitled%201.png" alt="Untitled"></p><h2 id="1-3-Go词法单元"><a href="#1-3-Go词法单元" class="headerlink" title="1.3 Go词法单元"></a>1.3 Go词法单元</h2><h3 id="1-3-1-token"><a href="#1-3-1-token" class="headerlink" title="1.3.1 token"></a>1.3.1 token</h3><p>token是构成源程序的基本不可再分割的单元。</p><p>编译器编译源程序的第一步就是将源程序分割成一个个独立的token，这个过程就是词法分析。</p><p>Go语言的token可以分为关键字、标识符、操作符、分隔符和字面常量</p><p><img src="/images/go_core_programming/Untitled%202.png" alt="Untitled"></p><h3 id="1-3-2-标识符"><a href="#1-3-2-标识符" class="headerlink" title="1.3.2 标识符"></a>1.3.2 标识符</h3><ol><li>标识符用来标识变量、类型、常量等语法对象的符号名称，其在语法分析时作为一个token存在。</li><li>标识符分为两类：<ul><li>语言设计者预留的标识符：语言设计者确定，包括语言的预声明标识符及保留字</li><li>编程者可以自定义的标识符：用户定义的变量名、常量名、函数名等</li></ul></li><li>标识符规则：开头一个字符必须是字母或下划线，区分大小写</li><li><strong>关键字（keywords，25个）</strong></li></ol><p><img src="/images/go_core_programming/Untitled%203.png" alt="Untitled"></p><ol><li><strong>内置数据类型标识符（20个）</strong></li></ol><p><img src="/images/go_core_programming/Untitled%204.png" alt="Untitled"></p><ol><li><strong>内置函数（15个）</strong></li></ol><p><img src="/images/go_core_programming/Untitled%205.png" alt="Untitled"></p><ol><li><strong>常量值标识符（4个）</strong></li></ol><p><img src="/images/go_core_programming/Untitled%206.png" alt="Untitled"></p><p>空白标识符： <code>_</code></p><h3 id="1-3-3-操作符（operators）和分隔符（delimiters）"><a href="#1-3-3-操作符（operators）和分隔符（delimiters）" class="headerlink" title="1.3.3 操作符（operators）和分隔符（delimiters）"></a>1.3.3 操作符（operators）和分隔符（delimiters）</h3><p>操作符包括运算符、现式的分隔符、其他语法辅助符号</p><h3 id="1-3-4-字面常量"><a href="#1-3-4-字面常量" class="headerlink" title="1.3.4 字面常量"></a>1.3.4 字面常量</h3><ol><li>Go的字面量出现在两个地方：<ul><li>用于常量和变量的初始化</li><li>用在表达式里或函数调用实参</li></ul></li><li>字面量分类：<ul><li>整型字面量</li><li>浮点型字面量</li><li>复数类型字面量</li><li>字符型字面量</li><li>字符串字面量</li></ul></li></ol><h2 id="1-4-变量和常量"><a href="#1-4-变量和常量" class="headerlink" title="1.4 变量和常量"></a>1.4 变量和常量</h2><h3 id="1-4-1-变量"><a href="#1-4-1-变量" class="headerlink" title="1.4.1 变量"></a>1.4.1 变量</h3><h3 id="1-4-2-常量"><a href="#1-4-2-常量" class="headerlink" title="1.4.2 常量"></a>1.4.2 常量</h3><h2 id="1-5-基本数据类型"><a href="#1-5-基本数据类型" class="headerlink" title="1.5 基本数据类型"></a>1.5 基本数据类型</h2><p>Go内置七类基本数据类型：</p><p><img src="/images/go_core_programming/Untitled%207.png" alt="Untitled"></p><p><img src="/images/go_core_programming/Untitled%208.png" alt="Untitled"></p><h2 id="1-5-4-复数类型"><a href="#1-5-4-复数类型" class="headerlink" title="1.5.4 复数类型"></a>1.5.4 复数类型</h2><p>Go语言内置的复数类型有两种，分别是complex64和complex128。复数的字面量表示和数学表示法一样。</p><p><img src="/images/go_core_programming/Untitled%209.png" alt="Untitled"></p><p><img src="/images/go_core_programming/Untitled%2010.png" alt="Untitled"></p><h3 id="1-5-6-rune类型"><a href="#1-5-6-rune类型" class="headerlink" title="1.5.6 rune类型"></a>1.5.6 rune类型</h3><p>Go内置两种字符类型：</p><ul><li>bute的字节类类型（byte是uint的别名）</li><li>表示Uniocode编码的字符rune（rune是int32类型的别名）</li></ul><h2 id="1-6-复合数据类型"><a href="#1-6-复合数据类型" class="headerlink" title="1.6 复合数据类型"></a>1.6 复合数据类型</h2><ol><li>复合数据类型就是由其他类型组合而成的类型。</li><li>Go基本的复合数据类型有：<ul><li><p>指针</p></li><li><p>数据</p></li><li><p>切片</p></li><li><p>字典（map）</p></li><li><p>通道</p></li><li><p>结构</p></li><li><p>接口</p><p><img src="/images/go_core_programming/Untitled%2011.png" alt="Untitled"></p></li></ul></li></ol><h3 id="1-6-1-指针"><a href="#1-6-1-指针" class="headerlink" title="1.6.1 指针"></a>1.6.1 指针</h3><ol><li>Go支持指针，声明类型为 <code>*T</code> ，Go支持多级指针 <code>**T</code> 。通过在变量名前加 <code>&amp;</code> 获取变量的地址。</li><li>指针的特点：<ul><li>在赋值语句中，<code>*T</code> 出现在 <code>=</code> 左边表示指针声明，<code>*T</code> 出现在 <code>=</code> 右边表示取指针指向的值（varName为变量名）。示例：<pre><code class="go">var a = 11p := &amp;a // *p和a的值都是11</code></pre></li><li>结构体指针访问结构体字段仍然使用 <code>.</code> 点操作符，Go语言没有 <code>-&gt;</code> 操作符，例如：<pre><code class="go">type User struct {    name string    age int}andes := User {    name: "andes",    age: 10,}p := &amp;andesfmt.Println(p.name) // p.name通过"."操作符访问成员变量</code></pre></li><li>Go不支持指针的运算  Go由于支持垃圾回收，如果支持指针运算则会给垃圾回收的实现带来很多不便。例如：  <img src="/images/go_core_programming/Untitled%2012.png" alt="Untitled"></li><li>函数中允许返回局部变量的地址  Go编译器使用”栈逃逸“机制将这种局部变量的空间分配在堆上，例如：  <img src="/images/go_core_programming/Untitled%2013.png" alt="Untitled"></li></ul></li></ol><h3 id="1-6-2-数组"><a href="#1-6-2-数组" class="headerlink" title="1.6.2 数组"></a>1.6.2 数组</h3><ol><li>数组的类型名是<code>[n]elementType</code>，n是数组长度，elementType是数组元素类型。</li></ol><p><img src="/images/go_core_programming/Untitled%2014.png" alt="Untitled"></p><ol><li>数组的特点：<ul><li>数组创建完长度就固定了，不可以再追加元素了</li><li>数组是值类型的，数组赋值或作为函数参数都是值拷贝</li><li>数组长度是数组类型的组成部分，<code>[10]int</code>和<code>[20]int</code>是不同的类型</li><li>可以根据数组创建切片</li></ul></li><li>数组相关操作：<ul><li><p>数组元素访问</p><p><img src="/images/go_core_programming/Untitled%2015.png" alt="Untitled"></p></li><li><p>数组长度</p><p><img src="/images/go_core_programming/Untitled%2016.png" alt="Untitled"></p></li></ul></li></ol><h3 id="1-6-3-切片"><a href="#1-6-3-切片" class="headerlink" title="1.6.3 切片"></a>1.6.3 切片</h3><p>Go语言的数组的定长性和值拷贝限制了其使用场景，Gp提供了另一种数据类型slice（切片），这是一种变长数组，其数据结构中有指向数组的指针，所以是一种引用类型。</p><p>例如：</p><pre><code class="go">type slice struct {    array unsafe.Pointer    len int    cap int}</code></pre><p>Go为切片维护三个元素：</p><ul><li>指向底层数组的指针</li><li>切片的元素数量</li><li>底层数组的容量</li></ul><p><img src="/images/go_core_programming/Untitled%2017.png" alt="Untitled"></p><ol><li>切片的创建<ul><li>由数组创建：创建语法<code>array[b:e]</code> ，表示创建一个包含e-b各元素额的切片，第一个元素是<code>array[b]</code>，最后一个元素是<code>array[e-1]</code> 。例如：  <img src="/images/go_core_programming/Untitled%2018.png" alt="Untitled"></li><li>通过内置函数<code>make</code>创建切片。<code>make</code>创建的切片各元素被默认为输出华为切片元素类型的零值。  <img src="/images/go_core_programming/Untitled%2019.png" alt="Untitled">  <img src="/images/go_core_programming/Untitled%2020.png" alt="Untitled"></li></ul><ol><li>切片支持的操作<ul><li>内置函数<code>len()</code>返回切片长度</li><li>内置函数<code>cap()</code>返回切片底层数组容量</li><li>内置函数<code>append()</code>对切片追加元素</li><li>内置函数<code>copy()</code>用于复制一个切片</li></ul></li></ol></li></ol><h3 id="1-6-4-map"><a href="#1-6-4-map" class="headerlink" title="1.6.4 map"></a>1.6.4 map</h3><p>Go语言内置的字典类型叫map。</p><p><code>map</code>类型的格式是：<code>map[K]T</code> ，其中K可以是任意可以进行比较的类型，T是值类型。</p><p><code>map</code>也是一种引用类型。</p><ol><li><code>map</code>的创建<ul><li>使用字面量创建，例如：  <img src="/images/go_core_programming/Untitled%2021.png" alt="Untitled"></li><li>使用内置的make函数创建，例如  <img src="/images/go_core_programming/Untitled%2022.png" alt="Untitled">  <img src="/images/go_core_programming/Untitled%2023.png" alt="Untitled"></li></ul></li><li><code>map</code>支持的操作<ul><li><p><code>map</code>的单个键值访问格式为<code>mapName[key]</code></p></li><li><p>可以使用<code>range</code>遍历一个<code>map</code>类型的变量，但不能保证每次迭代元素的顺序</p></li><li><p>删除<code>map</code>中的某个键值，<code>delete(mapName,key)</code> 。<code>delete</code>是内置函数，用来删除<code>map</code>中的某个键值对</p></li><li><p>可以使用内置的<code>len()</code> 函数返回<code>map</code>中的键值对数量</p><p>注意：</p></li><li><p>Go内置的<code>map</code>不是并发安全的，并发安全的<code>map</code>可以使用标准包<code>sync</code>中的map</p></li><li><p>不要直接修改<code>map value</code>内某个元素的值，如果想修改<code>map</code>的某个键值，则必须整理赋值</p></li></ul></li></ol><h3 id="1-6-5-struct"><a href="#1-6-5-struct" class="headerlink" title="1.6.5 struct"></a>1.6.5 struct</h3><p>Go中的struct类型和C类似，中文翻译为结构，由多个不同类型元素组合而成。</p><ul><li>struct结构中的类型可以是任意类型</li><li>struct的存储空间是连续的，其字段按照声明时的顺序存放（注意字段值之间有对齐要求）</li></ul><p>struct有两种形式：</p><ul><li>struct类型字面量</li><li>使用type声明的自定义struct类型</li></ul><ol><li>strct类型字面量 struct类型字面量的声明格式如下： <img src="/images/go_core_programming/Untitled%2024.png" alt="Untitled"></li><li>自定义struct类型 自定义struct类型声明格式如下： <img src="/images/go_core_programming/Untitled%2025.png" alt="Untitled"></li><li>struct类型变量的初始化，示例： <img src="/images/go_core_programming/Untitled%2026.png" alt="Untitled"></li><li>其他复合类型<ul><li>接口（Interface）</li><li>通道（chan）</li></ul></li></ol><h2 id="1-7-控制结构"><a href="#1-7-控制结构" class="headerlink" title="1.7 控制结构"></a>1.7 控制结构</h2><p>程序执行从本质上来说就是两种模式：顺序和跳转</p><h3 id="1-7-1-if-语句"><a href="#1-7-1-if-语句" class="headerlink" title="1.7.1 if 语句"></a>1.7.1 if 语句</h3><h3 id="1-7-2-switch-语句"><a href="#1-7-2-switch-语句" class="headerlink" title="1.7.2 switch 语句"></a>1.7.2 switch 语句</h3><h3 id="1-7-3-for-语句"><a href="#1-7-3-for-语句" class="headerlink" title="1.7.3 for 语句"></a>1.7.3 for 语句</h3><h3 id="1-7-4-标签和跳转"><a href="#1-7-4-标签和跳转" class="headerlink" title="1.7.4 标签和跳转"></a>1.7.4 标签和跳转</h3><ol><li>标签 Go语言使用标签（Lable）来标识一个语句的位置，用于goto、break、continue语句的跳转。标签的语法是： <img src="/images/go_core_programming/Untitled%2027.png" alt="Untitled"></li><li>goto goto语句用于函数的内部跳转，需要配合标签一起使用： <img src="/images/go_core_programming/Untitled%2028.png" alt="Untitled"> goto特点：<ul><li>goto语句只能在函数内跳转</li><li>goto语句不能跳过内部变量声明语句，这些变量在goto语句的标签语句处有事可见的</li><li>goto语句只能调到同级作用域或者上层作用域，不能跳到内部作用域</li></ul></li><li>break break用于函数内跳出for、switch、select语句的执行，有两种使用格式：<ul><li>单独使用：用于跳出break当前所在的for、switch、select语句的执行</li><li>和标签一起使用：用于跳出标签所标识的for、switch、select语句的执行，可用于跳出多重循环，但标签和break必须在同一个函数内，例如：  <img src="/images/go_core_programming/Untitled%2029.png" alt="Untitled"></li></ul></li><li>continue continue用于跳出for循环的本次迭代，跳到for循环的下一次迭代的post语句处执行，有两种使用格式：<ul><li><p>单独使用：跳出continue当前所在的for循环的本次迭代</p></li><li><p>和标签一起使用：跳出标签所标示的for语句的本次迭代，但标签和continue必须在同一个函数内，例如：</p><p><img src="/images/go_core_programming/Untitled%2030.png" alt="Untitled"></p></li></ul></li><li>return和函数调用 return语句也能引发控制流程的跳转，用于函数和方法的退出。</li></ol><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ol><li><p><code>slice</code> 和 <code>array</code> 区别</p><ul><li>创建方式不同：数组<code>var identifier [len]type</code> ；切片<code>var slice3 = []int{}</code></li><li><code>slice</code>的<code>array</code>实际上是数组的指针，所以作为函数参数传递时不同：数组传递的是数组的副本；<code>slice</code>传递的是数组的指针</li><li>长度是否固定：数组长度固定；切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大</li></ul></li><li><p>struct能不能比较？<a href="https://juejin.cn/post/6881912621616857102">https://juejin.cn/post/6881912621616857102</a> </p></li><li><p>slice，len，cap，共享，扩容</p></li><li><p>for 循环遍历 slice 有什么问题</p><ul><li>for rang A，是对A的值拷贝，问题代码：<pre><code class="go">func TestName(t *testing.T) {    s :=[]int{1,2,3,4}    m :=make(map[int]*int)    for k,v:=range s{        m[k]= &amp;v    }    for key, value := range m {        fmt.Printf("map[%v]=%v\n", key, *value)    }    fmt.Println(m)}</code></pre>  改正：<pre><code class="go">func TestName(t *testing.T) {    s := []int{1, 2, 3, 4}    m := make(map[int]*int)    for k, v := range s {        // 这里变动        n := v        m[k] = &amp;n    }    for key, value := range m {        fmt.Printf("map[%v]=%v\n", key, *value)    }    fmt.Println(m)}</code></pre></li></ul></li><li><p>请你说说golang的CSP思想</p></li><li><p>进程，协程，线程各自的优缺点</p></li></ol><h1 id="第-2-章-函数"><a href="#第-2-章-函数" class="headerlink" title="第 2 章 函数"></a>第 2 章 函数</h1><p>Go中的函数：</p><ul><li>函数是一种类型，函数类型变量可以向其他类型变量一样使用，可以作为其它函数的参数或返回值，也可以直接调用执行</li><li>函数支持多值返回</li><li>支持闭包</li><li>函数支持可变参数</li></ul><h2 id="2-1-基本概念"><a href="#2-1-基本概念" class="headerlink" title="2.1 基本概念"></a>2.1 基本概念</h2><h3 id="2-1-1-函数定义"><a href="#2-1-1-函数定义" class="headerlink" title="2.1.1 函数定义"></a>2.1.1 函数定义</h3><p>包括如下几个部分：</p><ul><li>函数声明关键字func</li><li>函数名</li><li>参数列表</li><li>返回列表和函数体</li></ul><p>函数的特点：</p><ul><li>函数可以没有输入参数，也可以没有返回值（默认返回0）</li><li>多个相邻的相同类型的参数可以使用简写模式</li><li>支持有名的返回值，参数名就相当于函数体内最外层的局部变量，命名返回值变量会被初始化成类型零值</li><li>不支持默认值参数</li><li>不支持函数重载</li><li>不支持函数嵌套，严格的说是不支持命名函数的嵌套定义，但支持嵌套匿名函数</li></ul><h3 id="2-1-2-多值返回"><a href="#2-1-2-多值返回" class="headerlink" title="2.1.2 多值返回"></a>2.1.2 多值返回</h3><p>习惯用法：如果多值返回之有错误类型，则一般将错误类型作为最后一个返回值</p><h3 id="2-1-3-实参到形参的传递"><a href="#2-1-3-实参到形参的传递" class="headerlink" title="2.1.3 实参到形参的传递"></a>2.1.3 实参到形参的传递</h3><p>Go函数实参到形参的传递永远是值拷贝。有时函数调用后实参指向的值发生了变化，那是因为参数传递的是指针值的拷贝，实参是一个指针变量，传递给形参的是这个指针变量的副本，二者指向同一地址。</p><h3 id="2-1-4-不定参数"><a href="#2-1-4-不定参数" class="headerlink" title="2.1.4 不定参数"></a>2.1.4 不定参数</h3><p>Go支持不定数据的形式参数，声明使用<code>param ...type</code> .</p><p>不定参数特点：</p><ul><li>所有的不定参数类型必须是相同的</li><li>不定参数必须是函数的最后一个参数</li><li>不定参数在函数体内相当于切片，对切片的操作同样适合对不定参数的操作</li><li>切片可以作为参数传递给不定参数，切片名后要加上”…”</li><li>形参为不定参数的函数和形参为切片的函数类型不相同</li></ul><h2 id="2-2-函数签名和匿名函数"><a href="#2-2-函数签名和匿名函数" class="headerlink" title="2.2 函数签名和匿名函数"></a>2.2 函数签名和匿名函数</h2><h3 id="2-2-1-函数签名"><a href="#2-2-1-函数签名" class="headerlink" title="2.2.1 函数签名"></a>2.2.1 函数签名</h3><p>函数类型又叫函数签名，可以使用fmt.Printf的%T格式化参数打印函数的类型</p><h3 id="2-2-2-匿名函数"><a href="#2-2-2-匿名函数" class="headerlink" title="2.2.2 匿名函数"></a>2.2.2 匿名函数</h3><p>Go提供两种函数：有名函数和匿名函数</p><p>匿名函数可以直接复制给函数变量，可以当做实参，也可以作为返回值，还可以直接被调用。</p><h2 id="2-3-defer"><a href="#2-3-defer" class="headerlink" title="2.3 defer"></a>2.3 defer</h2><p>Go提供了defer关键字，可以注册多个延迟调用，这些调用以先进后出的顺序在函数返回前被执行。这有点类似于Java语言中异常处理的finaly语句。</p><p>defer常用语保证一些资源最终一定能够得到回收和释放。</p><p>特点：</p><ul><li>defer后面必须是函数或方法的调用，不能是语句</li><li>defer函数的实参在注册时通过值拷贝传递进去</li><li>defer语句必须先注册后才能执行</li></ul><p>优势：可以在一定程度上避免资源泄露</p><p>缺点：</p><ul><li>defer会推迟资源的释放</li><li>defer不要写在循环语句里面</li><li>defer最好不要对有名返回值参数进行操作</li></ul><h2 id="2-4-闭包"><a href="#2-4-闭包" class="headerlink" title="2.4 闭包"></a>2.4 闭包</h2><p>闭包是由函数及其相关引用环境组合而成的实体。</p><p><code>闭包 = 函数 + 引用环境</code></p><ol><li>闭包对闭包外的环境引入是直接引用，编译器检测到闭包会将闭包引用的外部变量分配到堆上</li><li>如果函数返回的闭包引用了该函数的局部变量（参数或函数内部变量）<ol><li>多次调用该函数返回的多个闭包所引用的外部变量是多个副本，原因是每次调用函数都会为局部变量分配内存</li><li>用一个闭包函数多次，如果该闭包修改了其引用的外部变量，则每一次调用该闭包对该外包变量都有影响，因为闭包函数共享外部引用</li></ol></li></ol><h3 id="2-4-2-闭包的价值"><a href="#2-4-2-闭包的价值" class="headerlink" title="2.4.2 闭包的价值"></a>2.4.2 闭包的价值</h3><p>对象是附有行为的数据，闭包是附有数据的行为。</p><h2 id="2-5-panic和recover"><a href="#2-5-panic和recover" class="headerlink" title="2.5 panic和recover"></a>2.5 panic和recover</h2><p>panic用来主动抛出错误</p><p>recover用来捕获panic抛出的错误</p><h3 id="2-5-1-基本概念"><a href="#2-5-1-基本概念" class="headerlink" title="2.5.1 基本概念"></a>2.5.1 基本概念</h3><p><img src="/images/go_core_programming/Untitled%2031.png" alt="Untitled"></p><p>引发panic的情况：</p><ul><li>程序主动调用panic函数</li><li>程序产生运行时错误，由运行时检测并抛出</li></ul><p>recover用来捕获panic，阻止panic继续向上传递</p><h3 id="2-5-2-使用场景"><a href="#2-5-2-使用场景" class="headerlink" title="2.5.2 使用场景"></a>2.5.2 使用场景</h3><ul><li>程序遇到了无法正常执行下去的错误，主动调用panic函数结束程序运行</li><li>在调试程序时，通过主动调用panic实现快速退出，panic打印出的堆栈能够更快的定位错误</li></ul><h2 id="2-6-错误处理"><a href="#2-6-错误处理" class="headerlink" title="2.6 错误处理"></a>2.6 错误处理</h2><h3 id="2-6-1-error"><a href="#2-6-1-error" class="headerlink" title="2.6.1 error"></a>2.6.1 error</h3><p>Go语言内置错误接口类型error</p><p>错误处理的最佳实践：</p><ul><li>在多个返回值的函数中，error通常作为函数最后一个返回值</li><li>如果一个函数返回error类型变量，则先用if语句处理<code>error != nil</code> 的异常场景，正常逻辑放到if语句块后面保持代码平坦</li><li>defer语句应该放到err判断的后面，不然有可能产生panic</li><li>在错误逐级向上传递的过程中，错误信息应该不断地丰富和完善，而不是简单抛出下层调用的错误</li></ul><pre><code class="go">func deferDemo() error {    err := createResource1()    if err != nil {        return ERR_CREATE_RESOURCE1_FAILED    }    defer func() {        if err != nil {            destroyResource1()        }    }()}</code></pre><h3 id="2-6-2-错误和异常"><a href="#2-6-2-错误和异常" class="headerlink" title="2.6.2 错误和异常"></a>2.6.2 错误和异常</h3><p>Go程序需要处理的错误类型：</p><ul><li>运行时错误：无法避免，可以recover这些panic</li><li>程序逻辑错误</li></ul><p>error和panic应该遵循如下原则：</p><ul><li>程序发生的错误导致程序不能容错继续执行，此时程序应该主动调用panic或由运行时抛出panic</li><li>程序虽然发生错误，但是程序能够容错继续执行，此时应该使用错误返回值的方式处理错误，或者在可能发生运行时错误的非关键分支上使用recover捕获panic</li></ul><pre><code class="go">func TestName(t *testing.T) {    height := []int{2,3,4,5,18,17,6}    defer func() {        if err := recover(); err != nil {            fmt.Println(err)        }    }()    print(height[10])}</code></pre><h2 id="2-7-底层实现"><a href="#2-7-底层实现" class="headerlink" title="2.7 底层实现"></a>2.7 底层实现</h2><h1 id="第-3-章-类型系统"><a href="#第-3-章-类型系统" class="headerlink" title="第 3 章 类型系统"></a>第 3 章 类型系统</h1><h2 id="3-1-类型简介"><a href="#3-1-类型简介" class="headerlink" title="3.1 类型简介"></a>3.1 类型简介</h2><h3 id="3-1-1-命名类型和未命名类型"><a href="#3-1-1-命名类型和未命名类型" class="headerlink" title="3.1.1 命名类型和未命名类型"></a>3.1.1 命名类型和未命名类型</h3><p>命名类型：可以通过标识符来表示（3.2节详细介绍）</p><p>未命名类型：一个类型由预声明类型、关键字和操作符组合而成，又称为类型字面量。例如：数组（array）、切片（slice）、字典（map）、通道（channel）、指针（pointer）、函数字面量（function）、结构（struct）和接口（interface）都属于类型字面量</p><h3 id="3-1-2-底层类型"><a href="#3-1-2-底层类型" class="headerlink" title="3.1.2 底层类型"></a>3.1.2 底层类型</h3><p>所有“类型”都有一个underlying type（底层类型）。底层类型的规则如下：</p><ul><li>预声明类型（Pre-declared types）和类型字面量（type literals）的底层类型是他们自身</li><li>自定义类型type newtype oldtype中的newtype的底层是逐层递归向下查找的，知道查到的oldtype是预声明类型（Pre-declared types）或类型字面量（type literals）为止。</li></ul><h3 id="3-1-3-类型相同和类型赋值"><a href="#3-1-3-类型相同和类型赋值" class="headerlink" title="3.1.3 类型相同和类型赋值"></a>3.1.3 类型相同和类型赋值</h3><p><strong>类型相同</strong></p><p>Go是强类型的语言，编译器在编译时会进行严格的类型校验。两个命名类型是否相同的判断：</p><ul><li>两个命名类型相同的条件是两个类型声明的语句完全相同</li><li>命名类型和未命令类型永远不相同</li><li>两个未命名类型相同的条件是他们的类型声明字面量的结构相同，并且内部元素的类型相同</li><li>通过类型别名语句声明的两个类型相同</li></ul><p><strong>类型可直接赋值</strong></p><p>类型为T1的变量a可以赋值给类型为T2的变量b，称为类型T1可以赋值给类型T2，伪代码：</p><pre><code class="go">var b T2 = a</code></pre><p>a可以赋值给变量b必须要满足如下条件中的一个：</p><ul><li>T1和T2的类型相同</li><li>T1和T2具有相同的底层类型，并且T1和T2里面至少有一个是未命名类型</li><li>T2是接口类型，T1是具体类型，T1的方法集是T2方法集的超级</li><li>T1和T2都是通道类型，他们拥有相同的元素类型，并且T1和T2至少有一个是未命名类型</li><li>a是预声明标识符nil，T2是pointer、function、slice、map、channel、interface类型中的一个</li><li>a是一个字面常量值，可以用来表示类型T的值</li></ul><h3 id="3-1-4-类型强制转换"><a href="#3-1-4-类型强制转换" class="headerlink" title="3.1.4 类型强制转换"></a>3.1.4 类型强制转换</h3><p>由于Go是强类型的语言，如果不满足自动转换的条件，则必须进行强制类型转换。</p><p>非常量类型的变量x可以强制转化并传递给类型T，需要满足如下任一条件：</p><ul><li>x可以直接赋值给T类型变量</li><li>x类型和T具有相同的底层类型</li><li>x的类型和T都是未命名的指针类型，并且指针指向的类型具有相同的底层类型</li><li>x的类型和T都是整型或者都是浮点型</li><li>x的类型和T都是复数类型</li><li>x是整数值或[]byte类型的值，T是string类型</li><li>x是一个字符串，T是[]byte或[]rune</li></ul><h2 id="3-2-类型方法"><a href="#3-2-类型方法" class="headerlink" title="3.2 类型方法"></a>3.2 类型方法</h2><h3 id="3-2-1-自定义类型"><a href="#3-2-1-自定义类型" class="headerlink" title="3.2.1 自定义类型"></a>3.2.1 自定义类型</h3><p>自定义类型都是命名类型</p><p><img src="/images/go_core_programming/Untitled%2032.png" alt="Untitled"></p><p>自定义struct类型</p><h3 id="3-2-2-方法"><a href="#3-2-2-方法" class="headerlink" title="3.2.2 方法"></a>3.2.2 方法</h3><p><img src="/images/go_core_programming/Untitled%2033.png" alt="Untitled"></p><p>类型方法有如下特点：</p><ul><li>可以为命名类型增加方法（除了接口），非命名类型不能自定义方法</li><li>为类型增加方法有一个限制，就是方法的定义必须和类型的定义在同一个包中</li><li>方法的命名空间可见性和变量一样，大写开头的方法可也在包外被访问，否则只能在包内可见</li><li>使用type定义的自定义类型是一个新类型，新类型不能调用原有类型的方法，但是底层类型支持的运算可以被新类型继承</li></ul><p><img src="/images/go_core_programming/Untitled%2034.png" alt="Untitled"></p><p><img src="/images/go_core_programming/Untitled%2035.png" alt="Untitled"></p><h2 id="3-3-方法调用"><a href="#3-3-方法调用" class="headerlink" title="3.3 方法调用"></a>3.3 方法调用</h2><h3 id="3-3-1-一般调用"><a href="#3-3-1-一般调用" class="headerlink" title="3.3.1 一般调用"></a>3.3.1 一般调用</h3><p><img src="/images/go_core_programming/Untitled%2036.png" alt="Untitled"></p><h3 id="3-3-2-方法值"><a href="#3-3-2-方法值" class="headerlink" title="3.3.2 方法值"></a>3.3.2 方法值</h3><p><img src="/images/go_core_programming/Untitled%2037.png" alt="Untitled"></p><h3 id="3-3-3-方法表达式"><a href="#3-3-3-方法表达式" class="headerlink" title="3.3.3 方法表达式"></a>3.3.3 方法表达式</h3><p>方法表达式相当于提供一种语法将类型方法调用显示第转换为函数调用，接受者必须显示地传递进去。</p><h3 id="3-3-4-方法集"><a href="#3-3-4-方法集" class="headerlink" title="3.3.4 方法集"></a>3.3.4 方法集</h3><p>命名类型方法接受者有两种类型，一个是值类型，另一个是指针类型，这个和函数是一样的，前者的形参是值类型，后者的形参是指针类型。</p><p>无论接受者是什么类型，方法和函数的实参传递都是值拷贝，如果接受者是值类型，则传递的是值的副本；如果接受者是指针类型，则传递的是指针的副本</p><h3 id="3-3-5-值调用和表达式调用的方法集"><a href="#3-3-5-值调用和表达式调用的方法集" class="headerlink" title="3.3.5 值调用和表达式调用的方法集"></a>3.3.5 值调用和表达式调用的方法集</h3><h2 id="3-4-组合和方法集"><a href="#3-4-组合和方法集" class="headerlink" title="3.4 组合和方法集"></a>3.4 组合和方法集</h2><p>结构类型为Go提供了强大的类型扩展，主要体现在两个方面：</p><ul><li>struct可以嵌入任意其他类型的字段</li><li>struct可以嵌套自身的指针类型的字段</li></ul><h3 id="3-4-1-组合"><a href="#3-4-1-组合" class="headerlink" title="3.4.1 组合"></a>3.4.1 组合</h3><p>因为Go没有继承的语义，结构和字段之间是“has a”的关系而不是“is a”的关系，没有父子概念，仅仅是整体和局部的概念，所以后续统称这种嵌套的结构和字段的关系为组合</p><h3 id="3-4-2-组合的方法集"><a href="#3-4-2-组合的方法集" class="headerlink" title="3.4.2 组合的方法集"></a>3.4.2 组合的方法集</h3><h2 id="3-5-函数类型"><a href="#3-5-函数类型" class="headerlink" title="3.5 函数类型"></a>3.5 函数类型</h2><h1 id="第-4-章-接口（未看）"><a href="#第-4-章-接口（未看）" class="headerlink" title="第 4 章 接口（未看）"></a>第 4 章 接口（未看）</h1><h1 id="第-5-章-并发"><a href="#第-5-章-并发" class="headerlink" title="第 5 章 并发"></a>第 5 章 并发</h1><h2 id="5-1-并发基础"><a href="#5-1-并发基础" class="headerlink" title="5.1 并发基础"></a>5.1 并发基础</h2><h3 id="5-1-1-并发和并行"><a href="#5-1-1-并发和并行" class="headerlink" title="5.1.1 并发和并行"></a>5.1.1 并发和并行</h3><ol><li>并行就是在任一粒度的时间内都具备同时执行的能力：例如多机</li><li>并发是在规定的时间内多个请求都得到执行和处理，强调的是给外界的感受，实际上内部可能是分时操作的</li></ol><h3 id="5-1-2-goroutine"><a href="#5-1-2-goroutine" class="headerlink" title="5.1.2 goroutine"></a>5.1.2 goroutine</h3><p>Go语言的并发执行体称为goroutine，通过go关键字来启动一个goroutine。</p><p>goroutine特性：</p><ul><li>go的执行是非阻塞的，不会等待</li><li>go后面的函数的返回值会被忽略</li><li>调度器不能保证多个goroutine的执行次序</li><li>没有父子goroutine的概念，所有goroutne是平等地被调用和执行的</li><li>Go程序在执行时会单独为main函数创建一个goroutine，遇到其他go关键字时再去创建其他的goroutinue</li><li>Go没有暴露goroutine id给用户，所以不能在一个goroutine里面显式地操作另一个goroutine，不过runtime包提供了一些函数访问和设置goroutine的相关信息</li></ul><ol><li>func GOMAXPROCS</li></ol><p>设置或查询可以并发执行的goroutine数目</p><pre><code class="go">package goroutine_testimport (    "runtime"    "testing")func TestName(t *testing.T) {    // 获取GOMAXPROCS    println("GOMAXPROCS=",runtime.GOMAXPROCS(0))    // 设置GOMAXPROCS    runtime.GOMAXPROCS(2)    // 获取GOMAXPROCS    println("GOMAXPROCS=",runtime.GOMAXPROCS(0))}</code></pre><ol><li>func Goexit</li></ol><p>结束当前goroutinue的运行。Goexit不会产生panic。</p><ol><li>fun Gosched</li></ol><p>放弃当前调度执行机会，将当前goroutinue放到队列中等待下次被调度</p><h3 id="5-1-3-chan"><a href="#5-1-3-chan" class="headerlink" title="5.1.3 chan"></a>5.1.3 chan</h3><ol><li>chan是Go语言里面的一个关键字，是channel的简写，通道。通道是Go通过通信来共享内容的载体。</li><li>通道类型：<ul><li><p>有缓冲的通道：主要用于通信</p></li><li><p>无缓冲的通道：既可以用于通信，也可以用于两个goroutinue的同步</p><p><img src="/images/go_core_programming/Untitled%2038.png" alt="Untitled"></p><pre><code class="go">func TestName(t *testing.T) {  println("NumGoroutinue=", runtime.NumGoroutine())  c := make(chan struct{})  ci := make(chan int, 100)  go func(i chan struct{}, j chan int) {      for i := 0; i &lt; 10; i++ {          ci &lt;- i      }      close(ci)      // 写通道      c &lt;- struct{}{}  }(c, ci)  // NumGoroutinue可以返回当前程序的goroutinue数目  println("NumGoroutinue=", runtime.NumGoroutine())  // 读通道c，通过通道进行同步等待  &lt;-c  // 此时ci通道已经关闭，匿名函数启动的goroutinue已经退出  println("NumGoroutinue=", runtime.NumGoroutine())  for v := range ci {      println(v)  }}</code></pre></li></ul></li><li>操作不同状态的chan会引发三种行为<ul><li>panic<ul><li>向已经关闭的通道写数据会导致panic。由写入者关闭通道能最大程度地避免向已经关闭的通道写数据而导致panic</li><li>重复关闭的通道会导致panic</li></ul></li><li>阻塞<ul><li>向未初始化的通道写数据或读数据都会导致当前goroutine的永久阻塞</li><li>向缓冲区已满的通道写入数据会导致goroutinue阻塞</li><li>通道中没有数据，读取该通道会导致goroutinue阻塞</li></ul></li><li>非阻塞<ul><li>读者已经关闭的通道不会引发阻塞而是立即返回通道元素类型的零值，可以使用comma，ok语法判断通道是否已经关闭</li><li>向有缓冲且没有满的通道读/写不会引发阻塞</li></ul></li></ul></li></ol><h3 id="5-1-4-WaitGroup"><a href="#5-1-4-WaitGroup" class="headerlink" title="5.1.4 WaitGroup"></a>5.1.4 WaitGroup</h3><p>sync包提供了多个goroutine同步的机制，主要是通过WaitGroup实现的。</p><h3 id="5-1-5-select"><a href="#5-1-5-select" class="headerlink" title="5.1.5 select"></a>5.1.5 select</h3><p>select用于多路监听多个通道</p><ul><li>当监听的通道没有状态是可读或可写的，select是阻塞的</li><li>监听的通道中有一个状态是可读或可写的，则select就不会阻塞，而是进入处理就绪通道的分支流程</li><li>如果监听的通道有多个可读或可写的状态，则select随机选取一个处理</li></ul><pre><code class="go">import "testing"func TestName(t *testing.T) {    ch := make(chan int, 2)    go func(chan int) {        for {            select {            case ch &lt;- 0:            case ch &lt;- 1:            }        }    }(ch)    for i := 0; i &lt; 10; i++ {        println(&lt;-ch)    }}</code></pre><h3 id="5-1-6-扇入（Fan-in）和扇出（Fan-out）"><a href="#5-1-6-扇入（Fan-in）和扇出（Fan-out）" class="headerlink" title="5.1.6 扇入（Fan in）和扇出（Fan out）"></a>5.1.6 扇入（Fan in）和扇出（Fan out）</h3><p>扇入：将多路通道聚合到一条通道中处理，Go最简单的扇入就是使用select聚合多条通道服务</p><p>扇出：将一条通道发散到多条通道中处理，Go语言里面具体实现就是使用go关键字启动多个goroutine并发处理 </p><pre><code class="go">import (    "fmt"    "sync"    "testing")var wg sync.WaitGroupfunc TestWaitGroup(t *testing.T) {    for i := 0; i &lt; 10; i++ {        wg.Add(1)        go func(i int) {            defer wg.Done()            fmt.Printf("go func: %d\n", i)        }(i)    }    wg.Wait()    println("success!")}</code></pre><h3 id="5-1-7-通知退出机制"><a href="#5-1-7-通知退出机制" class="headerlink" title="5.1.7 通知退出机制"></a>5.1.7 通知退出机制</h3><p>读取已经关闭的通道不会引起阻塞，也不会导致panic，而是立即返回该通道存储类型的零值。</p><p>关闭select监听的某个通道能使select立即感知这种通知，然后进行相应的处理，这就是所谓的退出通知机制。</p><p>下面通过一个随机数生成器的示例掩饰退出通知机制，下游的消费者不需要随机数时显式地通知生产者停止生产：</p><pre><code class="go">import (    "fmt"    "math/rand"    "runtime"    "testing")func GenerateIntA(done chan struct{}) chan int {    ch := make(chan int)    go func() {    Lable:        for {            select {            case ch &lt;- rand.Int():            case &lt;-done:                break Lable            }        }        close(ch)    }()    return ch}func TestNotiExit(t *testing.T) {    println("NumGoroutine=", runtime.NumGoroutine())    done := make(chan struct{})    ch := GenerateIntA(done)    println("NumGoroutine=", runtime.NumGoroutine())    fmt.Println(&lt;-ch)    fmt.Println(&lt;-ch)    close(done)    fmt.Println(&lt;-ch)    fmt.Println(&lt;-ch)    println("NumGoroutine=", runtime.NumGoroutine())}</code></pre><h2 id="5-2-并发范式"><a href="#5-2-并发范式" class="headerlink" title="5.2 并发范式"></a>5.2 并发范式</h2><h3 id="5-2-1-生成器"><a href="#5-2-1-生成器" class="headerlink" title="5.2.1 生成器"></a>5.2.1 生成器</h3><ol><li>最简单的带缓冲的生成器</li></ol><pre><code class="go">import (    "fmt"    "math/rand"    "testing")func GenerateInt() chan int {    ch := make(chan int, 3)    go func() {        for {            ch &lt;- rand.Int()        }    }()    return ch}func TestGenerateInt(t *testing.T) {    ch := GenerateInt()    fmt.Println(&lt;-ch)    fmt.Println(&lt;-ch)    fmt.Println(&lt;-ch)    fmt.Println(&lt;-ch)}</code></pre><ol><li>多个goroutinue增强型生成器</li></ol><p><img src="/images/go_core_programming/Untitled%2039.png" alt="Untitled"></p><ol><li>有时希望生成器能够自动退出，可以借助Go通道的退出通知机制实现，例如：</li></ol><p><img src="/images/go_core_programming/Untitled%2040.png" alt="Untitled"></p><p><img src="/images/go_core_programming/Untitled%2041.png" alt="Untitled"></p><ol><li>融合并发、缓冲、退出通知等多重特性的生成器</li></ol><pre><code class="go">package genericimport (    "fmt"    "math/rand"    "testing")func GenerateIntA(done chan struct{}) chan int {    fmt.Println("GenerateIntA")    ch := make(chan int, 5)    go func() {    Lable:        for {            select {            case ch &lt;- rand.Int():            case &lt;-done:                break Lable            }        }        close(ch)    }()    return ch}func GenerateIntB(done chan struct{}) chan int {    fmt.Println("GenerateIntB")    ch := make(chan int, 5)    go func() {    Lable:        for {            select {            case ch &lt;- rand.Int():            case &lt;-done:                break Lable            }        }        close(ch)    }()    return ch}func GenerateInt(done chan struct{}) chan int {    ch := make(chan int)    send := make(chan struct{})    go func() {    Lable:        for {            select {            case ch &lt;- &lt;-GenerateIntA(send):            case ch &lt;- &lt;-GenerateIntB(send):            case &lt;-done:                send &lt;- struct{}{}                send &lt;- struct{}{}                break Lable            }        }        close(ch)    }()    return ch}func Test(t *testing.T)  {    done := make(chan struct{})    ch := GenerateInt(done)    for i := 0; i &lt; 10; i++ {        fmt.Println(&lt;-ch)    }    done &lt;- struct{}{}    fmt.Println("stop generate")}</code></pre><h3 id="5-2-2-管道"><a href="#5-2-2-管道" class="headerlink" title="5.2.2 管道"></a>5.2.2 管道</h3><p>通道可以分为两个方向，一个是读另一个是写，加入一个函数的输入参数和输出参数都是相同的chan类型，则该函数可以调用自己，最终形成一个调用链。这很像UNIX系统的管道，是一个有类型的管道</p><h3 id="5-2-3-每个请求一个goroutine"><a href="#5-2-3-每个请求一个goroutine" class="headerlink" title="5.2.3 每个请求一个goroutine"></a>5.2.3 每个请求一个goroutine</h3><p>来一个请求或任务就启动一个goroutine去处理，典型的就是Go中的HTTP server服务。</p><h3 id="5-2-4-固定worker工作池"><a href="#5-2-4-固定worker工作池" class="headerlink" title="5.2.4 固定worker工作池"></a>5.2.4 固定worker工作池</h3><p>程序中除了主要的main goroutine，还开启了如下几类goroutine：</p><ul><li>初始化任务的goroutine</li><li>分发任务的goroutine</li><li>等待所有worker结束通知，然后关闭结果通道的goroutine</li></ul><p>程序采用三个通道，分别是：</p><ul><li>传递task任务的通道</li><li>传递task结果的通道</li><li>接收worker处理完任务后所发送通知的通道</li></ul><p>计算多个整数的和样例代码：</p><pre><code class="go">package mainimport (    "fmt"    "math/rand"    "time")// 工作池的goroutine数目const NUMBER = 10// 工作任务type task struct {    // 存放数据    data int    // 任务结果    result chan&lt;- int}// 任务处理：计算begin和end的和// 执行结果写入结果chan resultfunc (t *task) do() {    // 模拟计算耗时    r := rand.Intn(1000)    fmt.Println("Sleep:", r, "ms")    time.Sleep(time.Duration(r) * time.Millisecond)    // 模拟任务结果就是任务数据    t.result &lt;- t.data}func main() {    workers := NUMBER    taskChan := make(chan task, 10)    resultChan := make(chan int, 10)    done := make(chan struct{}, 10)    // 初始化task的goroutine    go InitTask(taskChan, resultChan, 100)    // 分发任务到NUMBER个goroutine池    DistributeTask(taskChan, workers, done)    // 获取各个goroutine处理完任务的通知并关闭结果通道    go CloseResult(done, resultChan, workers)    // 通过结果通道获取结果并汇总    sum := ProcessResult(resultChan)    fmt.Println("sum=", sum)}// 初始化待处理task chanfunc InitTask(taskChan chan&lt;- task, r chan int, p int) {    for i := 0; i &lt;= p; i++ {        taskChan &lt;- task{            data:   i,            result: r,        }    }    close(taskChan)}// 读取task chan并分发到worker goroutine处理，总的数量是workersfunc DistributeTask(taskChan &lt;-chan task, works int, done chan struct{}) {    for i := 0; i &lt; works; i++ {        go ProcessTask(taskChan, done)    }}// 工作goroutine处理具体工作，并将处理结果发送到结果chanfunc ProcessTask(taskChan &lt;-chan task, done chan struct{}) {    for t := range taskChan {        t.do()    }    done &lt;- struct{}{}}// 通过done channel同步等待所有工作goroutine的结束，然后关闭结果chanfunc CloseResult(done chan struct{}, resultChan chan int, workers int) {    for i := 0; i &lt; workers; i++ {        &lt;-done    }    close(done)    close(resultChan)}// 读取结果通道，汇总结果func ProcessResult(resultChan chan int) int {    sum := 0    for r := range resultChan {        sum += r    }    return sum}</code></pre><p><img src="/images/go_core_programming/Untitled%2042.png" alt="Untitled"></p><p><img src="/images/go_core_programming/Untitled%2043.png" alt="Untitled"></p><h3 id="5-2-5-future模式"><a href="#5-2-5-future模式" class="headerlink" title="5.2.5 future模式"></a>5.2.5 future模式</h3><p>用处：子调用相互之间没有依赖，如果串行调用则耗时会很长，此时可以使用Go并发编程中的future模式</p><p>工作原理：</p><ol><li>使用chan作为函数参数</li><li>启动goroutine调用安徽省农户</li><li>通过chan传递如参数</li><li>做其他可以并行处理的事情</li><li>通过chan异步获取结果</li></ol><pre><code class="go">package mainimport (    "fmt"    "time")// 一个查询结构体// 这里的sql和result是一个简单的抽象，具体的应用可能是更复杂的数据类型type query struct {    // 参数Channel    sql chan string    // 结果Channel    result chan string}// 执行Queryfunc execQuery(q query) {    // 启动协程    go func() {        // 获取输入        sql := &lt;-q.sql        // 访问数据库        // 输出结果通道        q.result &lt;- "result from " + sql    }()}func main() {    // 初始化Query    q := query{make(chan string, 1), make(chan string, 1)}    // 执行Query，注意执行的时候无需准备参数    go execQuery(q)    // 发送参数    q.sql &lt;- "select * from table"    // 做其他事情    time.Sleep(1 * time.Second)    // 获取结果    fmt.Println(&lt;-q.result)}</code></pre><p><img src="/images/go_core_programming/Untitled%2044.png" alt="Untitled"></p><h2 id="5-3-context标准库"><a href="#5-3-context标准库" class="headerlink" title="5.3 context标准库"></a>5.3 context标准库</h2><p>Go中的goroutine之间没有父与子的关系，没有所谓的子进程退出后的通知机制，goroutine之间平行地被调度，多个goroutine如何协作工作设计通信、同步、通知和退出四个方面</p><ul><li>通信：chan通道是goroutine之间通信的基础（通信指程序的数据通道）</li><li>同步：不带缓冲的chan提供了一个天然的同步等待机制；sync.WaitGroup也为多个goroutine协同工作提供一种同步等待机制</li><li>通知：这个通知和上面通信的数据不一样，通知不是业务数据，而是管理、控制流数据。在输入端绑定两个chan，一个用于业务流数据，另一个用于异常通知数据，然后使用select收敛进行处理</li><li>退出：借助通道和select的广播机制实现退出</li></ul><h3 id="5-3-1-context的设计目的"><a href="#5-3-1-context的设计目的" class="headerlink" title="5.3.1 context的设计目的"></a>5.3.1 context的设计目的</h3><ul><li>退出通知机制：通知可以传递给整个goroutine调用树上的每一个goroutine</li><li>数据传递：数据可以传递给整个goroutine调用树上的每一个goroutine</li></ul><h3 id="5-3-2-基本数据结构"><a href="#5-3-2-基本数据结构" class="headerlink" title="5.3.2 基本数据结构"></a>5.3.2 基本数据结构</h3><p>context工作机制：第一个创建 Context goroutine被称为 root 节点。 root 节点负责创建一个实现context接口的具体对象，并将该对象作为参数传递到其新拉起的goroutine，下游的 goroutine 继续封装该对象，再传递到更下游的goroutine，Context 对象在传递的过程中最终形成一个树状的数据结构，这样通过位于 root 节点（树的根节点） Context 对象就能遍历整个 Context 对象树，通知和消息就可以通过 root 节点传递出去，实现了上游 goroutine 下游 goroutine 的消息传递。</p><p><strong>Context接口</strong></p><p>Context作为参数传递</p><p><img src="/images/go_core_programming/Untitled%2045.png" alt="Untitled"></p><p><img src="/images/go_core_programming/Untitled%2046.png" alt="Untitled"></p><p><strong>canceler接口</strong></p><p>conceler规定了取消通知的Context具体类型需要实现的接口</p><p><img src="/images/go_core_programming/Untitled%2047.png" alt="Untitled"></p><p><strong>empty Context结构</strong></p><p>实现了Context接口但不具备任何功能，其存在的目的是作为Context对象树的根（root节点）</p><p><strong>cancelCtx</strong></p><p>cancelCtx是一个实现了Context耳机口的具体类型，同时实现了conceler接口</p><p><strong>timerCtx</strong></p><p>timerCtx是一个实现了Context接口的具体类型，内部封装cancelCtx类型实例，同时有一个deadlinebianl,yonglaishixian定时退出通知</p><p><strong>valueCtx</strong></p><p>valueCtx是一个实现了Context接口的具体类型，内部封装了Context接口类型，同时封装了一个k/v的存储遍历，valueCtx可以用来传递通知信息</p><p><img src="/images/go_core_programming/Untitled%2048.png" alt="Untitled"></p><h3 id="5-3-3-API函数"><a href="#5-3-3-API函数" class="headerlink" title="5.3.3 API函数"></a>5.3.3 API函数</h3><p>以下两个函数是构造Context取消树的根节点对象，根节点对象用作后续With包装函数的实参：</p><ul><li>func Background() Context</li><li>func TODO() Context</li></ul><h3 id="5-3-6-使用Context传递数据的争议"><a href="#5-3-6-使用Context传递数据的争议" class="headerlink" title="5.3.6 使用Context传递数据的争议"></a>5.3.6 使用Context传递数据的争议</h3><p>使用context传递数据的坏处：</p><ul><li>传递的都是interface{}类型的值，编译器不能进行严格的类型校验</li><li>从interface{}到具体类型需要使用类型断言和接口查询，有一定的运行期开销和性能损失</li><li>值在传递过程中有可能被后续的服务覆盖且不易被发现</li><li>传递信息不简明。较晦涩；不能通过代码或文档一眼看到传递的是什么，不利于后续维护</li></ul><p>context应该传递什么数据：</p><ul><li>日志信息</li><li>调低是信息</li><li>不影响业务主逻辑的可选数据</li></ul><h2 id="5-4-并发模型"><a href="#5-4-并发模型" class="headerlink" title="5.4 并发模型"></a>5.4 并发模型</h2><h3 id="5-4-1-CSP简介"><a href="#5-4-1-CSP简介" class="headerlink" title="5.4.1 CSP简介"></a>5.4.1 CSP简介</h3><p>CSP基本思想：将并发系统抽象为Channel和Process两部分，Channel用来传递消息，Process用于执行，Channel和Process之间相互独立，没有从属关系，消息的发送和接收有严格的时序限制。</p><p>Go中Channel就是通道，Process就是goroutine</p><h3 id="5-4-2-调度模型"><a href="#5-4-2-调度模型" class="headerlink" title="5.4.2 调度模型"></a>5.4.2 调度模型</h3><p>协程是一种用户态的轻量级线程，写成的调度完全由用户态程序控制，协程拥有自己的寄存器上下文和栈。</p><p>协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候恢复先前保存的寄存器上下文和栈，每个内核线程可以对应多个用户协程，当一个协程执行体阻塞了，调度器会调度另一个携程执行，最大效率地利用操作系统分给系统线程的时间片。</p><p>好处：</p><ul><li>控制了系统线程数，保证每个线程的运行时间片充足</li><li>调度层能进行用户态的切换，不会导致单个协程阻塞整个程序的情况，尽量减少上下文切换，提升运行效率</li></ul><p>由此可见，协程是一种非常高效、理想的执行模型。Go的并发执行模型就是一种变种的协程模型。</p><h3 id="5-4-3-并发和调度"><a href="#5-4-3-并发和调度" class="headerlink" title="5.4.3 并发和调度"></a>5.4.3 并发和调度</h3><p>goroutine好处：</p><ul><li>goroutine可以在用户空间调度，避免了内核态和用户态的切换导致的成本</li><li>goroutine是语言原生支持的，提供了非常简洁的语法，屏蔽了大部分复杂底层实现</li><li>goroutine更小的占空间允许用户创建成千上万的实例</li></ul><p>goroutinue调度模型：</p><ol><li>实体G（Goroutine）</li></ol><p>G是Go运行时对goroutine的抽象描述，G中存放并发执行的代码入口地址、上下文、运行环境（关联的P和M）、运行栈等执行相关的元信息</p><ol><li>实体M（Machine）</li></ol><p>M代表OS内核线程，是操作系统层面调度和执行的实体。M仅负责执行，M不停地被唤醒或创建，然后执行。M启动时进入的是运行时的管理代码，有这段代码获取G和P资源，然后执行调度。另外Go</p><p>语言运行时会单独创建一个监控线程，负责对程序的内存、调度等信息进行监控和控制</p><ol><li>实体P（Processor）</li></ol><p>P代表M运行G所需的资源，是对资源的一种抽象和管理，P不是一段代码实体，而是一个管理的数据结构，P主要是降低M管理调度G的复杂性，增加一个简洁的控制层数据结构。</p><p><img src="/images/go_core_programming/Untitled%2049.png" alt="Untitled"></p><p><strong>m0和g0</strong></p><p>m0和g0是启动程序后的主线程，这个m对应的信息会存放在全局变量m0种，m0负责执行初始化操作和启动第一个g，之后m0就和其他m一样了。</p><p><img src="/images/go_core_programming/Untitled%2050.png" alt="Untitled"></p><h1 id="第-7-章-语言陷阱"><a href="#第-7-章-语言陷阱" class="headerlink" title="第 7 章 语言陷阱"></a>第 7 章 语言陷阱</h1><h2 id="7-1-多值赋值和短变量声明"><a href="#7-1-多值赋值和短变量声明" class="headerlink" title="7.1 多值赋值和短变量声明"></a>7.1 多值赋值和短变量声明</h2><h3 id="7-1-1-多值赋值"><a href="#7-1-1-多值赋值" class="headerlink" title="7.1.1 多值赋值"></a>7.1.1 多值赋值</h3><p>非法：</p><p><img src="/images/go_core_programming/Untitled%2051.png" alt="Untitled"></p><p>多值赋值语义：</p><ul><li>对左侧操作数中的表达式、索引值进行计算和确定，首先确定左侧的操作数的地址，然后对右侧的赋值表达式进行计算，如果发现右侧的表达式计算引用了左侧的变量，则创建临时变量进行值拷贝，最后完成计算</li><li>从左到右的顺序依次赋值</li></ul><p>示例：</p><pre><code class="go">import (    "fmt"    "testing")func Test(t *testing.T) {    x := []int{1, 2, 3}    i := 0    i, x[i] = 1, 2    fmt.Println(i, x) // 1 [2 2 3]    x = []int{1, 2, 3}    i = 0    x[i], i = 2, 1    fmt.Println(i, x) // 1 [2 2 3]    x = []int{1, 2, 3}    i = 0    x[i], i = 2, x[i] // set tmp=x[0],x[0]=2,i=tmp ==&gt; i=1    fmt.Println(i, x) // 1 [2 2 3]    x[0], x[0] = 1, 2    fmt.Println(x[0]) // 2}</code></pre><h3 id="7-1-2-短变量的声明和赋值"><a href="#7-1-2-短变量的声明和赋值" class="headerlink" title="7.1.2 短变量的声明和赋值"></a>7.1.2 短变量的声明和赋值</h3><p>约定：</p><ul><li>使用“:=”操作符，变量的定义和初始化同时完成</li><li>变量名后不要跟任何类型名，Go编译器完全靠右边的值进行推导</li><li>支持多值短变量声明赋值</li><li>只能用在函数和类型方法的内部</li></ul><p><img src="/images/go_core_programming/Untitled%2052.png" alt="Untitled"></p><p><img src="/images/go_core_programming/Untitled%2053.png" alt="Untitled"></p><h2 id="7-2-range复用临时变量"><a href="#7-2-range复用临时变量" class="headerlink" title="7.2 range复用临时变量"></a>7.2 range复用临时变量</h2><p><img src="/images/go_core_programming/Untitled%2054.png" alt="Untitled"></p><p>结果打印的都是9，原因：</p><ul><li>for range下的迭代变量i的值是共用的</li><li>main函数所在的goiroutinue和后续启动的goroutines存在竞争关系</li></ul><p>正确写法：</p><p><img src="/images/go_core_programming/Untitled%2055.png" alt="Untitled"></p><h2 id="7-3-defer陷阱"><a href="#7-3-defer陷阱" class="headerlink" title="7.3 defer陷阱"></a>7.3 defer陷阱</h2><p>对带defer的函数返回整体上有三个步骤</p><ul><li>执行return的值拷贝，将return语句返回的值复制到函数返回值栈区（如果只有一个return，不带任何变量或值，则此步骤不做任何动作）</li><li>执行defer语句，多个defer按照FILO顺序执行</li><li>执行调整RET指令</li></ul><h2 id="7-4-切片困惑"><a href="#7-4-切片困惑" class="headerlink" title="7.4 切片困惑"></a>7.4 切片困惑</h2><h3 id="7-4-1-数组"><a href="#7-4-1-数组" class="headerlink" title="7.4.1 数组"></a>7.4.1 数组</h3><p>Go的数组是有固定个相同类型元素的数据结构，底层采用连续的内存空间存放，数组一旦声明后大小就不可改变了。</p><p>Go中的数组是一种基本类型。数组的类型不仅包括其元素类型，也包括其大小，[2]int和[5]int是两个完全不同的数组类型</p><p><img src="/images/go_core_programming/Untitled%2056.png" alt="Untitled"></p><p>数组名无论作为函数实参还是作为struct嵌入字段，或者数组之间的直接赋值都是值拷贝</p><h3 id="7-4-2-切片"><a href="#7-4-2-切片" class="headerlink" title="7.4.2 切片"></a>7.4.2 切片</h3><p><strong>切片创建</strong></p><ol><li>通过数组创建</li></ol><p>array[b:e]创建一个包括e-b个元素的切片，包含b，不包含e</p><ol><li>make</li></ol><p>make([]T, len, cap)中的T是切片元素类型，len是长度，cap是底层数组的容量。cap是可选参数</p><ol><li>直接声明</li></ol><p><img src="/images/go_core_programming/Untitled%2057.png" alt="Untitled"></p><p>切片数据结构</p><p><img src="/images/go_core_programming/Untitled%2058.png" alt="Untitled"></p><p>多个切片共享一个底层数组，其中一个切片的append操作可能引发如下两种情况：</p><ul><li>append追加的元素没有超过底层数组的容量，此种append操作会直接操作共享的底层数组，如果其他切片有引用数组被覆盖的原色，则会导致其他切片的值也会隐式地发生变化</li><li>append追加的元素加上原来的元素如果超出底层数组的容量，则此种append操作会重新申请新数组，并将原来数组的值复制到新数组</li></ul><p>由于有这种二义性，所以在使用切片过程中应该尽量避免多个切面共享底层数组，可以使用copy进行显式的复制</p><h2 id="7-5-值、指针和引用"><a href="#7-5-值、指针和引用" class="headerlink" title="7.5 值、指针和引用"></a>7.5 值、指针和引用</h2><h3 id="7-5-1-传值还是传引用"><a href="#7-5-1-传值还是传引用" class="headerlink" title="7.5.1 传值还是传引用"></a>7.5.1 传值还是传引用</h3><p>Go只有一种参数传递规则：值拷贝，含义：</p><ul><li>函数参数传递时使用的是值拷贝</li><li>实例赋值给接口变量，接口对实例的引用是值拷贝</li></ul><p>有时在明明是值拷贝的地方结果却修改了变量的内容，有以下两种情况：</p><ul><li>直接传递的是指针，指针传递同样是值拷贝，但指针和指针副本的值指向的地址是同一地方，所以能修改实参值</li><li>参数是负荷数据类型，这些复合数据类型内部有指针类型的元素，此时参数的值bi拷贝并不影响指针的指向</li></ul><h3 id="7-5-2-函数名的意义"><a href="#7-5-2-函数名的意义" class="headerlink" title="7.5.2 函数名的意义"></a>7.5.2 函数名的意义</h3><ul><li>类型信息</li><li>函数的执行代码的起始位置</li><li>可以通过函数名进行函数调用</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go面试题手写内容</title>
      <link href="/2022/01/16/go/Go%E9%9D%A2%E8%AF%95%E9%A2%98%E6%89%8B%E5%86%99/"/>
      <url>/2022/01/16/go/Go%E9%9D%A2%E8%AF%95%E9%A2%98%E6%89%8B%E5%86%99/</url>
      
        <content type="html"><![CDATA[<p><img src="/images/go_interview/GO-r-01.jpg" alt="img"><br><img src="/images/go_interview/GO-r-02.jpg" alt="img"><br><img src="/images/go_interview/GO-r-03.jpg" alt="img"><br><img src="/images/go_interview/GO-r-04.jpg" alt="img"><br><img src="/images/go_interview/GO-r-05.jpg" alt="img"><br><img src="/images/go_interview/GO-r-06.jpg" alt="img"><br><img src="/images/go_interview/GO-r-07.jpg" alt="img"><br><img src="/images/go_interview/GO-r-08.jpg" alt="img"><br><img src="/images/go_interview/GO-r-09.jpg" alt="img"><br><img src="/images/go_interview/GO-r-10.jpg" alt="img"><br><img src="/images/go_interview/GO-r-11.jpg" alt="img"><br><img src="/images/go_interview/GO-r-12.jpg" alt="img"><br><img src="/images/go_interview/GO-r-13.jpg" alt="img"><br><img src="/images/go_interview/GO-r-14.jpg" alt="img"><br><img src="/images/go_interview/GO-r-15.jpg" alt="img"><br><img src="/images/go_interview/GO-r-16.jpg" alt="img"><br><img src="/images/go_interview/GO-r-17.jpg" alt="img"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> 面试题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go面试题</title>
      <link href="/2022/01/16/go/Go%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
      <url>/2022/01/16/go/Go%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p><a href="https://geektutu.com/post/qa-golang.html">参考链接</a></p><h1 id="一、Go-语言笔试面试题-基础语法"><a href="#一、Go-语言笔试面试题-基础语法" class="headerlink" title="一、Go 语言笔试面试题(基础语法)"></a>一、Go 语言笔试面试题(基础语法)</h1><h2 id="1-和-的区别？"><a href="#1-和-的区别？" class="headerlink" title="1. = 和 := 的区别？"></a>1. = 和 := 的区别？</h2><p>答案<br>:= 声明+赋值<br>= 仅赋值</p><pre><code class="go">var foo intfoo = 10// 等价于foo := 10</code></pre><h2 id="2-指针的作用？"><a href="#2-指针的作用？" class="headerlink" title="2. 指针的作用？"></a>2. 指针的作用？</h2><p>答案<br>指针用来保存变量的地址。<br>例如</p><pre><code class="go">var x =  5var p *int = &amp;xfmt.Printf("x = %d",  *p) // x 可以用 *p 访问</code></pre><ul><li>运算符，也称为解引用运算符，用于访问地址中的值。<br>＆运算符，也称为地址运算符，用于返回变量的地址。<br>Q3 Go 允许多个返回值吗？<br>答案<br>允许<pre><code>func swap(x, y string) (string, string) { return y, x}</code></pre></li></ul><p>func main() {<br>   a, b := swap(“A”, “B”)<br>   fmt.Println(a, b) // B A<br>}</p><pre><code>## 4. Go 有异常类型吗？答案Go 没有异常类型，只有错误类型（Error），通常使用返回值来表示异常状态。```gof, err := os.Open("test.txt")if err != nil {    log.Fatal(err)}</code></pre><h2 id="5-什么是协程（Goroutine）"><a href="#5-什么是协程（Goroutine）" class="headerlink" title="5. 什么是协程（Goroutine）"></a>5. 什么是协程（Goroutine）</h2><p>答案<br>Goroutine 是与其他函数或方法同时运行的函数或方法。 Goroutines 可以被认为是轻量级的线程。 与线程相比，创建 Goroutine 的开销很小。 Go应用程序同时运行数千个 Goroutine 是非常常见的做法。</p><h2 id="6-如何高效地拼接字符串"><a href="#6-如何高效地拼接字符串" class="headerlink" title="6. 如何高效地拼接字符串"></a>6. 如何高效地拼接字符串</h2><p>答案<br>Go 语言中，字符串是只读的，也就意味着每次修改操作都会创建一个新的字符串。如果需要拼接多次，应使用 strings.Builder，最小化内存拷贝次数。</p><pre><code class="go">var str strings.Builderfor i := 0; i &lt; 1000; i++ {    str.WriteString("a")}fmt.Println(str.String())</code></pre><h2 id="7-什么是-rune-类型"><a href="#7-什么是-rune-类型" class="headerlink" title="7. 什么是 rune 类型"></a>7. 什么是 rune 类型</h2><p>答案<br>ASCII 码只需要 7 bit 就可以完整地表示，但只能表示英文字母在内的128个字符，为了表示世界上大部分的文字系统，发明了 Unicode， 它是ASCII的超集，包含世界上书写系统中存在的所有字符，并为每个代码分配一个标准编号（称为Unicode CodePoint），在 Go 语言中称之为 rune，是 int32 类型的别名。<br>Go 语言中，字符串的底层表示是 byte (8 bit) 序列，而非 rune (32 bit) 序列。例如下面的例子中 语 和 言 使用 UTF-8 编码后各占 3 个 byte，因此 len(“Go语言”) 等于 8，当然我们也可以将字符串转换为 rune 序列。</p><pre><code class="go">fmt.Println(len("Go语言")) // 8fmt.Println(len([]rune("Go语言"))) // 4</code></pre><h2 id="8-如何判断-map-中是否包含某个-key-？"><a href="#8-如何判断-map-中是否包含某个-key-？" class="headerlink" title="8. 如何判断 map 中是否包含某个 key ？"></a>8. 如何判断 map 中是否包含某个 key ？</h2><p>答案</p><pre><code class="go">if val, ok := dict["foo"]; ok {    //do something here}</code></pre><p>dict[“foo”] 有 2 个返回值，val 和 ok，如果 ok 等于 true，则说明 dict 包含 key “foo”，val 将被赋予 “foo” 对应的值。</p><h2 id="9-Go-支持默认参数或可选参数吗？"><a href="#9-Go-支持默认参数或可选参数吗？" class="headerlink" title="9. Go 支持默认参数或可选参数吗？"></a>9. Go 支持默认参数或可选参数吗？</h2><p>答案<br>Go 语言不支持可选参数（python 支持），也不支持方法重载（java支持）。</p><h2 id="10-defer-的执行顺序"><a href="#10-defer-的执行顺序" class="headerlink" title="10. defer 的执行顺序"></a>10. defer 的执行顺序</h2><p>答案<br>多个 defer 语句，遵从后进先出(Last In First Out，LIFO)的原则，最后声明的 defer 语句，最先得到执行。<br>defer 在 return 语句之后执行，但在函数退出之前，defer 可以修改返回值。<br>例如：</p><pre><code class="go">func test() int {    i := 0    defer func() {        fmt.Println("defer1")    }()    defer func() {        i += 1        fmt.Println("defer2")    }()    return i}func main() {    fmt.Println("return", test())}// defer2// defer1// return 0</code></pre><p>这个例子中，可以看到 defer 的执行顺序：后进先出。但是返回值并没有被修改，这是由于 Go 的返回机制决定的，执行 return 语句后，Go 会创建一个临时变量保存返回值，因此，defer 语句修改了局部变量 i，并没有修改返回值。那如果是有名的返回值呢？</p><pre><code class="go">func test() (i int) {    i = 0    defer func() {        i += 1        fmt.Println("defer2")    }()    return i}func main() {    fmt.Println("return", test())}// defer2// return 1</code></pre><p>这个例子中，返回值被修改了。对于有名返回值的函数，执行 return 语句时，并不会再创建临时变量保存，因此，defer 语句修改了 i，即对返回值产生了影响。<br>Q11 如何交换 2 个变量的值？<br>答案</p><pre><code class="go">a, b := "A", "B"a, b = b, afmt.Println(a, b) // B A</code></pre><h2 id="12-Go-语言-tag-的用处？"><a href="#12-Go-语言-tag-的用处？" class="headerlink" title="12. Go 语言 tag 的用处？"></a>12. Go 语言 tag 的用处？</h2><p>答案<br>tag 可以理解为 struct 字段的注解，可以用来定义字段的一个或多个属性。框架/工具可以通过反射获取到某个字段定义的属性，采取相应的处理方式。tag 丰富了代码的语义，增强了灵活性。<br>例如：</p><pre><code class="go">package mainimport "fmt"import "encoding/json"type Stu struct {    Name string `json:"stu_name"`    ID   string `json:"stu_id"`    Age  int    `json:"-"`}func main() {    buf, _ := json.Marshal(Stu{"Tom", "t001", 18})    fmt.Printf("%s\n", buf)}</code></pre><p>这个例子使用 tag 定义了结构体字段与 json 字段的转换关系，Name -&gt; stu_name, ID -&gt; stu_id，忽略 Age 字段。很方便地实现了 Go 结构体与不同规范的 json 文本之间的转换。</p><h2 id="13-如何判断-2-个字符串切片（slice-是相等的？"><a href="#13-如何判断-2-个字符串切片（slice-是相等的？" class="headerlink" title="13. 如何判断 2 个字符串切片（slice) 是相等的？"></a>13. 如何判断 2 个字符串切片（slice) 是相等的？</h2><p>答案<br>go 语言中可以使用反射 reflect.DeepEqual(a, b) 判断 a、b 两个切片是否相等，但是通常不推荐这么做，使用反射非常影响性能。<br>通常采用的方式如下，遍历比较切片中的每一个元素（注意处理越界的情况）。</p><pre><code class="go">func StringSliceEqualBCE(a, b []string) bool {    if len(a) != len(b) {        return false    }    if (a == nil) != (b == nil) {        return false    }    b = b[:len(a)]    for i, v := range a {        if v != b[i] {            return false        }    }    return true}</code></pre><h2 id="14-字符串打印时，-v-和-v-的区别"><a href="#14-字符串打印时，-v-和-v-的区别" class="headerlink" title="14. 字符串打印时，%v 和 %+v 的区别"></a>14. 字符串打印时，%v 和 %+v 的区别</h2><p>答案<br>%v 和 %+v 都可以用来打印 struct 的值，区别在于 %v 仅打印各个字段的值，%+v 还会打印各个字段的名称。</p><pre><code class="go">type Stu struct {    Name string}func main() {    fmt.Printf("%v\n", Stu{"Tom"}) // {Tom}    fmt.Printf("%+v\n", Stu{"Tom"}) // {Name:Tom}}</code></pre><p>但如果结构体定义了 String() 方法，%v 和 %+v 都会调用 String() 覆盖默认值。</p><h2 id="15-Go-语言中如何表示枚举值-enums"><a href="#15-Go-语言中如何表示枚举值-enums" class="headerlink" title="15. Go 语言中如何表示枚举值(enums)"></a>15. Go 语言中如何表示枚举值(enums)</h2><p>答案<br>通常使用常量(const) 来表示枚举值。</p><pre><code class="go">type StuType int32const (    Type1 StuType = iota    Type2    Type3    Type4)func main() {    fmt.Println(Type1, Type2, Type3, Type4) // 0, 1, 2, 3}</code></pre><p>参考 What is an idiomatic way of representing enums in Go? - StackOverflow</p><h2 id="16-空-struct-的用途"><a href="#16-空-struct-的用途" class="headerlink" title="16. 空 struct{} 的用途"></a>16. 空 struct{} 的用途</h2><p>答案<br>使用空结构体 struct{} 可以节省内存，一般作为占位符使用，表明这里并不需要一个值。</p><pre><code class="go">fmt.Println(unsafe.Sizeof(struct{}{})) // 0</code></pre><p>比如使用 map 表示集合时，只关注 key，value 可以使用 struct{} 作为占位符。如果使用其他类型作为占位符，例如 int，bool，不仅浪费了内存，而且容易引起歧义。</p><pre><code class="go">type Set map[string]struct{}func main() {    set := make(Set)    for _, item := range []string{"A", "A", "B", "C"} {        set[item] = struct{}{}    }    fmt.Println(len(set)) // 3    if _, ok := set["A"]; ok {        fmt.Println("A exists") // A exists    }}</code></pre><p>再比如，使用信道(channel)控制并发时，我们只是需要一个信号，但并不需要传递值，这个时候，也可以使用 struct{} 代替。</p><pre><code class="go">func main() {    ch := make(chan struct{}, 1)    go func() {        &lt;-ch        // do something    }()    ch &lt;- struct{}{}    // ...}</code></pre><p>再比如，声明只包含方法的结构体。</p><pre><code class="go">type Lamp struct{}func (l Lamp) On() {        println("On")}func (l Lamp) Off() {        println("Off")}</code></pre><h1 id="二、Go-语言笔试面试题-实现原理"><a href="#二、Go-语言笔试面试题-实现原理" class="headerlink" title="二、Go 语言笔试面试题(实现原理)"></a>二、Go 语言笔试面试题(实现原理)</h1><h2 id="1-init-函数是什么时候执行的？"><a href="#1-init-函数是什么时候执行的？" class="headerlink" title="1. init() 函数是什么时候执行的？"></a>1. init() 函数是什么时候执行的？</h2><p>答案<br>init() 函数是 Go 程序初始化的一部分。Go 程序初始化先于 main 函数，由 runtime 初始化每个导入的包，初始化顺序不是按照从上到下的导入顺序，而是按照解析的依赖关系，没有依赖的包最先初始化。<br>每个包首先初始化包作用域的常量和变量（常量优先于变量），然后执行包的 init() 函数。同一个包，甚至是同一个源文件可以有多个 init() 函数。init() 函数没有入参和返回值，不能被其他函数调用，同一个包内多个 init() 函数的执行顺序不作保证。<br>一句话总结： import –&gt; const –&gt; var –&gt; init() –&gt; main()<br>示例：</p><pre><code class="go">package mainimport "fmt"func init()  {    fmt.Println("init1:", a)}func init()  {    fmt.Println("init2:", a)}var a = 10const b = 100func main() {    fmt.Println("main:", a)}// 执行结果// init1: 10// init2: 10// main: 10</code></pre><h2 id="2-Go-语言的局部变量分配在栈上还是堆上？"><a href="#2-Go-语言的局部变量分配在栈上还是堆上？" class="headerlink" title="2. Go 语言的局部变量分配在栈上还是堆上？"></a>2. Go 语言的局部变量分配在栈上还是堆上？</h2><p>答案<br>由编译器决定。Go 语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做逃逸分析(escape analysis)，当发现变量的作用域没有超出函数范围，就可以在栈上，反之则必须分配在堆上。</p><pre><code class="go">func foo() *int {    v := 11    return &amp;v}func main() {    m := foo()    println(*m) // 11}</code></pre><p>foo() 函数中，如果 v 分配在栈上，foo 函数返回时，&amp;v 就不存在了，但是这段函数是能够正常运行的。Go 编译器发现 v 的引用脱离了 foo 的作用域，会将其分配在堆上。因此，main 函数中仍能够正常访问该值。</p><h2 id="3-2-个-interface-可以比较吗？"><a href="#3-2-个-interface-可以比较吗？" class="headerlink" title="3. 2 个 interface 可以比较吗？"></a>3. 2 个 interface 可以比较吗？</h2><p>答案<br>Go 语言中，interface 的内部实现包含了 2 个字段，类型 T 和 值 V，interface 可以使用 == 或 != 比较。2 个 interface 相等有以下 2 种情况<br>两个 interface 均等于 nil（此时 V 和 T 都处于 unset 状态）<br>类型 T 相同，且对应的值 V 相等。<br>看下面的例子：</p><pre><code class="go">type Stu struct {    Name string}type StuInt interface{}func main() {    var stu1, stu2 StuInt = &amp;Stu{"Tom"}, &amp;Stu{"Tom"}    var stu3, stu4 StuInt = Stu{"Tom"}, Stu{"Tom"}    fmt.Println(stu1 == stu2) // false    fmt.Println(stu3 == stu4) // true}</code></pre><p>stu1 和 stu2 对应的类型是 *Stu，值是 Stu 结构体的地址，两个地址不同，因此结果为 false。<br>stu3 和 stu4 对应的类型是 Stu，值是 Stu 结构体，且各字段相等，因此结果为 true。</p><h2 id="4-两个-nil-可能不相等吗？"><a href="#4-两个-nil-可能不相等吗？" class="headerlink" title="4. 两个 nil 可能不相等吗？"></a>4. 两个 nil 可能不相等吗？</h2><p>答案<br>可能。<br>接口(interface) 是对非接口值(例如指针，struct等)的封装，内部实现包含 2 个字段，类型 T 和 值 V。一个接口等于 nil，当且仅当 T 和 V 处于 unset 状态（T=nil，V is unset）。<br>两个接口值比较时，会先比较 T，再比较 V。<br>接口值与非接口值比较时，会先将非接口值尝试转换为接口值，再比较。</p><pre><code class="go">func main() {    var p *int = nil    var i interface{} = p    fmt.Println(i == p) // true    fmt.Println(p == nil) // true    fmt.Println(i == nil) // false}</code></pre><p>上面这个例子中，将一个 nil 非接口值 p 赋值给接口 i，此时，i 的内部字段为(T=*int, V=nil)，i 与 p 作比较时，将 p 转换为接口后再比较，因此 i == p，p 与 nil 比较，直接比较值，所以 p == nil。<br>但是当 i 与 nil 比较时，会将 nil 转换为接口 (T=nil, V=nil)，与i (T=*int, V=nil) 不相等，因此 i != nil。因此 V 为 nil ，但 T 不为 nil 的接口不等于 nil。</p><h2 id="5-简述-Go-语言GC-垃圾回收-的工作原理"><a href="#5-简述-Go-语言GC-垃圾回收-的工作原理" class="headerlink" title="5. 简述 Go 语言GC(垃圾回收)的工作原理"></a>5. 简述 Go 语言GC(垃圾回收)的工作原理</h2><p>答案<br>最常见的垃圾回收算法有标记清除(Mark-Sweep) 和引用计数(Reference Count)，Go 语言采用的是标记清除算法。并在此基础上使用了三色标记法和写屏障技术，提高了效率。<br>标记清除收集器是跟踪式垃圾收集器，其执行过程可以分成标记（Mark）和清除（Sweep）两个阶段：<br>标记阶段 — 从根对象出发查找并标记堆中所有存活的对象；<br>清除阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表。<br>标记清除算法的一大问题是在标记期间，需要暂停程序（Stop the world，STW），标记结束之后，用户程序才可以继续执行。为了能够异步执行，减少 STW 的时间，Go 语言采用了三色标记法。<br>三色标记算法将程序中的对象分成白色、黑色和灰色三类。<br>白色：不确定对象。<br>灰色：存活对象，子对象待处理。<br>黑色：存活对象。<br>标记开始时，所有对象加入白色集合（这一步需 STW ）。首先将根对象标记为灰色，加入灰色集合，垃圾搜集器取出一个灰色对象，将其标记为黑色，并将其指向的对象标记为灰色，加入灰色集合。重复这个过程，直到灰色集合为空为止，标记阶段结束。那么白色对象即可需要清理的对象，而黑色对象均为根可达的对象，不能被清理。<br>三色标记法因为多了一个白色的状态来存放不确定对象，所以后续的标记阶段可以并发地执行。当然并发执行的代价是可能会造成一些遗漏，因为那些早先被标记为黑色的对象可能目前已经是不可达的了。所以三色标记法是一个 false negative（假阴性）的算法。<br>三色标记法并发执行仍存在一个问题，即在 GC 过程中，对象指针发生了改变。比如下面的例子：</p><pre><code>A (黑) -&gt; B (灰) -&gt; C (白) -&gt; D (白)</code></pre><p>正常情况下，D 对象最终会被标记为黑色，不应被回收。但在标记和用户程序并发执行过程中，用户程序删除了 C 对 D 的引用，而 A 获得了 D 的引用。标记继续进行，D 就没有机会被标记为黑色了（A 已经处理过，这一轮不会再被处理）。</p><pre><code>A (黑) -&gt; B (灰) -&gt; C (白)   ↓ D (白)</code></pre><p>为了解决这个问题，Go 使用了内存屏障技术，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，类似于一个钩子。垃圾收集器使用了写屏障（Write Barrier）技术，当对象新增或更新时，会将其着色为灰色。这样即使与用户程序并发执行，对象的引用发生改变时，垃圾收集器也能正确处理了。<br>一次完整的 GC 分为四个阶段：<br>1）标记准备(Mark Setup，需 STW)，打开写屏障(Write Barrier)<br>2）使用三色标记法标记（Marking, 并发）<br>3）标记结束(Mark Termination，需 STW)，关闭写屏障。<br>4）清理(Sweeping, 并发)<br>参考 fullstack</p><h2 id="6-函数返回局部变量的指针是否安全？"><a href="#6-函数返回局部变量的指针是否安全？" class="headerlink" title="6. 函数返回局部变量的指针是否安全？"></a>6. 函数返回局部变量的指针是否安全？</h2><p>答案<br>这在 Go 中是安全的，Go 编译器将会对每个局部变量进行逃逸分析。如果发现局部变量的作用域超出该函数，则不会将内存分配在栈上，而是分配在堆上。</p><h2 id="7-非接口非接口的任意类型-T-都能够调用-T-的方法吗？反过来呢？"><a href="#7-非接口非接口的任意类型-T-都能够调用-T-的方法吗？反过来呢？" class="headerlink" title="7. 非接口非接口的任意类型 T() 都能够调用 *T 的方法吗？反过来呢？"></a>7. 非接口非接口的任意类型 T() 都能够调用 *T 的方法吗？反过来呢？</h2><p>答案<br>一个T类型的值可以调用为<em>T类型声明的方法，但是仅当此T的值是可寻址(addressable) 的情况下。编译器在调用指针属主方法前，会自动取此T值的地址。因为不是任何T值都是可寻址的，所以并非任何T值都能够调用为类型</em>T声明的方法。<br>反过来，一个<em>T类型的值可以调用为类型T声明的方法，这是因为解引用指针总是合法的。事实上，你可以认为对于每一个为类型 T 声明的方法，编译器都会为类型</em>T自动隐式声明一个同名和同签名的方法。<br>哪些值是不可寻址的呢？<br>字符串中的字节；<br>map 对象中的元素（slice 对象中的元素是可寻址的，slice的底层是数组）；<br>常量；<br>包级别的函数等。<br>举一个例子，定义类型 T，并为类型 *T 声明一个方法 hello()，变量 t1 可以调用该方法，但是常量 t2 调用该方法时，会产生编译错误。</p><pre><code class="go">type T stringfunc (t *T) hello() {    fmt.Println("hello")}func main() {    var t1 T = "ABC"    t1.hello() // hello    const t2 T = "ABC"    t2.hello() // error: cannot call pointer method on t}</code></pre><h1 id="三、Go-语言笔试面试题-并发编程"><a href="#三、Go-语言笔试面试题-并发编程" class="headerlink" title="三、Go 语言笔试面试题(并发编程)"></a>三、Go 语言笔试面试题(并发编程)</h1><h2 id="1-无缓冲的-channel-和-有缓冲的-channel-的区别？"><a href="#1-无缓冲的-channel-和-有缓冲的-channel-的区别？" class="headerlink" title="1. 无缓冲的 channel 和 有缓冲的 channel 的区别？"></a>1. 无缓冲的 channel 和 有缓冲的 channel 的区别？</h2><p>答案<br>对于无缓冲的 channel，发送方将阻塞该信道，直到接收方从该信道接收到数据为止，而接收方也将阻塞该信道，直到发送方将数据发送到该信道中为止。<br>对于有缓存的 channel，发送方在没有空插槽（缓冲区使用完）的情况下阻塞，而接收方在信道为空的情况下阻塞。<br>例如:</p><pre><code class="go">func main() {    st := time.Now()    ch := make(chan bool)    go func ()  {        time.Sleep(time.Second * 2)        &lt;-ch    }()    ch &lt;- true  // 无缓冲，发送方阻塞直到接收方接收到数据。    fmt.Printf("cost %.1f s\n", time.Now().Sub(st).Seconds())    time.Sleep(time.Second * 5)}</code></pre><pre><code class="go">func main() {    st := time.Now()    ch := make(chan bool, 2)    go func ()  {        time.Sleep(time.Second * 2)        &lt;-ch    }()    ch &lt;- true    ch &lt;- true // 缓冲区为 2，发送方不阻塞，继续往下执行    fmt.Printf("cost %.1f s\n", time.Now().Sub(st).Seconds()) // cost 0.0 s    ch &lt;- true // 缓冲区使用完，发送方阻塞，2s 后接收方接收到数据，释放一个插槽，继续往下执行    fmt.Printf("cost %.1f s\n", time.Now().Sub(st).Seconds()) // cost 2.0 s    time.Sleep(time.Second * 5)}</code></pre><h2 id="2-什么是协程泄露-Goroutine-Leak-？"><a href="#2-什么是协程泄露-Goroutine-Leak-？" class="headerlink" title="2. 什么是协程泄露(Goroutine Leak)？"></a>2. 什么是协程泄露(Goroutine Leak)？</h2><p>答案<br>协程泄露是指协程创建后，长时间得不到释放，并且还在不断地创建新的协程，最终导致内存耗尽，程序崩溃。常见的导致协程泄露的场景有以下几种：<br>缺少接收器，导致发送阻塞<br>这个例子中，每执行一次 query，则启动1000个协程向信道 ch 发送数字 0，但只接收了一次，导致 999 个协程被阻塞，不能退出。</p><pre><code class="go">func query() int {    ch := make(chan int)    for i := 0; i &lt; 1000; i++ {        go func() { ch &lt;- 0 }()    }    return &lt;-ch}func main() {    for i := 0; i &lt; 4; i++ {        query()        fmt.Printf("goroutines: %d\n", runtime.NumGoroutine())    }}// goroutines: 1001// goroutines: 2000// goroutines: 2999// goroutines: 3998</code></pre><p>缺少发送器，导致接收阻塞<br>那同样的，如果启动 1000 个协程接收信道的信息，但信道并不会发送那么多次的信息，也会导致接收协程被阻塞，不能退出。<br>死锁(dead lock)<br>两个或两个以上的协程在执行过程中，由于竞争资源或者由于彼此通信而造成阻塞，这种情况下，也会导致协程被阻塞，不能退出。<br>无限循环(infinite loops)<br>这个例子中，为了避免网络等问题，采用了无限重试的方式，发送 HTTP 请求，直到获取到数据。那如果 HTTP 服务宕机，永远不可达，导致协程不能退出，发生泄漏。</p><pre><code class="go">func request(url string, wg *sync.WaitGroup) {    i := 0    for {        if _, err := http.Get(url); err == nil {            // write to db            break        }        i++        if i &gt;= 3 {            break        }        time.Sleep(time.Second)    }    wg.Done()}func main() {    var wg sync.WaitGroup    for i := 0; i &lt; 1000; i++ {        wg.Add(1)        go request(fmt.Sprintf("https://127.0.0.1:8080/%d", i), &amp;wg)    }    wg.Wait()}</code></pre><h2 id="3-Go-可以限制运行时操作系统线程的数量吗？"><a href="#3-Go-可以限制运行时操作系统线程的数量吗？" class="headerlink" title="3. Go 可以限制运行时操作系统线程的数量吗？"></a>3. Go 可以限制运行时操作系统线程的数量吗？</h2><p>答案<br>The GOMAXPROCS variable limits the number of operating system threads that can execute user-level Go code simultaneously. There is no limit to the number of threads that can be blocked in system calls on behalf of Go code; those do not count against the GOMAXPROCS limit.<br>可以使用环境变量 GOMAXPROCS 或 runtime.GOMAXPROCS(num int) 设置，例如：</p><pre><code class="go">runtime.GOMAXPROCS(1) // 限制同时执行Go代码的操作系统线程数为 1</code></pre><p>从官方文档的解释可以看到，GOMAXPROCS 限制的是同时执行用户态 Go 代码的操作系统线程的数量，但是对于被系统调用阻塞的线程数量是没有限制的。GOMAXPROCS 的默认值等于 CPU 的逻辑核数，同一时间，一个核只能绑定一个线程，然后运行被调度的协程。因此对于 CPU 密集型的任务，若该值过大，例如设置为 CPU 逻辑核数的 2 倍，会增加线程切换的开销，降低性能。对于 I/O 密集型应用，适当地调大该值，可以提高 I/O 吞吐率。</p><h1 id="三、Go-语言笔试面试题-代码输出"><a href="#三、Go-语言笔试面试题-代码输出" class="headerlink" title="三、Go 语言笔试面试题(代码输出)"></a>三、Go 语言笔试面试题(代码输出)</h1><h2 id="1-常量与变量"><a href="#1-常量与变量" class="headerlink" title="1. 常量与变量"></a>1. 常量与变量</h2><h3 id="1-1-下列代码的输出是："><a href="#1-1-下列代码的输出是：" class="headerlink" title="1.1 下列代码的输出是："></a>1.1 下列代码的输出是：</h3><pre><code class="go">func main() {    const (        a, b = "golang", 100        d, e        f bool = true        g    )    fmt.Println(d, e, g)}</code></pre><p>答案<br>golang 100 true<br>在同一个 const group 中，如果常量定义与前一行的定义一致，则可以省略类型和值。编译时，会按照前一行的定义自动补全。即等价于</p><pre><code class="go">func main() {    const (        a, b = "golang", 100        d, e = "golang", 100        f bool = true        g bool = true    )    fmt.Println(d, e, g)}</code></pre><h3 id="1-2-下列代码的输出是："><a href="#1-2-下列代码的输出是：" class="headerlink" title="1.2 下列代码的输出是："></a>1.2 下列代码的输出是：</h3><pre><code class="go">func main() {    const N = 100    var x int = N    const M int32 = 100    var y int = M    fmt.Println(x, y)}</code></pre><p>答案<br>编译失败：cannot use M (type int32) as type int in assignment<br>Go 语言中，常量分为无类型常量和有类型常量两种，const N = 100，属于无类型常量，赋值给其他变量时，如果字面量能够转换为对应类型的变量，则赋值成功，例如，var x int = N。但是对于有类型的常量 const M int32 = 100，赋值给其他变量时，需要类型匹配才能成功，所以显示地类型转换：</p><pre><code class="go">var y int = int(M)</code></pre><h3 id="1-3-下列代码的输出是："><a href="#1-3-下列代码的输出是：" class="headerlink" title="1.3 下列代码的输出是："></a>1.3 下列代码的输出是：</h3><pre><code class="go">func main() {    var a int8 = -1    var b int8 = -128 / a    fmt.Println(b)}</code></pre><p>答案<br>-128<br>int8 能表示的数字的范围是 [-2^7, 2^7-1]，即 [-128, 127]。-128 是无类型常量，转换为 int8，再除以变量 -1，结果为 128，常量除以变量，结果是一个变量。变量转换时允许溢出，符号位变为1，转为补码后恰好等于 -128。<br>对于有符号整型，最高位是是符号位，计算机用补码表示负数。补码 = 原码取反加一。<br>例如：</p><pre><code>-1 :  1111111100000001(原码)    11111110(取反)    11111111(加一)-128：    10000000(原码)    01111111(取反)    10000000(加一)-1 + 1 = 011111111 + 00000001 = 00000000(最高位溢出省略)-128 + 127 = -110000000 + 01111111 = 11111111</code></pre><h3 id="1-4-下列代码的输出是："><a href="#1-4-下列代码的输出是：" class="headerlink" title="1.4 下列代码的输出是："></a>1.4 下列代码的输出是：</h3><pre><code class="go">func main() {    const a int8 = -1    var b int8 = -128 / a    fmt.Println(b)}</code></pre><p>答案<br>编译失败：constant 128 overflows int8<br>-128 和 a 都是常量，在编译时求值，-128 / a = 128，两个常量相除，结果也是一个常量，常量类型转换时不允许溢出，因而编译失败。</p><h2 id="2-作用域"><a href="#2-作用域" class="headerlink" title="2. 作用域"></a>2. 作用域</h2><h3 id="2-1-下列代码的输出是："><a href="#2-1-下列代码的输出是：" class="headerlink" title="2.1 下列代码的输出是："></a>2.1 下列代码的输出是：</h3><pre><code class="go">func main() {    var err error    if err == nil {        err := fmt.Errorf("err")        fmt.Println(1, err)    }    if err != nil {        fmt.Println(2, err)    }}</code></pre><p>答案<br>1 err<br>:= 表示声明并赋值，= 表示仅赋值。<br>变量的作用域是大括号，因此在第一个 if 语句 if err == nil 内部重新声明且赋值了与外部变量同名的局部变量 err。对该局部变量的赋值不会影响到外部的 err。因此第二个 if 语句 if err != nil 不成立。所以只打印了 1 err。</p><h2 id="3-defer-延迟调用"><a href="#3-defer-延迟调用" class="headerlink" title="3. defer 延迟调用"></a>3. defer 延迟调用</h2><h3 id="3-1-下列代码的输出是："><a href="#3-1-下列代码的输出是：" class="headerlink" title="3.1 下列代码的输出是："></a>3.1 下列代码的输出是：</h3><pre><code class="go">type T struct{}func (t T) f(n int) T {    fmt.Print(n)    return t}func main() {    var t T    defer t.f(1).f(2)    fmt.Print(3)}</code></pre><p>答案<br>132<br>defer 延迟调用时，需要保存函数指针和参数，因此链式调用的情况下，除了最后一个函数/方法外的函数/方法都会在调用时直接执行。也就是说 t.f(1) 直接执行，然后执行 fmt.Print(3)，最后函数返回时再执行 .f(2)，因此输出是 132。</p><h3 id="3-2-下列代码的输出是："><a href="#3-2-下列代码的输出是：" class="headerlink" title="3.2 下列代码的输出是："></a>3.2 下列代码的输出是：</h3><pre><code class="go">func f(n int) {    defer fmt.Println(n)    n += 100}func main() {    f(1)}</code></pre><p>答案<br>1<br>打印 1 而不是 101。defer 语句执行时，会将需要延迟调用的函数和参数保存起来，也就是说，执行到 defer 时，参数 n(此时等于1) 已经被保存了。因此后面对 n 的改动并不会影响延迟函数调用的结果。</p><h3 id="3-3-下列代码的输出是："><a href="#3-3-下列代码的输出是：" class="headerlink" title="3.3 下列代码的输出是："></a>3.3 下列代码的输出是：</h3><pre><code class="go">func main() {    n := 1    defer func() {        fmt.Println(n)    }()    n += 100}</code></pre><p>答案<br>101<br>匿名函数没有通过传参的方式将 n 传入，因此匿名函数内的 n 和函数外部的 n 是同一个，延迟执行时，已经被改变为 101。</p><h3 id="3-4-下列代码的输出是："><a href="#3-4-下列代码的输出是：" class="headerlink" title="3.4 下列代码的输出是："></a>3.4 下列代码的输出是：</h3><pre><code class="go">func main() {    n := 1    if n == 1 {        defer fmt.Println(n)        n += 100    }    fmt.Println(n)}</code></pre><p>答案<br>1<br>2<br>101<br>1<br>先打印 101，再打印 1。defer 的作用域是函数，而不是代码块，因此 if 语句退出时，defer 不会执行，而是等 101 打印后，整个函数返回时，才会执行。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> 面试题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文下载</title>
      <link href="/2022/01/12/other/%E8%AE%BA%E6%96%87%E4%B8%8B%E8%BD%BD/"/>
      <url>/2022/01/12/other/%E8%AE%BA%E6%96%87%E4%B8%8B%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<ol><li><a href="https://www.scidown.cn/">scidown</a></li><li><a href="https://doi.qqsci.com/">企鹅论文</a></li><li><a href="https://tool.yovisun.com/scihub/">sci-hub</a></li><li><a href="http://www.5638.org/">科研宝库</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Other </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文翻译</title>
      <link href="/2022/01/12/other/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"/>
      <url>/2022/01/12/other/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/</url>
      
        <content type="html"><![CDATA[<ol><li><a href="https://www.onlinedoctranslator.com/">DocTranslator</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Other </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>共识算法</title>
      <link href="/2022/01/08/blockchain/consensus/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/"/>
      <url>/2022/01/08/blockchain/consensus/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h1><ol><li>拜占庭将军问题概述</li><li>共识算法定义(作用)</li><li>共识算法种类</li><li>共识算法优缺点对比以及应用</li></ol><h1 id="拜占庭将军问题"><a href="#拜占庭将军问题" class="headerlink" title="拜占庭将军问题"></a>拜占庭将军问题</h1><p>莱斯利·兰波特在其论文中描述了如下问题：</p><blockquote><p>一组拜占庭将军分别各率领一支军队共同围困一座城市。为了简化问题，将各支军队的行动策略限定为进攻或撤离两种。因为部分军队进攻部分军队撤离可能会造成灾难性后果，因此各位将军必须通过投票来达成一致策略，即所有军队一起进攻或所有军队一起撤离。因为各位将军分处城市不同方向，他们只能通过信使互相联系。在投票过程中每位将军都将自己投票给进攻还是撤退的信息通过信使分别通知其他所有将军，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以知道共同的投票结果而决定行动策略。</p></blockquote><p>系统的问题在于，可能将军中出现叛徒，他们不仅可能向较为糟糕的策略投票，还可能选择性地发送投票信息。</p><p>上述的故事映射到计算机系统里便是：</p><p>在分布式系统中存在恶意的计算机节点，这些节点会选择性响应某些请求或篡改系统中的数据。 那么<font color="red">在上述不可靠的信道上，系统中所有非恶意节点如何通过消息传递达成共识？</font></p><h1 id="共识算法"><a href="#共识算法" class="headerlink" title="共识算法"></a>共识算法</h1><h2 id="定义-作用"><a href="#定义-作用" class="headerlink" title="定义(作用)"></a>定义(作用)</h2><p>共识算法<font color="red">使高度分散且彼此不信任的网络环境中的节点就某个事务达成一致且不分叉</font></p><p>按拜占庭容错性分类：</p><ol><li><p>容忍非拜占庭错误（CTF）：容忍网络环境中存在故障节点但不存在恶意节点</p></li><li><p>容忍拜占庭错误（BFT）：容忍网络环境中同时存在故障节点和恶意节点</p></li></ol><h2 id="算法需满足的条件"><a href="#算法需满足的条件" class="headerlink" title="算法需满足的条件"></a>算法需满足的条件</h2><p>FLP不可能问题：在异步网络中，哪怕只有一个节点故障也不可能存在能够容忍节点故障的一致性算法。</p><p>需满足的约束条件：</p><ol><li><strong>消息安全</strong>：节点件必须采用非对称加密对消息进行签名保证消息可传递（不可用对称加密，因为信道不安全）</li><li><strong>处理FLP不可能问题</strong>：设置消息最大时延</li><li><strong>共识结论合法</strong>：结论必须是一个节点的提案</li></ol><h2 id="算法详情"><a href="#算法详情" class="headerlink" title="算法详情"></a>算法详情</h2><h3 id="Paxos（CTF）"><a href="#Paxos（CTF）" class="headerlink" title="Paxos（CTF）"></a>Paxos（CTF）</h3><ol><li><p>概念</p><p>Paxos原理基于<font color="red">“两阶段提交”</font>算法并进行泛化和扩展，通过消息传递来逐步消除系统中的不确定状态，是Raft、ZAB设计的基础</p><p>Paxos角色：</p><ul><li><strong>提案者（Proposer）</strong>：提出一个提案等待大家批准为结案（value）</li><li><strong>接受者（Acceptor）</strong>：对提案进行投票，接受提案</li><li><strong>学习者（Learner）</strong>：获取批准结果，不参与投票</li></ul></li><li><p>共识过程</p><p><img src="/images/consensus/paxos_flow_chart.png" alt="img.png"><br>pok：收到提议请求； aok：收到提交请求；最大提案编号：MaxN；AcceptN：接收到的提案编号； AcceptV：接收到的提案值；</p></li><li><p>举例说明 假设集群中有2个Proposer、3个Acceptor、1个Learner</p><ul><li>有两个Proposer，两个都提出 prepare request。来自 Proposer A的 request 先于Proposer B 的 request 到达 Acceptor X和 Acceptor Y， 但来自Proposer B的 request 首先到达 Proposer Z.<br><img src="/images/consensus/paxos_prepare1.png" alt="img.png"></li><li>如果接收（accept）prepare request 的 Acceptor 之前没有看到其他的提议，则 Acceptor 以 prepare response 作出响应， 该 prepare response承诺永远不接受具有较低提议编号的另一提议。<br><img src="/images/consensus/paxos_prepare2.png" alt="img.png"></li><li>Acceptor Z收到了 Proposer A 的 request ，Acceptor X和 Acceptor Y收到了 Proposer B的 request 。 如果 Proposer 之前已经看到具有更高提议号的request ，则忽略晚到的 request，如Acceptor Z将忽略 Proposer A的 request（因为2&lt;4）。 如果 Proposer 之前没有看到更高编号的 request，它再次承诺忽略具有较低提议编号的任何请求，并发回其已接受的编号最高的提议以及该提议的值。 如 Acceptor X和Y 对Proposer B的 request 的做法。<br><img src="/images/consensus/paxos_prepare3.png" alt="img.png"></li><li>一旦 Proposer 收到大多数 Acceptor 的准备响应，它就可以发出接受请求<ul><li>对于Proposer A：由于 Proposer A仅收到表明没有先前提案的答复， 因此它向每个具有与其初始提案相同的提议编号和值的 Acceptor 发送 accept request（n = 2，v = 8）。然而，这些 request 都将被忽略，因为目标 Acceptor 都承诺不接受的提议编号低于4 的 request（这是对 Proposer B 的承诺）</li><li>对于Proposer B：Proposer B 向每个 Acceptor 发送 accept request ， 该 request 包含先前使用的提议号（n = 4）以及与其接收的准备响应消息中的最高提议号相关联的值（v = 8）。 请注意，这不是 Proposer B 最初提出的值，而是它看到的 prepare response 消息中的最高值。<br><img src="/images/consensus/paxos_accept1.png" alt="img.png"></li></ul></li><li>如果 Acceptor accept 的 accept request 的 编号 比其已经看到的更高或相等，则它会 accept 并向每个 Learner 节点发送通知。 当 Learner 发现大多数 Acceptor已接受某个值时，Paxos算法会选择该值<br><img src="/images/consensus/paxos_sync1.png" alt="img.png"></li><li>一旦Paxos选择了一个值，与其他 Proposer 的进一步沟通就无法改变这个值。 如果另一个 Proposer（如 Proposer C）发送的 request 的 提案号比之前看到的提案号更高，并且具有不同的值（例如，n= 6，v = 7）， 则每个接受者都会使用之前的最高提案进行响应（n = 4，v = 8）。这要求提议者C发送包含[n = 6，v = 8] 的接受请求，该请求仅确认已经选择的值。此外，如果一些少数接受者还没有选择一个价值，这个过程可以确保他们最终就同一价值达成共识。 （批注，这个过程总是成立的，具体论证过程见上）</li></ul></li></ol><h3 id="Raft（CTF）"><a href="#Raft（CTF）" class="headerlink" title="Raft（CTF）"></a>Raft（CTF）</h3><ol><li><p>概念</p><p>Raft相比Paxos是一种旨在<font color="red">易于理解</font>的共识算法。</p><p>Raft角色：</p><ul><li><strong>领导者（Leader）</strong></li><li><strong>候选领导者（Candidate）</strong></li><li><strong>跟随者（Follower）</strong></li></ul></li><li><p>共识过程</p><p><a href="http://www.kailing.pub/raft/index.html">Raft演示地址</a></p><p>主要阶段：</p><ul><li><strong>Leader选举</strong></li><li><strong>同步日志</strong></li></ul></li></ol><h3 id="PoW（BFT）"><a href="#PoW（BFT）" class="headerlink" title="PoW（BFT）"></a>PoW（BFT）</h3><ol><li><p>概念</p><p>POW <font color="red">工作量证明共识机制</font>，系统通过让所有节点公平地去计算一个随机数，最先寻找到随机数的节点即拥有记账权</p></li><li><p>比特币共识过程</p><ul><li>客户端发起交易广播到网络中等待确认</li><li>网络中的用户将所有等待确认的交易打包到一个区块链中</li><li><strong>不断修改区块头中的Nonce值以使该区块头的hash值小于一个特定的目标值</strong></li><li>计算出Nonce后向全网广播</li><li>网络中收到提案区块的节点对Nonce进行验证，验证合法交易被确认，该块加入链</li></ul></li></ol><h3 id="PoS（BFT）"><a href="#PoS（BFT）" class="headerlink" title="PoS（BFT）"></a>PoS（BFT）</h3><p>权益证明机制，是为解决PoW算法大量浪费资源问题而提出的一种替代算法，该算法中区块的记账权<font color="red">由权益最高的节点获得</font></p><h3 id="DPoS（BFT）"><a href="#DPoS（BFT）" class="headerlink" title="DPoS（BFT）"></a>DPoS（BFT）</h3><ol><li><p>概念</p><p>股份授权证明机制，是PoS的一种衍生算法，算法的思想是<font color="red">系统中持有权益的节点投票选举出一部分代表，再由这些代表轮流获取区块链记账权</font>，类似于股份制公司的“董事会”</p></li><li><p>共识过程</p><ul><li>每个节点将自己持有的权益转换为选票投给自己信任的节点</li><li>选票最多的N个节点当选为见证人（Witness），即代表</li><li>见证人在一个规定时间内随机排列并轮流对交易打包，生成新区块连接到最长链，见证人收获m％的交易手续费</li></ul></li></ol><h3 id="PBFT（BFT）"><a href="#PBFT（BFT）" class="headerlink" title="PBFT（BFT）"></a>PBFT（BFT）</h3><ol><li><p>概念</p><p><font color="red">PBFT在保证可用性和安全性的前提下，提供了(n-1)/3的容错性</font>，意思就是如果系统内有n个节点，那么系统最多能容忍的作恶/故障节点为(n-1)/3个。（作恶节点可以不响应或者回应错误的信息）</p></li><li><p>共识过程</p><p>​    <img src="/images/consensus/pbft_flow_chart.png" alt="共识算法系列：PBFT算法关键点综述、优缺点总结"></p><p>定义：</p><ul><li><p>f：恶意节点</p></li><li><p>Digest(m)：消息摘要</p></li></ul><p>过程：</p><ul><li><strong>预准备阶段</strong>：发送原本的消息m，让每个节点都获取原始消息</li><li><strong>准备阶段</strong>：用Digest(m)去发送，如果一个节点收到<strong>2f+1</strong>个prepare消息，就认为准备阶段结束，说明已经有大部分节点认同了这个m</li><li><strong>提交阶段</strong>：用Digest(m)去发送，如果一个节点收到<strong>2f+1</strong>个commit，那么就可以认为，就说明已经有大多数节点“执行”了这些m，这个阶段主要是为了View Change服务</li><li><strong>回执阶段</strong>：提交结束后将结果返回给客户端，客户端收到至少<strong>f+1</strong>个消息即可确认</li></ul></li></ol><h3 id="DBFT（BFT）"><a href="#DBFT（BFT）" class="headerlink" title="DBFT（BFT）"></a>DBFT（BFT）</h3><ol><li><p>概念</p><p>授权拜占庭容错，系统中的代币持有者<font color="red">通过投票选举出自己所支持的共识节点，这些选出来的共识节点再通过BFT来达成共识并生成区块</font></p></li><li><p>共识过程</p><p><img src="/images/consensus/dbft_flow_chart.png" alt="image-20220108234438067"></p><p>过程：</p><ul><li>节点<strong>投票</strong>选出一定数量的共识节点</li><li>议长设置视图并广播提案<code>&lt;PrepareRequest&gt;</code>消息</li><li>议员收到提案对其验证，验证通过后议员向全网发送<code>&lt;PrepareResponse&gt;</code>消息</li><li>当收到n-f条<code>&lt;PrepareResponse&gt;</code>消息时，议员们发布一个新的区块，对区块签名，发送给其他节点进行同步<code>&lt;Synchronization&gt;</code></li><li>其他节点收到完整区块后达到相同的区块高度，清除本地内存中所存储的当前视图交易数据，准备下一次共识</li></ul></li></ol><h2 id="算法优缺点与应用"><a href="#算法优缺点与应用" class="headerlink" title="算法优缺点与应用"></a>算法优缺点与应用</h2><table><thead><tr><th>算法</th><th>优点</th><th>缺点</th><th>应用</th></tr></thead><tbody><tr><td>Paxos</td><td>- 容忍非拜占庭错误节点能力高<br>- 性能高</td><td>- 算法难以理解<br>- 不能容忍拜占庭错误节点</td><td>ZooKeeper、GoogleChubby</td></tr><tr><td>Raft</td><td>- 算法容忍非拜占庭错误节点能力高<br>- 性能高<br>- 易于理解和实现</td><td>- 不能容忍拜占庭错误节点</td><td>IPFS Private Cluster、R3 CodaQuorum</td></tr><tr><td>Pow</td><td>- 算法逻辑简单<br>- 安全性高<br>- 容错性高</td><td>- 资源消耗过高<br>- 系统吞吐量低</td><td>Bitcoin、Ethereum、Dogcoin、Litecoin、Zcash</td></tr><tr><td>PoS</td><td>- 缓解PoW资源浪费问题<br>- 相对PoW提高了出块速度</td><td>- 易出现持币人屯币现象，造成寡头优势</td><td>Blackcoin、ADA、Peercoin、Casper、Nxt</td></tr><tr><td>DPoS</td><td>- 解决了PoW资源浪费问题<br>- 性能较高<br>- 出块速度较快</td><td>- 相比其他算法该算法趋于中心化<br>- 投票无门槛，权益余额大票数越大，易造成联合选举行为</td><td>EOS、Bitshares、Steemit、Lisk、Ark、GXChain、ASCH</td></tr><tr><td>PBFT</td><td>- 无代币<br>- 性能效率高<br>- 安全性高</td><td>- 确认流程过多，通信开销大<br>- 无法避免恶意节点担任主节点<br>- 节点不可进行动态增删<br>- 无法承受大规模节点</td><td>Fabric</td></tr><tr><td>DBFT</td><td>- 借鉴DPoS，参与共识节点数量较少，因此提高了性能</td><td>- 相比其他算法该算法趋于中心化</td><td>NEO</td></tr></tbody></table><h1 id="引发思考"><a href="#引发思考" class="headerlink" title="引发思考"></a>引发思考</h1><ol><li><p>PBFT在节点数超过100后性能继续下降，如何缓解？</p><ul><li><p>方法一：带宽优化：</p><ul><li>客户端将请求发给任意节点，而不是只发给主节点，然后节点直接将请求广播给所有节点</li><li>设计共享交易池，预先进行交易的广播，仅共识交易哈希值主节点打包交易hash，广播包含hash的提案消息，而不是广播交易数据</li><li>从节点在提交之前主动向主节点获取可能缺失的交易，最终提交之前确认交易合法性</li></ul><p><img src="/images/consensus/pbft_bandwidth_optimization.png" alt="image-20220109102820146"></p></li><li><p>方法二：BFT问题转换成CFT问题，即规避拜占庭行为</p><p><img src="/images/consensus/fast_bft_flow_chart.png" alt="image-20220109104150146"></p></li><li><p>方法三：点对点网络转换为星型网络</p><p><img src="/images/consensus/hot_stuff_flow_chart.png" alt="image-20220109104400275"></p></li></ul></li><li><p>PBFT无法动态增删节点，如何解决？</p><p>先请求分布式CA，再通过配置交易的方式，准入与删除共识节点</p><p><img src="/images/consensus/pbft_add_delete_node.png" alt="image-20220109103818671"></p></li><li><p>PBFT中prepare和commit阶段为何都要2f+1个节点反馈确认?（这2f+1节点反馈的结果并不一定是相同的）</p><p>对于prepare和commit来说，节点需要在2f+1个状态复制机的沟通内就要做出决定，这是刚好可以保证一致性的，考虑最坏的情况：我们假设收到的有f个是正常节点发过来的，也有f个是恶意节点发过来的，那么，第2f+1个只可能是正常节点发过来的。（因为我们限制了最多只有f个恶意节点）由此可知，“大多数”正常的节点还是可以让系统工作下去的。所以2f+1这个参数和n&gt;3f+1的要求是逻辑自洽的。</p></li><li><p>PBFT中client为何只需要f+1个相同的回复就可确认？</p><p>之前我们说，prepare和commit阶段为何都要2f+1个节点反馈，才能确认。client只需要f+1个相同的reply就可以了呢？我们还是来考虑最坏的情况，我们假设这f+1个相同的reply中，有f个都是恶意节点。</p><p>所以至少有一个rely是正常节点发出来的，因为在prepare阶段，这个正常的节点已经可以保证prepared(m,v,n,i)为真，所以已经能代表大多数的意见，所以，client只需要f+1个相同的reply就能保证他拿到的是整个系统内“大多数正常节点“的意见，从而达到一致性。</p></li><li><p>PBFT中如果primary是恶意节点呢？</p><p>对于一致性，我们可以这么看：如果prepared(m，v，n，i)为真，那么prepared(m’，v，n，j)一定是错误的，因为对于同一个提案我们不可能有两种结果，从而保证整个系统的一致性。</p><p>假设primary节点是恶意的，那么意味着在replicas节点中⾄多有f-1个恶意的节点，prepared(m，v，n，i)为真，则证明有f+1个善意节点达成了了⼀致，prepared(m’，v，n，j)为真，意味着另外f+1个善意节点达成了一致，因为系统中只有2f+1个善意节点，因此最少有⼀个善意节点发送了两个冲突的prepare消息，这是不可能的。所以prepared(m，v，n，i)为真，那么prepared(m’，v，n，j)是错误的。</p></li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://b23.tv/c2IGPiA">李永乐老师讲解拜占庭将军问题</a></li><li><a href="https://zh.wikipedia.org/wiki/%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E9%97%AE%E9%A2%98">维基百科对拜占庭将军问题的解释</a></li><li><a href="https://blog.csdn.net/alinyua/article/details/86153013">Paxos学习笔记及图解</a></li><li><a href="https://pmg.csail.mit.edu/papers/osdi99.pdf">PBFT提出者论文《Practical Byzantine Fault Tolerance》</a></li><li><a href="https://zhuanlan.zhihu.com/p/53897982">共识算法系列：PBFT算法关键点综述、优缺点总结</a></li><li><a href="http://www.jsjkx.com/CN/article/openArticlePDF.jsp?id=19169">区块链共识算法对比研究</a></li><li><a href="https://www.modb.pro/doc/42136">联盟区块链共识算法的实践与挑战 - 端豪 杭州趣链科技架构师</a></li><li><a href="http://lamport.azurewebsites.net/pubs/paxos-simple.pdf">Paxos论文</a></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 共识算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fabric区块链应用开发</title>
      <link href="/2021/10/26/blockchain/fabric/%E7%AC%AC13%E7%AB%A0-%E5%8C%BA%E5%9D%97%E9%93%BE%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/"/>
      <url>/2021/10/26/blockchain/fabric/%E7%AC%AC13%E7%AB%A0-%E5%8C%BA%E5%9D%97%E9%93%BE%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<h1 id="Fabric区块链应用开发"><a href="#Fabric区块链应用开发" class="headerlink" title="Fabric区块链应用开发"></a>Fabric区块链应用开发</h1><h2 id="13-1-简介"><a href="#13-1-简介" class="headerlink" title="13.1 简介"></a>13.1 简介</h2><p>智能合约是无状态的、事件驱动的代码</p><h3 id="1-智能合约开发"><a href="#1-智能合约开发" class="headerlink" title="1. 智能合约开发"></a>1. 智能合约开发</h3><p>智能合约代码本质上是为了对上层业务逻辑进行支持</p><p>需要开发者具备的能力：</p><ul><li>了解所选用区块链平台的智能合约结构、语言特性、状态存储方式等知识</li><li>对智能合约的生命周期管理进行考虑，包括代码编写、版本管理、提交验证以及升级版本</li></ul><h3 id="2-应用程序开发"><a href="#2-应用程序开发" class="headerlink" title="2. 应用程序开发"></a>2. 应用程序开发</h3><p>应用程序通过调用智能合约提供的方法接口来实现业务逻辑。可以运行在区块链的网络节点上，也可以运行在中心化的服务器上。</p><p>需要开发者具备的能力：</p><ul><li>掌握至少一种应用程序开发语言</li><li>熟练使用智能合约SDK</li></ul><h2 id="13-2-链码的原理、接口与结构"><a href="#13-2-链码的原理、接口与结构" class="headerlink" title="13.2 链码的原理、接口与结构"></a>13.2 链码的原理、接口与结构</h2><p>链码职责：</p><ul><li>对Fabric应用程序发送的交易做出响应，执行代码逻辑，与账本进行交互</li><li>创建一些状态（state）并写入账本</li></ul><p>链码与节点的交互使用gRPC协议</p><h3 id="13-2-1-Chaincode接口"><a href="#13-2-1-Chaincode接口" class="headerlink" title="13.2.1 Chaincode接口"></a>13.2.1 Chaincode接口</h3><pre><code class="go">// Chaincode interface must be implemented by all chaincodes. The fabric runs// the transactions by calling these functions as specified.type Chaincode interface {    // Init is called during Instantiate transaction after the chaincode container    // has been established for the first time, allowing the chaincode to    // initialize its internal data    // 当链码收到实例化的交易时，Init方法会被调用（Fabric1.4版本）    Init(stub ChaincodeStubInterface) pb.Response    // Invoke is called to update or query the ledger in a proposal transaction.    // Updated state variables are not committed to the ledger until the    // transaction is committed.    // 当链码收到升级或查询类型的交易时，Invoke方法会被调用（Fabric1.4版本）    Invoke(stub ChaincodeStubInterface) pb.Response}</code></pre><h3 id="13-2-2-链码结构"><a href="#13-2-2-链码结构" class="headerlink" title="13.2.2 链码结构"></a>13.2.2 链码结构</h3><pre><code class="go">package main// 引入必要的包import (    "fmt"    // shim包提供了链码与账本交互的中间层。链码通过shim.ChaincodeStubInterface提供的方法来读取和修改账本状态    "github.com/hyperledger/fabric/core/chaincode/shim"    // Init和Invoke方法需要返回pb.Response类型    pb "github.com/hyperledger/fabric/protos/peer")// 声明一个结构体type SimpleChaincode struct {}// 为结构体添加Init方法func (t *SimpleChaincode) Init(stub shim.ChaincodeStubInterface) pb.Response {    // 该方法用来完成一些初始化的工作    return shim.Success(nil)}// 为结构体添加Invoke方法func (t *SimpleChaincode) Invoke(stub shim.ChaincodeStubInterface) pb.Response {    // 响应调用或查询的业务逻辑在该方法中实现    return shim.Success(nil)}// 主函数，需要调用shim.Start()方法func main() {    err := shim.Start(new(SimpleChaincode))    if err != nil {        fmt.Printf("Error starting Simple chaincode: %s", err)    }}</code></pre><h3 id="13-2-3-链码基本工作原理"><a href="#13-2-3-链码基本工作原理" class="headerlink" title="13.2.3 链码基本工作原理"></a>13.2.3 链码基本工作原理</h3><p><img src="https://img-blog.csdnimg.cn/2e6b5bf1c26e4f8396154f82fcbe29fe.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><p>步骤：</p><ul><li>用户通过客户端（SDK或CLI）向Fabric的背书节点（endorser）发出调用链码的交易提案（proposal）。节点对提案进行包括ACL权限检查在内的各种检验，通过后则创建模拟执行这一交易的环境</li><li>节点和链码容器之间通过gRPC消息来交互，模拟执行交易并给出背书结论</li></ul><h2 id="13-3-链码开发API"><a href="#13-3-链码开发API" class="headerlink" title="13.3 链码开发API"></a>13.3 链码开发API</h2><h3 id="13-3-1-账本状态交互API"><a href="#13-3-1-账本状态交互API" class="headerlink" title="13.3.1 账本状态交互API"></a>13.3.1 账本状态交互API</h3><p><img src="https://img-blog.csdnimg.cn/edd578638df647ce87034b4e1ae34133.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="13-3-2-交易信息相关API"><a href="#13-3-2-交易信息相关API" class="headerlink" title="13.3.2 交易信息相关API"></a>13.3.2 交易信息相关API</h3><p><img src="https://img-blog.csdnimg.cn/53fea4951f7f457d8f9175cc3935a3cc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="13-3-3-参数读取API"><a href="#13-3-3-参数读取API" class="headerlink" title="13.3.3 参数读取API"></a>13.3.3 参数读取API</h3><p><img src="https://img-blog.csdnimg.cn/e8c5d6e04792454dbeec1f4c3039cac7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="13-3-4-其他API"><a href="#13-3-4-其他API" class="headerlink" title="13.3.4 其他API"></a>13.3.4 其他API</h3><p><img src="https://img-blog.csdnimg.cn/dde665b33019483ba78615f5f0ec9b37.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="13-4-应用开发案例一：转账"><a href="#13-4-应用开发案例一：转账" class="headerlink" title="13.4 应用开发案例一：转账"></a>13.4 应用开发案例一：转账</h2><p>目标：</p><ul><li>掌握智能合约的基本结构</li><li>掌握查询账本、修改账本、删除账本的方法</li></ul><p><a href="https://gitee.com/hbuzzs/fabric-chaincode-example/blob/master/chaincode/src/github.com/1.chaincode_example02/chaincode_example02.go">查看代码</a></p><h2 id="13-5-应用开发案例二：资产权属管理"><a href="#13-5-应用开发案例二：资产权属管理" class="headerlink" title="13.5 应用开发案例二：资产权属管理"></a>13.5 应用开发案例二：资产权属管理</h2><p>目标：</p><ul><li>掌握资产的创建、查询、转移所有权等操作</li></ul><p><a href="https://gitee.com/hbuzzs/fabric-chaincode-example/blob/master/chaincode/src/github.com/2.marbles02/marbles_chaincode.go">查看代码</a></p><h2 id="13-6-应用开发案例三：调用其他链码"><a href="#13-6-应用开发案例三：调用其他链码" class="headerlink" title="13.6 应用开发案例三：调用其他链码"></a>13.6 应用开发案例三：调用其他链码</h2><p>目标：</p><ul><li>掌握如何调用其他链码<br><a href="https://gitee.com/hbuzzs/fabric-chaincode-example/blob/master/chaincode/src/github.com/3.passthru/passthru.go">查看代码</a></li></ul><h2 id="13-7-应用开发案例四：发送事件"><a href="#13-7-应用开发案例四：发送事件" class="headerlink" title="13.7 应用开发案例四：发送事件"></a>13.7 应用开发案例四：发送事件</h2><p>目标：</p><ul><li>掌握如何发送事件</li></ul><p><a href="https://gitee.com/hbuzzs/fabric-chaincode-example/blob/master/chaincode/src/github.com/4.eventsender/eventsender.go">查看代码</a></p><h2 id="13-8-开发最佳实践小结"><a href="#13-8-开发最佳实践小结" class="headerlink" title="13.8 开发最佳实践小结"></a>13.8 开发最佳实践小结</h2><ol><li>重视资源限制</li><li>无状态设计</li><li>避免非确定性逻辑</li><li>链码结构设计</li><li>链码生命周期的管理</li></ol><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li>《区块链原理、设计与应用-杨保华、陈昌》</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Fabric </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fabric CA应用与配置</title>
      <link href="/2021/10/18/blockchain/fabric/%E7%AC%AC11%E7%AB%A0-Fabric-CA%E5%BA%94%E7%94%A8%E4%B8%8E%E9%85%8D%E7%BD%AE/"/>
      <url>/2021/10/18/blockchain/fabric/%E7%AC%AC11%E7%AB%A0-Fabric-CA%E5%BA%94%E7%94%A8%E4%B8%8E%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="Fabric-CA应用与配置"><a href="#Fabric-CA应用与配置" class="headerlink" title="Fabric CA应用与配置"></a>Fabric CA应用与配置</h1><h2 id="11-1-简介"><a href="#11-1-简介" class="headerlink" title="11.1 简介"></a>11.1 简介</h2><ol><li>Fabric CA项目主要功能：</li></ol><ul><li>负责Fabric网络内所有实体的身份管理，包括身份的注册、注销等</li><li>负责证书管理，包括ECerts（身份证书）、TCerts（交易证书）等的发放和注销</li><li>服务端支持基于客户端命令行和RESTful API的交互方式</li></ul><ol start="2"><li>基本组件<br>采用典型的CS架构，目前包含两个基本组件：</li></ol><ul><li>服务端：fabric-ca-server实现核心的PKI服务功能，支持多种数据库后台（包括MySQL、PostgreSQL等），并支持集成LDAP作为用户注册管理功能</li><li>客户端（Client）：fabric-ca-client封装了服务端的RESTful API，提供访问服务端的命令，供用户与服务端进行交互</li></ul><h2 id="11-2-安装服务端和客户端"><a href="#11-2-安装服务端和客户端" class="headerlink" title="11.2 安装服务端和客户端"></a>11.2 安装服务端和客户端</h2><h3 id="11-2-1-本地编译"><a href="#11-2-1-本地编译" class="headerlink" title="11.2.1 本地编译"></a>11.2.1 本地编译</h3><ol><li>配置编译环境<br>基本依赖：</li></ol><ul><li>Golang 1.7+，并配置GOPATH环境变量</li><li>libtool和libltdl-dev依赖库</li></ul><ol start="2"><li>编译二进制文件</li></ol><h3 id="11-2-2-获取和使用Docker镜像（推荐）"><a href="#11-2-2-获取和使用Docker镜像（推荐）" class="headerlink" title="11.2.2 获取和使用Docker镜像（推荐）"></a>11.2.2 获取和使用Docker镜像（推荐）</h3><pre><code class="shell">docker pull hyperledger/fabric-ca：1.4.0</code></pre><p>快速进入容器，采用默认配置快速初始化并启动服务：</p><pre><code class="shell">docker run -it hyperledger/fabric-cafabric-ca-server init -b admin:adminpw</code></pre><ol><li>挂载本地配置文件<pre><code class="shell">docker run -it -v LOCAL_PATH:/etc/hyperledger/fabric-ca-server hyperledger/fabric-ca bash</code></pre></li><li>暴露RESTful服务<br>为了让其他物理机能访问到容器内的服务，可以将该端口映射到本地宿主机<br>例如下面命令将本地的7054端口与容器端口映射关联，之后其他物理机可以通过访问本地宿主机的7054端口来访问容器内服务：<pre><code class="shell">docker run -it -v LOCAL_PATH:/etc/hyperledger/fabric-ca-server -p 7054:7054 hyperledger/fabric-ca bash</code></pre></li></ol><h2 id="11-3-启动CA服务"><a href="#11-3-启动CA服务" class="headerlink" title="11.3 启动CA服务"></a>11.3 启动CA服务</h2><ol><li>配置读取<br>fabric-ca-server服务所需要的相关配置项会依次尝试从命令行参数、环境变量（命名需要带有<code>FABIRIC_CA_SERVER</code>前缀）或主配置目录（未指定配置文件路径时）下本地配置文件来读取。<br>例如指定启用TLS可以通过如下三种方式来进行配置，优先级由高到低：</li></ol><ul><li>命令行参数：<code>--tls-enabled=true</code></li><li>环境变量：<code>FABRIC_CA_SERVER_TLS_ENABLED=true</code></li><li>配置文件：<code>tls.enabled=true</code><br>如果都未发现，则采用内置的默认值（false）</li></ul><ol start="2"><li>主配置目录<br>本地配置文件默认都是从所谓主配置目录（Home Dir）下进行查找，还可以预置证书和密钥文件<br>主配置目录的具体路径获取规则：依此从环境变量<code>FABRIC_CA_SERVER_HOME</code>、<code>FABRIC_CA_HOME</code>、<code>CA_CFG_PATH</code>等中读取。一般推荐使用默认的<code>/etc/hyperledger/fabric-ca-server</code>路径作为主配置目录环境变量的指向路径，用户也可以根据需求自行设定。</li><li>初始化fabric-ca-server<br>首次使用fabric-ca-server服务的情况下，使用init命令来完成初始化<pre><code class="shell">fabric-ca-server init -b admin:adminpw</code></pre></li><li>启动fabric-ca-server<pre><code class="shell">fabric-ca-server start -b admin:adminpw</code></pre></li><li>RESTful API<br>默认的RESTful服务监听在7054地址，服务前缀为/api/v1<br>参考<a href="https://github.com/hyperledger/fabric-ca/blob/release-1.4/swagger/swagger-fabric-ca.json">swagger</a>，主要接口：</li></ol><ul><li>POST /cainfo：获取某个CA服务的基本信息，body中可带有cname信息</li><li>POST /enroll：使用用户登记功能，body中可带有host、request、profile、label、caname等信息</li><li>POST /reenroll：使用用户重新登记功能，body中可带有host、request、profile、label、caname信息</li><li>POST /register：使用用户注册功能，body中可带有id、type、secret、max_enrollments、affiliation_path、attires、caname等信息</li><li>POST /revoke：撤销某个证书，body中可带有id、aki、serial、reson、caname等信息</li><li>POST /tcert：申请获取一批交易证书，body可以带有count、arr_names、encrypy_attrs、validity_period、caname等信息</li></ul><h2 id="11-4-服务端命令剖析"><a href="#11-4-服务端命令剖析" class="headerlink" title="11.4 服务端命令剖析"></a>11.4 服务端命令剖析</h2><h3 id="11-4-1-全局命令参数"><a href="#11-4-1-全局命令参数" class="headerlink" title="11.4.1 全局命令参数"></a>11.4.1 全局命令参数</h3><ol><li><p>通用参数<br><img src="https://img-blog.csdnimg.cn/d38a58e238c74b05bffda95b4f82ca17.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/a80a90a362f248bb85d771717a33edda.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>证书签名请求参数<br><img src="https://img-blog.csdnimg.cn/3028936c69b346e2a6a019110b707b06.png" alt="在这里插入图片描述"></p></li><li><p>数据库相关参数<br><img src="https://img-blog.csdnimg.cn/e92be96027a641b494192a6422585b4c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>TLS相关参数<br><img src="https://img-blog.csdnimg.cn/762ade5b32084acdbf63dca432a04017.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>LDAP参数</p></li></ol><p><img src="https://img-blog.csdnimg.cn/85444b1b43624510a4cb2d2cb309f1de.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="11-4-2-init命令"><a href="#11-4-2-init命令" class="headerlink" title="11.4.2 init命令"></a>11.4.2 init命令</h3><p>fabric-ca-server init [flags]<br>初始化一个fabric-ca-server服务，主要用于生成密钥相关的证书文件以及配置文件等</p><h3 id="11-4-3-start命令"><a href="#11-4-3-start命令" class="headerlink" title="11.4.3 start命令"></a>11.4.3 start命令</h3><p>fabric-ca-server start [flags]<br>启动一个fabric-ca-server服务</p><h2 id="11-5-服务端配置文件解析"><a href="#11-5-服务端配置文件解析" class="headerlink" title="11.5 服务端配置文件解析"></a>11.5 服务端配置文件解析</h2><p>服务端配置文件最常见的路径在<code>/etc/hyperledger/fabric-ca-server/fabric-ca-server-config.yaml</code>，包括通用配置、TLS配置、CA配置、注册管理配置、数据库配置、LDAP配置、组织结构配置、签名、证书申请等几个部分</p><ol><li>通用配置<br>包括服务监听的端口号，是否输出更多的DEBUG日志等：</li></ol><ul><li>port：7054:指定服务的监听端口；</li><li>debug：false：是否启用DEBUG模式，输出更多的调试信息</li></ul><ol start="2"><li>TLS配置<br>是否在服务端启用TLS，身份验证的证书和签名的私钥。<br>客户端进行TLS认证的模式：</li></ol><ul><li>NoClientCert：不启用，默认值</li><li>RequestClientCert：请求客户端提供证书</li><li>RequireAnyClientCert：要求客户端提供合法格式的证书</li><li>VerifyClientCertIfGiven：如果客户端提供证书则进行验证</li><li>RequireAndVerfyClientCert：要求并且要验证客户端的证书<br><img src="https://img-blog.csdnimg.cn/1f825f49e6ce4934950b5f592f2d2a4c.png" alt="在这里插入图片描述"></li></ul><ol start="3"><li>CA配置<br>包括实例的名称、签名私钥文件、身份验证证书和证书链文件等。这些私钥和证书文件会用来作为生成ECert、TCert的跟证书</li></ol><p><img src="https://img-blog.csdnimg.cn/e589721894da46f98846a55600162d17.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_12,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>4. 注册管理配置<br>   当fabric-ca-server自身提供用户的注册管理时使用，这种情况下需要禁用LDAP功能，否则fabric-ca-server将会把注册管理数据转发到LDAP进行查询<br>   配置内容：</p><ul><li>对enrollment过程的用户名和密码进行验证</li><li>获取某个认证实体的用户属性信息<br><img src="https://img-blog.csdnimg.cn/1fae1c7aac014e7883509aa6f1ca1fe6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li></ul><ol start="5"><li>数据库配置</li></ol><p>数据库支持SQlite3、Postgres、MySQL，可以在本段中进行配置，默认为SQlite3类型的本地数据库。<br><img src="https://img-blog.csdnimg.cn/02546b184e374c5ebccdf1f4745f9e92.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/77cad42365984779910a8bacc78a8e10.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><ol start="6"><li>LDAP配置<br>配置使用远端的LDAP来进行注册管理，认证enrollment的用户名和密码，并获取用户属性信息。</li></ol><p><img src="https://img-blog.csdnimg.cn/6bd9a1e5382c47ec90ad5dd4a4de068e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>7. 组织结构配置<br>   每个组织若干部门<br>   <img src="https://img-blog.csdnimg.cn/1a00ad4dabeb487b99c4c8708f385f7f.png" alt="在这里插入图片描述"></p><ol start="8"><li><p>签发证书相关配置<br>签发证书相关的配置包括签名方法、证书超时时间等<br>fabric-ca-server可以作为用户证书的签发CA，还可以作为根CA来进一步支持其他中间CA<br><img src="https://img-blog.csdnimg.cn/d160955a705a46c5bbe7b8f04afc8b7f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_13,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>证书申请请求配置<br>CA自身证书的申请请求配置。<br>当CA作为根证书服务时，将给予请求生成一个自签名的证书；当CA作为中间证书服务时，将请求发给上层的根证书进行签署。<br><img src="https://img-blog.csdnimg.cn/1daf145fbb9c45aaac6fc7839950e659.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_14,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>BCCSP配置<br>配置所选择的加密库<br><img src="https://img-blog.csdnimg.cn/7a71d04006b04ee2abfccc343c1f1146.png" alt="在这里插入图片描述"></p></li><li><p>多CA支持配置<br>通过cacount：自动创建除了默认CA外的多个CA实例，如ca1、ca2等<br>通过cafiles：可以指定多个CA配置文件路径，每个配置文件会启动一个CA服务，注意不同配置文件之间需要避免冲突</p></li><li><p>中间层CA配置<br>当CA作为中间层CA服务时的相关配置，包括父CA的地址和名称、登记信息、TLS配置等。注意当intermediate.parentserver.url非空时，意味着本CA是中间层CA服务，否则为根CA服务。</p></li></ol><p><img src="https://img-blog.csdnimg.cn/66edf93596874e29bf47f8d179bf25d8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_8,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="11-6-与服务端进行交互"><a href="#11-6-与服务端进行交互" class="headerlink" title="11.6 与服务端进行交互"></a>11.6 与服务端进行交互</h2><h3 id="1-配置读取"><a href="#1-配置读取" class="headerlink" title="1. 配置读取"></a>1. 配置读取</h3><p>主配置目录回一次尝试从环境变量FABRIC_CA_CLIENT_HOME、FABRIC_CA_HOME、CA_CFG_PATH中读取。一般推荐使用$HOME/.fabric-ca-client作为主目录环境变量的指向路径。用户也可以根据需求自行设定</p><h3 id="2-登记用户"><a href="#2-登记用户" class="headerlink" title="2. 登记用户"></a>2. 登记用户</h3><p>通过enroll命令可以对注册到fabric-ca-server中的尸体进行登记，获取其证书信息</p><h3 id="3-注册用户"><a href="#3-注册用户" class="headerlink" title="3. 注册用户"></a>3. 注册用户</h3><p>登记后的用户身份可以采用如下命令来注册新用户：<br><img src="https://img-blog.csdnimg.cn/7671d461d79d489dbfc385099893eda4.png" alt="在这里插入图片描述"></p><h3 id="4-登记节点"><a href="#4-登记节点" class="headerlink" title="4. 登记节点"></a>4. 登记节点</h3><p>登记Peer或Orderer节点的操作与登记用户身份类似。通过-M可以制定本地MSP的跟路径来在其下存放证书文件：<br><img src="https://img-blog.csdnimg.cn/50e9a165e55a486ca563c02f331353cd.png" alt="在这里插入图片描述"></p><h2 id="11-7-客户端命令剖析"><a href="#11-7-客户端命令剖析" class="headerlink" title="11.7 客户端命令剖析"></a>11.7 客户端命令剖析</h2><p>fabric-ca-client命令可以跟服务端进行交互，主要功能如下：</p><ul><li>enroll：登陆获取ECert</li><li>getcacert：获取CA服务的证书链</li><li>reenroll：再次登陆</li><li>register：注册用户实体</li><li>revoke：吊销签发的实体证书</li></ul><h3 id="11-7-1-全局命令参数"><a href="#11-7-1-全局命令参数" class="headerlink" title="11.7.1 全局命令参数"></a>11.7.1 全局命令参数</h3><ol><li><p>通用参数<br><img src="https://img-blog.csdnimg.cn/4eee18cbd50240e1a6470fc39b32116c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>证书签名请求参数</p></li></ol><p><img src="https://img-blog.csdnimg.cn/ab42cc36468241dba8d999a52c41c210.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><ol start="3"><li>登记相关参数<br><img src="https://img-blog.csdnimg.cn/b99ecbab7c174619a1f3d74bb51515be.png" alt="在这里插入图片描述"></li><li>身份实体相关参数<br><img src="https://img-blog.csdnimg.cn/8aace32f85084e83a30989546a0d80c0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li><li>吊销证书相关参数<br><img src="https://img-blog.csdnimg.cn/c200513ee89d42948556a5c8fc5e7a0c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></li><li>TLS相关参数<br><img src="https://img-blog.csdnimg.cn/0ccc5b4916714fb99d4f084a20eda7bf.png" alt="在这里插入图片描述"><h3 id="11-7-2-enroll命令"><a href="#11-7-2-enroll命令" class="headerlink" title="11.7.2 enroll命令"></a>11.7.2 enroll命令</h3></li></ol><p>命令格式为：<code>fabric-ca-client enrool -u http://user:userpw@serverAddr.serverPort</code>。该命令会向服务器申请签发ECert证书。</p><h3 id="11-7-3-getcacert命令"><a href="#11-7-3-getcacert命令" class="headerlink" title="11.7.3 getcacert命令"></a>11.7.3 getcacert命令</h3><p>想服务端申请根证书信息</p><h3 id="11-7-4-reenroll命令"><a href="#11-7-4-reenroll命令" class="headerlink" title="11.7.4 reenroll命令"></a>11.7.4 reenroll命令</h3><p>生成新的签名证书材料</p><h3 id="11-7-5-register命令"><a href="#11-7-5-register命令" class="headerlink" title="11.7.5 register命令"></a>11.7.5 register命令</h3><p>注册新的用户实体身份</p><h3 id="11-7-6-revoke命令"><a href="#11-7-6-revoke命令" class="headerlink" title="11.7.6 revoke命令"></a>11.7.6 revoke命令</h3><p>吊销指定的证书或者指定实体相关的所有的证书</p><h2 id="11-8-客户端配置文件解析"><a href="#11-8-客户端配置文件解析" class="headerlink" title="11.8 客户端配置文件解析"></a>11.8 客户端配置文件解析</h2><ol><li><p>通用配置<br><img src="https://img-blog.csdnimg.cn/6f2976a99c6d4e4797fe4d8dbee5491a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>TLS配置<br><img src="https://img-blog.csdnimg.cn/21baf3eab22447cca6581cbba1be4d8b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>证书签名申请配置<br>客户端想要申请一个ECert时，需要提供证书签名申请文件（CSR）相关的信息<br><img src="https://img-blog.csdnimg.cn/633022e95b7140f1aeacb90a901ee7af.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>注册管理配置<br><img src="https://img-blog.csdnimg.cn/3c19735238e74a97855c28e462437994.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>登记配置<br><img src="https://img-blog.csdnimg.cn/d8e0eda7b98d41bdac2fc78ac2423c13.png" alt="在这里插入图片描述"></p></li><li><p>BCCSP配置<br><img src="https://img-blog.csdnimg.cn/f1aed0c548c444899afef3cc821a28c0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_17,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h2 id="11-9-生产环境部署"><a href="#11-9-生产环境部署" class="headerlink" title="11.9 生产环境部署"></a>11.9 生产环境部署</h2></li><li><p>根证书的生成<br><img src="https://img-blog.csdnimg.cn/a450542e7d5140ebb99e551c3bcacf58.png" alt="在这里插入图片描述"></p></li><li><p>分层部署结构<br>PKI推荐采用分层的结构，即不由根CA来直接签发证书，而是通过由根CA签发的中间CA甚至更下层CA来实现对服务器实体和用户证书的管理。<br><img src="https://img-blog.csdnimg.cn/e8990f51f1e34fc49822fd36bf77c765.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>TLS机制<br><img src="https://img-blog.csdnimg.cn/1953c78b88f640e2a2980dae3612bfaa.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li><li><p>负载均衡和高可用<br><img src="https://img-blog.csdnimg.cn/ed38164183bf471090acd45d1a50199b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/94883dcb5f964e2e90bfd221c812791e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p></li></ol><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ul><li><a href="https://hyperledger-fabric.readthedocs.io/zh_CN/latest/identity/identity.html">Fabric CA官方介绍</a></li><li>《区块链原理、设计与应用-杨保华、陈昌》</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Fabric </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fabric1.0架构与设计</title>
      <link href="/2021/09/24/blockchain/fabric/%E7%AC%AC12%E7%AB%A0-Fabric1-0%E6%9E%B6%E6%9E%84%E4%B8%8E%E8%AE%BE%E8%AE%A1/"/>
      <url>/2021/09/24/blockchain/fabric/%E7%AC%AC12%E7%AB%A0-Fabric1-0%E6%9E%B6%E6%9E%84%E4%B8%8E%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="Fabric1-0架构与设计"><a href="#Fabric1-0架构与设计" class="headerlink" title="Fabric1.0架构与设计"></a>Fabric1.0架构与设计</h1><h2 id="12-1-整理架构概览"><a href="#12-1-整理架构概览" class="headerlink" title="12.1 整理架构概览"></a>12.1 整理架构概览</h2><h3 id="12-1-1-核心特性"><a href="#12-1-1-核心特性" class="headerlink" title="12.1.1 核心特性"></a>12.1.1 核心特性</h3><ul><li>消除网络处理瓶颈，提高可扩展性：解耦了原子排序环节与其他复杂处理环节</li><li>根据负载进行灵活部署：解藕交易处理节点的逻辑角色为背书节点（Endorser）、确认节点（Commotter）</li><li>提供更多功能：加强了身份证书管理服务，作为单独的Fabric CA项目</li><li>提交隔离安全性：支持多通道特性，不同通道之间的数据彼此隔离</li><li>支持可插拔的架构，包括共识、权限管理、加解密、账本机制等模块，支持多种类型</li><li>支持可编程和第三方实现：引入系统链码来实现区块链系统的处理</li></ul><h3 id="12-1-2-整体架构"><a href="#12-1-2-整体架构" class="headerlink" title="12.1.2 整体架构"></a>12.1.2 整体架构</h3><p><img src="https://img-blog.csdnimg.cn/b05b1fe7b97344f8b0d5ee3edab23675.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_10,color_FFFFFF,t_70,g_se,x_16"></p><h3 id="12-1-3-典型工作流程"><a href="#12-1-3-典型工作流程" class="headerlink" title="12.1.3 典型工作流程"></a>12.1.3 典型工作流程</h3><p>交易处理过程：</p><p><img src="/images/fabric/image-20220307194816235.png" alt="image-20220307194816235"></p><p>各个组件功能：</p><ol><li>客户端（APP）</li></ol><p>客户端使用SDK与Fabric网络交互。</p><p>步骤：</p><ul><li>客户端从CA获取合法的身份证书来加入网络内的应用通道</li><li>构造交易提案（Proposal）提交给Endorser进行背书</li><li>客户端收到足够（背书策略决定）的背书支持后可以利用背书构造一个合法的交易请求</li><li>发给Orderer进行排序处理</li></ul><ol start="2"><li>Endorser节点</li></ol><p>主要提供ProcessProposal方法供客户端调用，完成对焦一天的背书（目前主要是签名）处理，只有部分节点担任Endorser角色</p><p>步骤：</p><ul><li>收到客户端的交易提案</li><li>进行合法性和ACL权限检查</li><li>模拟运行交易，对交易导致的状态变化进行背书并返回结果给客户端</li></ul><ol start="3"><li>Committer节点</li></ol><p>负责维护区块链和账本结构（包括DB、历史DB、索引DB等），同一物理节点可以仅作为Committer角色运行也可以同时担任Endorser和Committer这两种角色</p><p>步骤：</p><ul><li>定期从Orderer获取排序后的批量交易区块结构，对这些交易进行落盘前的最终检查（包括交易消息结构、签名完整性、是否重复、读写集合版本是否匹配等）</li><li>将结果写入账本，同时构造新的区块、更新区块中BlockMetadata[2]记录交易是否合法等信息</li></ul><ol start="4"><li>Orderer</li></ol><p>仅负责排序。为网络中所有合法交易进行全局排序，并将一批排序后的交易组合成区块结构</p><ol start="5"><li>CA</li></ol><p>负责网络中所有证书的管理（分发、撤销等），实现标准的PKI架构</p><h2 id="12-2-核心概念与组件"><a href="#12-2-核心概念与组件" class="headerlink" title="12.2 核心概念与组件"></a>12.2 核心概念与组件</h2><p><img src="https://img-blog.csdnimg.cn/069a68e6f29a42f48f64ce967a44c933.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_13,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><ol><li>网络层</li></ol><ul><li>面向：系统管理人员</li><li>功能：实现P2P网络，提供底层构建区块链网络的基本能力，包括代表不同角色的节点和服务</li></ul><ol start="2"><li>共识机制和权限管理</li></ol><ul><li>面向：联盟和组织的管理人员</li><li>功能：基于网络层的连通，实现共识机制和权限管理，提供分布式账本的基础</li></ul><ol start="3"><li>业务层</li></ol><ul><li>面向：业务应用开发人员</li><li>功能：基于分布式账本，支持链码、交易等跟业务相关的功能模块，提供更高一层的应用开发支持</li></ul><h3 id="12-2-1-网络层相关组件"><a href="#12-2-1-网络层相关组件" class="headerlink" title="12.2.1 网络层相关组件"></a>12.2.1 网络层相关组件</h3><ol><li>节点</li></ol><ul><li>Endorser（背书节点）：负责对来自客户端的交易进行检查和背书</li><li>Committer（确认节点）：负责检查交易请求，执行交易并维护区块链和账本结构</li><li>Submitter（提交节点）：负责接收交易，转发给排序者</li></ul><ol start="2"><li>排序者</li></ol><p>排序者（Orderer）也称为排序节点，负责对所收到的交易在网络中进行全局排序</p><ol start="3"><li>客户端</li></ol><p>客户端是用户和应用跟区块链网络打交道的桥梁</p><p>功能：</p><ul><li>操作Fabric网络</li><li>操作运行在网络中的链码</li></ul><ol start="4"><li>成员身份管理</li></ol><p>CA节点（Fabric-CA）负责对Fabric网络中的成员身份进行管理</p><p>Fabric网络目前采用数字证书机制来实现对身份的鉴别和权限控制，CA节点则实现了PKI服务，主要负责对身份证书进行管理，包括生成、撤销等</p><ol start="5"><li>Gossip协议</li></ol><p>Fabric网络中的节点之间通过Gossip协议来进行状态同步和数据分发</p><p>基本思想：数据发送方从网络中随机选取若干节点，将数据发送过去；接受方重复这一过程（往往只选择发送方之外的节点进行传播）。数据传输方向可以是发送方发送或获取方拉取</p><h3 id="12-2-2-共识相关组件"><a href="#12-2-2-共识相关组件" class="headerlink" title="12.2.2 共识相关组件"></a>12.2.2 共识相关组件</h3><ol><li>背书过程</li></ol><p>背书：背书节点对收到的来自客户端的请求（交易提案）按照自身分逻辑进行金叉，一决策是否给予支持的过程</p><ol start="2"><li>排序服务</li></ol><p>排序服务通常是由排序节点组成的集群来提供</p><p>排序功能：对一段时间内的一批交易达成一个网络内全局一致的顺序</p><ol start="3"><li>验证过程</li></ol><p>验证是对排序后的一批交易进行提交到账本之前最终检查的过程</p><p>验证内容：</p><ul><li>检查交易结构自身完整性</li><li>检查交易所带背书签名是否满足预设的背书策略</li><li>交易的读写集是否满足多版本并发控制的相关要求</li><li>等</li></ul><h3 id="12-2-3-权限管理相关组件"><a href="#12-2-3-权限管理相关组件" class="headerlink" title="12.2.3 权限管理相关组件"></a>12.2.3 权限管理相关组件</h3><ol><li>成员服务提供者（Membership Service Provider，MSP）</li></ol><p>MSP：抽象代表了一个身份验证的实体，代表用于对某个资源（成员/节点/组织等）进行身份验证的一组机制，是实现权限管理的基础</p><p>基于MSP可以实现对不同资源进行基于身份证书的权限验证。通常情况下，一个组织或联盟可以对应到一个层级化的MSP</p><ol start="2"><li>组织</li></ol><p>组织代表一组拥有共同信任的根证书（可以为根CA证书或中间CA证书）的成员</p><p>组织之间可以相互交换比较敏感的内容</p><p>同一个组织的成员节点在网络中可以被认为是同一个身份，代表组织进行签名</p><p>组织中的成员可以为普通成员角色或者管理员角色，后者拥有更好的权限，可以对组织配置进行修改</p><p>组织中</p><ol start="3"><li>联盟</li></ol><p>联盟由若干组织构成的集合，是联盟联场景所独有的结构形式</p><p>联盟一般用于多个组织相互合作的场景，例如某联盟中指定需要所有参与方同时对交易背书，才允许在网络中执行执行</p><ol start="4"><li>身份证书</li></ol><p>身份证书是Fabric中权限管理的基础，采用基于ECDSA算法的非对称加密算法生成公钥和私钥，证书格式则采用了X.509标准规范</p><h3 id="12-2-4-业务层相关组件"><a href="#12-2-4-业务层相关组件" class="headerlink" title="12.2.4 业务层相关组件"></a>12.2.4 业务层相关组件</h3><ol><li>交易</li></ol><p>交易意味着通过调用链码实现对账本状态进行一次改变</p><ol start="2"><li>区块</li></ol><p>区块意味着一组进行排序后的交易的集合</p><p>区块结构包括：</p><ul><li>区块头：构建区块结构，包含Number（区块序号）、PreviousHash（前一区块头部Hash）、DataHash（本区块Data域内容的Hash值）</li><li>数据：以Envelope结构记录区块内的多个交易信息，使用Merkle树结构</li><li>元数据：记录辅助信息，包括：签名信息、通道的最新配置区块的索引、交易是否合法标记、通道的排序服务信息</li></ul><ol start="3"><li>链码<br>链码源自智能合约的思想</li></ol><p>种类：</p><ul><li>用户链码</li><li>系统链码</li></ul><ol start="4"><li>通道</li></ol><p>通道，狭义地讲，是排序服务上划分的彼此隔离的原子广播渠道，由排序服务进行管理</p><ol start="5"><li>链结构</li></ol><p>链结构内容：</p><ul><li>所绑定的通道内的所有的交易信息，这些交易以区块形式进行存放</li><li>通道内所安装和实例化的链码的相关信息</li><li>对链进行操作的权限管理，以及参与到链上的组织成员</li></ul><ol start="6"><li>账本</li></ol><p>账本主要负责记录发生在网络中的交易信息，账本包括区块链结构和多个数据库结构</p><p><img src="https://img-blog.csdnimg.cn/7046bcd0555f4b1c8b906124c1583c11.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><ul><li>State Database：状态数据库，由区块链结构中交易执行推演而成，记录最新的世界状态</li><li>History Database：历史数据库，存放各个状态的历史变化记录</li><li>Index Database：索引数据库，存放索引信息</li></ul><h2 id="12-3-gRPC消息协议【待补充】"><a href="#12-3-gRPC消息协议【待补充】" class="headerlink" title="12.3 gRPC消息协议【待补充】"></a>12.3 gRPC消息协议【待补充】</h2><h2 id="12-4-权限管理和策略"><a href="#12-4-权限管理和策略" class="headerlink" title="12.4 权限管理和策略"></a>12.4 权限管理和策略</h2><h3 id="12-4-1-策略应用场景"><a href="#12-4-1-策略应用场景" class="headerlink" title="12.4.1 策略应用场景"></a>12.4.1 策略应用场景</h3><p><img src="https://img-blog.csdnimg.cn/d7491f1b67b64f7ca0061c1db13bc2fb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="12-4-2-身份证书"><a href="#12-4-2-身份证书" class="headerlink" title="12.4.2 身份证书"></a>12.4.2 身份证书</h3><ul><li>登记证书（ECert）：颁发给提供了注册凭证的用户或节点等实体，一般长期有效</li><li>交易证书（TCert）：办法给用户，控制每个交易的权限，一般针对某个交易，短期有效；</li><li>通信证书（TLSCert）：控制对网络层的接入访问，可以对远端实体身份进行校验，防止窃听</li></ul><h3 id="12-4-3-权限策略的实现"><a href="#12-4-3-权限策略的实现" class="headerlink" title="12.4.3 权限策略的实现"></a>12.4.3 权限策略的实现</h3><p>功能：对通道内数据的各种操作权进行管理。包括对读身份（例如获取通道的交易、区块等数据）、写身份（例如向通道发起交易）、管理员身份（例如加入通道、修改通道的配置信息）等权限进行限制</p><ol><li>数据结构</li></ol><p>实现上，每种策略结构都要实现Evaluate方法，该方法中会对于给定的一组签名数据按照一定规则对它们进行校验，看是否符合约定的条件，符合则说明满足了该策略</p><ol start="2"><li>SIGNATURE策略</li></ol><p>通过签名来对数据进行认证，例如数据必须满足一定的签名身份组合</p><p>SignaturePolicy结构体代表了一个策略的具体内容。支持指定某个特性签名或者满足给定策略集合中的若干个（NOutOf）即可。</p><p>SignaturePolicyEnvelope结构体代表了一个完整的策略，包括版本号、策略规则和策略关联的实体集合。</p><ol start="3"><li>IMPLICIT_META策略</li></ol><p>该策略不直接进行签名检查，而是通过引用其子元素的策略（最终还是通过SIGNATURE策略）来进行检查。检查结果通过Rule来进行限制。</p><h3 id="12-4-4-通道策略"><a href="#12-4-4-通道策略" class="headerlink" title="12.4.4 通道策略"></a>12.4.4 通道策略</h3><p>通道策略是层级化结构，最上层为/Channel。在每一级别都可以指定策略，作为本层级的默认策略。</p><p><img src="https://img-blog.csdnimg.cn/fb8f53d53d93442bb99be2c966e8c128.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><p>未经修改的情况下，会为通道内元素预先定义一些默认的策略，如下所示：</p><p><img src="https://img-blog.csdnimg.cn/ab4a0a6391d5405ea7eeecc9cc4f73c1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="12-4-5-背书策略"><a href="#12-4-5-背书策略" class="headerlink" title="12.4.5 背书策略"></a>12.4.5 背书策略</h3><p>用户在实例化链码使，可以指定背书策略</p><p>背书策略采用SignaturePolicy结构进行指定，同样可以基于MSPPrincipal结构构建任意复杂的签名校验组合</p><p>下面的命令指定要么Org1的管理员进行背书，或者Org2和Org3的成员同时进行背书才满足背书策略：<br><img src="https://img-blog.csdnimg.cn/54576b21b6bd4f499ae6ca0f358ea0c4.png" alt="在这里插入图片描述"></p><h3 id="12-4-6-实例化策略"><a href="#12-4-6-实例化策略" class="headerlink" title="12.4.6 实例化策略"></a>12.4.6 实例化策略</h3><p>实例化策略一般用于最终确认阶段，Committer利用VSCC对网络中进行链码部署的cao zuo操作进行权限检查</p><p>实例化策略采用SignaturePolicy结构进行指定，可以给予MSTPPrincipal结构构建任意复杂的签名校验组合</p><p>默认情况下，会以当前MSP的管理员身份作为默认的策略，这可以避免脸吗被通道中其他组织成员私自在其他通道内进行实例化</p><h2 id="12-5-用户链码"><a href="#12-5-用户链码" class="headerlink" title="12.5 用户链码"></a>12.5 用户链码</h2><h3 id="12-5-1-基本结构"><a href="#12-5-1-基本结构" class="headerlink" title="12.5.1 基本结构"></a>12.5.1 基本结构</h3><p>链码的典型结构：</p><p><img src="https://img-blog.csdnimg.cn/1312f1b5804645f2a4534ffa4eafdca7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><p>用户只需要关注到Init()和Invoke()函数的视线，其中利用shim.ChaincodeStubInterface结构实现跟账本的交互逻辑</p><p>用户链码支持install、instantiate、invoke、query、upgrade、package、signpackage等操作，其生命周期被生命周期管理系统链码（LSCC）进行管理</p><h3 id="12-5-2-链码与Peer的交互过程"><a href="#12-5-2-链码与Peer的交互过程" class="headerlink" title="12.5.2 链码与Peer的交互过程"></a>12.5.2 链码与Peer的交互过程</h3><p><img src="https://img-blog.csdnimg.cn/5859c9af4dac47d29d0fb51746ee4742.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><ul><li>Type：消息的类型</li><li>TxId：关联的交易ID</li><li>Payload：存储消息内容</li></ul><p>交互过程：<br><img src="https://img-blog.csdnimg.cn/a9909a44a56e4a9cba4fa7890df883fa.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><ul><li>用户链码调用shim.Start()方法后，首先向Peer发送<code>ChaincodeMessage_REGISTER</code>消息尝试进行注册。之后开始等待接收来自Peer的消息。此时状态为出事的created</li><li>Peer收到来自链码容器的<code>ChaincodeMessage_REGISTER</code>消息，注册到本地的一个handler结构，返回<code>ChaincodeMessage_REGISTERED</code>消息给链码容器，更新状态为established，之后自动发出<code>ChaincodeMessage_READY</code>消息给链码容器，更新状态为ready</li><li>链码侧收到<code>ChaincodeMessage_REGISTERED</code>消息后，不进行任何操作，注册成功。更新状态为establied。收到<code>ChaincodeMessage_READY</code>消息后更新状态为ready</li><li>Peer侧发出<code>ChaincodeMessage_INIT</code>消息给链码容器，对链码进行初始化</li><li>链码容器收到<code>ChaincodeMessage_INIT</code>消息，调用用户链码代码Init()方法进行初始化，成功后返回<code>ChaincodeMessage_COMPLETED</code>消息，此时链码容器可以被调用了</li><li>链码被调用时，Peer发出<code>ChaincodeMessage_TRANSACTION</code>消息给链码</li><li>链码收到<code>ChaincodeMessage_TRANSACTION</code>消息，会调用Invoke()方法。根据Invoke()方法中用户实现的逻辑发送消息。Peer侧收到这些消息，进行相应处理，并回复<code>ChaincodeMessage_RESPONSE</code>消息，最后链码侧会回复调用完成的消息<code>ChaincodeMessage_COMPLETE</code>给Peer侧</li></ul><p>上述过程中，Peer和链码侧会定期的发送<code>ChaincodeMessage_KEEPALIVE</code>消息给对方，以确保彼此在线</p><h3 id="12-5-3-链码处理状态机"><a href="#12-5-3-链码处理状态机" class="headerlink" title="12.5.3 链码处理状态机"></a>12.5.3 链码处理状态机</h3><p><img src="https://img-blog.csdnimg.cn/93a115e4e5c84464b0dbca6c18a5ecbe.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_18,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h3 id="12-6-系统链码"><a href="#12-6-系统链码" class="headerlink" title="12.6 系统链码"></a>12.6 系统链码</h3><p>系统链码负责Fabric节点自身的处理逻辑，包括系统配置、背书、校验等工作</p><p>类型：</p><p><img src="https://img-blog.csdnimg.cn/ed6c8e03be1142d5bd37d2a2da50f85c.png" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/67644becc0894c9e9322b56981a2b27b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5p2v57OW5LiN5Yqg5ZKW5ZWh,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h4 id="1-配置系统链码"><a href="#1-配置系统链码" class="headerlink" title="1. 配置系统链码"></a>1. 配置系统链码</h4><p>Configuration System Chaincode即配置系统链码，是负责配置管理的系统链码，支持被从链外进行调用。</p><p>CSCC支持如下类型Invoke方法：</p><ul><li>JoinChain：当某个节点申请加入某条通道时被调用。负责跟根据传入的初始区块参数生成所加入通道的创世区块，并完成账本、通道相关数据结构的初始化工作。调用后节点本地将维护所加入通道的数据结构，并创建初始区块。</li><li>GetConfigBlock：当需要获取节点在某个通道上配置时候被调用。该方法获取指定通道的配置区块（未更新时等价于初始区块）的内容</li><li>UpdateConfigBlock：当需要更新节点在某个通道上的配置时被调用。根据传入的区块数据生成区块结构，替换掉现有的配置区块结构。替换后配置区块数据将跟该通道内的初始区块不再一致</li><li>GetChannels：需要获取到节点所加入所有通道列表时被调用。该方法获取该节点已经加入的所有通道的信息</li></ul><h4 id="2-背书管理系统链码"><a href="#2-背书管理系统链码" class="headerlink" title="2. 背书管理系统链码"></a>2. 背书管理系统链码</h4><p>Endorsement Sysment Chaincode即背书管理系统链码。负责背书（签名）过程，并可以支持对被书策略进行管理，仅支持链内系统调用。</p><h4 id="3-生命周期系统链码"><a href="#3-生命周期系统链码" class="headerlink" title="3. 生命周期系统链码"></a>3. 生命周期系统链码</h4><p>Liftcycle System Chaincode即生命周期系统链码，负责对用户链码的生命周期进行管理，支持被从链外进行调用</p><p>链码生命周期包括安装、部署、升级、权限管理、获取信息等环节。这些操作都可以通过对LSCC进行Invoke来实现：</p><ul><li>INSTALL：安装意味着将用户链码相关文件打包，放置到节点的文件系统，默认在/var/hyperledger/production/chaincodes/路径下</li><li>DEPLOY：意味着链码被部署和实例化，生成链码容器。此过程中会检查通道的ACL，从本地拿到链码数据，检查Instantiation Policy</li><li>UPGRADE：升级链码时被调用。检查Instantiation Policy，通过则对本地文件进行替换，并生成新的链码容器</li><li>GETCCINFO：获取链码信息时被调用。检查节点对钙通道是否有读权限，通过则返回指定链码的信息</li><li>GETCCDATA：获取链码数据时被调用。检查节点对该通道是否有读权限，通过则返回指定链码的完整数据</li><li>GETCHAINCODES：获取节点在通道上的连码信息，检查节点是否具有管理员权限，通过则返回在通道上的所有链码信息，包括已安装和已实例化的</li></ul><h4 id="4-查询系统链码"><a href="#4-查询系统链码" class="headerlink" title="4. 查询系统链码"></a>4. 查询系统链码</h4><p>Query System Chaincode，查询系统链码，负责提供一些账本和链信息的查询方法：</p><ul><li>GetChainInfo：获取区块链的信息，包括高度值、当前区块Hash值、上一个区块Hash值等</li><li>GetBlockByNumber：根据给定高度，返回对应区块的数据</li><li>GetBlockByHash：根据给定的区块头Hash值，返回对应区块的数据</li><li>GetTransactionByID：根据给定的TxID，返回对应交易的数据</li><li>GetBlockByTxID：根据给定的TxID，返回包含该交易的区块的数据</li></ul><h4 id="5-验证系统链码"><a href="#5-验证系统链码" class="headerlink" title="5. 验证系统链码"></a>5. 验证系统链码</h4><p>Verification System Chaincode验证系统链码，负责担任Committer角色的节点对从Orderer收到的一批交易进行写入前的再次验证，仅支持链内系统调用。</p><p>VSCC主要过程：</p><ul><li>首先解析出交易结构，并对交易结构格式进行校验</li><li>检查交易的读集合中元素版本跟本地账本中版本一致</li><li>检查带有合法的背书信息（目前主要是检查签名信息）</li><li>通过则返回正确，否则返回错误信息</li></ul><h3 id="12-7-排序服务"><a href="#12-7-排序服务" class="headerlink" title="12.7 排序服务"></a>12.7 排序服务</h3><p>排序服务在超级账本Fabric网络中起到十分核心的作用。所有交易在发送到网络中交由Committer进行验证接受之前，需要先经过排序服务进行全局排序。排序服务提供了原子广播排序功能。</p><p>排序服务三部分：</p><ul><li>gRPC协议对外提供服务接口</li><li>账本组件网络中每个应用通道维护区块链结构</li><li>排序插件跟不同类型的排序后端打交道</li></ul><p><img src="/images/fabric/image-20220306155841781.png" alt="image-20220306155841781"></p><h4 id="12-7-1-gRPC服务接口"><a href="#12-7-1-gRPC服务接口" class="headerlink" title="12.7.1 gRPC服务接口"></a>12.7.1 gRPC服务接口</h4><p>Orderer通过gRPC接口提供了对外的调用服务，主要包括：</p><ul><li>Broadcast：意味着客户端发送交易请求到排序服务进行排序处理</li><li>Deliver：意味着客户端或Peer从排序服务获取排序后的区块（批量交易）</li></ul><h4 id="12-7-2-链和账本管理"><a href="#12-7-2-链和账本管理" class="headerlink" title="12.7.2 链和账本管理"></a>12.7.2 链和账本管理</h4><p>Orderer节点本地需要维护网络中的账本结构。其中账本结构支持三种实现类型：</p><ul><li>ram：存放近期若干区块到内存中</li><li>file：存放区块记录到本地文件系统</li><li>json：存放区块记录到本地文件系统（存储格式为json）</li></ul><h4 id="12-7-3-通道配置更新"><a href="#12-7-3-通道配置更新" class="headerlink" title="12.7.3 通道配置更新"></a>12.7.3 通道配置更新</h4><p>对通道配置的更新主要通过Processor结构来完成，该结构主要提供了Process方法。该方法接收一个CONFIG_UPDATE类型的Envelope结构消息，根据请求类型（新建通道或更新配置），将其转换为新建应用通道的请求，或者转换为对通道进行配置更改的请求。</p><p>主要步骤：</p><ul><li>从请求中提取channelID，检查本地是否存在对应的链结构</li><li>如果channelID对应的链在本地存在，则意味着这是一个对已有通道进行配置更新的请求</li><li>如果channelID对应的链在本地不存在，则意味着这是一个新通道的请求</li></ul><h4 id="12-7-4-共识插件"><a href="#12-7-4-共识插件" class="headerlink" title="12.7.4 共识插件"></a>12.7.4 共识插件</h4><p>Orderer模块中包含三种共识插件：</p><ul><li>Solo：单节点的排序功能，试验性质，不具备可扩展性和容错，不能在生产环境中使用</li><li>Kafka：基于Kafka集群的排序实现。支持CFT容错，支持可持久化和扩展性，可在生产环境中使用</li><li>SBFT：支持BFT容错的排序实现，1.0尚未实现</li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li>《区块链原理、设计与应用-杨保华、陈昌》</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Fabric </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-涉及到的数据结构与算法</title>
      <link href="/2021/07/08/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E6%B6%89%E5%8F%8A%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
      <url>/2021/07/08/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E6%B6%89%E5%8F%8A%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h1><p>源码分析使用的版本为：<a href="https://github.com/ethereum/go-ethereum/tree/v1.10.3">v1.10.3</a></p><h1 id="一、数据结构"><a href="#一、数据结构" class="headerlink" title="一、数据结构"></a>一、数据结构</h1><h2 id="1-MPT"><a href="#1-MPT" class="headerlink" title="1. MPT"></a>1. MPT</h2><p>以太坊源码中的trie包实现了Merkle Patricia Tries（MPT），这种数据结构实际上是一种Trie树变种。<br>MPT是以太坊中一种非常重要的数据结构，用来存储用户账户的状态及其变更、交易信息、交易的收据信息。<br>MPT实际上是三种数据结构的组合，分别是Merkle树、Patricia Trie和Trie树。</p><p>🔎详情：</p><ul><li><a href="https://blog.csdn.net/qq_36254699/article/details/117325437">MPT(Merkle树、Patricia Tries、Trie树)</a></li></ul><h2 id="2-LevelDB"><a href="#2-LevelDB" class="headerlink" title="2. LevelDB"></a>2. LevelDB</h2><p>go-ethereum所有的数据存储在levelDB这个Google开源的KeyValue文件数据库中，整个区块链的所有数据都存储在一个levelDB的数据库中，levelDB支持按照文件大小切分文件的功能，所以我们看到的区块链的数据都是一个一个小文件，其实这些小文件都是同一个levelDB实例。<br>levelDB官方网站介绍特点：</p><ul><li>key和value都是任意长度的字节数组；</li><li>entry（即一条K-V记录）默认是按照key的字典顺序存储的，当然开发者也可以重载这个排序函数；</li><li>提供的基本操作接口：Put()、Delete()、Get()、Batch()；</li><li>支持批量操作以原子操作进行；</li><li>可以创建数据全景的snapshot(快照)，并允许在快照中查找数据；</li><li>可以通过前向（或后向）迭代器遍历数据（迭代器会隐含的创建一个snapshot）；</li><li>自动使用Snappy压缩数据；</li><li>可移植性；</li></ul><p>限制：</p><ul><li> 非关系型数据模型（NoSQL），不支持sql语句，也不支持索引；</li><li> 一次只允许一个进程访问一个特定的数据库；</li><li> 没有内置的C/S架构，但开发者可以使用LevelDB库自己封装一个server；</li></ul><p>🔎详情：</p><ul><li><a href="https://blog.csdn.net/qq_36254699/article/details/117906308?spm=1001.2014.3001.5501">https://blog.csdn.net/qq_36254699/article/details/117906308?spm=1001.2014.3001.5501</a></li><li><a href="https://github.com/google/leveldb">https://github.com/google/leveldb</a></li></ul><h1 id="二、算法"><a href="#二、算法" class="headerlink" title="二、算法"></a>二、算法</h1><h2 id="1-迪菲-赫尔曼密钥交换"><a href="#1-迪菲-赫尔曼密钥交换" class="headerlink" title="1. 迪菲-赫尔曼密钥交换"></a>1. 迪菲-赫尔曼密钥交换</h2><p>迪菲－赫尔曼通过公共信道交换一个信息，就可以创建一个可以用于在公共信道上安全通信的共享秘密（shared secret）。</p><p>🔎详情：</p><ul><li><a href="https://gitee.com/hbuzzs/go-ethereum-code-analysis/blob/analysis-zzs/p2p-rlpx%E8%8A%82%E7%82%B9%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8A%A0%E5%AF%86%E9%93%BE%E8%B7%AF.md#%E8%BF%AA%E8%8F%B2-%E8%B5%AB%E5%B0%94%E6%9B%BC%E5%AF%86%E9%92%A5%E4%BA%A4%E6%8D%A2">迪菲-赫尔曼密钥交换</a></li></ul><h2 id="2-以太坊快速同步算法"><a href="#2-以太坊快速同步算法" class="headerlink" title="2. 以太坊快速同步算法"></a>2. 以太坊快速同步算法</h2><p>区块链最开始的同步工作，当前的同步有两种模式：<br>一种是传统的fullmode,这种模式通过下载区块头，和区块体来构建区块链，同步的过程就和普通的区块插入的过程一样，包括区块头的验证，交易的验证，交易执行，账户状态的改变等操作，这其实是一个比较消耗CPU和磁盘的一个过程。<br>另一种模式就是快速同步的fast sync模式。简单的说 fast sync的模式会下载区块头，区块体和收据， 插入的过程不会执行交易，然后在一个区块高度(最高的区块高度 - 1024)的时候同步所有的账户状态，后面的1024个区块会采用fullmode的方式来构建。 这种模式会加快区块的插入时间，同时不会产生大量的历史的账户信息，会相对节约磁盘， 但是对于网络的消耗会更高。 因为需要下载收据和状态。<br>即快速同步算法的目标是用带宽换计算。 快速同步不是通过一个链接处理整个区块链，而是重放历史上发生的所有事务，快速同步会沿着这些块下载事务处理单据，然后拉取整个最近的状态数据库。 这允许快速同步的节点仍然保持其包含用于用户查询的所有历史数据的存档节点的状态（并且因此不会一般地影响网络的健康状况），对于最新的区块状态更改，会使用全量的区块处理方式。</p><p>快速同步算法的概要：</p><ul><li>与原有的同步类似，下载组成区块链的区块头和区块body</li><li>类似于原有的同步，验证区块头的一致性（POW，总难度等）</li><li>下载由区块头定义的交易收据,而不是处理区块。</li><li>存储下载的区块链和收据链，启用所有历史查询</li><li>当链条达到最近的状态（头部 - 1024个块）时，暂停状态同步：<ul><li>获取由 pivot point定义的区块的完整的Merkel Patricia Trie状态</li><li>对于Merkel Patricia Trie里面的每个账户，获取他的合约代码和中间存储的Trie</li></ul></li><li>当Merkel Patricia Trie下载成功后，将pivot point定义的区块作为当前的区块头</li><li>通过像原有的同步一样对其进行完全处理，导入所有剩余的块（1024）</li></ul><p>🔎详情：</p><ul><li><a href="https://github.com/ethereum/go-ethereum/pull/1889">以太坊快速同步算法-原文</a></li><li><a href="https://gitee.com/hbuzzs/go-ethereum-code-analysis/blob/analysis-zzs/%E4%BB%A5%E5%A4%AA%E5%9D%8Afast%20sync%E7%AE%97%E6%B3%95.md">以太坊快速同步算法-译文</a></li></ul><h2 id="3-以太坊的布隆过滤器"><a href="#3-以太坊的布隆过滤器" class="headerlink" title="3. 以太坊的布隆过滤器"></a>3. 以太坊的布隆过滤器</h2><p>以太坊的区块头中包含了一个叫做logsBloom的区域。 这个区域存储了当前区块中所有的收据的日志的布隆过滤器，一共是2048个bit。也就是256个字节。而我们的一个交易的收据包含了很多的日志记录。 每个日志记录包含了 合约的地址， 多个Topic。 而在我们的收据中也存在一个布隆过滤器，这个布隆过滤器记录了所有的日志记录的信息。</p><p>🔎详情：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/43263751">布隆过滤器简介</a></li><li><a href="https://gitee.com/hbuzzs/go-ethereum-code-analysis/blob/analysis-zzs/eth-bloombits%E5%92%8Cfilter%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.md#%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%9A%84%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8">以太坊的布隆过滤器</a></li></ul><h2 id="4-POW一致性算法"><a href="#4-POW一致性算法" class="headerlink" title="4. POW一致性算法"></a>4. POW一致性算法</h2><p>在CPU挖矿部分，CpuAgent的mine函数，执行挖矿操作的时候调用了self.engine.Seal函数。这里的engine是就是共识引擎。Seal为其中很重要的一个接口。它实现了nonce值的寻找和hash的计算。并且该函数是保证共识并且不能伪造的一个重要的函数。 再PoW共识算法中，Seal函数实现了工作证明。该部分源码在consensus/ethhash下。</p><ul><li><a href="https://gitee.com/hbuzzs/go-ethereum-code-analysis/blob/analysis-zzs/pow%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95.md">POW一致性算法</a></li></ul><h1 id="三、协议"><a href="#三、协议" class="headerlink" title="三、协议"></a>三、协议</h1><h2 id="1-RPC协议"><a href="#1-RPC协议" class="headerlink" title="1. RPC协议"></a>1. RPC协议</h2><p>rpc包提供这样一种能力，可以通过网络或者其他I/O连接，可以访问对象被导出的方法。创建一个服务器之后，对象可以注册到服务器上，然后可以让外界访问。通过脂肪方式导出的方法可以被远程调用。 同时还支持发布/订阅模式。</p><p>🔎详情：</p><ul><li><a href="https://blog.csdn.net/qq_36254699/article/details/118497242">https://blog.csdn.net/qq_36254699/article/details/118497242</a></li></ul><h2 id="2-Kademlia协议"><a href="#2-Kademlia协议" class="headerlink" title="2. Kademlia协议"></a>2. Kademlia协议</h2><p>Kad 是一种分布式哈希表（DHT）技术，不过和其他 DHT 实现技术比较，如Chord、CAN、Pastry 等，Kad 通过独特的以异或算法（XOR）为距离度量基础，建立了一种全新的 DHT 拓扑结构，相比于其他算法，大大提高了路由查询速度。</p><p>🔎详情：</p><ul><li><a href="https://gitee.com/hbuzzs/go-ethereum-code-analysis/blob/analysis-zzs/references/Kademlia%E5%8D%8F%E8%AE%AE%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B.pdf">Kademlia协议简介下载地址</a></li></ul><h2 id="3-UDP协议"><a href="#3-UDP协议" class="headerlink" title="3. UDP协议"></a>3. UDP协议</h2><p>p2p的网络发现协议使用了Kademlia protocol 来处理网络的节点发现。节点查找和节点更新。Kademlia protocol使用了UDP协议来进行网络通信。</p><p>🔎详情：</p><ul><li><a href="https://gitee.com/hbuzzs/go-ethereum-code-analysis/blob/analysis-zzs/p2p-udp.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.md">p2p-udp.go源码分析.</a></li></ul><h1 id="参考资料地址"><a href="#参考资料地址" class="headerlink" title="参考资料地址"></a>参考资料地址</h1><ul><li><a href="https://ethereum.org/en/whitepaper">以太坊白皮书</a></li><li><a href="https://ethereum.github.io/yellowpaper/paper.pdf">以太坊黄皮书（英文版）</a></li><li><a href="https://github.com/wanshan1024/ethereum_yellowpaper/blob/master/ethereum_yellow_paper_cn.pdf">以太坊黄皮书（中文版）</a></li><li><a href="https://github.com/ZtesoftCS/go-ethereum-code-analysis">分析参考资料</a></li><li><a href="https://segmentfault.com/a/1190000016050921">博客参考资料</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-以太坊源码分析-RPC</title>
      <link href="/2021/07/05/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-RPC/"/>
      <url>/2021/07/05/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-RPC/</url>
      
        <content type="html"><![CDATA[<h1 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h1><p>源码分析使用的版本为：<a href="https://github.com/ethereum/go-ethereum/tree/v1.10.3">v1.10.3</a></p><h2 id="RPC包的官方文档"><a href="#RPC包的官方文档" class="headerlink" title="RPC包的官方文档"></a>RPC包的官方文档</h2><p>Package rpc provides access to the exported methods of an object across a network<br>or other I/O connection. After creating a server instance objects can be registered,<br>making it visible from the outside. Exported methods that follow specific<br>conventions can be called remotely. It also has support for the publish/subscribe<br>pattern.</p><p>rpc包提供这样一种能力，可以通过网络或者其他I/O连接，可以访问对象被导出的方法。创建一个服务器之后，对象可以注册到服务器上，然后可以让外界访问。通过脂肪方式导出的方法可以被远程调用。 同时还支持发布/订阅模式。</p><p>Methods that satisfy the following criteria are made available for remote access:</p><ul><li>object must be exported</li><li>method must be exported</li><li>method returns 0, 1 (response or error) or 2 (response and error) values</li><li>method argument(s) must be exported or builtin types</li><li>method returned value(s) must be exported or builtin types</li></ul><p>符合以下标准的方法可用于远程访问：</p><ul><li>对象必须导出</li><li>方法必须导出</li><li>方法返回0，1（响应或错误）或2（响应和错误）值</li><li>方法参数必须导出或是内置类型</li><li>方法返回值必须导出或是内置类型</li></ul><p>An example method:</p><pre><code>func (s *CalcService) Add(a, b int) (int, error)</code></pre><p>When the returned error isn’t nil the returned integer is ignored and the error is<br>send back to the client. Otherwise the returned integer is send back to the client.</p><p>当返回的error不等于nil的时候，返回的整形值被忽略，error被发送回客户端。 否则整形的会返回被发送回客户端。</p><p>Optional arguments are supported by accepting pointer values as arguments. E.g.<br>if we want to do the addition in an optional finite field we can accept a mod<br>argument as pointer value.<br>通过提供指针类型的参数可以使得方法支持可选参数。后面有点看不懂了。</p><pre><code> func (s *CalService) Add(a, b int, mod *int) (int, error)</code></pre><p>This RPC method can be called with 2 integers and a null value as third argument.<br>In that case the mod argument will be nil. Or it can be called with 3 integers,<br>in that case mod will be pointing to the given third argument. Since the optional<br>argument is the last argument the RPC package will also accept 2 integers as<br>arguments. It will pass the mod argument as nil to the RPC method.</p><p>RPC方法可以通过传两个integer和一个null值作为第三个参数来调用。在这种情况下mod参数会被设置为nil。或者可以传递三个integer,这样mod会被设置为指向第三个参数。尽管可选的参数是最后的参数，RPC包任然接收传递两个integer,这样mod参数会被设置为nil。</p><p>The server offers the ServeCodec method which accepts a ServerCodec instance. It will<br>read requests from the codec, process the request and sends the response back to the<br>client using the codec. The server can execute requests concurrently. Responses<br>can be sent back to the client out of order.</p><p>server提供了ServerCodec方法，这个方法接收ServerCodec实例作为参数。 服务器会使用codec读取请求，处理请求，然后通过codec发送回应给客户端。server可以并发的执行请求。response的顺序可能和request的顺序不一致。</p><pre><code>//An example server which uses the JSON codec: type CalculatorService struct {} func (s *CalculatorService) Add(a, b int) int {    return a + b } func (s *CalculatorService Div(a, b int) (int, error) {    if b == 0 {        return 0, errors.New("divide by zero")    }    return a/b, nil }calculator := new(CalculatorService) server := NewServer() server.RegisterName("calculator", calculator") l, _ := net.ListenUnix("unix", &amp;net.UnixAddr{Net: "unix", Name: "/tmp/calculator.sock"}) for {    c, _ := l.AcceptUnix()    codec := v2.NewJSONCodec(c)    go server.ServeCodec(codec) }</code></pre><p>The package also supports the publish subscribe pattern through the use of subscriptions.<br>A method that is considered eligible for notifications must satisfy the following criteria:</p><ul><li>object must be exported</li><li>method must be exported</li><li>first method argument type must be context.Context</li><li>method argument(s) must be exported or builtin types</li><li>method must return the tuple Subscription, error</li></ul><p>该软件包还通过使用订阅来支持发布订阅模式。<br>被认为符合通知条件的方法必须满足以下条件：</p><ul><li>对象必须导出</li><li>方法必须导出</li><li>第一个方法参数类型必须是context.Context</li><li>方法参数必须导出或内置类型</li><li>方法必须返回元组订阅，错误</li></ul><p>An example method:</p><pre><code> func (s *BlockChainService) NewBlocks(ctx context.Context) (Subscription, error) {     ... }</code></pre><p>Subscriptions are deleted when:</p><ul><li>the user sends an unsubscribe request</li><li>the connection which was used to create the subscription is closed. This can be initiated<br>by the client and server. The server will close the connection on an write error or when<br>the queue of buffered notifications gets too big.</li></ul><p>订阅在下面几种情况下会被删除</p><ul><li>用户发送了一个取消订阅的请求</li><li>创建订阅的连接被关闭。这种情况可能由客户端或者服务器触发。 服务器在写入出错或者是通知队列长度太大的时候会选择关闭连接。</li></ul><h2 id="RPC包的大致结构"><a href="#RPC包的大致结构" class="headerlink" title="RPC包的大致结构"></a>RPC包的大致结构</h2><p>网络协议 channels和Json格式的请求和回应的编码和解码都是同时与服务端和客户端打交道的类。网络协议channels主要提供连接和数据传输的功能。 json格式的编码和解码主要提供请求和回应的序列化和反序列化功能(Json -&gt; Go的对象)。</p><p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-LKcBwinM-1625486180219)(picture/rpc_1.png)]</p><h2 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h2><h3 id="server-go"><a href="#server-go" class="headerlink" title="server.go"></a>server.go</h3><p>server.go主要实现了RPC服务端的核心逻辑。 包括RPC方法的注册， 读取请求，处理请求，发送回应等逻辑。<br>server的核心数据结构是Server结构体。 services字段是一个map，记录了所有注册的方法和类。 run参数是用来控制Server的运行和停止的。 codecs是一个set。 用来存储所有的编码解码器，其实就是所有的连接。 codecsMu是用来保护多线程访问codecs的锁。</p><p>services字段的value类型是service类型。 service代表了一个注册到Server的实例，是一个对象和方法的组合。 service字段的name代表了service的namespace， typ实例的类型， callbacks是实例的回调方法， subscriptions是实例的订阅方法。</p><pre><code>type serviceRegistry map[string]*service // collection of servicestype callbacks map[string]*callback      // collection of RPC callbackstype subscriptions map[string]*callback type Server struct {    services serviceRegistry    run      int32    codecsMu sync.Mutex    codecs   *set.Set}// callback is a method callback which was registered in the servertype callback struct {    rcvr        reflect.Value  // receiver of method    method      reflect.Method // callback    argTypes    []reflect.Type // input argument types    hasCtx      bool           // method's first argument is a context (not included in argTypes)    errPos      int            // err return idx, of -1 when method cannot return error    isSubscribe bool           // indication if the callback is a subscription}// service represents a registered objecttype service struct {    name          string        // name for service    typ           reflect.Type  // receiver type    callbacks     callbacks     // registered handlers    subscriptions subscriptions // available subscriptions/notifications}</code></pre><p>Server的创建，Server创建的时候通过调用server.RegisterName把自己的实例注册上来，提供一些RPC服务的元信息。</p><pre><code>const MetadataApi = "rpc"// NewServer will create a new server instance with no registered handlers.func NewServer() *Server {    server := &amp;Server{        services: make(serviceRegistry),        codecs:   set.New(),        run:      1,    }    // register a default service which will provide meta information about the RPC service such as the services and    // methods it offers.    rpcService := &amp;RPCService{server}    server.RegisterName(MetadataApi, rpcService)    return server}</code></pre><p>服务注册server.RegisterName，RegisterName方法会通过传入的参数来创建一个service对象，如过传入的rcvr实例没有找到任何合适的方法，那么会返回错误。 如果没有错误，就把创建的service实例加入serviceRegistry。</p><pre><code>// RegisterName will create a service for the given rcvr type under the given name. When no methods on the given rcvr// match the criteria to be either a RPC method or a subscription an error is returned. Otherwise a new service is// created and added to the service collection this server instance serves.func (s *Server) RegisterName(name string, rcvr interface{}) error {    if s.services == nil {        s.services = make(serviceRegistry)    }    svc := new(service)    svc.typ = reflect.TypeOf(rcvr)    rcvrVal := reflect.ValueOf(rcvr)    if name == "" {        return fmt.Errorf("no service name for type %s", svc.typ.String())    }    //如果实例的类名不是导出的(类名的首字母大写)，就返回错误。    if !isExported(reflect.Indirect(rcvrVal).Type().Name()) {        return fmt.Errorf("%s is not exported", reflect.Indirect(rcvrVal).Type().Name())    }    //通过反射信息找到合适的callbacks 和subscriptions方法    methods, subscriptions := suitableCallbacks(rcvrVal, svc.typ)    //如果这个名字当前已经被注册过了，那么如果有同名的方法就用新的替代，否者直接插入。    // already a previous service register under given sname, merge methods/subscriptions    if regsvc, present := s.services[name]; present {        if len(methods) == 0 &amp;&amp; len(subscriptions) == 0 {            return fmt.Errorf("Service %T doesn't have any suitable methods/subscriptions to expose", rcvr)        }        for _, m := range methods {            regsvc.callbacks[formatName(m.method.Name)] = m        }        for _, s := range subscriptions {            regsvc.subscriptions[formatName(s.method.Name)] = s        }        return nil    }    svc.name = name    svc.callbacks, svc.subscriptions = methods, subscriptions    if len(svc.callbacks) == 0 &amp;&amp; len(svc.subscriptions) == 0 {        return fmt.Errorf("Service %T doesn't have any suitable methods/subscriptions to expose", rcvr)    }    s.services[svc.name] = svc    return nil}</code></pre><p>通过反射信息找出合适的方法，suitableCallbacks，这个方法在utils.go里面。 这个方法会遍历这个类型的所有方法，找到适配RPC callback或者subscription callback类型标准的方法并返回。关于RPC的标准，请参考文档开头的RPC标准。</p><pre><code>// suitableCallbacks iterates over the methods of the given type. It will determine if a method satisfies the criteria// for a RPC callback or a subscription callback and adds it to the collection of callbacks or subscriptions. See server// documentation for a summary of these criteria.func suitableCallbacks(rcvr reflect.Value, typ reflect.Type) (callbacks, subscriptions) {    callbacks := make(callbacks)    subscriptions := make(subscriptions)METHODS:    for m := 0; m &lt; typ.NumMethod(); m++ {        method := typ.Method(m)        mtype := method.Type        mname := formatName(method.Name)        if method.PkgPath != "" { // method must be exported            continue        }        var h callback        h.isSubscribe = isPubSub(mtype)        h.rcvr = rcvr        h.method = method        h.errPos = -1        firstArg := 1        numIn := mtype.NumIn()        if numIn &gt;= 2 &amp;&amp; mtype.In(1) == contextType {            h.hasCtx = true            firstArg = 2        }        if h.isSubscribe {            h.argTypes = make([]reflect.Type, numIn-firstArg) // skip rcvr type            for i := firstArg; i &lt; numIn; i++ {                argType := mtype.In(i)                if isExportedOrBuiltinType(argType) {                    h.argTypes[i-firstArg] = argType                } else {                    continue METHODS                }            }            subscriptions[mname] = &amp;h            continue METHODS        }        // determine method arguments, ignore first arg since it's the receiver type        // Arguments must be exported or builtin types        h.argTypes = make([]reflect.Type, numIn-firstArg)        for i := firstArg; i &lt; numIn; i++ {            argType := mtype.In(i)            if !isExportedOrBuiltinType(argType) {                continue METHODS            }            h.argTypes[i-firstArg] = argType        }        // check that all returned values are exported or builtin types        for i := 0; i &lt; mtype.NumOut(); i++ {            if !isExportedOrBuiltinType(mtype.Out(i)) {                continue METHODS            }        }        // when a method returns an error it must be the last returned value        h.errPos = -1        for i := 0; i &lt; mtype.NumOut(); i++ {            if isErrorType(mtype.Out(i)) {                h.errPos = i                break            }        }        if h.errPos &gt;= 0 &amp;&amp; h.errPos != mtype.NumOut()-1 {            continue METHODS        }        switch mtype.NumOut() {        case 0, 1, 2:            if mtype.NumOut() == 2 &amp;&amp; h.errPos == -1 { // method must one return value and 1 error                continue METHODS            }            callbacks[mname] = &amp;h        }    }    return callbacks, subscriptions}</code></pre><p>server启动和服务， server的启动和服务这里参考ipc.go中的一部分代码。可以看到每Accept()一个链接，就启动一个goroutine调用srv.ServeCodec来进行服务，这里也可以看出JsonCodec的功能，Codec类似于装饰器模式，在连接外面包了一层。Codec会放在后续来介绍，这里先简单了解一下。</p><pre><code>func (srv *Server) ServeListener(l net.Listener) error {    for {        conn, err := l.Accept()        if err != nil {            return err        }        log.Trace(fmt.Sprint("accepted conn", conn.RemoteAddr()))        go srv.ServeCodec(NewJSONCodec(conn), OptionMethodInvocation|OptionSubscriptions)    }}</code></pre><p>ServeCodec, 这个方法很简单，提供了codec.Close的关闭功能。 serveRequest的第二个参数singleShot是控制长连接还是短连接的参数，如果singleShot为真，那么处理完一个请求之后会退出。 不过咱们的serveRequest方法是一个死循环，不遇到异常，或者客户端主动关闭，服务端是不会关闭的。 所以rpc提供的是长连接的功能。</p><pre><code>// ServeCodec reads incoming requests from codec, calls the appropriate callback and writes the// response back using the given codec. It will block until the codec is closed or the server is// stopped. In either case the codec is closed.func (s *Server) ServeCodec(codec ServerCodec, options CodecOption) {    defer codec.Close()    s.serveRequest(codec, false, options)}</code></pre><p>我们的重磅方法终于出场，serveRequest 这个方法就是Server的主要处理流程。从codec读取请求，找到对应的方法并调用，然后把回应写入codec。</p><p>部分标准库的代码可以参考网上的使用教程， sync.WaitGroup 实现了一个信号量的功能。 Context实现上下文管理。</p><pre><code>// serveRequest will reads requests from the codec, calls the RPC callback and// writes the response to the given codec.//// If singleShot is true it will process a single request, otherwise it will handle// requests until the codec returns an error when reading a request (in most cases// an EOF). It executes requests in parallel when singleShot is false.func (s *Server) serveRequest(codec ServerCodec, singleShot bool, options CodecOption) error {    var pend sync.WaitGroup    defer func() {        if err := recover(); err != nil {            const size = 64 &lt;&lt; 10            buf := make([]byte, size)            buf = buf[:runtime.Stack(buf, false)]            log.Error(string(buf))        }        s.codecsMu.Lock()        s.codecs.Remove(codec)        s.codecsMu.Unlock()    }()    ctx, cancel := context.WithCancel(context.Background())    defer cancel()    // if the codec supports notification include a notifier that callbacks can use    // to send notification to clients. It is thight to the codec/connection. If the    // connection is closed the notifier will stop and cancels all active subscriptions.    if options&amp;OptionSubscriptions == OptionSubscriptions {        ctx = context.WithValue(ctx, notifierKey{}, newNotifier(codec))    }    s.codecsMu.Lock()    if atomic.LoadInt32(&amp;s.run) != 1 { // server stopped        s.codecsMu.Unlock()        return &amp;shutdownError{}    }    s.codecs.Add(codec)    s.codecsMu.Unlock()    // test if the server is ordered to stop    for atomic.LoadInt32(&amp;s.run) == 1 {        reqs, batch, err := s.readRequest(codec)        if err != nil {            // If a parsing error occurred, send an error            if err.Error() != "EOF" {                log.Debug(fmt.Sprintf("read error %v\n", err))                codec.Write(codec.CreateErrorResponse(nil, err))            }            // Error or end of stream, wait for requests and tear down            //这里主要是考虑多线程处理的时候等待所有的request处理完毕，            //每启动一个go线程会调用pend.Add(1)。             //处理完成后调用pend.Done()会减去1。当为0的时候，Wait()方法就会返回。            pend.Wait()            return nil        }        // check if server is ordered to shutdown and return an error        // telling the client that his request failed.        if atomic.LoadInt32(&amp;s.run) != 1 {            err = &amp;shutdownError{}            if batch {                resps := make([]interface{}, len(reqs))                for i, r := range reqs {                    resps[i] = codec.CreateErrorResponse(&amp;r.id, err)                }                codec.Write(resps)            } else {                codec.Write(codec.CreateErrorResponse(&amp;reqs[0].id, err))            }            return nil        }        // If a single shot request is executing, run and return immediately        //如果只执行一次，那么执行完成后返回。        if singleShot {            if batch {                s.execBatch(ctx, codec, reqs)            } else {                s.exec(ctx, codec, reqs[0])            }            return nil        }        // For multi-shot connections, start a goroutine to serve and loop back        pend.Add(1)        //启动线程对请求进行服务。        go func(reqs []*serverRequest, batch bool) {            defer pend.Done()            if batch {                s.execBatch(ctx, codec, reqs)            } else {                s.exec(ctx, codec, reqs[0])            }        }(reqs, batch)    }    return nil}</code></pre><p>readRequest方法，从codec读取请求，然后根据请求查找对应的方法组装成requests对象。<br>rpcRequest是codec返回的请求类型。j</p><pre><code>type rpcRequest struct {    service  string    method   string    id       interface{}    isPubSub bool    params   interface{}    err      Error // invalid batch element}</code></pre><p>serverRequest进行处理之后返回的request</p><pre><code>// serverRequest is an incoming requesttype serverRequest struct {    id            interface{}    svcname       string    callb         *callback    args          []reflect.Value    isUnsubscribe bool    err           Error}</code></pre><p>readRequest方法，从codec读取请求，对请求进行处理生成serverRequest对象返回。</p><pre><code>// readRequest requests the next (batch) request from the codec. It will return the collection// of requests, an indication if the request was a batch, the invalid request identifier and an// error when the request could not be read/parsed.func (s *Server) readRequest(codec ServerCodec) ([]*serverRequest, bool, Error) {    reqs, batch, err := codec.ReadRequestHeaders()    if err != nil {        return nil, batch, err    }    requests := make([]*serverRequest, len(reqs))    // 根据reqs构建requests    // verify requests    for i, r := range reqs {        var ok bool        var svc *service        if r.err != nil {            requests[i] = &amp;serverRequest{id: r.id, err: r.err}            continue        }        //如果请求是发送/订阅方面的请求，而且方法名称有_unsubscribe后缀。        if r.isPubSub &amp;&amp; strings.HasSuffix(r.method, unsubscribeMethodSuffix) {            requests[i] = &amp;serverRequest{id: r.id, isUnsubscribe: true}            argTypes := []reflect.Type{reflect.TypeOf("")} // expect subscription id as first arg            if args, err := codec.ParseRequestArguments(argTypes, r.params); err == nil {                requests[i].args = args            } else {                requests[i].err = &amp;invalidParamsError{err.Error()}            }            continue        }        //如果没有注册这个服务。        if svc, ok = s.services[r.service]; !ok { // rpc method isn't available            requests[i] = &amp;serverRequest{id: r.id, err: &amp;methodNotFoundError{r.service, r.method}}            continue        }        //如果是发布和订阅模式。 调用订阅方法。        if r.isPubSub { // eth_subscribe, r.method contains the subscription method name            if callb, ok := svc.subscriptions[r.method]; ok {                requests[i] = &amp;serverRequest{id: r.id, svcname: svc.name, callb: callb}                if r.params != nil &amp;&amp; len(callb.argTypes) &gt; 0 {                    argTypes := []reflect.Type{reflect.TypeOf("")}                    argTypes = append(argTypes, callb.argTypes...)                    if args, err := codec.ParseRequestArguments(argTypes, r.params); err == nil {                        requests[i].args = args[1:] // first one is service.method name which isn't an actual argument                    } else {                        requests[i].err = &amp;invalidParamsError{err.Error()}                    }                }            } else {                requests[i] = &amp;serverRequest{id: r.id, err: &amp;methodNotFoundError{r.method, r.method}}            }            continue        }        if callb, ok := svc.callbacks[r.method]; ok { // lookup RPC method            requests[i] = &amp;serverRequest{id: r.id, svcname: svc.name, callb: callb}            if r.params != nil &amp;&amp; len(callb.argTypes) &gt; 0 {                if args, err := codec.ParseRequestArguments(callb.argTypes, r.params); err == nil {                    requests[i].args = args                } else {                    requests[i].err = &amp;invalidParamsError{err.Error()}                }            }            continue        }        requests[i] = &amp;serverRequest{id: r.id, err: &amp;methodNotFoundError{r.service, r.method}}    }    return requests, batch, nil}</code></pre><p>exec和execBatch方法,调用s.handle方法对request进行处理。</p><pre><code>// exec executes the given request and writes the result back using the codec.func (s *Server) exec(ctx context.Context, codec ServerCodec, req *serverRequest) {    var response interface{}    var callback func()    if req.err != nil {        response = codec.CreateErrorResponse(&amp;req.id, req.err)    } else {        response, callback = s.handle(ctx, codec, req)    }    if err := codec.Write(response); err != nil {        log.Error(fmt.Sprintf("%v\n", err))        codec.Close()    }    // when request was a subscribe request this allows these subscriptions to be actived    if callback != nil {        callback()    }}// execBatch executes the given requests and writes the result back using the codec.// It will only write the response back when the last request is processed.func (s *Server) execBatch(ctx context.Context, codec ServerCodec, requests []*serverRequest) {    responses := make([]interface{}, len(requests))    var callbacks []func()    for i, req := range requests {        if req.err != nil {            responses[i] = codec.CreateErrorResponse(&amp;req.id, req.err)        } else {            var callback func()            if responses[i], callback = s.handle(ctx, codec, req); callback != nil {                callbacks = append(callbacks, callback)            }        }    }    if err := codec.Write(responses); err != nil {        log.Error(fmt.Sprintf("%v\n", err))        codec.Close()    }    // when request holds one of more subscribe requests this allows these subscriptions to be activated    for _, c := range callbacks {        c()    }}</code></pre><p>handle方法，执行一个request，然后返回response</p><pre><code>// handle executes a request and returns the response from the callback.func (s *Server) handle(ctx context.Context, codec ServerCodec, req *serverRequest) (interface{}, func()) {    if req.err != nil {        return codec.CreateErrorResponse(&amp;req.id, req.err), nil    }    //如果是取消订阅的消息。NotifierFromContext(ctx)获取之前我们存入ctx的notifier。    if req.isUnsubscribe { // cancel subscription, first param must be the subscription id        if len(req.args) &gt;= 1 &amp;&amp; req.args[0].Kind() == reflect.String {            notifier, supported := NotifierFromContext(ctx)            if !supported { // interface doesn't support subscriptions (e.g. http)                return codec.CreateErrorResponse(&amp;req.id, &amp;callbackError{ErrNotificationsUnsupported.Error()}), nil            }            subid := ID(req.args[0].String())            if err := notifier.unsubscribe(subid); err != nil {                return codec.CreateErrorResponse(&amp;req.id, &amp;callbackError{err.Error()}), nil            }            return codec.CreateResponse(req.id, true), nil        }        return codec.CreateErrorResponse(&amp;req.id, &amp;invalidParamsError{"Expected subscription id as first argument"}), nil    }    //如果是订阅消息。 那么创建订阅。并激活订阅。    if req.callb.isSubscribe {        subid, err := s.createSubscription(ctx, codec, req)        if err != nil {            return codec.CreateErrorResponse(&amp;req.id, &amp;callbackError{err.Error()}), nil        }        // active the subscription after the sub id was successfully sent to the client        activateSub := func() {            notifier, _ := NotifierFromContext(ctx)            notifier.activate(subid, req.svcname)        }        return codec.CreateResponse(req.id, subid), activateSub    }    // regular RPC call, prepare arguments    if len(req.args) != len(req.callb.argTypes) {        rpcErr := &amp;invalidParamsError{fmt.Sprintf("%s%s%s expects %d parameters, got %d",            req.svcname, serviceMethodSeparator, req.callb.method.Name,            len(req.callb.argTypes), len(req.args))}        return codec.CreateErrorResponse(&amp;req.id, rpcErr), nil    }    arguments := []reflect.Value{req.callb.rcvr}    if req.callb.hasCtx {        arguments = append(arguments, reflect.ValueOf(ctx))    }    if len(req.args) &gt; 0 {        arguments = append(arguments, req.args...)    }    //调用提供的rpc方法，并获取reply    // execute RPC method and return result    reply := req.callb.method.Func.Call(arguments)    if len(reply) == 0 {        return codec.CreateResponse(req.id, nil), nil    }    if req.callb.errPos &gt;= 0 { // test if method returned an error        if !reply[req.callb.errPos].IsNil() {            e := reply[req.callb.errPos].Interface().(error)            res := codec.CreateErrorResponse(&amp;req.id, &amp;callbackError{e.Error()})            return res, nil        }    }    return codec.CreateResponse(req.id, reply[0].Interface()), nil}</code></pre><h3 id="subscription-go-发布订阅模式。"><a href="#subscription-go-发布订阅模式。" class="headerlink" title="subscription.go 发布订阅模式。"></a>subscription.go 发布订阅模式。</h3><p>在之前的server.go中就有出现了一些发布订阅模式的代码， 在这里集中阐述一下。</p><p>我们在serveRequest的代码中，就有这样的代码。</p><pre><code>如果codec支持, 可以通过一个叫notifier的对象执行回调函数发送消息给客户端。他和codec/connection关系很紧密。 如果连接被关闭，那么notifier会关闭，并取消掉所有激活的订阅。// if the codec supports notification include a notifier that callbacks can use// to send notification to clients. It is thight to the codec/connection. If the// connection is closed the notifier will stop and cancels all active subscriptions.if options&amp;OptionSubscriptions == OptionSubscriptions {    ctx = context.WithValue(ctx, notifierKey{}, newNotifier(codec))}</code></pre><p>在服务一个客户端连接时候，调用newNotifier方法创建了一个notifier对象存储到ctx中。可以观察到Notifier对象保存了codec的实例，也就是说Notifier对象保存了网络连接，用来在需要的时候发送数据。</p><pre><code>// newNotifier creates a new notifier that can be used to send subscription// notifications to the client.func newNotifier(codec ServerCodec) *Notifier {    return &amp;Notifier{        codec:    codec,        active:   make(map[ID]*Subscription),        inactive: make(map[ID]*Subscription),    }}</code></pre><p>然后在handle方法中， 我们处理一类特殊的方法，这种方法被标识为isSubscribe. 调用createSubscription方法创建了了一个Subscription并调用notifier.activate方法存储到notifier的激活队列里面。 代码里面有一个技巧。 这个方法调用完成后并没有直接激活subscription，而是把激活部分的代码作为一个函数返回回去。然后在exec或者execBatch代码里面等待codec.CreateResponse(req.id, subid)这个response被发送给客户端之后被调用。避免客户端还没有收到subscription ID的时候就收到了subscription信息。</p><pre><code>if req.callb.isSubscribe {    subid, err := s.createSubscription(ctx, codec, req)    if err != nil {        return codec.CreateErrorResponse(&amp;req.id, &amp;callbackError{err.Error()}), nil    }    // active the subscription after the sub id was successfully sent to the client    activateSub := func() {        notifier, _ := NotifierFromContext(ctx)        notifier.activate(subid, req.svcname)    }    return codec.CreateResponse(req.id, subid), activateSub}</code></pre><p>createSubscription方法会调用指定的注册上来的方法，并得到回应。</p><pre><code>// createSubscription will call the subscription callback and returns the subscription id or error.func (s *Server) createSubscription(ctx context.Context, c ServerCodec, req *serverRequest) (ID, error) {    // subscription have as first argument the context following optional arguments    args := []reflect.Value{req.callb.rcvr, reflect.ValueOf(ctx)}    args = append(args, req.args...)    reply := req.callb.method.Func.Call(args)    if !reply[1].IsNil() { // subscription creation failed        return "", reply[1].Interface().(error)    }    return reply[0].Interface().(*Subscription).ID, nil}</code></pre><p>在来看看我们的activate方法，这个方法激活了subscription。 subscription在subscription ID被发送给客户端之后被激活，避免客户端还没有收到subscription ID的时候就收到了subscription信息。</p><pre><code>// activate enables a subscription. Until a subscription is enabled all// notifications are dropped. This method is called by the RPC server after// the subscription ID was sent to client. This prevents notifications being// send to the client before the subscription ID is send to the client.func (n *Notifier) activate(id ID, namespace string) {    n.subMu.Lock()    defer n.subMu.Unlock()    if sub, found := n.inactive[id]; found {        sub.namespace = namespace        n.active[id] = sub        delete(n.inactive, id)    }}</code></pre><p>我们再来看一个取消订阅的函数</p><pre><code>// unsubscribe a subscription.// If the subscription could not be found ErrSubscriptionNotFound is returned.func (n *Notifier) unsubscribe(id ID) error {    n.subMu.Lock()    defer n.subMu.Unlock()    if s, found := n.active[id]; found {        close(s.err)        delete(n.active, id)        return nil    }    return ErrSubscriptionNotFound}</code></pre><p>最后是一个发送订阅的函数，调用这个函数把数据发送到客户端， 这个也比较简单。</p><pre><code>// Notify sends a notification to the client with the given data as payload.// If an error occurs the RPC connection is closed and the error is returned.func (n *Notifier) Notify(id ID, data interface{}) error {    n.subMu.RLock()    defer n.subMu.RUnlock()    sub, active := n.active[id]    if active {        notification := n.codec.CreateNotification(string(id), sub.namespace, data)        if err := n.codec.Write(notification); err != nil {            n.codec.Close()            return err        }    }    return nil}</code></pre><p>如何使用建议通过subscription_test.go的TestNotifications来查看完整的流程。</p><h3 id="client-go-RPC客户端源码分析。"><a href="#client-go-RPC客户端源码分析。" class="headerlink" title="client.go  RPC客户端源码分析。"></a>client.go  RPC客户端源码分析。</h3><p>客户端的主要功能是把请求发送到服务端，然后接收回应，再把回应传递给调用者。</p><p>客户端的数据结构</p><pre><code>// Client represents a connection to an RPC server.type Client struct {    idCounter   uint32    //生成连接的函数，客户端会调用这个函数生成一个网络连接对象。    connectFunc func(ctx context.Context) (net.Conn, error)    //HTTP协议和非HTTP协议有不同的处理流程， HTTP协议不支持长连接， 只支持一个请求对应一个回应的这种模式，同时也不支持发布/订阅模式。     isHTTP      bool    // writeConn is only safe to access outside dispatch, with the    // write lock held. The write lock is taken by sending on    // requestOp and released by sending on sendDone.    //通过这里的注释可以看到，writeConn是调用这用来写入请求的网络连接对象，    //只有在dispatch方法外面调用才是安全的，而且需要通过给requestOp队列发送请求来获取锁，    //获取锁之后就可以把请求写入网络，写入完成后发送请求给sendDone队列来释放锁，供其它的请求使用。    writeConn net.Conn    // for dispatch    //下面有很多的channel，channel一般来说是goroutine之间用来通信的通道，后续会随着代码介绍channel是如何使用的。    close       chan struct{}    didQuit     chan struct{}                  // closed when client quits    reconnected chan net.Conn                  // where write/reconnect sends the new connection    readErr     chan error                     // errors from read    readResp    chan []*jsonrpcMessage         // valid messages from read    requestOp   chan *requestOp                // for registering response IDs    sendDone    chan error                     // signals write completion, releases write lock    respWait    map[string]*requestOp          // active requests    subs        map[string]*ClientSubscription // active subscriptions}</code></pre><p>newClient， 新建一个客户端。 通过调用connectFunc方法来获取一个网络连接，如果网络连接是httpConn对象的化，那么isHTTP设置为true。然后是对象的初始化， 如果是HTTP连接的化，直接返回，否者就启动一个goroutine调用dispatch方法。 dispatch方法是整个client的指挥中心，通过上面提到的channel来和其他的goroutine来进行通信，获取信息，根据信息做出各种决策。后续会详细介绍dispatch。 因为HTTP的调用方式非常简单， 这里先对HTTP的方式做一个简单的阐述。</p><pre><code>func newClient(initctx context.Context, connectFunc func(context.Context) (net.Conn, error)) (*Client, error) {    conn, err := connectFunc(initctx)    if err != nil {        return nil, err    }    _, isHTTP := conn.(*httpConn)    c := &amp;Client{        writeConn:   conn,        isHTTP:      isHTTP,        connectFunc: connectFunc,        close:       make(chan struct{}),        didQuit:     make(chan struct{}),        reconnected: make(chan net.Conn),        readErr:     make(chan error),        readResp:    make(chan []*jsonrpcMessage),        requestOp:   make(chan *requestOp),        sendDone:    make(chan error, 1),        respWait:    make(map[string]*requestOp),        subs:        make(map[string]*ClientSubscription),    }    if !isHTTP {        go c.dispatch(conn)    }    return c, nil}</code></pre><p>请求调用通过调用client的 Call方法来进行RPC调用。</p><pre><code>// Call performs a JSON-RPC call with the given arguments and unmarshals into// result if no error occurred.//// The result must be a pointer so that package json can unmarshal into it. You// can also pass nil, in which case the result is ignored.返回值必须是一个指针，这样才能把json值转换成对象。 如果你不关心返回值，也可以通过传nil来忽略。func (c *Client) Call(result interface{}, method string, args ...interface{}) error {    ctx := context.Background()    return c.CallContext(ctx, result, method, args...)}func (c *Client) CallContext(ctx context.Context, result interface{}, method string, args ...interface{}) error {    msg, err := c.newMessage(method, args...)    if err != nil {        return err    }    //构建了一个requestOp对象。 resp是读取返回的队列，队列的长度是1。    op := &amp;requestOp{ids: []json.RawMessage{msg.ID}, resp: make(chan *jsonrpcMessage, 1)}        if c.isHTTP {        err = c.sendHTTP(ctx, op, msg)    } else {        err = c.send(ctx, op, msg)    }    if err != nil {        return err    }    // dispatch has accepted the request and will close the channel it when it quits.    switch resp, err := op.wait(ctx); {    case err != nil:        return err    case resp.Error != nil:        return resp.Error    case len(resp.Result) == 0:        return ErrNoResult    default:        return json.Unmarshal(resp.Result, &amp;result)    }}</code></pre><p>sendHTTP,这个方法直接调用doRequest方法进行请求拿到回应。然后写入到resp队列就返回了。</p><pre><code>func (c *Client) sendHTTP(ctx context.Context, op *requestOp, msg interface{}) error {    hc := c.writeConn.(*httpConn)    respBody, err := hc.doRequest(ctx, msg)    if err != nil {        return err    }    defer respBody.Close()    var respmsg jsonrpcMessage    if err := json.NewDecoder(respBody).Decode(&amp;respmsg); err != nil {        return err    }    op.resp &lt;- &amp;respmsg    return nil}</code></pre><p>在看看上面的另一个方法 op.wait()方法，这个方法会查看两个队列的信息。如果是http那么从resp队列获取到回应就会直接返回。 这样整个HTTP的请求过程就完成了。 中间没有涉及到多线程问题，都在一个线程内部完成了。</p><pre><code>func (op *requestOp) wait(ctx context.Context) (*jsonrpcMessage, error) {    select {    case &lt;-ctx.Done():        return nil, ctx.Err()    case resp := &lt;-op.resp:        return resp, op.err    }}</code></pre><p>如果不是HTTP请求呢。 那处理的流程就比较复杂了， 还记得如果不是HTTP请求。在newClient的时候是启动了一个goroutine 调用了dispatch方法。 我们先看非http的 send方法。</p><p>从注释来看。 这个方法把op写入到requestOp这个队列，注意的是这个队列是没有缓冲区的，也就是说如果这个时候这个队列没有人处理的化，这个调用是会阻塞在这里的。 这就相当于一把锁，如果发送op到requestOp成功了就拿到了锁，可以继续下一步，下一步是调用write方法把请求的全部内容发送到网络上。然后发送消息给sendDone队列。sendDone可以看成是锁的释放，后续在dispatch方法里面会详细分析这个过程。 然后返回。返回之后方法会阻塞在op.wait方法里面。直到从op.resp队列收到一个回应，或者是收到一个ctx.Done()消息(这个消息一般会在完成或者是强制退出的时候获取到。)</p><pre><code>// send registers op with the dispatch loop, then sends msg on the connection.// if sending fails, op is deregistered.func (c *Client) send(ctx context.Context, op *requestOp, msg interface{}) error {    select {    case c.requestOp &lt;- op:        log.Trace("", "msg", log.Lazy{Fn: func() string {            return fmt.Sprint("sending ", msg)        }})        err := c.write(ctx, msg)        c.sendDone &lt;- err        return err    case &lt;-ctx.Done():        // This can happen if the client is overloaded or unable to keep up with        // subscription notifications.        return ctx.Err()    case &lt;-c.didQuit:        //已经退出，可能被调用了Close        return ErrClientQuit    }}</code></pre><p>dispatch方法</p><pre><code>// dispatch is the main loop of the client.// It sends read messages to waiting calls to Call and BatchCall// and subscription notifications to registered subscriptions.func (c *Client) dispatch(conn net.Conn) {    // Spawn the initial read loop.    go c.read(conn)    var (        lastOp        *requestOp    // tracks last send operation        requestOpLock = c.requestOp // nil while the send lock is held        reading       = true        // if true, a read loop is running    )    defer close(c.didQuit)    defer func() {        c.closeRequestOps(ErrClientQuit)        conn.Close()        if reading {            // Empty read channels until read is dead.            for {                select {                case &lt;-c.readResp:                case &lt;-c.readErr:                    return                }            }        }    }()    for {        select {        case &lt;-c.close:            return        // Read path.        case batch := &lt;-c.readResp:            //读取到一个回应。调用相应的方法处理            for _, msg := range batch {                switch {                case msg.isNotification():                    log.Trace("", "msg", log.Lazy{Fn: func() string {                        return fmt.Sprint("&lt;-readResp: notification ", msg)                    }})                    c.handleNotification(msg)                case msg.isResponse():                    log.Trace("", "msg", log.Lazy{Fn: func() string {                        return fmt.Sprint("&lt;-readResp: response ", msg)                    }})                    c.handleResponse(msg)                default:                    log.Debug("", "msg", log.Lazy{Fn: func() string {                        return fmt.Sprint("&lt;-readResp: dropping weird message", msg)                    }})                    // TODO: maybe close                }            }        case err := &lt;-c.readErr:            //接收到读取失败信息，这个是read线程传递过来的。            log.Debug(fmt.Sprintf("&lt;-readErr: %v", err))            c.closeRequestOps(err)            conn.Close()            reading = false        case newconn := &lt;-c.reconnected:            //接收到一个重连接信息            log.Debug(fmt.Sprintf("&lt;-reconnected: (reading=%t) %v", reading, conn.RemoteAddr()))            if reading {                //等待之前的连接读取完成。                // Wait for the previous read loop to exit. This is a rare case.                conn.Close()                &lt;-c.readErr            }            //开启阅读的goroutine            go c.read(newconn)            reading = true            conn = newconn        // Send path.        case op := &lt;-requestOpLock:            // Stop listening for further send ops until the current one is done.            //接收到一个requestOp消息，那么设置requestOpLock为空，            //这个时候如果有其他人也希望发送op到requestOp，会因为没有人处理而阻塞。            requestOpLock = nil            lastOp = op            //把这个op加入等待队列。            for _, id := range op.ids {                c.respWait[string(id)] = op            }        case err := &lt;-c.sendDone:            //当op的请求信息已经发送到网络上。会发送信息到sendDone。如果发送过程出错，那么err !=nil。            if err != nil {                // Remove response handlers for the last send. We remove those here                // because the error is already handled in Call or BatchCall. When the                // read loop goes down, it will signal all other current operations.                //把所有的id从等待队列删除。                for _, id := range lastOp.ids {                    delete(c.respWait, string(id))                }            }            // Listen for send ops again.            //重新开始处理requestOp的消息。            requestOpLock = c.requestOp            lastOp = nil        }    }}</code></pre><p>下面通过下面这种图来说明dispatch的主要流程。下面图片中圆形是线程。 蓝色矩形是channel。 箭头代表了channel的数据流动方向。</p><p>[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-M5kvNmUc-1625486180224)(picture/rpc_2.png)]</p><ul><li>多线程串行发送请求到网络上的流程 首先发送requestOp请求到dispatch获取到锁， 然后把请求信息写入到网络，然后发送sendDone信息到dispatch解除锁。 通过requestOp和sendDone这两个channel以及dispatch代码的配合完成了串行的发送请求到网络上的功能。</li><li>读取返回信息然后返回给调用者的流程。 把请求信息发送到网络上之后， 内部的goroutine read会持续不断的从网络上读取信息。 read读取到返回信息之后，通过readResp队列发送给dispatch。 dispatch查找到对应的调用者，然后把返回信息写入调用者的resp队列中。完成返回信息的流程。</li><li>重连接流程。 重连接在外部调用者写入失败的情况下被外部调用者主动调用。 调用完成后发送新的连接给dispatch。 dispatch收到新的连接之后，会终止之前的连接，然后启动新的read goroutine来从新的连接上读取信息。</li><li>关闭流程。 调用者调用Close方法，Close方法会写入信息到close队列。 dispatch接收到close信息之后。 关闭didQuit队列，关闭连接，等待read goroutine停止。 所有等待在didQuit队列上面的客户端调用全部返回。</li></ul><h4 id="客户端-订阅模式的特殊处理"><a href="#客户端-订阅模式的特殊处理" class="headerlink" title="客户端 订阅模式的特殊处理"></a>客户端 订阅模式的特殊处理</h4><p>上面提到的主要流程是方法调用的流程。 以太坊的RPC框架还支持发布和订阅的模式。</p><p>我们先看看订阅的方法，以太坊提供了几种主要service的订阅方式(EthSubscribe ShhSubscribe).同时也提供了自定义服务的订阅方法(Subscribe)，</p><pre><code>// EthSubscribe registers a subscripion under the "eth" namespace.func (c *Client) EthSubscribe(ctx context.Context, channel interface{}, args ...interface{}) (*ClientSubscription, error) {    return c.Subscribe(ctx, "eth", channel, args...)}// ShhSubscribe registers a subscripion under the "shh" namespace.func (c *Client) ShhSubscribe(ctx context.Context, channel interface{}, args ...interface{}) (*ClientSubscription, error) {    return c.Subscribe(ctx, "shh", channel, args...)}// Subscribe calls the "&lt;namespace&gt;_subscribe" method with the given arguments,// registering a subscription. Server notifications for the subscription are// sent to the given channel. The element type of the channel must match the// expected type of content returned by the subscription.//// The context argument cancels the RPC request that sets up the subscription but has no// effect on the subscription after Subscribe has returned.//// Slow subscribers will be dropped eventually. Client buffers up to 8000 notifications// before considering the subscriber dead. The subscription Err channel will receive// ErrSubscriptionQueueOverflow. Use a sufficiently large buffer on the channel or ensure// that the channel usually has at least one reader to prevent this issue.//Subscribe会使用传入的参数调用"&lt;namespace&gt;_subscribe"方法来订阅指定的消息。 //服务器的通知会写入channel参数指定的队列。 channel参数必须和返回的类型相同。 //ctx参数可以用来取消RPC的请求，但是如果订阅已经完成就不会有效果了。 //处理速度太慢的订阅者的消息会被删除，每个客户端有8000个消息的缓存。func (c *Client) Subscribe(ctx context.Context, namespace string, channel interface{}, args ...interface{}) (*ClientSubscription, error) {    // Check type of channel first.    chanVal := reflect.ValueOf(channel)    if chanVal.Kind() != reflect.Chan || chanVal.Type().ChanDir()&amp;reflect.SendDir == 0 {        panic("first argument to Subscribe must be a writable channel")    }    if chanVal.IsNil() {        panic("channel given to Subscribe must not be nil")    }    if c.isHTTP {        return nil, ErrNotificationsUnsupported    }    msg, err := c.newMessage(namespace+subscribeMethodSuffix, args...)    if err != nil {        return nil, err    }    //requestOp的参数和Call调用的不一样。 多了一个参数sub.    op := &amp;requestOp{        ids:  []json.RawMessage{msg.ID},        resp: make(chan *jsonrpcMessage),        sub:  newClientSubscription(c, namespace, chanVal),    }    // Send the subscription request.    // The arrival and validity of the response is signaled on sub.quit.    if err := c.send(ctx, op, msg); err != nil {        return nil, err    }    if _, err := op.wait(ctx); err != nil {        return nil, err    }    return op.sub, nil}</code></pre><p>newClientSubscription方法，这个方法创建了一个新的对象ClientSubscription，这个对象把传入的channel参数保存起来。 然后自己又创建了三个chan对象。后续会对详细介绍这三个chan对象</p><pre><code>func newClientSubscription(c *Client, namespace string, channel reflect.Value) *ClientSubscription {    sub := &amp;ClientSubscription{        client:    c,        namespace: namespace,        etype:     channel.Type().Elem(),        channel:   channel,        quit:      make(chan struct{}),        err:       make(chan error, 1),        in:        make(chan json.RawMessage),    }    return sub}</code></pre><p>从上面的代码可以看出。订阅过程根Call过程差不多，构建一个订阅请求。调用send发送到网络上，然后等待返回。 我们通过dispatch对返回结果的处理来看看订阅和Call的不同。</p><pre><code>func (c *Client) handleResponse(msg *jsonrpcMessage) {    op := c.respWait[string(msg.ID)]    if op == nil {        log.Debug(fmt.Sprintf("unsolicited response %v", msg))        return    }    delete(c.respWait, string(msg.ID))    // For normal responses, just forward the reply to Call/BatchCall.    如果op.sub是nil，普通的RPC请求，这个字段的值是空白的，只有订阅请求才有值。    if op.sub == nil {        op.resp &lt;- msg        return    }    // For subscription responses, start the subscription if the server    // indicates success. EthSubscribe gets unblocked in either case through    // the op.resp channel.    defer close(op.resp)    if msg.Error != nil {        op.err = msg.Error        return    }    if op.err = json.Unmarshal(msg.Result, &amp;op.sub.subid); op.err == nil {        //启动一个新的goroutine 并把op.sub.subid记录起来。        go op.sub.start()        c.subs[op.sub.subid] = op.sub    }}</code></pre><p>op.sub.start方法。 这个goroutine专门用来处理订阅消息。主要的功能是从in队列里面获取订阅消息，然后把订阅消息放到buffer里面。 如果能够数据能够发送。就从buffer里面发送一些数据给用户传入的那个channel。 如果buffer超过指定的大小，就丢弃。</p><pre><code>func (sub *ClientSubscription) start() {    sub.quitWithError(sub.forward())}func (sub *ClientSubscription) forward() (err error, unsubscribeServer bool) {    cases := []reflect.SelectCase{        {Dir: reflect.SelectRecv, Chan: reflect.ValueOf(sub.quit)},        {Dir: reflect.SelectRecv, Chan: reflect.ValueOf(sub.in)},        {Dir: reflect.SelectSend, Chan: sub.channel},    }    buffer := list.New()    defer buffer.Init()    for {        var chosen int        var recv reflect.Value        if buffer.Len() == 0 {            // Idle, omit send case.            chosen, recv, _ = reflect.Select(cases[:2])        } else {            // Non-empty buffer, send the first queued item.            cases[2].Send = reflect.ValueOf(buffer.Front().Value)            chosen, recv, _ = reflect.Select(cases)        }        switch chosen {        case 0: // &lt;-sub.quit            return nil, false        case 1: // &lt;-sub.in            val, err := sub.unmarshal(recv.Interface().(json.RawMessage))            if err != nil {                return err, true            }            if buffer.Len() == maxClientSubscriptionBuffer {                return ErrSubscriptionQueueOverflow, true            }            buffer.PushBack(val)        case 2: // sub.channel&lt;-            cases[2].Send = reflect.Value{} // Don't hold onto the value.            buffer.Remove(buffer.Front())        }    }}</code></pre><p>当接收到一条Notification消息的时候会调用handleNotification方法。会把消息传送给in队列。</p><pre><code>func (c *Client) handleNotification(msg *jsonrpcMessage) {    if !strings.HasSuffix(msg.Method, notificationMethodSuffix) {        log.Debug(fmt.Sprint("dropping non-subscription message: ", msg))        return    }    var subResult struct {        ID     string          `json:"subscription"`        Result json.RawMessage `json:"result"`    }    if err := json.Unmarshal(msg.Params, &amp;subResult); err != nil {        log.Debug(fmt.Sprint("dropping invalid subscription message: ", msg))        return    }    if c.subs[subResult.ID] != nil {        c.subs[subResult.ID].deliver(subResult.Result)    }}func (sub *ClientSubscription) deliver(result json.RawMessage) (ok bool) {    select {    case sub.in &lt;- result:        return true    case &lt;-sub.quit:        return false    }}</code></pre><h1 id="参考资料地址"><a href="#参考资料地址" class="headerlink" title="参考资料地址"></a>参考资料地址</h1><ul><li><a href="https://ethereum.org/en/whitepaper">以太坊白皮书</a></li><li><a href="https://ethereum.github.io/yellowpaper/paper.pdf">以太坊黄皮书（英文版）</a></li><li><a href="https://github.com/wanshan1024/ethereum_yellowpaper/blob/master/ethereum_yellow_paper_cn.pdf">以太坊黄皮书（中文版）</a></li><li><a href="https://github.com/ZtesoftCS/go-ethereum-code-analysis">分析参考资料</a></li><li><a href="https://segmentfault.com/a/1190000016050921">博客参考资料</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-ethdb源码分析</title>
      <link href="/2021/06/05/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-ethdb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/06/05/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-ethdb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h1><p>源码分析使用的版本为：<a href="https://github.com/ethereum/go-ethereum/tree/v1.10.3">v1.10.3</a></p><h1 id="ethdb源码分析"><a href="#ethdb源码分析" class="headerlink" title="ethdb源码分析"></a>ethdb源码分析</h1><p>go-ethereum所有的数据存储在levelDB这个Google开源的KeyValue文件数据库中，整个区块链的所有数据都存储在一个levelDB的数据库中，levelDB支持按照文件大小切分文件的功能，所以我们看到的区块链的数据都是一个一个小文件，其实这些小文件都是同一个levelDB实例。这里简单的看下levelDB的go封装代码。</p><p>levelDB官方网站介绍的特点</p><p>特点：</p><ul><li>key和value都是任意长度的字节数组；</li><li>entry（即一条K-V记录）默认是按照key的字典顺序存储的，当然开发者也可以重载这个排序函数；</li><li>提供的基本操作接口：Put()、Delete()、Get()、Batch()；</li><li>支持批量操作以原子操作进行；</li><li>可以创建数据全景的snapshot(快照)，并允许在快照中查找数据；</li><li>可以通过前向（或后向）迭代器遍历数据（迭代器会隐含的创建一个snapshot）；</li><li>自动使用Snappy压缩数据；</li><li>可移植性；</li></ul><p>限制：</p><ul><li>非关系型数据模型（NoSQL），不支持sql语句，也不支持索引；</li><li>一次只允许一个进程访问一个特定的数据库；</li><li>没有内置的C/S架构，但开发者可以使用LevelDB库自己封装一个server；</li></ul><p>源码所在的目录在ethereum/ethdb目录。代码比较简单， 分为下面几个文件</p><ul><li>testsuite.go</li><li>leveldb.go</li><li>leveldb_test.go</li><li>memorydb.go 供测试用的基于内存的数据库，不会持久化为文件，仅供测试</li><li>memorydb_test.go</li><li>batch.go</li><li>database.go levelDB的封装代码</li><li>iterator.go</li></ul><p>看下面的代码，基本上定义了KeyValue数据库的基本操作， Put， Get， Has， Delete等基本操作，levelDB是不支持SQL的，基本可以理解为数据结构里面的Map。</p><pre><code class="go">package ethdbconst IdealBatchSize = 100 * 1024// Putter wraps the database write operation supported by both batches and regular databases.//Putter接口定义了批量操作和普通操作的写入接口type Putter interface {    Put(key []byte, value []byte) error}// Database wraps all database operations. All methods are safe for concurrent use.//数据库接口定义了所有的数据库操作， 所有的方法都是多线程安全的。type Database interface {    Putter    Get(key []byte) ([]byte, error)    Has(key []byte) (bool, error)    Delete(key []byte) error    Close()    NewBatch() Batch}// Batch is a write-only database that commits changes to its host database// when Write is called. Batch cannot be used concurrently.//批量操作接口，不能多线程同时使用，当Write方法被调用的时候，数据库会提交写入的更改。type Batch interface {    Putter    ValueSize() int // amount of data in the batch    Write() error}</code></pre><h2 id="memory-database-go"><a href="#memory-database-go" class="headerlink" title="memory_database.go"></a>memory_database.go</h2><p>这个基本上就是封装了一个内存的Map结构。然后使用了一把锁来对多线程进行资源的保护。</p><pre><code class="go">type MemDatabase struct {    db   map[string][]byte    lock sync.RWMutex}func NewMemDatabase() (*MemDatabase, error) {    return &amp;MemDatabase{        db: make(map[string][]byte),    }, nil}func (db *MemDatabase) Put(key []byte, value []byte) error {    db.lock.Lock()    defer db.lock.Unlock()    db.db[string(key)] = common.CopyBytes(value)    return nil}func (db *MemDatabase) Has(key []byte) (bool, error) {    db.lock.RLock()    defer db.lock.RUnlock()    _, ok := db.db[string(key)]    return ok, nil}</code></pre><p>然后是Batch的操作。也比较简单，一看便明白。</p><pre><code class="go">type kv struct{ k, v []byte }type memBatch struct {    db     *MemDatabase    writes []kv    size   int}func (b *memBatch) Put(key, value []byte) error {    b.writes = append(b.writes, kv{common.CopyBytes(key), common.CopyBytes(value)})    b.size += len(value)    return nil}func (b *memBatch) Write() error {    b.db.lock.Lock()    defer b.db.lock.Unlock()    for _, kv := range b.writes {        b.db.db[string(kv.k)] = kv.v    }    return nil}</code></pre><h2 id="database-go"><a href="#database-go" class="headerlink" title="database.go"></a>database.go</h2><p>这个就是实际ethereum客户端使用的代码， 封装了levelDB的接口。</p><pre><code class="go">import (    "strconv"    "strings"    "sync"    "time"    "github.com/ethereum/go-ethereum/log"    "github.com/ethereum/go-ethereum/metrics"    "github.com/syndtr/goleveldb/leveldb"    "github.com/syndtr/goleveldb/leveldb/errors"    "github.com/syndtr/goleveldb/leveldb/filter"    "github.com/syndtr/goleveldb/leveldb/iterator"    "github.com/syndtr/goleveldb/leveldb/opt"    gometrics "github.com/rcrowley/go-metrics")</code></pre><p>使用了github.com/syndtr/goleveldb/leveldb的leveldb的封装，所以一些使用的文档可以在那里找到。可以看到，数据结构主要增加了很多的Mertrics用来记录数据库的使用情况，增加了quitChan用来处理停止时候的一些情况，这个后面会分析。如果下面代码可能有疑问的地方应该再Filter: filter.NewBloomFilter(10)这个可以暂时不用关注，这个是levelDB里面用来进行性能优化的一个选项，可以不用理会。</p><pre><code class="go">type LDBDatabase struct {    fn string      // filename for reporting    db *leveldb.DB // LevelDB instance    getTimer       gometrics.Timer // Timer for measuring the database get request counts and latencies    putTimer       gometrics.Timer // Timer for measuring the database put request counts and latencies    ...metrics     quitLock sync.Mutex      // Mutex protecting the quit channel access    quitChan chan chan error // Quit channel to stop the metrics collection before closing the database    log log.Logger // Contextual logger tracking the database path}// NewLDBDatabase returns a LevelDB wrapped object.func NewLDBDatabase(file string, cache int, handles int) (*LDBDatabase, error) {    logger := log.New("database", file)    // Ensure we have some minimal caching and file guarantees    if cache &lt; 16 {        cache = 16    }    if handles &lt; 16 {        handles = 16    }    logger.Info("Allocated cache and file handles", "cache", cache, "handles", handles)    // Open the db and recover any potential corruptions    db, err := leveldb.OpenFile(file, &amp;opt.Options{        OpenFilesCacheCapacity: handles,        BlockCacheCapacity:     cache / 2 * opt.MiB,        WriteBuffer:            cache / 4 * opt.MiB, // Two of these are used internally        Filter:                 filter.NewBloomFilter(10),    })    if _, corrupted := err.(*errors.ErrCorrupted); corrupted {        db, err = leveldb.RecoverFile(file, nil)    }    // (Re)check for errors and abort if opening of the db failed    if err != nil {        return nil, err    }    return &amp;LDBDatabase{        fn:  file,        db:  db,        log: logger,    }, nil}</code></pre><p>再看看下面的Put和Has的代码，因为github.com/syndtr/goleveldb/leveldb封装之后的代码是支持多线程同时访问的，所以下面这些代码是不用使用锁来保护的，这个可以注意一下。这里面大部分的代码都是直接调用leveldb的封装，所以不详细介绍了。 有一个比较有意思的地方是Metrics代码。</p><pre><code class="go">// Put puts the given key / value to the queuefunc (db *LDBDatabase) Put(key []byte, value []byte) error {    // Measure the database put latency, if requested    if db.putTimer != nil {        defer db.putTimer.UpdateSince(time.Now())    }    // Generate the data to write to disk, update the meter and write    //value = rle.Compress(value)    if db.writeMeter != nil {        db.writeMeter.Mark(int64(len(value)))    }    return db.db.Put(key, value, nil)}func (db *LDBDatabase) Has(key []byte) (bool, error) {    return db.db.Has(key, nil)}</code></pre><h2 id="Metrics的处理"><a href="#Metrics的处理" class="headerlink" title="Metrics的处理"></a>Metrics的处理</h2><p>之前在创建NewLDBDatabase的时候，并没有初始化内部的很多Mertrics，这个时候Mertrics是为nil的。初始化Mertrics是在Meter方法中。外部传入了一个prefix参数，然后创建了各种Mertrics(具体如何创建Merter，会后续在Meter专题进行分析),然后创建了quitChan。 最后启动了一个线程调用了db.meter方法。</p><pre><code class="go">// Meter configures the database metrics collectors andfunc (db *LDBDatabase) Meter(prefix string) {    // Short circuit metering if the metrics system is disabled    if !metrics.Enabled {        return    }    // Initialize all the metrics collector at the requested prefix    db.getTimer = metrics.NewTimer(prefix + "user/gets")    db.putTimer = metrics.NewTimer(prefix + "user/puts")    db.delTimer = metrics.NewTimer(prefix + "user/dels")    db.missMeter = metrics.NewMeter(prefix + "user/misses")    db.readMeter = metrics.NewMeter(prefix + "user/reads")    db.writeMeter = metrics.NewMeter(prefix + "user/writes")    db.compTimeMeter = metrics.NewMeter(prefix + "compact/time")    db.compReadMeter = metrics.NewMeter(prefix + "compact/input")    db.compWriteMeter = metrics.NewMeter(prefix + "compact/output")    // Create a quit channel for the periodic collector and run it    db.quitLock.Lock()    db.quitChan = make(chan chan error)    db.quitLock.Unlock()    go db.meter(3 * time.Second)}</code></pre><p>这个方法每3秒钟获取一次leveldb内部的计数器，然后把他们公布到metrics子系统。 这是一个无限循环的方法， 直到quitChan收到了一个退出信号。</p><pre><code class="go">// meter periodically retrieves internal leveldb counters and reports them to// the metrics subsystem.// This is how a stats table look like (currently)://下面的注释就是我们调用 db.db.GetProperty("leveldb.stats")返回的字符串，后续的代码需要解析这个字符串并把信息写入到Meter中。//   Compactions//    Level |   Tables   |    Size(MB)   |    Time(sec)  |    Read(MB)   |   Write(MB)//   -------+------------+---------------+---------------+---------------+---------------//      0   |          0 |       0.00000 |       1.27969 |       0.00000 |      12.31098//      1   |         85 |     109.27913 |      28.09293 |     213.92493 |     214.26294//      2   |        523 |    1000.37159 |       7.26059 |      66.86342 |      66.77884//      3   |        570 |    1113.18458 |       0.00000 |       0.00000 |       0.00000func (db *LDBDatabase) meter(refresh time.Duration) {    // Create the counters to store current and previous values    counters := make([][]float64, 2)    for i := 0; i &lt; 2; i++ {        counters[i] = make([]float64, 3)    }    // Iterate ad infinitum and collect the stats    for i := 1; ; i++ {        // Retrieve the database stats        stats, err := db.db.GetProperty("leveldb.stats")        if err != nil {            db.log.Error("Failed to read database stats", "err", err)            return        }        // Find the compaction table, skip the header        lines := strings.Split(stats, "\n")        for len(lines) &gt; 0 &amp;&amp; strings.TrimSpace(lines[0]) != "Compactions" {            lines = lines[1:]        }        if len(lines) &lt;= 3 {            db.log.Error("Compaction table not found")            return        }        lines = lines[3:]        // Iterate over all the table rows, and accumulate the entries        for j := 0; j &lt; len(counters[i%2]); j++ {            counters[i%2][j] = 0        }        for _, line := range lines {            parts := strings.Split(line, "|")            if len(parts) != 6 {                break            }            for idx, counter := range parts[3:] {                value, err := strconv.ParseFloat(strings.TrimSpace(counter), 64)                if err != nil {                    db.log.Error("Compaction entry parsing failed", "err", err)                    return                }                counters[i%2][idx] += value            }        }        // Update all the requested meters        if db.compTimeMeter != nil {            db.compTimeMeter.Mark(int64((counters[i%2][0] - counters[(i-1)%2][0]) * 1000 * 1000 * 1000))        }        if db.compReadMeter != nil {            db.compReadMeter.Mark(int64((counters[i%2][1] - counters[(i-1)%2][1]) * 1024 * 1024))        }        if db.compWriteMeter != nil {            db.compWriteMeter.Mark(int64((counters[i%2][2] - counters[(i-1)%2][2]) * 1024 * 1024))        }        // Sleep a bit, then repeat the stats collection        select {        case errc := &lt;-db.quitChan:            // Quit requesting, stop hammering the database            errc &lt;- nil            return        case &lt;-time.After(refresh):            // Timeout, gather a new set of stats        }    }}</code></pre><h1 id="参考资料地址"><a href="#参考资料地址" class="headerlink" title="参考资料地址"></a>参考资料地址</h1><ul><li><a href="https://ethereum.org/en/whitepaper">以太坊白皮书</a></li><li><a href="https://ethereum.github.io/yellowpaper/paper.pdf">以太坊黄皮书（英文版）</a></li><li><a href="https://github.com/wanshan1024/ethereum_yellowpaper/blob/master/ethereum_yellow_paper_cn.pdf">以太坊黄皮书（中文版）</a></li><li><a href="https://github.com/ZtesoftCS/go-ethereum-code-analysis">分析参考资料</a></li><li><a href="https://segmentfault.com/a/1190000016050921">博客参考资料</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-封装的一些基础工具</title>
      <link href="/2021/05/27/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%B0%81%E8%A3%85%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%B7%A5%E5%85%B7/"/>
      <url>/2021/05/27/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%B0%81%E8%A3%85%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%B7%A5%E5%85%B7/</url>
      
        <content type="html"><![CDATA[<h1 id="封装的一些基础工具"><a href="#封装的一些基础工具" class="headerlink" title="封装的一些基础工具"></a>封装的一些基础工具</h1><p>在<a href="https://github.com/ethereum/go-ethereum">以太坊</a> 项目中，存在对golang生态体系中一些优秀工具进行封装的小模块，由于功能较为单一，单独成篇显得过于单薄。但是由于以太坊对这些小工具的封装非常优雅，具有很强的独立性和实用性。我们在此作一些分析，至少对于熟悉以太坊源码的编码方式是有帮助的。</p><h2 id="metrics（探针）"><a href="#metrics（探针）" class="headerlink" title="metrics（探针）"></a>metrics（探针）</h2><p>在<a href="/ethdb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.md">ethdb源码分析</a>中，我们看到了对<a href="https://github.com/syndtr/goleveldb">goleveldb</a>项目的封装。ethdb除了对goleveldb抽象了一层：</p><p><a href="https://github.com/ethereum/go-ethereum/blob/master/ethdb/interface.go#L29">type Database interface</a></p><p>以支持与MemDatabase的同接口使用互换外，还在LDBDatabase中使用很多<a href="https://github.com/rcrowley/go-metrics">gometrics</a>包下面的探针工具，以及能启动一个goroutine执行</p><p><a href="https://github.com/ethereum/go-ethereum/blob/master/ethdb/database.go#L198">go db.meter(3 * time.Second)</a></p><p>以3秒为周期，收集使用goleveldb过程中的延时和I/O数据量等指标。看起来很方便，但问题是我们如何使用这些收集来的信息呢？</p><h2 id="log（日志）"><a href="#log（日志）" class="headerlink" title="log（日志）"></a>log（日志）</h2><p>golang的内置log包一直被作为槽点，而以太坊项目也不例外。故引入了<a href="https://github.com/inconshreveable/log15">log15</a>以解决日志使用不便的问题。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-分析包Trie</title>
      <link href="/2021/05/27/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%88%86%E6%9E%90%E5%8C%85Trie/"/>
      <url>/2021/05/27/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%88%86%E6%9E%90%E5%8C%85Trie/</url>
      
        <content type="html"><![CDATA[<h1 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h1><p>源码分析使用的版本为：<a href="https://github.com/ethereum/go-ethereum/tree/v1.10.3">v1.10.3</a></p><h1 id="知识补充"><a href="#知识补充" class="headerlink" title="知识补充"></a>知识补充</h1><p>以太坊源码中的trie包实现了Merkle Patricia Tries（MPT），这种数据结构实际上是一种Trie树变种。</p><p>MPT是以太坊中一种非常重要的数据结构，用来存储用户账户的状态及其变更、交易信息、交易的收据信息。</p><p>MPT实际上是三种数据结构的组合，分别是Merkle树、Patricia Trie、和Trie树。</p><p>下面分别介绍这三种数据结构。</p><h2 id="Merkle树"><a href="#Merkle树" class="headerlink" title="Merkle树"></a>Merkle树</h2><p>Merkle Tree，通常也被称作Hash Tree，顾名思义，就是存储hash值的一棵树。Merkle树的叶子是数据块(例如，文件或者文件的集合)的hash值。非叶节点是其对应子节点串联字符串的hash</p><p><img src="https://img-blog.csdnimg.cn/20210527141955845.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>Merkle Tree的主要作用是当我拿到Top Hash的时候，这个hash值代表了整颗树的信息摘要，当树里面任何一个数据发生了变动，都会导致Top Hash的值发生变化。 而Top Hash的值是会存储到区块链的区块头里面去的， 区块头是必须经过工作量证明。 这也就是说我只要拿到一个区块头，就可以对区块信息进行验证。 更加详细的信息请参考那个博客。有详细的介绍。</p><h2 id="Patricia-Tries"><a href="#Patricia-Tries" class="headerlink" title="Patricia Tries"></a>Patricia Tries</h2><p>Patricia Tries即为前缀树，<br>前缀树跟Trie树的不同之处在于Trie树给每一个字符串分配一个节点，这样将使那些很长但又没有公共节点的字符串的Trie树退化成数组。在以太坊里面会由黑客构造很多这种节点造成拒绝服务攻击。前缀树的不同之处在于如果节点公共前缀，那么就使用公共前缀，否则就把剩下的所有节点插入同一个节点。Patricia相对Tire的优化正如下图：<br><img src="https://img-blog.csdnimg.cn/20210527141719517.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210527141728827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><table><thead><tr><th>Key</th><th>value</th></tr></thead><tbody><tr><td>6c0a5c71ec20bq3w</td><td>5</td></tr><tr><td>6c0a5c71ec20CX7j</td><td>27</td></tr><tr><td>6c0a5c71781a1FXq</td><td>18</td></tr><tr><td>6c0a5c71781a9Dog</td><td>64</td></tr><tr><td>6c0a8f743b95zUfe</td><td>30</td></tr><tr><td>6c0a8f743b95jx5R</td><td>2</td></tr><tr><td>6c0a8f740d16y03G</td><td>43</td></tr><tr><td>6c0a8f740d16vcc1</td><td>48</td></tr></tbody></table><h2 id="Trie树"><a href="#Trie树" class="headerlink" title="Trie树"></a>Trie树</h2><p>Trie树，又称字典树，单词查找树或者前缀树，是一种用于快速检索的多叉树结构，如英文字母的字典树是一个26叉树，数字的字典树是一个10叉树。</p><p>Trie树可以利用字符串的公共前缀来节约存储空间。如下图所示，该trie树用10个节点保存了6个字符串：tea，ten，to，in，inn，int：</p><p><img src="https://img-blog.csdnimg.cn/20210527141507347.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>在该trie树中，字符串in，inn和int的公共前缀是“in”，因此可以只存储一份“in”以节省空间。当然，如果系统中存在大量字符串且这些字符串基本没有公共前缀，则相应的trie树将非常消耗内存，这也是trie树的一个缺点。</p><p>Trie树的基本性质可以归纳为：</p><ul><li>根节点不包含字符，除根节点以外每个节点只包含一个字符</li><li>从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串</li><li>每个节点的所有子节点包含的字符串不相同</li></ul><h2 id="以太坊的MPT"><a href="#以太坊的MPT" class="headerlink" title="以太坊的MPT"></a>以太坊的MPT</h2><p>每一个以太坊的区块头包含三颗MPT树，分别是</p><ul><li>交易树</li><li>收据树(交易执行过程中的一些数据)</li><li>状态树(账号信息， 合约账户和用户账户)</li></ul><p>下图中是两个区块头，其中state root，tx root receipt root分别存储了这三棵树的树根，第二个区块显示了当账号 175的数据变更(27 -&gt; 45)的时候，只需要存储跟这个账号相关的部分数据，而且老的区块中的数据还是可以正常访问。(这个有点类似与函数式编程语言中的不可变的数据结构的实现)</p><p><img src="https://img-blog.csdnimg.cn/20210527142811419.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h1><h2 id="编码转换：encoding-go"><a href="#编码转换：encoding-go" class="headerlink" title="编码转换：encoding.go"></a>编码转换：encoding.go</h2><p>encoding.go主要处理trie树中的三种编码格式的相互转换的工作。 三种编码格式分别为下面的三种编码格式。</p><ul><li>KEYBYTES encoding这种编码格式就是原生的key字节数组，大部分的Trie的API都是使用这边编码格式</li><li>HEX encoding 这种编码格式每一个字节包含了Key的一个半字节，尾部接上一个可选的’终结符’,’终结符’代表这个节点到底是叶子节点还是扩展节点。当节点被加载到内存里面的时候使用的是这种节点，因为它的方便访问。</li><li>COMPACT encoding 这种编码格式就是上面黄皮书里面说到的Hex-Prefix Encoding，这种编码格式可以看成是HEX encoding这种编码格式的另外一种版本，可以在存储到数据库的时候节约磁盘空间。</li></ul><p>简单的理解为：将普通的字节序列keybytes编码为带有t标志与奇数个半字节nibble标志位的keybytes</p><ul><li>keybytes为按完整字节（8bit）存储的正常信息</li><li>hex为按照半字节nibble（4bit）储存信息的格式。供compact使用</li></ul><p>为了便于作黄皮书中Modified Merkle Patricia Tree的节点的key，编码为偶数字节长度的hex格式。其第一个半字节nibble会在低的2个bit位中，由高到低分别存放t标志与奇数标志。经compact编码的keybytes，在增加了hex的t标志与半字节nibble为偶数个（即完整的字节）的情况下，便于存储</p><h2 id="数据结构与方法"><a href="#数据结构与方法" class="headerlink" title="数据结构与方法"></a>数据结构与方法</h2><h3 id="node：node-go"><a href="#node：node-go" class="headerlink" title="node：node.go"></a>node：node.go</h3><h4 id="node的结构"><a href="#node的结构" class="headerlink" title="node的结构"></a>node的结构</h4><p>可以看到node分为4种类型：</p><ul><li>fullNode：黄皮书里面的分支节点</li><li>shortNode：黄皮书里面的扩展节点和叶子节点(通过shortNode.Val的类型来判断当前节点是叶子节点(shortNode.Val为valueNode)还是拓展节点(通过shortNode.Val指向下一个node))</li><li>hashNode</li><li>valueNode</li></ul><pre><code class="go">type node interface {    fstring(string) string    cache() (hashNode, bool)}type (    fullNode struct {        Children [17]node // Actual trie node data to encode/decode (needs custom encoder)        flags    nodeFlag    }    shortNode struct {        Key   []byte        Val   node        flags nodeFlag    }    hashNode  []byte    valueNode []byte)</code></pre><h4 id="node的方法"><a href="#node的方法" class="headerlink" title="node的方法"></a>node的方法</h4><h3 id="Trie：trie-go"><a href="#Trie：trie-go" class="headerlink" title="Trie：trie.go"></a>Trie：trie.go</h3><h4 id="Trie的结构"><a href="#Trie的结构" class="headerlink" title="Trie的结构"></a>Trie的结构</h4><p>root包含了当前的root节点， db是后端的KV存储，trie的结构最终都是需要通过KV的形式存储到数据库里面去，然后启动的时候是需要从数据库里面加载的。 originalRoot 启动加载的时候的hash值，通过这个hash值可以在数据库里面恢复出整颗的trie树。cachegen字段指示了当前Trie树的cache时代，每次调用Commit操作的时候，会增加Trie树的cache时代。 cache时代会被附加在node节点上面，如果当前的cache时代 - cachelimit参数 大于node的cache时代，那么node会从cache里面卸载，以便节约内存。 其实这就是缓存更新的LRU算法， 如果一个缓存在多久没有被使用，那么就从缓存里面移除，以节约内存空间。</p><pre><code class="go">// Trie is a Merkle Patricia Trie.// The zero value is an empty trie with no database.// Use New to create a trie that sits on top of a database.//// Trie is not safe for concurrent use.type Trie struct {    db   *Database    root node    // Keep track of the number leafs which have been inserted since the last    // hashing operation. This number will not directly map to the number of    // actually unhashed nodes    unhashed int}</code></pre><h4 id="Trie的方法"><a href="#Trie的方法" class="headerlink" title="Trie的方法"></a>Trie的方法</h4><h5 id="1-Trie树的新建"><a href="#1-Trie树的新建" class="headerlink" title="1. Trie树的新建"></a>1. Trie树的新建</h5><p>Trie树的插入，查找和删除 Trie树的初始化调用New函数，函数接受一个hash值和一个Database参数，如果hash值不是空值的化，就说明是从数据库加载一个已经存在的Trie树， 就调用trei.resolveHash方法来加载整颗Trie树，这个方法后续会介绍。 如果root是空，那么就新建一颗Trie树返回</p><pre><code class="go">// New creates a trie with an existing root node from db.//// If root is the zero hash or the sha3 hash of an empty string, the// trie is initially empty and does not require a database. Otherwise,// New will panic if db is nil and returns a MissingNodeError if root does// not exist in the database. Accessing the trie loads nodes from db on demand.func New(root common.Hash, db *Database) (*Trie, error) {    if db == nil {        panic("trie.New called without a database")    }    trie := &amp;Trie{        db: db,    }    if root != (common.Hash{}) &amp;&amp; root != emptyRoot {        rootnode, err := trie.resolveHash(root[:], nil)        if err != nil {            return nil, err        }        trie.root = rootnode    }    return trie, nil}</code></pre><h5 id="2-Trie树的插入"><a href="#2-Trie树的插入" class="headerlink" title="2. Trie树的插入"></a>2. Trie树的插入</h5><p>Trie树的插入，这是一个递归调用的方法，从根节点开始，一直往下找，直到找到可以插入的点，进行插入操作。参数node是当前插入的节点， prefix是当前已经处理完的部分key， key是还没有处理玩的部分key, 完整的key = prefix + key。 value是需要插入的值。 返回值bool是操作是否改变了Trie树(dirty)，node是插入完成后的子树的根节点， error是错误信息。</p><ul><li><p>如果节点类型是nil(一颗全新的Trie树的节点就是nil的),这个时候整颗树是空的，直接返回shortNode{key, value, t.newFlag()}， 这个时候整颗树的跟就含有了一个shortNode节点。</p></li><li><p>如果当前的根节点类型是shortNode(也就是叶子节点)，首先计算公共前缀，如果公共前缀就等于key，那么说明这两个key是一样的，如果value也一样的(dirty == false)，那么返回错误。 如果没有错误就更新shortNode的值然后返回。如果公共前缀不完全匹配，那么就需要把公共前缀提取出来形成一个独立的节点(扩展节点),扩展节点后面连接一个branch节点，branch节点后面看情况连接两个short节点。首先构建一个branch节点(branch := &amp;fullNode{flags: t.newFlag()}),然后再branch节点的Children位置调用t.insert插入剩下的两个short节点。这里有个小细节，key的编码是HEX encoding,而且末尾带了一个终结符。考虑我们的根节点的key是abc0x16，我们插入的节点的key是ab0x16。下面的branch.Children[key[matchlen]]才可以正常运行，0x16刚好指向了branch节点的第17个孩子。如果匹配的长度是0，那么直接返回这个branch节点，否则返回shortNode节点作为前缀节点。</p></li><li><p>如果当前的节点是fullNode(也就是branch节点)，那么直接往对应的孩子节点调用insert方法,然后把对应的孩子节点只想新生成的节点。</p></li><li><p>如果当前节点是hashNode, hashNode的意思是当前节点还没有加载到内存里面来，还是存放在数据库里面，那么首先调用 t.resolveHash(n, prefix)来加载到内存，然后对加载出来的节点调用insert方法来进行插入。</p><pre><code class="go">func (t *Trie) insert(n node, prefix, key []byte, value node) (bool, node, error) {  if len(key) == 0 {      if v, ok := n.(valueNode); ok {          return !bytes.Equal(v, value.(valueNode)), value, nil      }      return true, value, nil  }  switch n := n.(type) {  case *shortNode:      matchlen := prefixLen(key, n.Key)      // If the whole key matches, keep this short node as is      // and only update the value.      if matchlen == len(n.Key) {          dirty, nn, err := t.insert(n.Val, append(prefix, key[:matchlen]...), key[matchlen:], value)          if !dirty || err != nil {              return false, n, err          }          return true, &amp;shortNode{n.Key, nn, t.newFlag()}, nil      }      // Otherwise branch out at the index where they differ.      branch := &amp;fullNode{flags: t.newFlag()}      var err error      _, branch.Children[n.Key[matchlen]], err = t.insert(nil, append(prefix, n.Key[:matchlen+1]...), n.Key[matchlen+1:], n.Val)      if err != nil {          return false, nil, err      }      _, branch.Children[key[matchlen]], err = t.insert(nil, append(prefix, key[:matchlen+1]...), key[matchlen+1:], value)      if err != nil {          return false, nil, err      }      // Replace this shortNode with the branch if it occurs at index 0.      if matchlen == 0 {          return true, branch, nil      }      // Otherwise, replace it with a short node leading up to the branch.      return true, &amp;shortNode{key[:matchlen], branch, t.newFlag()}, nil  case *fullNode:      dirty, nn, err := t.insert(n.Children[key[0]], append(prefix, key[0]), key[1:], value)      if !dirty || err != nil {          return false, n, err      }      n = n.copy()      n.flags = t.newFlag()      n.Children[key[0]] = nn      return true, n, nil  case nil:      return true, &amp;shortNode{key, value, t.newFlag()}, nil  case hashNode:      // We've hit a part of the trie that isn't loaded yet. Load      // the node and insert into it. This leaves all child nodes on      // the path to the value in the trie.      rn, err := t.resolveHash(n, prefix)      if err != nil {          return false, nil, err      }      dirty, nn, err := t.insert(rn, prefix, key, value)      if !dirty || err != nil {          return false, rn, err      }      return true, nn, nil  default:      panic(fmt.Sprintf("%T: invalid node: %v", n, n))  }}</code></pre><h5 id="3-Trie树的获取"><a href="#3-Trie树的获取" class="headerlink" title="3. Trie树的获取"></a>3. Trie树的获取</h5><p>Trie树的Get方法，基本上就是很简单的遍历Trie树，来获取Key的信息。</p><pre><code class="go">// Get returns the value for key stored in the trie.// The value bytes must not be modified by the caller.func (t *Trie) Get(key []byte) []byte {  res, err := t.TryGet(key)  if err != nil {      log.Error(fmt.Sprintf("Unhandled trie error: %v", err))  }  return res}// TryGet returns the value for key stored in the trie.// The value bytes must not be modified by the caller.// If a node was not found in the database, a MissingNodeError is returned.func (t *Trie) TryGet(key []byte) ([]byte, error) {  value, newroot, didResolve, err := t.tryGet(t.root, keybytesToHex(key), 0)  if err == nil &amp;&amp; didResolve {      t.root = newroot  }  return value, err}func (t *Trie) tryGet(origNode node, key []byte, pos int) (value []byte, newnode node, didResolve bool, err error) {  switch n := (origNode).(type) {  case nil:      return nil, nil, false, nil  case valueNode:      return n, n, false, nil  case *shortNode:      if len(key)-pos &lt; len(n.Key) || !bytes.Equal(n.Key, key[pos:pos+len(n.Key)]) {          // key not found in trie          return nil, n, false, nil      }      value, newnode, didResolve, err = t.tryGet(n.Val, key, pos+len(n.Key))      if err == nil &amp;&amp; didResolve {          n = n.copy()          n.Val = newnode      }      return value, n, didResolve, err  case *fullNode:      value, newnode, didResolve, err = t.tryGet(n.Children[key[pos]], key, pos+1)      if err == nil &amp;&amp; didResolve {          n = n.copy()          n.Children[key[pos]] = newnode      }      return value, n, didResolve, err  case hashNode:      child, err := t.resolveHash(n, key[:pos])      if err != nil {          return nil, n, true, err      }      value, newnode, _, err := t.tryGet(child, key, pos)      return value, newnode, true, err  default:      panic(fmt.Sprintf("%T: invalid node: %v", origNode, origNode))  }}// TryGetNode attempts to retrieve a trie node by compact-encoded path. It is not// possible to use keybyte-encoding as the path might contain odd nibbles.func (t *Trie) TryGetNode(path []byte) ([]byte, int, error) {  item, newroot, resolved, err := t.tryGetNode(t.root, compactToHex(path), 0)  if err != nil {      return nil, resolved, err  }  if resolved &gt; 0 {      t.root = newroot  }  if item == nil {      return nil, resolved, nil  }  return item, resolved, err}func (t *Trie) tryGetNode(origNode node, path []byte, pos int) (item []byte, newnode node, resolved int, err error) {  // If we reached the requested path, return the current node  if pos &gt;= len(path) {      // Although we most probably have the original node expanded, encoding      // that into consensus form can be nasty (needs to cascade down) and      // time consuming. Instead, just pull the hash up from disk directly.      var hash hashNode      if node, ok := origNode.(hashNode); ok {          hash = node      } else {          hash, _ = origNode.cache()      }      if hash == nil {          return nil, origNode, 0, errors.New("non-consensus node")      }      blob, err := t.db.Node(common.BytesToHash(hash))      return blob, origNode, 1, err  }  // Path still needs to be traversed, descend into children  switch n := (origNode).(type) {  case nil:      // Non-existent path requested, abort      return nil, nil, 0, nil  case valueNode:      // Path prematurely ended, abort      return nil, nil, 0, nil  case *shortNode:      if len(path)-pos &lt; len(n.Key) || !bytes.Equal(n.Key, path[pos:pos+len(n.Key)]) {          // Path branches off from short node          return nil, n, 0, nil      }      item, newnode, resolved, err = t.tryGetNode(n.Val, path, pos+len(n.Key))      if err == nil &amp;&amp; resolved &gt; 0 {          n = n.copy()          n.Val = newnode      }      return item, n, resolved, err  case *fullNode:      item, newnode, resolved, err = t.tryGetNode(n.Children[path[pos]], path, pos+1)      if err == nil &amp;&amp; resolved &gt; 0 {          n = n.copy()          n.Children[path[pos]] = newnode      }      return item, n, resolved, err  case hashNode:      child, err := t.resolveHash(n, path[:pos])      if err != nil {          return nil, n, 1, err      }      item, newnode, resolved, err := t.tryGetNode(child, path, pos)      return item, newnode, resolved + 1, err  default:      panic(fmt.Sprintf("%T: invalid node: %v", origNode, origNode))  }}</code></pre></li></ul><h5 id="4-Trie树的删除"><a href="#4-Trie树的删除" class="headerlink" title="4. Trie树的删除"></a>4. Trie树的删除</h5><p>代码跟插入比较类似</p><pre><code class="go">// Delete removes any existing value for key from the trie.func (t *Trie) Delete(key []byte) {    if err := t.TryDelete(key); err != nil {        log.Error(fmt.Sprintf("Unhandled trie error: %v", err))    }}// TryDelete removes any existing value for key from the trie.// If a node was not found in the database, a MissingNodeError is returned.func (t *Trie) TryDelete(key []byte) error {    t.unhashed++    k := keybytesToHex(key)    _, n, err := t.delete(t.root, nil, k)    if err != nil {        return err    }    t.root = n    return nil}// delete returns the new root of the trie with key deleted.// It reduces the trie to minimal form by simplifying// nodes on the way up after deleting recursively.func (t *Trie) delete(n node, prefix, key []byte) (bool, node, error) {    switch n := n.(type) {    case *shortNode:        matchlen := prefixLen(key, n.Key)        if matchlen &lt; len(n.Key) {            return false, n, nil // don't replace n on mismatch        }        if matchlen == len(key) {            return true, nil, nil // remove n entirely for whole matches        }        // The key is longer than n.Key. Remove the remaining suffix        // from the subtrie. Child can never be nil here since the        // subtrie must contain at least two other values with keys        // longer than n.Key.        dirty, child, err := t.delete(n.Val, append(prefix, key[:len(n.Key)]...), key[len(n.Key):])        if !dirty || err != nil {            return false, n, err        }        switch child := child.(type) {        case *shortNode:            // Deleting from the subtrie reduced it to another            // short node. Merge the nodes to avoid creating a            // shortNode{..., shortNode{...}}. Use concat (which            // always creates a new slice) instead of append to            // avoid modifying n.Key since it might be shared with            // other nodes.            return true, &amp;shortNode{concat(n.Key, child.Key...), child.Val, t.newFlag()}, nil        default:            return true, &amp;shortNode{n.Key, child, t.newFlag()}, nil        }    case *fullNode:        dirty, nn, err := t.delete(n.Children[key[0]], append(prefix, key[0]), key[1:])        if !dirty || err != nil {            return false, n, err        }        n = n.copy()        n.flags = t.newFlag()        n.Children[key[0]] = nn        // Check how many non-nil entries are left after deleting and        // reduce the full node to a short node if only one entry is        // left. Since n must've contained at least two children        // before deletion (otherwise it would not be a full node) n        // can never be reduced to nil.        //        // When the loop is done, pos contains the index of the single        // value that is left in n or -2 if n contains at least two        // values.        pos := -1        for i, cld := range &amp;n.Children {            if cld != nil {                if pos == -1 {                    pos = i                } else {                    pos = -2                    break                }            }        }        if pos &gt;= 0 {            if pos != 16 {                // If the remaining entry is a short node, it replaces                // n and its key gets the missing nibble tacked to the                // front. This avoids creating an invalid                // shortNode{..., shortNode{...}}.  Since the entry                // might not be loaded yet, resolve it just for this                // check.                cnode, err := t.resolve(n.Children[pos], prefix)                if err != nil {                    return false, nil, err                }                if cnode, ok := cnode.(*shortNode); ok {                    k := append([]byte{byte(pos)}, cnode.Key...)                    return true, &amp;shortNode{k, cnode.Val, t.newFlag()}, nil                }            }            // Otherwise, n is replaced by a one-nibble short node            // containing the child.            return true, &amp;shortNode{[]byte{byte(pos)}, n.Children[pos], t.newFlag()}, nil        }        // n still contains at least two values and cannot be reduced.        return true, n, nil    case valueNode:        return true, nil, nil    case nil:        return false, nil, nil    case hashNode:        // We've hit a part of the trie that isn't loaded yet. Load        // the node and delete from it. This leaves all child nodes on        // the path to the value in the trie.        rn, err := t.resolveHash(n, prefix)        if err != nil {            return false, nil, err        }        dirty, nn, err := t.delete(rn, prefix, key)        if !dirty || err != nil {            return false, rn, err        }        return true, nn, nil    default:        panic(fmt.Sprintf("%T: invalid node: %v (%v)", n, n, key))    }}</code></pre><h5 id="5-Trie树的序列化和反序列化"><a href="#5-Trie树的序列化和反序列化" class="headerlink" title="5. Trie树的序列化和反序列化"></a>5. Trie树的序列化和反序列化</h5><p>序列化主要是指把内存表示的数据存放到数据库里面， 反序列化是指把数据库里面的Trie数据加载成内存表示的数据。 序列化的目的主要是方便存储，减少存储大小等。 反序列化的目的是把存储的数据加载到内存，方便Trie树的插入，查询，修改等需求。</p><p>Trie的序列化主要才作用了前面介绍的Compat Encoding和 RLP编码格式。 序列化的结构在黄皮书里面有详细的介绍。</p><p><img src="https://img-blog.csdnimg.cn/20210527171804758.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>Trie树的使用方法在trie_test.go里面有比较详细的参考。 这里我列出一个简单的使用流程。首先创建一个空的Trie树，然后插入一些数据，最后调用trie.Commit()方法进行序列化并得到一个hash值(root), 也就是上图中的KEC(c(J,0))或者是TRIE(J)。</p><pre><code class="go">func TestInsert(t *testing.T) {    trie := newEmpty()    updateString(trie, "doe", "reindeer")    updateString(trie, "dog", "puppy")    updateString(trie, "dogglesworth", "cat")    exp := common.HexToHash("8aad789dff2f538bca5d8ea56e8abe10f4c7ba3a5dea95fea4cd6e7c3a1168d3")    root := trie.Hash()    if root != exp {        t.Errorf("case 1: exp %x got %x", exp, root)    }    trie = newEmpty()    updateString(trie, "A", "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa")    exp = common.HexToHash("d23786fb4a010da3ce639d66d5e904a11dbc02746d1ce25029e53290cabf28ab")    root, err := trie.Commit(nil)    if err != nil {        t.Fatalf("commit error: %v", err)    }    if root != exp {        t.Errorf("case 2: exp %x got %x", exp, root)    }}</code></pre><p>下面我们来分析下Commit()的主要流程。 经过一系列的调用，最终调用了hasher.go的hash方法。</p><pre><code class="go">// Commit writes all nodes to the trie's memory database, tracking the internal// and external (for account tries) references.func (t *Trie) Commit(onleaf LeafCallback) (root common.Hash, err error) {    if t.db == nil {        panic("commit called on trie with nil database")    }    if t.root == nil {        return emptyRoot, nil    }    // Derive the hash for all dirty nodes first. We hold the assumption    // in the following procedure that all nodes are hashed.    rootHash := t.Hash()    h := newCommitter()    defer returnCommitterToPool(h)    // Do a quick check if we really need to commit, before we spin    // up goroutines. This can happen e.g. if we load a trie for reading storage    // values, but don't write to it.    if _, dirty := t.root.cache(); !dirty {        return rootHash, nil    }    var wg sync.WaitGroup    if onleaf != nil {        h.onleaf = onleaf        h.leafCh = make(chan *leaf, leafChanSize)        wg.Add(1)        go func() {            defer wg.Done()            h.commitLoop(t.db)        }()    }    var newRoot hashNode    newRoot, err = h.Commit(t.root, t.db)    if onleaf != nil {        // The leafch is created in newCommitter if there was an onleaf callback        // provided. The commitLoop only _reads_ from it, and the commit        // operation was the sole writer. Therefore, it's safe to close this        // channel here.        close(h.leafCh)        wg.Wait()    }    if err != nil {        return common.Hash{}, err    }    t.root = newRoot    return rootHash, nil}// Hash returns the root hash of the trie. It does not write to the// database and can be used even if the trie doesn't have one.func (t *Trie) Hash() common.Hash {    hash, cached, _ := t.hashRoot()    t.root = cached    return common.BytesToHash(hash.(hashNode))}</code></pre><p>下面我们简单介绍下hash方法，hash方法主要做了两个操作。 一个是保留原有的树形结构，并用cache变量中， 另一个是计算原有树形结构的hash并把hash值存放到cache变量中保存下来。</p><p>计算原有hash值的主要流程：</p><ul><li>如果当前节点是shortNode, 调用h.hashShortNodeChildren(n)把所有的子节点的hash值求出来，把原有的子节点替换成子节点的hash值。 这是一个递归调用的过程，会从树叶依次往上计算直到树根。然后调用shortnodeToHash方法计算当前节点的hash值，并把当前节点的hash值放入cache节点，然后返回。</li><li>如果当前节点是fullNode, 调用h.hashFullNodeChildren(n)把所有的子节点的hash值求出来，把原有的子节点替换成子节点的hash值。 这是一个递归调用的过程，会从树叶依次往上计算直到树根。然后调用fullnodeToHash方法计算当前节点的hash值，并把当前节点的hash值放入cache节点，然后返回。</li><li>否则的话这个节点没有children。直接返回。<br>返回值说明， cache变量包含了原有的node节点，并且包含了node节点的hash值。 hash变量返回了当前节点的hash值(这个值其实是根据node和node的所有子节点计算出来的)。</li></ul><p>有一个小细节： 根节点调用hash函数的时候， force参数是为true的，其他的子节点调用的时候force参数是为false的。 force参数的用途是当||c(J,i)||&lt;32的时候也对c(J,i)进行hash计算，这样保证无论如何也会对根节点进行Hash计算。</p><pre><code class="go">// hash collapses a node down into a hash node, also returning a copy of the// original node initialized with the computed hash to replace the original one.func (h *hasher) hash(n node, force bool) (hashed node, cached node) {    // Return the cached hash if it's available    if hash, _ := n.cache(); hash != nil {        return hash, n    }    // Trie not processed yet, walk the children    switch n := n.(type) {    case *shortNode:        collapsed, cached := h.hashShortNodeChildren(n)        hashed := h.shortnodeToHash(collapsed, force)        // We need to retain the possibly _not_ hashed node, in case it was too        // small to be hashed        if hn, ok := hashed.(hashNode); ok {            cached.flags.hash = hn        } else {            cached.flags.hash = nil        }        return hashed, cached    case *fullNode:        collapsed, cached := h.hashFullNodeChildren(n)        hashed = h.fullnodeToHash(collapsed, force)        if hn, ok := hashed.(hashNode); ok {            cached.flags.hash = hn        } else {            cached.flags.hash = nil        }        return hashed, cached    default:        // Value and hash nodes don't have children so they're left as were        return n, n    }}// shortnodeToHash creates a hashNode from a shortNode. The supplied shortnode// should have hex-type Key, which will be converted (without modification)// into compact form for RLP encoding.// If the rlp data is smaller than 32 bytes, `nil` is returned.func (h *hasher) shortnodeToHash(n *shortNode, force bool) node {    h.tmp.Reset()    if err := rlp.Encode(&amp;h.tmp, n); err != nil {        panic("encode error: " + err.Error())    }    if len(h.tmp) &lt; 32 &amp;&amp; !force {        return n // Nodes smaller than 32 bytes are stored inside their parent    }    return h.hashData(h.tmp)}</code></pre><p>hashShortNodeChildren方法,这个方法把所有的子节点替换成他们的hash，可以看到cache变量接管了原来的Trie树的完整结构，collapsed变量把子节点替换成子节点的hash值。<br>首先把collapsed.Key从Hex Encoding 替换成 Compact Encoding, 然后递归调用hash方法计算子节点的hash和cache，这样就把子节点替换成了子节点的hash值。</p><pre><code class="go">// hashShortNodeChildren collapses the short node. The returned collapsed node// holds a live reference to the Key, and must not be modified.// The cachedfunc (h *hasher) hashShortNodeChildren(n *shortNode) (collapsed, cached *shortNode) {    // Hash the short node's child, caching the newly hashed subtree    collapsed, cached = n.copy(), n.copy()    // Previously, we did copy this one. We don't seem to need to actually    // do that, since we don't overwrite/reuse keys    //cached.Key = common.CopyBytes(n.Key)    collapsed.Key = hexToCompact(n.Key)    // Unless the child is a valuenode or hashnode, hash it    switch n.Val.(type) {    case *fullNode, *shortNode:        collapsed.Val, cached.Val = h.hash(n.Val, false)    }    return collapsed, cached}</code></pre><p>hashFullNodeChildren方法,这个方法遍历每个子节点，把子节点替换成子节点的Hash值。</p><pre><code class="go">func (h *hasher) hashFullNodeChildren(n *fullNode) (collapsed *fullNode, cached *fullNode) {    // Hash the full node's children, caching the newly hashed subtrees    cached = n.copy()    collapsed = n.copy()    if h.parallel {        var wg sync.WaitGroup        wg.Add(16)        for i := 0; i &lt; 16; i++ {            go func(i int) {                hasher := newHasher(false)                if child := n.Children[i]; child != nil {                    collapsed.Children[i], cached.Children[i] = hasher.hash(child, false)                } else {                    collapsed.Children[i] = nilValueNode                }                returnHasherToPool(hasher)                wg.Done()            }(i)        }        wg.Wait()    } else {        for i := 0; i &lt; 16; i++ {            if child := n.Children[i]; child != nil {                collapsed.Children[i], cached.Children[i] = h.hash(child, false)            } else {                collapsed.Children[i] = nilValueNode            }        }    }    return collapsed, cached}</code></pre><p>fullnodeToHash方法和shortnodeToHash方法：<br>直接调用rlp.Encode方法对这个节点进行编码（此时认为node的所有子节点都替换成了子节点的hash值）</p><p>如果编码后的值小于32，并且这个节点不是根节点，那么就把他们直接存储在他们的父节点里面，否则调用h.sha.Write方法进行hash计算， 然后把hash值和编码后的数据存储到数据库里面，然后返回hash值。</p><p>可以看到每个值大于32的节点的值和hash都存储到了数据库里面。</p><pre><code class="go">// shortnodeToHash creates a hashNode from a shortNode. The supplied shortnode// should have hex-type Key, which will be converted (without modification)// into compact form for RLP encoding.// If the rlp data is smaller than 32 bytes, `nil` is returned.func (h *hasher) shortnodeToHash(n *shortNode, force bool) node {    h.tmp.Reset()    if err := rlp.Encode(&amp;h.tmp, n); err != nil {        panic("encode error: " + err.Error())    }    if len(h.tmp) &lt; 32 &amp;&amp; !force {        return n // Nodes smaller than 32 bytes are stored inside their parent    }    return h.hashData(h.tmp)}// shortnodeToHash is used to creates a hashNode from a set of hashNodes, (which// may contain nil values)func (h *hasher) fullnodeToHash(n *fullNode, force bool) node {    h.tmp.Reset()    // Generate the RLP encoding of the node    if err := n.EncodeRLP(&amp;h.tmp); err != nil {        panic("encode error: " + err.Error())    }    if len(h.tmp) &lt; 32 &amp;&amp; !force {        return n // Nodes smaller than 32 bytes are stored inside their parent    }    return h.hashData(h.tmp)}</code></pre><p>Trie的反序列化过程。还记得之前创建Trie树的流程么。 如果参数root的hash值不为空，那么就会调用rootnode, err := trie.resolveHash(root[:], nil) 方法来得到rootnode节点。</p><p>首先从数据库里面通过hash值获取节点的RLP编码后的内容。 然后调用decodeNode来解析内容。</p><pre><code class="go">func (it *nodeIterator) resolveHash(hash hashNode, path []byte) (node, error) {    if it.resolver != nil {        if blob, err := it.resolver.Get(hash); err == nil &amp;&amp; len(blob) &gt; 0 {            if resolved, err := decodeNode(hash, blob); err == nil {                return resolved, nil            }        }    }    resolved, err := it.trie.resolveHash(hash, path)    return resolved, err}</code></pre><p>decodeNode方法，这个方法根据rlp的list的长度来判断这个编码到底属于什么节点，如果是2个字段那么就是shortNode节点，如果是17个字段，那么就是fullNode，然后分别调用各自的解析函数。</p><pre><code class="go">// decodeNode parses the RLP encoding of a trie node.func decodeNode(hash, buf []byte, cachegen uint16) (node, error) {    if len(buf) == 0 {        return nil, io.ErrUnexpectedEOF    }    elems, _, err := rlp.SplitList(buf)    if err != nil {        return nil, fmt.Errorf("decode error: %v", err)    }    switch c, _ := rlp.CountValues(elems); c {    case 2:        n, err := decodeShort(hash, elems)        return n, wrapError(err, "short")    case 17:        n, err := decodeFull(hash, elems)        return n, wrapError(err, "full")    default:        return nil, fmt.Errorf("invalid number of list elements: %v", c)    }}</code></pre><p>decodeShort方法，通过key是否有终结符号来判断到底是叶子节点还是中间节点。如果有终结符那么就是叶子结点，通过SplitString方法解析出来val然后生成一个shortNode。 不过没有终结符，那么说明是扩展节点， 通过decodeRef来解析剩下的节点，然后生成一个shortNode。</p><pre><code class="go">func decodeShort(hash, buf, elems []byte, cachegen uint16) (node, error) {    kbuf, rest, err := rlp.SplitString(elems)    if err != nil {        return nil, err    }    flag := nodeFlag{hash: hash}    key := compactToHex(kbuf)    if hasTerm(key) {        // value node        val, _, err := rlp.SplitString(rest)        if err != nil {            return nil, fmt.Errorf("invalid value node: %v", err)        }        return &amp;shortNode{key, append(valueNode{}, val...), flag}, nil    }    r, _, err := decodeRef(rest)    if err != nil {        return nil, wrapError(err, "val")    }    return &amp;shortNode{key, r, flag}, nil}</code></pre><p>decodeRef方法根据数据类型进行解析，如果类型是list，那么有可能是内容&lt;32的值，那么调用decodeNode进行解析。 如果是空节点，那么返回空，如果是hash值，那么构造一个hashNode进行返回，注意的是这里没有继续进行解析，如果需要继续解析这个hashNode，那么需要继续调用resolveHash方法。 到这里decodeShort方法就调用完成了。</p><pre><code class="go">func decodeRef(buf []byte, cachegen uint16) (node, []byte, error) {    kind, val, rest, err := rlp.Split(buf)    if err != nil {        return nil, buf, err    }    switch {    case kind == rlp.List:        // 'embedded' node reference. The encoding must be smaller        // than a hash in order to be valid.        if size := len(buf) - len(rest); size &gt; hashLen {            err := fmt.Errorf("oversized embedded node (size is %d bytes, want size &lt; %d)", size, hashLen)            return nil, buf, err        }        n, err := decodeNode(nil, buf)        return n, rest, err    case kind == rlp.String &amp;&amp; len(val) == 0:        // empty node        return nil, rest, nil    case kind == rlp.String &amp;&amp; len(val) == 32:        return append(hashNode{}, val...), rest, nil    default:        return nil, nil, fmt.Errorf("invalid RLP string size %d (want 0 or 32)", len(val))    }}</code></pre><p>decodeFull方法。根decodeShort方法的流程差不多。</p><pre><code class="go">func decodeFull(hash, buf, elems []byte, cachegen uint16) (*fullNode, error) {    n := &amp;fullNode{flags: nodeFlag{hash: hash}}    for i := 0; i &lt; 16; i++ {        cld, rest, err := decodeRef(elems)        if err != nil {            return n, wrapError(err, fmt.Sprintf("[%d]", i))        }        n.Children[i], elems = cld, rest    }    val, _, err := rlp.SplitString(elems)    if err != nil {        return n, err    }    if len(val) &gt; 0 {        n.Children[16] = append(valueNode{}, val...)    }    return n, nil}</code></pre><h2 id="Trie树的默克尔证明：proof-go"><a href="#Trie树的默克尔证明：proof-go" class="headerlink" title="Trie树的默克尔证明：proof.go"></a>Trie树的默克尔证明：proof.go</h2><p>主要提供两个方法，Prove方法获取指定Key的proof证明， proof证明是从根节点到叶子节点的所有节点的hash值列表。 VerifyProof方法，接受一个roothash值和proof证明和key来验证key是否存在。</p><p>Prove方法，从根节点开始。把经过的节点的hash值一个一个存入到list中。然后返回。</p><pre><code class="go">// Prove constructs a merkle proof for key. The result contains all encoded nodes// on the path to the value at key. The value itself is also included in the last// node and can be retrieved by verifying the proof.//// If the trie does not contain a value for key, the returned proof contains all// nodes of the longest existing prefix of the key (at least the root node), ending// with the node that proves the absence of the key.func (t *Trie) Prove(key []byte, fromLevel uint, proofDb ethdb.KeyValueWriter) error {    // Collect all nodes on the path to key.    key = keybytesToHex(key)    var nodes []node    tn := t.root    for len(key) &gt; 0 &amp;&amp; tn != nil {        switch n := tn.(type) {        case *shortNode:            if len(key) &lt; len(n.Key) || !bytes.Equal(n.Key, key[:len(n.Key)]) {                // The trie doesn't contain the key.                tn = nil            } else {                tn = n.Val                key = key[len(n.Key):]            }            nodes = append(nodes, n)        case *fullNode:            tn = n.Children[key[0]]            key = key[1:]            nodes = append(nodes, n)        case hashNode:            var err error            tn, err = t.resolveHash(n, nil)            if err != nil {                log.Error(fmt.Sprintf("Unhandled trie error: %v", err))                return err            }        default:            panic(fmt.Sprintf("%T: invalid node: %v", tn, tn))        }    }    hasher := newHasher(false)    defer returnHasherToPool(hasher)    for i, n := range nodes {        if fromLevel &gt; 0 {            fromLevel--            continue        }        var hn node        n, hn = hasher.proofHash(n)        if hash, ok := hn.(hashNode); ok || i == 0 {            // If the node's database encoding is a hash (or is the            // root node), it becomes a proof element.            enc, _ := rlp.EncodeToBytes(n)            if !ok {                hash = hasher.hashData(enc)            }            proofDb.Put(hash, enc)        }    }    return nil}</code></pre><p>VerifyProof方法，接收一个rootHash参数，key参数，和KeyValueReader， 来一个一个验证是否能够和数据库里面的能够对应上。</p><pre><code class="go">// VerifyProof checks merkle proofs. The given proof must contain the value for// key in a trie with the given root hash. VerifyProof returns an error if the// proof contains invalid trie nodes or the wrong value.func VerifyProof(rootHash common.Hash, key []byte, proofDb ethdb.KeyValueReader) (value []byte, err error) {    key = keybytesToHex(key)    wantHash := rootHash    for i := 0; ; i++ {        buf, _ := proofDb.Get(wantHash[:])        if buf == nil {            return nil, fmt.Errorf("proof node %d (hash %064x) missing", i, wantHash)        }        n, err := decodeNode(wantHash[:], buf)        if err != nil {            return nil, fmt.Errorf("bad proof node %d: %v", i, err)        }        keyrest, cld := get(n, key, true)        switch cld := cld.(type) {        case nil:            // The trie doesn't contain the key.            return nil, nil        case hashNode:            key = keyrest            copy(wantHash[:], cld)        case valueNode:            return cld, nil        }    }}// get returns the child of the given node. Return nil if the// node with specified key doesn't exist at all.//// There is an additional flag `skipResolved`. If it's set then// all resolved nodes won't be returned.func get(tn node, key []byte, skipResolved bool) ([]byte, node) {    for {        switch n := tn.(type) {        case *shortNode:            if len(key) &lt; len(n.Key) || !bytes.Equal(n.Key, key[:len(n.Key)]) {                return nil, nil            }            tn = n.Val            key = key[len(n.Key):]            if !skipResolved {                return key, tn            }        case *fullNode:            tn = n.Children[key[0]]            key = key[1:]            if !skipResolved {                return key, tn            }        case hashNode:            return key, n        case nil:            return key, nil        case valueNode:            return nil, n        default:            panic(fmt.Sprintf("%T: invalid node: %v", tn, tn))        }    }}</code></pre><h2 id="Trie的加密：security-trie-go"><a href="#Trie的加密：security-trie-go" class="headerlink" title="Trie的加密：security_trie.go"></a>Trie的加密：security_trie.go</h2><p>为了避免刻意使用很长的key导致访问时间的增加， security_trie包装了一下trie树， 所有的key都转换成keccak256算法计算的hash值。同时在数据库里面存储hash值对应的原始的key。</p><pre><code class="go">// SecureTrie wraps a trie with key hashing. In a secure trie, all// access operations hash the key using keccak256. This prevents// calling code from creating long chains of nodes that// increase the access time.//// Contrary to a regular trie, a SecureTrie can only be created with// New and must have an attached database. The database also stores// the preimage of each key.//// SecureTrie is not safe for concurrent use.type SecureTrie struct {    trie             Trie    hashKeyBuf       [common.HashLength]byte    secKeyCache      map[string][]byte    secKeyCacheOwner *SecureTrie // Pointer to self, replace the key cache on mismatch}// NewSecure creates a trie with an existing root node from a backing database// and optional intermediate in-memory node pool.//// If root is the zero hash or the sha3 hash of an empty string, the// trie is initially empty. Otherwise, New will panic if db is nil// and returns MissingNodeError if the root node cannot be found.//// Accessing the trie loads nodes from the database or node pool on demand.// Loaded nodes are kept around until their 'cache generation' expires.// A new cache generation is created by each call to Commit.// cachelimit sets the number of past cache generations to keep.func NewSecure(root common.Hash, db *Database) (*SecureTrie, error) {    if db == nil {        panic("trie.NewSecure called without a database")    }    trie, err := New(root, db)    if err != nil {        return nil, err    }    return &amp;SecureTrie{trie: *trie}, nil}// Get returns the value for key stored in the trie.// The value bytes must not be modified by the caller.func (t *SecureTrie) Get(key []byte) []byte {    res, err := t.TryGet(key)    if err != nil {        log.Error(fmt.Sprintf("Unhandled trie error: %v", err))    }    return res}// TryGet returns the value for key stored in the trie.// The value bytes must not be modified by the caller.// If a node was not found in the database, a MissingNodeError is returned.func (t *SecureTrie) TryGet(key []byte) ([]byte, error) {    return t.trie.TryGet(t.hashKey(key))}// Commit writes all nodes and the secure hash pre-images to the trie's database.// Nodes are stored with their sha3 hash as the key.//// Committing flushes nodes from memory. Subsequent Get calls will load nodes// from the database.func (t *SecureTrie) Commit(onleaf LeafCallback) (root common.Hash, err error) {    // Write all the pre-images to the actual disk database    if len(t.getSecKeyCache()) &gt; 0 {        if t.trie.db.preimages != nil { // Ugly direct check but avoids the below write lock            t.trie.db.lock.Lock()            for hk, key := range t.secKeyCache {                t.trie.db.insertPreimage(common.BytesToHash([]byte(hk)), key)            }            t.trie.db.lock.Unlock()        }        t.secKeyCache = make(map[string][]byte)    }    // Commit the trie to its intermediate node database    return t.trie.Commit(onleaf)}</code></pre><h2 id="trie包中其他的功能"><a href="#trie包中其他的功能" class="headerlink" title="trie包中其他的功能"></a>trie包中其他的功能</h2><ul><li>databases.go trie数据结构和磁盘数据库之间的一个写入层，方便trie中节点的插入删除操作</li><li>iterator.go 遍历Trie的键值迭代器</li></ul><h1 id="参考资料地址"><a href="#参考资料地址" class="headerlink" title="参考资料地址"></a>参考资料地址</h1><ul><li><a href="https://ethereum.org/en/whitepaper">以太坊白皮书</a></li><li><a href="https://ethereum.github.io/yellowpaper/paper.pdf">以太坊黄皮书（英文版）</a></li><li><a href="https://github.com/wanshan1024/ethereum_yellowpaper/blob/master/ethereum_yellow_paper_cn.pdf">以太坊黄皮书（中文版）</a></li><li><a href="https://github.com/ZtesoftCS/go-ethereum-code-analysis">分析参考资料</a></li><li><a href="https://segmentfault.com/a/1190000016050921">博客参考资料</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-accounts源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-accounts%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-accounts%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>accounts包实现了以太坊客户端的钱包和账户管理。以太坊的钱包提供了keyStore模式和usb两种钱包。同时以太坊的 合约的ABI的代码也放在了account/abi目录。 abi项目好像跟账户管理没有什么关系。 这里暂时只分析了账号管理的接口。 具体的keystore和usb的实现代码暂时不会给出。</p><p>账号是通过数据结构和接口来定义了</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>账号</p><pre><code>// Account represents an Ethereum account located at a specific location defined// by the optional URL field.// 一个账号是20个字节的数据。 URL是可选的字段。type Account struct {    Address common.Address `json:"address"` // Ethereum account address derived from the key    URL     URL            `json:"url"`     // Optional resource locator within a backend}const (    HashLength    = 32    AddressLength = 20)// Address represents the 20 byte address of an Ethereum account.type Address [AddressLength]byte</code></pre><p>钱包。钱包应该是这里面最重要的一个接口了。 具体的钱包也是实现了这个接口。<br>钱包又有所谓的分层确定性钱包和普通钱包。</p><pre><code>// Wallet represents a software or hardware wallet that might contain one or more// accounts (derived from the same seed).// Wallet 是指包含了一个或多个账户的软件钱包或者硬件钱包type Wallet interface {    // URL retrieves the canonical path under which this wallet is reachable. It is    // user by upper layers to define a sorting order over all wallets from multiple    // backends.    // URL 用来获取这个钱包可以访问的规范路径。 它会被上层使用用来从所有的后端的钱包来排序。    URL() URL    // Status returns a textual status to aid the user in the current state of the    // wallet. It also returns an error indicating any failure the wallet might have    // encountered.    // 用来返回一个文本值用来标识当前钱包的状态。 同时也会返回一个error用来标识钱包遇到的任何错误。    Status() (string, error)    // Open initializes access to a wallet instance. It is not meant to unlock or    // decrypt account keys, rather simply to establish a connection to hardware    // wallets and/or to access derivation seeds.    // Open 初始化对钱包实例的访问。这个方法并不意味着解锁或者解密账户，而是简单地建立与硬件钱包的连接和/或访问衍生种子。    // The passphrase parameter may or may not be used by the implementation of a    // particular wallet instance. The reason there is no passwordless open method    // is to strive towards a uniform wallet handling, oblivious to the different    // backend providers.    // passphrase参数可能在某些实现中并不需要。 没有提供一个无passphrase参数的Open方法的原因是为了提供一个统一的接口。     // Please note, if you open a wallet, you must close it to release any allocated    // resources (especially important when working with hardware wallets).    // 请注意，如果你open了一个钱包，你必须close它。不然有些资源可能没有释放。 特别是使用硬件钱包的时候需要特别注意。    Open(passphrase string) error    // Close releases any resources held by an open wallet instance.    // Close 释放由Open方法占用的任何资源。    Close() error    // Accounts retrieves the list of signing accounts the wallet is currently aware    // of. For hierarchical deterministic wallets, the list will not be exhaustive,    // rather only contain the accounts explicitly pinned during account derivation.    // Accounts用来获取钱包发现了账户列表。 对于分层次的钱包， 这个列表不会详尽的列出所有的账号， 而是只包含在帐户派生期间明确固定的帐户。    Accounts() []Account    // Contains returns whether an account is part of this particular wallet or not.    // Contains 返回一个账号是否属于本钱包。    Contains(account Account) bool    // Derive attempts to explicitly derive a hierarchical deterministic account at    // the specified derivation path. If requested, the derived account will be added    // to the wallet's tracked account list.    // Derive尝试在指定的派生路径上显式派生出分层确定性帐户。 如果pin为true，派生帐户将被添加到钱包的跟踪帐户列表中。    Derive(path DerivationPath, pin bool) (Account, error)    // SelfDerive sets a base account derivation path from which the wallet attempts    // to discover non zero accounts and automatically add them to list of tracked    // accounts.    // SelfDerive设置一个基本帐户导出路径，从中钱包尝试发现非零帐户，并自动将其添加到跟踪帐户列表中。    // Note, self derivaton will increment the last component of the specified path    // opposed to decending into a child path to allow discovering accounts starting    // from non zero components.    // 注意，SelfDerive将递增指定路径的最后一个组件，而不是下降到子路径，以允许从非零组件开始发现帐户。    // You can disable automatic account discovery by calling SelfDerive with a nil    // chain state reader.    // 你可以通过传递一个nil的ChainStateReader来禁用自动账号发现。    SelfDerive(base DerivationPath, chain ethereum.ChainStateReader)    // SignHash requests the wallet to sign the given hash.    // SignHash 请求钱包来给传入的hash进行签名。    // It looks up the account specified either solely via its address contained within,    // or optionally with the aid of any location metadata from the embedded URL field.    //它可以通过其中包含的地址（或可选地借助嵌入式URL字段中的任何位置元数据）来查找指定的帐户。    // If the wallet requires additional authentication to sign the request (e.g.    // a password to decrypt the account, or a PIN code o verify the transaction),    // an AuthNeededError instance will be returned, containing infos for the user    // about which fields or actions are needed. The user may retry by providing    // the needed details via SignHashWithPassphrase, or by other means (e.g. unlock    // the account in a keystore).    // 如果钱包需要额外的验证才能签名(比如说 需要密码来解锁账号， 或者是需要一个PIN 代码来验证交易。)    // 会返回一个AuthNeededError的错误，里面包含了用户的信息，以及哪些字段或者操作需要提供。    // 用户可以通过 SignHashWithPassphrase来签名或者通过其他手段(在keystore里面解锁账号)    SignHash(account Account, hash []byte) ([]byte, error)    // SignTx requests the wallet to sign the given transaction.    // SignTx 请求钱包对指定的交易进行签名。    // It looks up the account specified either solely via its address contained within,    // or optionally with the aid of any location metadata from the embedded URL field.    //     // If the wallet requires additional authentication to sign the request (e.g.    // a password to decrypt the account, or a PIN code o verify the transaction),    // an AuthNeededError instance will be returned, containing infos for the user    // about which fields or actions are needed. The user may retry by providing    // the needed details via SignTxWithPassphrase, or by other means (e.g. unlock    // the account in a keystore).    SignTx(account Account, tx *types.Transaction, chainID *big.Int) (*types.Transaction, error)    // SignHashWithPassphrase requests the wallet to sign the given hash with the    // given passphrase as extra authentication information.    // SignHashWithPassphrase请求钱包使用给定的passphrase来签名给定的hash    // It looks up the account specified either solely via its address contained within,    // or optionally with the aid of any location metadata from the embedded URL field.    SignHashWithPassphrase(account Account, passphrase string, hash []byte) ([]byte, error)    // SignTxWithPassphrase requests the wallet to sign the given transaction, with the    // given passphrase as extra authentication information.    // SignHashWithPassphrase请求钱包使用给定的passphrase来签名给定的transaction    // It looks up the account specified either solely via its address contained within,    // or optionally with the aid of any location metadata from the embedded URL field.    SignTxWithPassphrase(account Account, passphrase string, tx *types.Transaction, chainID *big.Int) (*types.Transaction, error)}</code></pre><p>后端 Backend</p><pre><code>// Backend is a "wallet provider" that may contain a batch of accounts they can// sign transactions with and upon request, do so.// Backend是一个钱包提供器。 可以包含一批账号。他们可以根据请求签署交易，这样做。type Backend interface {    // Wallets retrieves the list of wallets the backend is currently aware of.    // Wallets获取当前能够查找到的钱包    // The returned wallets are not opened by default. For software HD wallets this    // means that no base seeds are decrypted, and for hardware wallets that no actual    // connection is established.    // 返回的钱包默认是没有打开的。     // The resulting wallet list will be sorted alphabetically based on its internal    // URL assigned by the backend. Since wallets (especially hardware) may come and    // go, the same wallet might appear at a different positions in the list during    // subsequent retrievals.    //所产生的钱包列表将根据后端分配的内部URL按字母顺序排序。 由于钱包（特别是硬件钱包）可能会打开和关闭，所以在随后的检索过程中，相同的钱包可能会出现在列表中的不同位置。    Wallets() []Wallet    // Subscribe creates an async subscription to receive notifications when the    // backend detects the arrival or departure of a wallet.    // 订阅创建异步订阅，以便在后端检测到钱包的到达或离开时接收通知。    Subscribe(sink chan&lt;- WalletEvent) event.Subscription}</code></pre><h2 id="manager-go"><a href="#manager-go" class="headerlink" title="manager.go"></a>manager.go</h2><p>Manager是一个包含所有东西的账户管理工具。 可以和所有的Backends来通信来签署交易。</p><p>数据结构</p><pre><code>// Manager is an overarching account manager that can communicate with various// backends for signing transactions.type Manager struct {    // 所有已经注册的Backend    backends map[reflect.Type][]Backend // Index of backends currently registered    // 所有Backend的更新订阅器    updaters []event.Subscription       // Wallet update subscriptions for all backends    // backend更新的订阅槽    updates  chan WalletEvent           // Subscription sink for backend wallet changes    // 所有已经注册的Backends的钱包的缓存    wallets  []Wallet                   // Cache of all wallets from all registered backends    // 钱包到达和离开的通知    feed event.Feed // Wallet feed notifying of arrivals/departures    // 退出队列    quit chan chan error    lock sync.RWMutex}</code></pre><p>创建Manager</p><pre><code>// NewManager creates a generic account manager to sign transaction via various// supported backends.func NewManager(backends ...Backend) *Manager {    // Subscribe to wallet notifications from all backends    updates := make(chan WalletEvent, 4*len(backends))    subs := make([]event.Subscription, len(backends))    for i, backend := range backends {        subs[i] = backend.Subscribe(updates)    }    // Retrieve the initial list of wallets from the backends and sort by URL    var wallets []Wallet    for _, backend := range backends {        wallets = merge(wallets, backend.Wallets()...)    }    // Assemble the account manager and return    am := &amp;Manager{        backends: make(map[reflect.Type][]Backend),        updaters: subs,        updates:  updates,        wallets:  wallets,        quit:     make(chan chan error),    }    for _, backend := range backends {        kind := reflect.TypeOf(backend)        am.backends[kind] = append(am.backends[kind], backend)    }    go am.update()    return am}</code></pre><p>update方法。 是一个goroutine。会监听所有backend触发的更新信息。 然后转发给feed.</p><pre><code>// update is the wallet event loop listening for notifications from the backends// and updating the cache of wallets.func (am *Manager) update() {    // Close all subscriptions when the manager terminates    defer func() {        am.lock.Lock()        for _, sub := range am.updaters {            sub.Unsubscribe()        }        am.updaters = nil        am.lock.Unlock()    }()    // Loop until termination    for {        select {        case event := &lt;-am.updates:            // Wallet event arrived, update local cache            am.lock.Lock()            switch event.Kind {            case WalletArrived:                am.wallets = merge(am.wallets, event.Wallet)            case WalletDropped:                am.wallets = drop(am.wallets, event.Wallet)            }            am.lock.Unlock()            // Notify any listeners of the event            am.feed.Send(event)        case errc := &lt;-am.quit:            // Manager terminating, return            errc &lt;- nil            return        }    }}</code></pre><p>返回backend</p><pre><code>// Backends retrieves the backend(s) with the given type from the account manager.func (am *Manager) Backends(kind reflect.Type) []Backend {    return am.backends[kind]}</code></pre><p>订阅消息</p><pre><code>// Subscribe creates an async subscription to receive notifications when the// manager detects the arrival or departure of a wallet from any of its backends.func (am *Manager) Subscribe(sink chan&lt;- WalletEvent) event.Subscription {    return am.feed.Subscribe(sink)}</code></pre><p>对于node来说。是什么时候创建的账号管理器。</p><pre><code>// New creates a new P2P node, ready for protocol registration.func New(conf *Config) (*Node, error) {    ...    am, ephemeralKeystore, err := makeAccountManager(conf)    func makeAccountManager(conf *Config) (*accounts.Manager, string, error) {    scryptN := keystore.StandardScryptN    scryptP := keystore.StandardScryptP    if conf.UseLightweightKDF {        scryptN = keystore.LightScryptN        scryptP = keystore.LightScryptP    }    var (        keydir    string        ephemeral string        err       error    )    switch {    case filepath.IsAbs(conf.KeyStoreDir):        keydir = conf.KeyStoreDir    case conf.DataDir != "":        if conf.KeyStoreDir == "" {            keydir = filepath.Join(conf.DataDir, datadirDefaultKeyStore)        } else {            keydir, err = filepath.Abs(conf.KeyStoreDir)        }    case conf.KeyStoreDir != "":        keydir, err = filepath.Abs(conf.KeyStoreDir)    default:        // There is no datadir.        keydir, err = ioutil.TempDir("", "go-ethereum-keystore")        ephemeral = keydir    }    if err != nil {        return nil, "", err    }    if err := os.MkdirAll(keydir, 0700); err != nil {        return nil, "", err    }    // Assemble the account manager and supported backends    // 创建了一个KeyStore的backend    backends := []accounts.Backend{        keystore.NewKeyStore(keydir, scryptN, scryptP),    }    // 如果是USB钱包。 需要做一些额外的操作。    if !conf.NoUSB {        // Start a USB hub for Ledger hardware wallets        if ledgerhub, err := usbwallet.NewLedgerHub(); err != nil {            log.Warn(fmt.Sprintf("Failed to start Ledger hub, disabling: %v", err))        } else {            backends = append(backends, ledgerhub)        }        // Start a USB hub for Trezor hardware wallets        if trezorhub, err := usbwallet.NewTrezorHub(); err != nil {            log.Warn(fmt.Sprintf("Failed to start Trezor hub, disabling: %v", err))        } else {            backends = append(backends, trezorhub)        }    }    return accounts.NewManager(backends...), ephemeral, nil}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-chain_indexer源码解析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-chain_indexer%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-chain_indexer%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="chain-indexer-区块链索引"><a href="#chain-indexer-区块链索引" class="headerlink" title="chain_indexer 区块链索引"></a>chain_indexer 区块链索引</h2><p>chain_indexer.go 源码解析</p><p>chain_indexer 顾名思义， 就是用来给区块链创建索引的功能。 之前在eth协议的时候，介绍过BloomIndexer的功能，其实BloomIndexer是chain_indexer的一个特殊的实现， 可以理解为派生类， 主要的功能其实实在chain_indexer这里面实现的。虽说是派生类，但是chain_indexer其实就只被BloomIndexer使用。也就是给区块链的布隆过滤器创建了索引，以便快速的响应用户的日志搜索功能。 下面就来分析这部分的代码。</p><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><pre><code>// ChainIndexerBackend defines the methods needed to process chain segments in// the background and write the segment results into the database. These can be// used to create filter blooms or CHTs.// ChainIndexerBackend定义了处理区块链片段的方法，并把处理结果写入数据库。 这些可以用来创建布隆过滤器或者CHTs.// BloomIndexer 其实就是实现了这个接口 ChainIndexerBackend 这里的CHTs不知道是什么东西。type ChainIndexerBackend interface {    // Reset initiates the processing of a new chain segment, potentially terminating    // any partially completed operations (in case of a reorg).    // Reset 方法用来初始化一个新的区块链片段，可能会终止任何没有完成的操作。    Reset(section uint64)    // Process crunches through the next header in the chain segment. The caller    // will ensure a sequential order of headers.    // 对区块链片段中的下一个区块头进行处理。 调用者将确保区块头的连续顺序。    Process(header *types.Header)    // Commit finalizes the section metadata and stores it into the database.    完成区块链片段的元数据并将其存储到数据库中。        Commit() error}// ChainIndexer does a post-processing job for equally sized sections of the// canonical chain (like BlooomBits and CHT structures). A ChainIndexer is// connected to the blockchain through the event system by starting a// ChainEventLoop in a goroutine.// ChainIndexer 对区块链进行 大小相等的片段 进行处。 ChainIndexer在ChainEventLoop方法中通过事件系统与区块链通信，// Further child ChainIndexers can be added which use the output of the parent// section indexer. These child indexers receive new head notifications only// after an entire section has been finished or in case of rollbacks that might// affect already finished sections.//更远可以添加使用父section索引器的输出的更多子链式索引器。 这些子链式索引器只有在整个部分完成后或在可能影响已完成部分的回滚的情况下才接收新的头部通知。type ChainIndexer struct {    chainDb  ethdb.Database      // Chain database to index the data from 区块链所在的数据库    indexDb  ethdb.Database      // Prefixed table-view of the db to write index metadata into 索引存储的数据库    backend  ChainIndexerBackend // Background processor generating the index data content  索引生成的后端。    children []*ChainIndexer     // Child indexers to cascade chain updates to    子索引    active uint32          // Flag whether the event loop was started    update chan struct{}   // Notification channel that headers should be processed  接收到的headers    quit   chan chan error // Quit channel to tear down running goroutines    sectionSize uint64 // Number of blocks in a single chain segment to process    section的大小。 默认是4096个区块为一个section    confirmsReq uint64 // Number of confirmations before processing a completed segment   处理完成的段之前的确认次数    storedSections uint64 // Number of sections successfully indexed into the database  成功索引到数据库的部分数量    knownSections  uint64 // Number of sections known to be complete (block wise) 已知完成的部分数量    cascadedHead   uint64 // Block number of the last completed section cascaded to subindexers 级联到子索引的最后一个完成部分的块号    throttling time.Duration // Disk throttling to prevent a heavy upgrade from hogging resources 磁盘限制，以防止大量资源的大量升级    log  log.Logger    lock sync.RWMutex}</code></pre><p>构造函数NewChainIndexer, </p><pre><code>这个方法是在eth/bloombits.go里面被调用的const (    // bloomConfirms is the number of confirmation blocks before a bloom section is    // considered probably final and its rotated bits are calculated.    // bloomConfirms 用来表示确认区块数量， 表示经过这么多区块之后， bloom section被认为是已经不会更改了。    bloomConfirms = 256    // bloomThrottling is the time to wait between processing two consecutive index    // sections. It's useful during chain upgrades to prevent disk overload.    // bloomThrottling是处理两个连续索引段之间的等待时间。 在区块链升级过程中防止磁盘过载是很有用的。    bloomThrottling = 100 * time.Millisecond)func NewBloomIndexer(db ethdb.Database, size uint64) *core.ChainIndexer {    backend := &amp;BloomIndexer{        db:   db,        size: size,    }    // 可以看到indexDb和chainDb实际是同一个数据库， 但是indexDb的每个key前面附加了一个BloomBitsIndexPrefix的前缀。    table := ethdb.NewTable(db, string(core.BloomBitsIndexPrefix))    return core.NewChainIndexer(db, table, backend, size, bloomConfirms, bloomThrottling, "bloombits")}// NewChainIndexer creates a new chain indexer to do background processing on// chain segments of a given size after certain number of confirmations passed.// The throttling parameter might be used to prevent database thrashing.func NewChainIndexer(chainDb, indexDb ethdb.Database, backend ChainIndexerBackend, section, confirm uint64, throttling time.Duration, kind string) *ChainIndexer {    c := &amp;ChainIndexer{        chainDb:     chainDb,        indexDb:     indexDb,        backend:     backend,        update:      make(chan struct{}, 1),        quit:        make(chan chan error),        sectionSize: section,        confirmsReq: confirm,        throttling:  throttling,        log:         log.New("type", kind),    }    // Initialize database dependent fields and start the updater    c.loadValidSections()    go c.updateLoop()    return c}</code></pre><p>loadValidSections,用来从数据库里面加载我们之前的处理信息， storedSections表示我们已经处理到哪里了。</p><pre><code>// loadValidSections reads the number of valid sections from the index database// and caches is into the local state.func (c *ChainIndexer) loadValidSections() {    data, _ := c.indexDb.Get([]byte("count"))    if len(data) == 8 {        c.storedSections = binary.BigEndian.Uint64(data[:])    }}</code></pre><p>updateLoop,是主要的事件循环，用于调用backend来处理区块链section，这个需要注意的是，所有的主索引节点和所有的 child indexer 都会启动这个goroutine 方法。</p><pre><code>func (c *ChainIndexer) updateLoop() {    var (        updating bool        updated  time.Time    )    for {        select {        case errc := &lt;-c.quit:            // Chain indexer terminating, report no failure and abort            errc &lt;- nil            return        case &lt;-c.update:  //当需要使用backend处理的时候，其他goroutine会往这个channel上面发送消息            // Section headers completed (or rolled back), update the index            c.lock.Lock()            if c.knownSections &gt; c.storedSections { // 如果当前以知的Section 大于已经存储的Section                // Periodically print an upgrade log message to the user                // 每隔8秒打印一次日志信息。                if time.Since(updated) &gt; 8*time.Second {                    if c.knownSections &gt; c.storedSections+1 {                        updating = true                        c.log.Info("Upgrading chain index", "percentage", c.storedSections*100/c.knownSections)                    }                    updated = time.Now()                }                // Cache the current section count and head to allow unlocking the mutex                section := c.storedSections                var oldHead common.Hash                if section &gt; 0 { // section - 1 代表section的下标是从0开始的。                     // sectionHead用来获取section的最后一个区块的hash值。                    oldHead = c.sectionHead(section - 1)                }                // Process the newly defined section in the background                c.lock.Unlock()                // 处理 返回新的section的最后一个区块的hash值                newHead, err := c.processSection(section, oldHead)                if err != nil {                    c.log.Error("Section processing failed", "error", err)                }                c.lock.Lock()                // If processing succeeded and no reorgs occcurred, mark the section completed                if err == nil &amp;&amp; oldHead == c.sectionHead(section-1) {                    c.setSectionHead(section, newHead) // 更新数据库的状态                    c.setValidSections(section + 1)    // 更新数据库状态                    if c.storedSections == c.knownSections &amp;&amp; updating {                        updating = false                        c.log.Info("Finished upgrading chain index")                    }                    // cascadedHead 是更新后的section的最后一个区块的高度                    // 用法是什么 ？                    c.cascadedHead = c.storedSections*c.sectionSize - 1                    for _, child := range c.children {                        c.log.Trace("Cascading chain index update", "head", c.cascadedHead)                        child.newHead(c.cascadedHead, false)                    }                } else { //如果处理失败，那么在有新的通知之前不会重试。                    // If processing failed, don't retry until further notification                    c.log.Debug("Chain index processing failed", "section", section, "err", err)                    c.knownSections = c.storedSections                }            }            // If there are still further sections to process, reschedule            // 如果还有section等待处理，那么等待throttling时间再处理。避免磁盘过载。            if c.knownSections &gt; c.storedSections {                time.AfterFunc(c.throttling, func() {                    select {                    case c.update &lt;- struct{}{}:                    default:                    }                })            }            c.lock.Unlock()        }    }}</code></pre><p>Start方法。 这个方法在eth协议启动的时候被调用,这个方法接收两个参数，一个是当前的区块头，一个是事件订阅器，通过这个订阅器可以获取区块链的改变信息。</p><pre><code>eth.bloomIndexer.Start(eth.blockchain.CurrentHeader(), eth.blockchain.SubscribeChainEvent)// Start creates a goroutine to feed chain head events into the indexer for// cascading background processing. Children do not need to be started, they// are notified about new events by their parents.// 子链不需要被启动。 以为他们的父节点会通知他们。func (c *ChainIndexer) Start(currentHeader *types.Header, chainEventer func(ch chan&lt;- ChainEvent) event.Subscription) {    go c.eventLoop(currentHeader, chainEventer)}// eventLoop is a secondary - optional - event loop of the indexer which is only// started for the outermost indexer to push chain head events into a processing// queue.// eventLoop 循环只会在最外面的索引节点被调用。 所有的Child indexer不会被启动这个方法。 func (c *ChainIndexer) eventLoop(currentHeader *types.Header, chainEventer func(ch chan&lt;- ChainEvent) event.Subscription) {    // Mark the chain indexer as active, requiring an additional teardown    atomic.StoreUint32(&amp;c.active, 1)    events := make(chan ChainEvent, 10)    sub := chainEventer(events)    defer sub.Unsubscribe()    // Fire the initial new head event to start any outstanding processing    // 设置我们的其实的区块高度，用来触发之前未完成的操作。    c.newHead(currentHeader.Number.Uint64(), false)    var (        prevHeader = currentHeader        prevHash   = currentHeader.Hash()    )    for {        select {        case errc := &lt;-c.quit:            // Chain indexer terminating, report no failure and abort            errc &lt;- nil            return        case ev, ok := &lt;-events:            // Received a new event, ensure it's not nil (closing) and update            if !ok {                errc := &lt;-c.quit                errc &lt;- nil                return            }            header := ev.Block.Header()            if header.ParentHash != prevHash { //如果出现了分叉，那么我们首先                //找到公共祖先， 从公共祖先之后的索引需要重建。                 c.newHead(FindCommonAncestor(c.chainDb, prevHeader, header).Number.Uint64(), true)            }            // 设置新的head            c.newHead(header.Number.Uint64(), false)            prevHeader, prevHash = header, header.Hash()        }    }}</code></pre><p>newHead方法,通知indexer新的区块链头，或者是需要重建索引，newHead方法会触发</p><pre><code>// newHead notifies the indexer about new chain heads and/or reorgs.func (c *ChainIndexer) newHead(head uint64, reorg bool) {    c.lock.Lock()    defer c.lock.Unlock()    // If a reorg happened, invalidate all sections until that point    if reorg { // 需要重建索引 从head开始的所有section都需要重建。        // Revert the known section number to the reorg point        changed := head / c.sectionSize        if changed &lt; c.knownSections {            c.knownSections = changed        }        // Revert the stored sections from the database to the reorg point        // 将存储的部分从数据库恢复到索引重建点        if changed &lt; c.storedSections {            c.setValidSections(changed)        }        // Update the new head number to te finalized section end and notify children        // 生成新的head 并通知所有的子索引        head = changed * c.sectionSize        if head &lt; c.cascadedHead {            c.cascadedHead = head            for _, child := range c.children {                child.newHead(c.cascadedHead, true)            }        }        return    }    // No reorg, calculate the number of newly known sections and update if high enough    var sections uint64    if head &gt;= c.confirmsReq {        sections = (head + 1 - c.confirmsReq) / c.sectionSize        if sections &gt; c.knownSections {            c.knownSections = sections            select {            case c.update &lt;- struct{}{}:            default:            }        }    }}</code></pre><p>父子索引数据的关系<br>父Indexer负载事件的监听然后把结果通过newHead传递给子Indexer的updateLoop来处理。</p><p><img src="/images/ethereum/source_analysis/chainindexer_1.png" alt="image"></p><p>setValidSections方法，写入当前已经存储的sections的数量。 如果传入的值小于已经存储的数量，那么从数据库里面删除对应的section</p><pre><code>// setValidSections writes the number of valid sections to the index databasefunc (c *ChainIndexer) setValidSections(sections uint64) {    // Set the current number of valid sections in the database    var data [8]byte    binary.BigEndian.PutUint64(data[:], sections)    c.indexDb.Put([]byte("count"), data[:])    // Remove any reorged sections, caching the valids in the mean time    for c.storedSections &gt; sections {        c.storedSections--        c.removeSectionHead(c.storedSections)    }    c.storedSections = sections // needed if new &gt; old}</code></pre><p>processSection</p><pre><code>// processSection processes an entire section by calling backend functions while// ensuring the continuity of the passed headers. Since the chain mutex is not// held while processing, the continuity can be broken by a long reorg, in which// case the function returns with an error.//processSection通过调用后端函数来处理整个部分，同时确保传递的头文件的连续性。 由于链接互斥锁在处理过程中没有保持，连续性可能会被重新打断，在这种情况下，函数返回一个错误。func (c *ChainIndexer) processSection(section uint64, lastHead common.Hash) (common.Hash, error) {    c.log.Trace("Processing new chain section", "section", section)    // Reset and partial processing    c.backend.Reset(section)    for number := section * c.sectionSize; number &lt; (section+1)*c.sectionSize; number++ {        hash := GetCanonicalHash(c.chainDb, number)        if hash == (common.Hash{}) {            return common.Hash{}, fmt.Errorf("canonical block #%d unknown", number)        }        header := GetHeader(c.chainDb, hash, number)        if header == nil {            return common.Hash{}, fmt.Errorf("block #%d [%x…] not found", number, hash[:4])        } else if header.ParentHash != lastHead {            return common.Hash{}, fmt.Errorf("chain reorged during section processing")        }        c.backend.Process(header)        lastHead = header.Hash()    }    if err := c.backend.Commit(); err != nil {        c.log.Error("Section commit failed", "error", err)        return common.Hash{}, err    }    return lastHead, nil}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-genesis创世区块源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-genesis%E5%88%9B%E4%B8%96%E5%8C%BA%E5%9D%97%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-genesis%E5%88%9B%E4%B8%96%E5%8C%BA%E5%9D%97%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>genesis 是创世区块的意思. 一个区块链就是从同一个创世区块开始,通过规则形成的.不同的网络有不同的创世区块, 主网络和测试网路的创世区块是不同的.</p><p>这个模块根据传入的genesis的初始值和database，来设置genesis的状态，如果不存在创世区块，那么在database里面创建它。</p><p>数据结构</p><pre><code>// Genesis specifies the header fields, state of a genesis block. It also defines hard// fork switch-over blocks through the chain configuration.// Genesis指定header的字段，起始块的状态。 它还通过配置来定义硬叉切换块。type Genesis struct {    Config     *params.ChainConfig `json:"config"`    Nonce      uint64              `json:"nonce"`    Timestamp  uint64              `json:"timestamp"`    ExtraData  []byte              `json:"extraData"`    GasLimit   uint64              `json:"gasLimit"   gencodec:"required"`    Difficulty *big.Int            `json:"difficulty" gencodec:"required"`    Mixhash    common.Hash         `json:"mixHash"`    Coinbase   common.Address      `json:"coinbase"`    Alloc      GenesisAlloc        `json:"alloc"      gencodec:"required"`    // These fields are used for consensus tests. Please don't use them    // in actual genesis blocks.    Number     uint64      `json:"number"`    GasUsed    uint64      `json:"gasUsed"`    ParentHash common.Hash `json:"parentHash"`}// GenesisAlloc specifies the initial state that is part of the genesis block.// GenesisAlloc 指定了最开始的区块的初始状态.type GenesisAlloc map[common.Address]GenesisAccount</code></pre><p>SetupGenesisBlock,</p><pre><code>// SetupGenesisBlock writes or updates the genesis block in db.// // The block that will be used is:////                          genesis == nil       genesis != nil//                       +------------------------------------------//     db has no genesis |  main-net default  |  genesis//     db has genesis    |  from DB           |  genesis (if compatible)//// The stored chain configuration will be updated if it is compatible (i.e. does not// specify a fork block below the local head block). In case of a conflict, the// error is a *params.ConfigCompatError and the new, unwritten config is returned.// 如果存储的区块链配置不兼容那么会被更新(). 为了避免发生冲突,会返回一个错误,并且新的配置和原来的配置会返回.// The returned chain configuration is never nil.// genesis 如果是 testnet dev 或者是 rinkeby 模式， 那么不为nil。如果是mainnet或者是私有链接。那么为空func SetupGenesisBlock(db ethdb.Database, genesis *Genesis) (*params.ChainConfig, common.Hash, error) {    if genesis != nil &amp;&amp; genesis.Config == nil {        return params.AllProtocolChanges, common.Hash{}, errGenesisNoConfig    }    // Just commit the new block if there is no stored genesis block.    stored := GetCanonicalHash(db, 0) //获取genesis对应的区块    if (stored == common.Hash{}) { //如果没有区块 最开始启动geth会进入这里。        if genesis == nil {             //如果genesis是nil 而且stored也是nil 那么使用主网络            // 如果是test  dev  rinkeby 那么genesis不为空 会设置为各自的genesis            log.Info("Writing default main-net genesis block")            genesis = DefaultGenesisBlock()        } else { // 否则使用配置的区块            log.Info("Writing custom genesis block")        }        // 写入数据库        block, err := genesis.Commit(db)        return genesis.Config, block.Hash(), err    }    // Check whether the genesis block is already written.    if genesis != nil { //如果genesis存在而且区块也存在 那么对比这两个区块是否相同        block, _ := genesis.ToBlock()        hash := block.Hash()        if hash != stored {            return genesis.Config, block.Hash(), &amp;GenesisMismatchError{stored, hash}        }    }    // Get the existing chain configuration.    // 获取当前存在的区块链的genesis配置    newcfg := genesis.configOrDefault(stored)    // 获取当前的区块链的配置    storedcfg, err := GetChainConfig(db, stored)    if err != nil {        if err == ErrChainConfigNotFound {            // This case happens if a genesis write was interrupted.            log.Warn("Found genesis block without chain config")            err = WriteChainConfig(db, stored, newcfg)        }        return newcfg, stored, err    }    // Special case: don't change the existing config of a non-mainnet chain if no new    // config is supplied. These chains would get AllProtocolChanges (and a compat error)    // if we just continued here.    // 特殊情况：如果没有提供新的配置，请不要更改非主网链的现有配置。     // 如果我们继续这里，这些链会得到AllProtocolChanges（和compat错误）。    if genesis == nil &amp;&amp; stored != params.MainnetGenesisHash {        return storedcfg, stored, nil   // 如果是私有链接会从这里退出。    }    // Check config compatibility and write the config. Compatibility errors    // are returned to the caller unless we're already at block zero.    // 检查配置的兼容性,除非我们在区块0,否则返回兼容性错误.    height := GetBlockNumber(db, GetHeadHeaderHash(db))    if height == missingNumber {        return newcfg, stored, fmt.Errorf("missing block number for head header hash")    }    compatErr := storedcfg.CheckCompatible(newcfg, height)    // 如果区块已经写入数据了,那么就不能更改genesis配置了    if compatErr != nil &amp;&amp; height != 0 &amp;&amp; compatErr.RewindTo != 0 {        return newcfg, stored, compatErr    }    // 如果是主网络会从这里退出。    return newcfg, stored, WriteChainConfig(db, stored, newcfg)}</code></pre><p>ToBlock, 这个方法使用genesis的数据，使用基于内存的数据库，然后创建了一个block并返回。</p><pre><code>// ToBlock creates the block and state of a genesis specification.func (g *Genesis) ToBlock() (*types.Block, *state.StateDB) {    db, _ := ethdb.NewMemDatabase()    statedb, _ := state.New(common.Hash{}, state.NewDatabase(db))    for addr, account := range g.Alloc {        statedb.AddBalance(addr, account.Balance)        statedb.SetCode(addr, account.Code)        statedb.SetNonce(addr, account.Nonce)        for key, value := range account.Storage {            statedb.SetState(addr, key, value)        }    }    root := statedb.IntermediateRoot(false)    head := &amp;types.Header{        Number:     new(big.Int).SetUint64(g.Number),        Nonce:      types.EncodeNonce(g.Nonce),        Time:       new(big.Int).SetUint64(g.Timestamp),        ParentHash: g.ParentHash,        Extra:      g.ExtraData,        GasLimit:   new(big.Int).SetUint64(g.GasLimit),        GasUsed:    new(big.Int).SetUint64(g.GasUsed),        Difficulty: g.Difficulty,        MixDigest:  g.Mixhash,        Coinbase:   g.Coinbase,        Root:       root,    }    if g.GasLimit == 0 {        head.GasLimit = params.GenesisGasLimit    }    if g.Difficulty == nil {        head.Difficulty = params.GenesisDifficulty    }    return types.NewBlock(head, nil, nil, nil), statedb}</code></pre><p>Commit方法和MustCommit方法, Commit方法把给定的genesis的block和state写入数据库， 这个block被认为是规范的区块链头。</p><pre><code>// Commit writes the block and state of a genesis specification to the database.// The block is committed as the canonical head block.func (g *Genesis) Commit(db ethdb.Database) (*types.Block, error) {    block, statedb := g.ToBlock()    if block.Number().Sign() != 0 {        return nil, fmt.Errorf("can't commit genesis block with number &gt; 0")    }    if _, err := statedb.CommitTo(db, false); err != nil {        return nil, fmt.Errorf("cannot write state: %v", err)    }    // 写入总难度    if err := WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty); err != nil {        return nil, err    }    // 写入区块    if err := WriteBlock(db, block); err != nil {        return nil, err    }    // 写入区块收据    if err := WriteBlockReceipts(db, block.Hash(), block.NumberU64(), nil); err != nil {        return nil, err    }    // 写入   headerPrefix + num (uint64 big endian) + numSuffix -&gt; hash    if err := WriteCanonicalHash(db, block.Hash(), block.NumberU64()); err != nil {        return nil, err    }    // 写入  "LastBlock" -&gt; hash    if err := WriteHeadBlockHash(db, block.Hash()); err != nil {        return nil, err    }    // 写入 "LastHeader" -&gt; hash    if err := WriteHeadHeaderHash(db, block.Hash()); err != nil {        return nil, err    }    config := g.Config    if config == nil {        config = params.AllProtocolChanges    }    // 写入 ethereum-config-hash -&gt; config    return block, WriteChainConfig(db, block.Hash(), config)}// MustCommit writes the genesis block and state to db, panicking on error.// The block is committed as the canonical head block.func (g *Genesis) MustCommit(db ethdb.Database) *types.Block {    block, err := g.Commit(db)    if err != nil {        panic(err)    }    return block}</code></pre><p>返回各种模式的默认Genesis</p><pre><code>// DefaultGenesisBlock returns the Ethereum main net genesis block.func DefaultGenesisBlock() *Genesis {    return &amp;Genesis{        Config:     params.MainnetChainConfig,        Nonce:      66,        ExtraData:  hexutil.MustDecode("0x11bbe8db4e347b4e8c937c1c8370e4b5ed33adb3db69cbdb7a38e1e50b1b82fa"),        GasLimit:   5000,        Difficulty: big.NewInt(17179869184),        Alloc:      decodePrealloc(mainnetAllocData),    }}// DefaultTestnetGenesisBlock returns the Ropsten network genesis block.func DefaultTestnetGenesisBlock() *Genesis {    return &amp;Genesis{        Config:     params.TestnetChainConfig,        Nonce:      66,        ExtraData:  hexutil.MustDecode("0x3535353535353535353535353535353535353535353535353535353535353535"),        GasLimit:   16777216,        Difficulty: big.NewInt(1048576),        Alloc:      decodePrealloc(testnetAllocData),    }}// DefaultRinkebyGenesisBlock returns the Rinkeby network genesis block.func DefaultRinkebyGenesisBlock() *Genesis {    return &amp;Genesis{        Config:     params.RinkebyChainConfig,        Timestamp:  1492009146,        ExtraData:  hexutil.MustDecode("0x52657370656374206d7920617574686f7269746168207e452e436172746d616e42eb768f2244c8811c63729a21a3569731535f067ffc57839b00206d1ad20c69a1981b489f772031b279182d99e65703f0076e4812653aab85fca0f00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"),        GasLimit:   4700000,        Difficulty: big.NewInt(1),        Alloc:      decodePrealloc(rinkebyAllocData),    }}// DevGenesisBlock returns the 'geth --dev' genesis block.func DevGenesisBlock() *Genesis {    return &amp;Genesis{        Config:     params.AllProtocolChanges,        Nonce:      42,        GasLimit:   4712388,        Difficulty: big.NewInt(131072),        Alloc:      decodePrealloc(devAllocData),    }}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-state-process源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-state-process%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-state-process%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="StateTransition"><a href="#StateTransition" class="headerlink" title="StateTransition"></a>StateTransition</h2><p>状态转换模型</p><pre><code>/*The State Transitioning Model状态转换模型A state transition is a change made when a transaction is applied to the current world state状态转换 是指用当前的world state来执行交易，并改变当前的world stateThe state transitioning model does all all the necessary work to work out a valid new state root.状态转换做了所有所需的工作来产生一个新的有效的state root1) Nonce handling  Nonce 处理2) Pre pay gas     预先支付Gas3) Create a new state object if the recipient is \0*32 如果接收人是空，那么创建一个新的state object4) Value transfer  转账== If contract creation ==  4a) Attempt to run transaction data 尝试运行输入的数据  4b) If valid, use result as code for the new state object 如果有效，那么用运行的结果作为新的state object的code== end ==5) Run Script section 运行脚本部分6) Derive new state root 导出新的state root*/type StateTransition struct {    gp         *GasPool   //用来追踪区块内部的Gas的使用情况    msg        Message        // Message Call    gas        uint64    gasPrice   *big.Int        // gas的价格    initialGas *big.Int        // 最开始的gas    value      *big.Int        // 转账的值    data       []byte        // 输入数据    state      vm.StateDB    // StateDB    evm        *vm.EVM        // 虚拟机}// Message represents a message sent to a contract.type Message interface {    From() common.Address    //FromFrontier() (common.Address, error)    To() *common.Address    //     GasPrice() *big.Int  // Message 的 GasPrice    Gas() *big.Int        //message 的 GasLimit    Value() *big.Int    Nonce() uint64    CheckNonce() bool    Data() []byte}</code></pre><p>构造</p><pre><code>// NewStateTransition initialises and returns a new state transition object.func NewStateTransition(evm *vm.EVM, msg Message, gp *GasPool) *StateTransition {    return &amp;StateTransition{        gp:         gp,        evm:        evm,        msg:        msg,        gasPrice:   msg.GasPrice(),        initialGas: new(big.Int),        value:      msg.Value(),        data:       msg.Data(),        state:      evm.StateDB,    }}</code></pre><p>执行Message</p><pre><code>// ApplyMessage computes the new state by applying the given message// against the old state within the environment.// ApplyMessage 通过应用给定的Message 和状态来生成新的状态// ApplyMessage returns the bytes returned by any EVM execution (if it took place),// the gas used (which includes gas refunds) and an error if it failed. An error always// indicates a core error meaning that the message would always fail for that particular// state and would never be accepted within a block.// ApplyMessage返回由任何EVM执行（如果发生）返回的字节，// 使用的Gas（包括Gas退款），如果失败则返回错误。 一个错误总是表示一个核心错误，// 意味着这个消息对于这个特定的状态将总是失败，并且永远不会在一个块中被接受。func ApplyMessage(evm *vm.EVM, msg Message, gp *GasPool) ([]byte, *big.Int, bool, error) {    st := NewStateTransition(evm, msg, gp)    ret, _, gasUsed, failed, err := st.TransitionDb()    return ret, gasUsed, failed, err}</code></pre><p>TransitionDb</p><pre><code>// TransitionDb will transition the state by applying the current message and returning the result// including the required gas for the operation as well as the used gas. It returns an error if it// failed. An error indicates a consensus issue.// TransitionDb func (st *StateTransition) TransitionDb() (ret []byte, requiredGas, usedGas *big.Int, failed bool, err error) {    if err = st.preCheck(); err != nil {        return    }    msg := st.msg    sender := st.from() // err checked in preCheck    homestead := st.evm.ChainConfig().IsHomestead(st.evm.BlockNumber)    contractCreation := msg.To() == nil // 如果msg.To是nil 那么认为是一个合约创建    // Pay intrinsic gas    // TODO convert to uint64    // 计算最开始的Gas  g0    intrinsicGas := IntrinsicGas(st.data, contractCreation, homestead)    if intrinsicGas.BitLen() &gt; 64 {        return nil, nil, nil, false, vm.ErrOutOfGas    }    if err = st.useGas(intrinsicGas.Uint64()); err != nil {        return nil, nil, nil, false, err    }    var (        evm = st.evm        // vm errors do not effect consensus and are therefor        // not assigned to err, except for insufficient balance        // error.        vmerr error    )    if contractCreation { //如果是合约创建， 那么调用evm的Create方法        ret, _, st.gas, vmerr = evm.Create(sender, st.data, st.gas, st.value)    } else {        // Increment the nonce for the next transaction        // 如果是方法调用。那么首先设置sender的nonce。        st.state.SetNonce(sender.Address(), st.state.GetNonce(sender.Address())+1)        ret, st.gas, vmerr = evm.Call(sender, st.to().Address(), st.data, st.gas, st.value)    }    if vmerr != nil {        log.Debug("VM returned with error", "err", vmerr)        // The only possible consensus-error would be if there wasn't        // sufficient balance to make the transfer happen. The first        // balance transfer may never fail.        if vmerr == vm.ErrInsufficientBalance {            return nil, nil, nil, false, vmerr        }    }    requiredGas = new(big.Int).Set(st.gasUsed()) // 计算被使用的Gas数量    st.refundGas()  //计算Gas的退费 会增加到 st.gas上面。 所以矿工拿到的是退税后的    st.state.AddBalance(st.evm.Coinbase, new(big.Int).Mul(st.gasUsed(), st.gasPrice)) // 给矿工增加收入。    // requiredGas和gasUsed的区别一个是没有退税的， 一个是退税了的。    // 看上面的调用 ApplyMessage直接丢弃了requiredGas, 说明返回的是退税了的。    return ret, requiredGas, st.gasUsed(), vmerr != nil, err}</code></pre><p>关于g0的计算，在黄皮书上由详细的介绍<br>和黄皮书有一定出入的部分在于if contractCreation &amp;&amp; homestead {igas.SetUint64(params.TxGasContractCreation) 这是因为 Gtxcreate+Gtransaction = TxGasContractCreation</p><pre><code>func IntrinsicGas(data []byte, contractCreation, homestead bool) *big.Int {    igas := new(big.Int)    if contractCreation &amp;&amp; homestead {        igas.SetUint64(params.TxGasContractCreation)    } else {        igas.SetUint64(params.TxGas)    }    if len(data) &gt; 0 {        var nz int64        for _, byt := range data {            if byt != 0 {                nz++            }        }        m := big.NewInt(nz)        m.Mul(m, new(big.Int).SetUint64(params.TxDataNonZeroGas))        igas.Add(igas, m)        m.SetInt64(int64(len(data)) - nz)        m.Mul(m, new(big.Int).SetUint64(params.TxDataZeroGas))        igas.Add(igas, m)    }    return igas}</code></pre><p>执行前的检查</p><pre><code>func (st *StateTransition) preCheck() error {    msg := st.msg    sender := st.from()    // Make sure this transaction's nonce is correct    if msg.CheckNonce() {        nonce := st.state.GetNonce(sender.Address())        // 当前本地的nonce 需要和 msg的Nonce一样 不然就是状态不同步了。        if nonce &lt; msg.Nonce() {            return ErrNonceTooHigh        } else if nonce &gt; msg.Nonce() {            return ErrNonceTooLow        }    }    return st.buyGas()}</code></pre><p>buyGas， 实现Gas的预扣费，  首先就扣除你的GasLimit * GasPrice的钱。 然后根据计算完的状态在退还一部分。</p><pre><code>func (st *StateTransition) buyGas() error {    mgas := st.msg.Gas()    if mgas.BitLen() &gt; 64 {        return vm.ErrOutOfGas    }    mgval := new(big.Int).Mul(mgas, st.gasPrice)    var (        state  = st.state        sender = st.from()    )    if state.GetBalance(sender.Address()).Cmp(mgval) &lt; 0 {        return errInsufficientBalanceForGas    }    if err := st.gp.SubGas(mgas); err != nil { // 从区块的gaspool里面减去， 因为区块是由GasLimit限制整个区块的Gas使用的。         return err    }    st.gas += mgas.Uint64()    st.initialGas.Set(mgas)    state.SubBalance(sender.Address(), mgval)    // 从账号里面减去 GasLimit * GasPrice    return nil}    </code></pre><p>退税，退税是为了奖励大家运行一些能够减轻区块链负担的指令， 比如清空账户的storage. 或者是运行suicide命令来清空账号。</p><pre><code>func (st *StateTransition) refundGas() {    // Return eth for remaining gas to the sender account,    // exchanged at the original rate.    sender := st.from() // err already checked    remaining := new(big.Int).Mul(new(big.Int).SetUint64(st.gas), st.gasPrice)    // 首先把用户还剩下的Gas还回去。    st.state.AddBalance(sender.Address(), remaining)    // Apply refund counter, capped to half of the used gas.    // 然后退税的总金额不会超过用户Gas总使用的1/2。     uhalf := remaining.Div(st.gasUsed(), common.Big2)    refund := math.BigMin(uhalf, st.state.GetRefund())    st.gas += refund.Uint64()    // 把退税的金额加到用户账户上。    st.state.AddBalance(sender.Address(), refund.Mul(refund, st.gasPrice))    // Also return remaining gas to the block gas counter so it is    // available for the next transaction.    // 同时也把退税的钱还给gaspool给下个交易腾点Gas空间。    st.gp.AddGas(new(big.Int).SetUint64(st.gas))}</code></pre><h2 id="StateProcessor"><a href="#StateProcessor" class="headerlink" title="StateProcessor"></a>StateProcessor</h2><p>StateTransition是用来处理一个一个的交易的。那么StateProcessor就是用来处理区块级别的交易的。</p><p>结构和构造</p><pre><code>// StateProcessor is a basic Processor, which takes care of transitioning// state from one point to another.//// StateProcessor implements Processor.type StateProcessor struct {    config *params.ChainConfig // Chain configuration options    bc     *BlockChain         // Canonical block chain    engine consensus.Engine    // Consensus engine used for block rewards}// NewStateProcessor initialises a new StateProcessor.func NewStateProcessor(config *params.ChainConfig, bc *BlockChain, engine consensus.Engine) *StateProcessor {    return &amp;StateProcessor{        config: config,        bc:     bc,        engine: engine,    }}</code></pre><p>Process，这个方法会被blockchain调用。</p><pre><code>// Process processes the state changes according to the Ethereum rules by running// the transaction messages using the statedb and applying any rewards to both// the processor (coinbase) and any included uncles.// Process 根据以太坊规则运行交易信息来对statedb进行状态改变，以及奖励挖矿者或者是其他的叔父节点。// Process returns the receipts and logs accumulated during the process and// returns the amount of gas that was used in the process. If any of the// transactions failed to execute due to insufficient gas it will return an error.// Process返回执行过程中累计的收据和日志，并返回过程中使用的Gas。 如果由于Gas不足而导致任何交易执行失败，将返回错误。func (p *StateProcessor) Process(block *types.Block, statedb *state.StateDB, cfg vm.Config) (types.Receipts, []*types.Log, *big.Int, error) {    var (        receipts     types.Receipts        totalUsedGas = big.NewInt(0)        header       = block.Header()        allLogs      []*types.Log        gp           = new(GasPool).AddGas(block.GasLimit())    )    // Mutate the the block and state according to any hard-fork specs    // DAO 事件的硬分叉处理     if p.config.DAOForkSupport &amp;&amp; p.config.DAOForkBlock != nil &amp;&amp; p.config.DAOForkBlock.Cmp(block.Number()) == 0 {        misc.ApplyDAOHardFork(statedb)    }    // Iterate over and process the individual transactions    for i, tx := range block.Transactions() {        statedb.Prepare(tx.Hash(), block.Hash(), i)        receipt, _, err := ApplyTransaction(p.config, p.bc, nil, gp, statedb, header, tx, totalUsedGas, cfg)        if err != nil {            return nil, nil, nil, err        }        receipts = append(receipts, receipt)        allLogs = append(allLogs, receipt.Logs...)    }    // Finalize the block, applying any consensus engine specific extras (e.g. block rewards)    p.engine.Finalize(p.bc, header, statedb, block.Transactions(), block.Uncles(), receipts)    // 返回收据 日志 总的Gas使用量和nil    return receipts, allLogs, totalUsedGas, nil}</code></pre><p>ApplyTransaction</p><pre><code>// ApplyTransaction attempts to apply a transaction to the given state database// and uses the input parameters for its environment. It returns the receipt// for the transaction, gas used and an error if the transaction failed,// indicating the block was invalid.ApplyTransaction尝试将事务应用于给定的状态数据库，并使用其环境的输入参数。 //它返回事务的收据，使用的Gas和错误，如果交易失败，表明块是无效的。func ApplyTransaction(config *params.ChainConfig, bc *BlockChain, author *common.Address, gp *GasPool, statedb *state.StateDB, header *types.Header, tx *types.Transaction, usedGas *big.Int, cfg vm.Config) (*types.Receipt, *big.Int, error) {    // 把交易转换成Message     // 这里如何验证消息确实是Sender发送的。 TODO    msg, err := tx.AsMessage(types.MakeSigner(config, header.Number))    if err != nil {        return nil, nil, err    }    // Create a new context to be used in the EVM environment    // 每一个交易都创建了新的虚拟机环境。    context := NewEVMContext(msg, header, bc, author)    // Create a new environment which holds all relevant information    // about the transaction and calling mechanisms.    vmenv := vm.NewEVM(context, statedb, config, cfg)    // Apply the transaction to the current state (included in the env)    _, gas, failed, err := ApplyMessage(vmenv, msg, gp)    if err != nil {        return nil, nil, err    }    // Update the state with pending changes    // 求得中间状态    var root []byte    if config.IsByzantium(header.Number) {        statedb.Finalise(true)    } else {        root = statedb.IntermediateRoot(config.IsEIP158(header.Number)).Bytes()    }    usedGas.Add(usedGas, gas)    // Create a new receipt for the transaction, storing the intermediate root and gas used by the tx    // based on the eip phase, we're passing wether the root touch-delete accounts.    // 创建一个收据, 用来存储中间状态的root, 以及交易使用的gas    receipt := types.NewReceipt(root, failed, usedGas)    receipt.TxHash = tx.Hash()    receipt.GasUsed = new(big.Int).Set(gas)    // if the transaction created a contract, store the creation address in the receipt.    // 如果是创建合约的交易.那么我们把创建地址存储到收据里面.    if msg.To() == nil {        receipt.ContractAddress = crypto.CreateAddress(vmenv.Context.Origin, tx.Nonce())    }    // Set the receipt logs and create a bloom for filtering    receipt.Logs = statedb.GetLogs(tx.Hash())    receipt.Bloom = types.CreateBloom(types.Receipts{receipt})    // 拿到所有的日志并创建日志的布隆过滤器.    return receipt, gas, err}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-vm-jumptable-instruction</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-vm-jumptable-instruction/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-vm-jumptable-instruction/</url>
      
        <content type="html"><![CDATA[<p>jumptable. 是一个 [256]operation 的数据结构. 每个下标对应了一种指令, 使用operation来存储了指令对应的处理逻辑, gas消耗, 堆栈验证方法, memory使用的大小等功能.</p><h2 id="jumptable"><a href="#jumptable" class="headerlink" title="jumptable"></a>jumptable</h2><p>数据结构operation存储了一条指令的所需要的函数.</p><pre><code>type operation struct {    // op is the operation function  执行函数    execute executionFunc    // gasCost is the gas function and returns the gas required for execution gas消耗函数    gasCost gasFunc    // validateStack validates the stack (size) for the operation 堆栈大小验证函数    validateStack stackValidationFunc    // memorySize returns the memory size required for the operation 需要的内存大小    memorySize memorySizeFunc    halts   bool // indicates whether the operation shoult halt further execution 表示操作是否停止进一步执行    jumps   bool // indicates whether the program counter should not increment 指示程序计数器是否不增加    writes  bool // determines whether this a state modifying operation 确定这是否是一个状态修改操作    valid   bool // indication whether the retrieved operation is valid and known 指示检索到的操作是否有效并且已知    reverts bool // determines whether the operation reverts state (implicitly halts)确定操作是否恢复状态（隐式停止）    returns bool // determines whether the opertions sets the return data content 确定操作是否设置了返回数据内容}</code></pre><p>指令集, 下面定义了三种指令集,针对三种不同的以太坊版本, </p><p>var (<br>    frontierInstructionSet  = NewFrontierInstructionSet()<br>    homesteadInstructionSet = NewHomesteadInstructionSet()<br>    byzantiumInstructionSet = NewByzantiumInstructionSet()<br>)<br>NewByzantiumInstructionSet 拜占庭版本首先调用NewHomesteadInstructionSet创造了前一个版本的指令,然后增加自己特有的指令.STATICCALL ,RETURNDATASIZE ,RETURNDATACOPY ,REVERT</p><pre><code>// NewByzantiumInstructionSet returns the frontier, homestead and// byzantium instructions.func NewByzantiumInstructionSet() [256]operation {    // instructions that can be executed during the homestead phase.    instructionSet := NewHomesteadInstructionSet()    instructionSet[STATICCALL] = operation{        execute:       opStaticCall,        gasCost:       gasStaticCall,        validateStack: makeStackFunc(6, 1),        memorySize:    memoryStaticCall,        valid:         true,        returns:       true,    }    instructionSet[RETURNDATASIZE] = operation{        execute:       opReturnDataSize,        gasCost:       constGasFunc(GasQuickStep),        validateStack: makeStackFunc(0, 1),        valid:         true,    }    instructionSet[RETURNDATACOPY] = operation{        execute:       opReturnDataCopy,        gasCost:       gasReturnDataCopy,        validateStack: makeStackFunc(3, 0),        memorySize:    memoryReturnDataCopy,        valid:         true,    }    instructionSet[REVERT] = operation{        execute:       opRevert,        gasCost:       gasRevert,        validateStack: makeStackFunc(2, 0),        memorySize:    memoryRevert,        valid:         true,        reverts:       true,        returns:       true,    }    return instructionSet}</code></pre><p>NewHomesteadInstructionSet</p><pre><code>// NewHomesteadInstructionSet returns the frontier and homestead// instructions that can be executed during the homestead phase.func NewHomesteadInstructionSet() [256]operation {    instructionSet := NewFrontierInstructionSet()    instructionSet[DELEGATECALL] = operation{        execute:       opDelegateCall,        gasCost:       gasDelegateCall,        validateStack: makeStackFunc(6, 1),        memorySize:    memoryDelegateCall,        valid:         true,        returns:       true,    }    return instructionSet}</code></pre><h2 id="instruction-go"><a href="#instruction-go" class="headerlink" title="instruction.go"></a>instruction.go</h2><p>因为指令很多,所以不一一列出来,  只列举几个例子. 虽然组合起来的功能可以很复杂,但是单个指令来说,还是比较直观的.</p><pre><code>func opPc(pc *uint64, evm *EVM, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) {    stack.push(evm.interpreter.intPool.get().SetUint64(*pc))    return nil, nil}func opMsize(pc *uint64, evm *EVM, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) {    stack.push(evm.interpreter.intPool.get().SetInt64(int64(memory.Len())))    return nil, nil}</code></pre><h2 id="gas-table-go"><a href="#gas-table-go" class="headerlink" title="gas_table.go"></a>gas_table.go</h2><p>gas_table返回了各种指令消耗的gas的函数<br>这个函数的返回值基本上只有errGasUintOverflow 整数溢出的错误.</p><pre><code>func gasBalance(gt params.GasTable, evm *EVM, contract *Contract, stack *Stack, mem *Memory, memorySize uint64) (uint64, error) {    return gt.Balance, nil}func gasExtCodeSize(gt params.GasTable, evm *EVM, contract *Contract, stack *Stack, mem *Memory, memorySize uint64) (uint64, error) {    return gt.ExtcodeSize, nil}func gasSLoad(gt params.GasTable, evm *EVM, contract *Contract, stack *Stack, mem *Memory, memorySize uint64) (uint64, error) {    return gt.SLoad, nil}func gasExp(gt params.GasTable, evm *EVM, contract *Contract, stack *Stack, mem *Memory, memorySize uint64) (uint64, error) {    expByteLen := uint64((stack.data[stack.len()-2].BitLen() + 7) / 8)    var (        gas      = expByteLen * gt.ExpByte // no overflow check required. Max is 256 * ExpByte gas        overflow bool    )    if gas, overflow = math.SafeAdd(gas, GasSlowStep); overflow {        return 0, errGasUintOverflow    }    return gas, nil}</code></pre><h2 id="interpreter-go-解释器"><a href="#interpreter-go-解释器" class="headerlink" title="interpreter.go  解释器"></a>interpreter.go  解释器</h2><p>数据结构</p><pre><code>// Config are the configuration options for the Interpretertype Config struct {    // Debug enabled debugging Interpreter options    Debug bool    // EnableJit enabled the JIT VM    EnableJit bool    // ForceJit forces the JIT VM    ForceJit bool    // Tracer is the op code logger    Tracer Tracer    // NoRecursion disabled Interpreter call, callcode,    // delegate call and create.    NoRecursion bool    // Disable gas metering    DisableGasMetering bool    // Enable recording of SHA3/keccak preimages    EnablePreimageRecording bool    // JumpTable contains the EVM instruction table. This    // may be left uninitialised and will be set to the default    // table.    JumpTable [256]operation}// Interpreter is used to run Ethereum based contracts and will utilise the// passed evmironment to query external sources for state information.// The Interpreter will run the byte code VM or JIT VM based on the passed// configuration.type Interpreter struct {    evm      *EVM    cfg      Config    gasTable params.GasTable   // 标识了很多操作的Gas价格    intPool  *intPool    readOnly   bool   // Whether to throw on stateful modifications    returnData []byte // Last CALL's return data for subsequent reuse 最后一个函数的返回值}</code></pre><p>构造函数</p><pre><code>// NewInterpreter returns a new instance of the Interpreter.func NewInterpreter(evm *EVM, cfg Config) *Interpreter {    // We use the STOP instruction whether to see    // the jump table was initialised. If it was not    // we'll set the default jump table.    // 用一个STOP指令测试JumpTable是否已经被初始化了, 如果没有被初始化,那么设置为默认值    if !cfg.JumpTable[STOP].valid {         switch {        case evm.ChainConfig().IsByzantium(evm.BlockNumber):            cfg.JumpTable = byzantiumInstructionSet        case evm.ChainConfig().IsHomestead(evm.BlockNumber):            cfg.JumpTable = homesteadInstructionSet        default:            cfg.JumpTable = frontierInstructionSet        }    }    return &amp;Interpreter{        evm:      evm,        cfg:      cfg,        gasTable: evm.ChainConfig().GasTable(evm.BlockNumber),        intPool:  newIntPool(),    }}</code></pre><p>解释器一共就两个方法enforceRestrictions方法和Run方法.</p><pre><code>func (in *Interpreter) enforceRestrictions(op OpCode, operation operation, stack *Stack) error {    if in.evm.chainRules.IsByzantium {        if in.readOnly {            // If the interpreter is operating in readonly mode, make sure no            // state-modifying operation is performed. The 3rd stack item            // for a call operation is the value. Transferring value from one            // account to the others means the state is modified and should also            // return with an error.            if operation.writes || (op == CALL &amp;&amp; stack.Back(2).BitLen() &gt; 0) {                return errWriteProtection            }        }    }    return nil}// Run loops and evaluates the contract's code with the given input data and returns// the return byte-slice and an error if one occurred.// 用给定的入参循环执行合约的代码，并返回返回的字节片段，如果发生错误则返回错误。// It's important to note that any errors returned by the interpreter should be// considered a revert-and-consume-all-gas operation. No error specific checks// should be handled to reduce complexity and errors further down the in.// 重要的是要注意，解释器返回的任何错误都会消耗全部gas。 为了减少复杂性,没有特别的错误处理流程。func (in *Interpreter) Run(snapshot int, contract *Contract, input []byte) (ret []byte, err error) {    // Increment the call depth which is restricted to 1024    in.evm.depth++    defer func() { in.evm.depth-- }()    // Reset the previous call's return data. It's unimportant to preserve the old buffer    // as every returning call will return new data anyway.    in.returnData = nil    // Don't bother with the execution if there's no code.    if len(contract.Code) == 0 {        return nil, nil    }    codehash := contract.CodeHash // codehash is used when doing jump dest caching    if codehash == (common.Hash{}) {        codehash = crypto.Keccak256Hash(contract.Code)    }    var (        op    OpCode        // current opcode        mem   = NewMemory() // bound memory        stack = newstack()  // local stack        // For optimisation reason we're using uint64 as the program counter.        // It's theoretically possible to go above 2^64. The YP defines the PC        // to be uint256. Practically much less so feasible.        pc   = uint64(0) // program counter        cost uint64        // copies used by tracer        stackCopy = newstack() // stackCopy needed for Tracer since stack is mutated by 63/64 gas rule         pcCopy uint64 // needed for the deferred Tracer        gasCopy uint64 // for Tracer to log gas remaining before execution        logged bool // deferred Tracer should ignore already logged steps    )    contract.Input = input    defer func() {        if err != nil &amp;&amp; !logged &amp;&amp; in.cfg.Debug {            in.cfg.Tracer.CaptureState(in.evm, pcCopy, op, gasCopy, cost, mem, stackCopy, contract, in.evm.depth, err)        }    }()    // The Interpreter main run loop (contextual). This loop runs until either an    // explicit STOP, RETURN or SELFDESTRUCT is executed, an error occurred during    // the execution of one of the operations or until the done flag is set by the    // parent context.    // 解释器的主要循环， 直到遇到STOP，RETURN，SELFDESTRUCT指令被执行，或者是遇到任意错误，或者说done 标志被父context设置。    for atomic.LoadInt32(&amp;in.evm.abort) == 0 {        // Get the memory location of pc        // 难道下一个需要执行的指令        op = contract.GetOp(pc)        if in.cfg.Debug {            logged = false            pcCopy = uint64(pc)            gasCopy = uint64(contract.Gas)            stackCopy = newstack()            for _, val := range stack.data {                stackCopy.push(val)            }        }        // get the operation from the jump table matching the opcode        // 通过JumpTable拿到对应的operation        operation := in.cfg.JumpTable[op]        // 这里检查了只读模式下面不能执行writes指令        // staticCall的情况下会设置为readonly模式        if err := in.enforceRestrictions(op, operation, stack); err != nil {            return nil, err        }        // if the op is invalid abort the process and return an error        if !operation.valid { //检查指令是否非法            return nil, fmt.Errorf("invalid opcode 0x%x", int(op))        }        // validate the stack and make sure there enough stack items available        // to perform the operation        // 检查是否有足够的堆栈空间。 包括入栈和出栈        if err := operation.validateStack(stack); err != nil {            return nil, err        }        var memorySize uint64        // calculate the new memory size and expand the memory to fit        // the operation        if operation.memorySize != nil { // 计算内存使用量，需要收费            memSize, overflow := bigUint64(operation.memorySize(stack))            if overflow {                return nil, errGasUintOverflow            }            // memory is expanded in words of 32 bytes. Gas            // is also calculated in words.            if memorySize, overflow = math.SafeMul(toWordSize(memSize), 32); overflow {                return nil, errGasUintOverflow            }        }        if !in.cfg.DisableGasMetering { //这个参数在本地模拟执行的时候比较有用，可以不消耗或者检查GAS执行交易并得到返回结果            // consume the gas and return an error if not enough gas is available.            // cost is explicitly set so that the capture state defer method cas get the proper cost            // 计算gas的Cost 并使用，如果不够，就返回OutOfGas错误。            cost, err = operation.gasCost(in.gasTable, in.evm, contract, stack, mem, memorySize)            if err != nil || !contract.UseGas(cost) {                return nil, ErrOutOfGas            }        }        if memorySize &gt; 0 { //扩大内存范围            mem.Resize(memorySize)        }        if in.cfg.Debug {            in.cfg.Tracer.CaptureState(in.evm, pc, op, gasCopy, cost, mem, stackCopy, contract, in.evm.depth, err)            logged = true        }        // execute the operation        // 执行命令        res, err := operation.execute(&amp;pc, in.evm, contract, mem, stack)        // verifyPool is a build flag. Pool verification makes sure the integrity        // of the integer pool by comparing values to a default value.        if verifyPool {            verifyIntegerPool(in.intPool)        }        // if the operation clears the return data (e.g. it has returning data)        // set the last return to the result of the operation.        if operation.returns { //如果有返回值，那么就设置返回值。 注意只有最后一个返回有效果。            in.returnData = res        }        switch {        case err != nil:            return nil, err        case operation.reverts:            return res, errExecutionReverted        case operation.halts:            return res, nil        case !operation.jumps:            pc++        }    }    return nil, nil}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-vm-stack-memory源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-vm-stack-memory%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-vm-stack-memory%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>vm使用了stack.go里面的对象Stack来作为虚拟机的堆栈。memory代表了虚拟机里面使用的内存对象。</p><h2 id="stack"><a href="#stack" class="headerlink" title="stack"></a>stack</h2><p>比较简单，就是用1024个big.Int的定长数组来作为堆栈的存储。</p><p>构造</p><pre><code>// stack is an object for basic stack operations. Items popped to the stack are// expected to be changed and modified. stack does not take care of adding newly// initialised objects.type Stack struct {    data []*big.Int}func newstack() *Stack {    return &amp;Stack{data: make([]*big.Int, 0, 1024)}}</code></pre><p>push操作 </p><pre><code>func (st *Stack) push(d *big.Int) { //追加到最末尾    // NOTE push limit (1024) is checked in baseCheck    //stackItem := new(big.Int).Set(d)    //st.data = append(st.data, stackItem)    st.data = append(st.data, d)}func (st *Stack) pushN(ds ...*big.Int) {    st.data = append(st.data, ds...)}</code></pre><p>pop操作</p><pre><code>func (st *Stack) pop() (ret *big.Int) { //从最末尾取出。    ret = st.data[len(st.data)-1]    st.data = st.data[:len(st.data)-1]    return}</code></pre><p>交换元素的值操作，还有这种操作？</p><pre><code>func (st *Stack) swap(n int) {     // 交换堆栈顶的元素和离栈顶n距离的元素的值。    st.data[st.len()-n], st.data[st.len()-1] = st.data[st.len()-1], st.data[st.len()-n]}</code></pre><p>dup操作 像复制指定位置的值到堆顶</p><pre><code>func (st *Stack) dup(pool *intPool, n int) {    st.push(pool.get().Set(st.data[st.len()-n]))}</code></pre><p>peek 操作. 偷看栈顶元素</p><pre><code>func (st *Stack) peek() *big.Int {    return st.data[st.len()-1]}</code></pre><p>Back 偷看指定位置的元素</p><pre><code>// Back returns the n'th item in stackfunc (st *Stack) Back(n int) *big.Int {    return st.data[st.len()-n-1]}</code></pre><p>require 保证堆栈元素的数量要大于等于n.</p><pre><code>func (st *Stack) require(n int) error {    if st.len() &lt; n {        return fmt.Errorf("stack underflow (%d &lt;=&gt; %d)", len(st.data), n)    }    return nil}</code></pre><h2 id="intpool"><a href="#intpool" class="headerlink" title="intpool"></a>intpool</h2><p>非常简单. 就是256大小的 big.int的池,用来加速bit.Int的分配</p><pre><code>var checkVal = big.NewInt(-42)const poolLimit = 256// intPool is a pool of big integers that// can be reused for all big.Int operations.type intPool struct {    pool *Stack}func newIntPool() *intPool {    return &amp;intPool{pool: newstack()}}func (p *intPool) get() *big.Int {    if p.pool.len() &gt; 0 {        return p.pool.pop()    }    return new(big.Int)}func (p *intPool) put(is ...*big.Int) {    if len(p.pool.data) &gt; poolLimit {        return    }    for _, i := range is {        // verifyPool is a build flag. Pool verification makes sure the integrity        // of the integer pool by comparing values to a default value.        if verifyPool {            i.Set(checkVal)        }        p.pool.push(i)    }}</code></pre><h2 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h2><p>构造, memory的存储就是byte[]. 还有一个lastGasCost的记录.</p><pre><code>type Memory struct {    store       []byte    lastGasCost uint64}func NewMemory() *Memory {    return &amp;Memory{}}</code></pre><p>使用首先需要使用Resize分配空间</p><pre><code>// Resize resizes the memory to sizefunc (m *Memory) Resize(size uint64) {    if uint64(m.Len()) &lt; size {        m.store = append(m.store, make([]byte, size-uint64(m.Len()))...)    }}</code></pre><p>然后使用Set来设置值</p><pre><code>// Set sets offset + size to valuefunc (m *Memory) Set(offset, size uint64, value []byte) {    // length of store may never be less than offset + size.    // The store should be resized PRIOR to setting the memory    if size &gt; uint64(len(m.store)) {        panic("INVALID memory: store empty")    }    // It's possible the offset is greater than 0 and size equals 0. This is because    // the calcMemSize (common.go) could potentially return 0 when size is zero (NO-OP)    if size &gt; 0 {        copy(m.store[offset:offset+size], value)    }}</code></pre><p>Get来取值, 一个是获取拷贝, 一个是获取指针.</p><pre><code>// Get returns offset + size as a new slicefunc (self *Memory) Get(offset, size int64) (cpy []byte) {    if size == 0 {        return nil    }    if len(self.store) &gt; int(offset) {        cpy = make([]byte, size)        copy(cpy, self.store[offset:offset+size])        return    }    return}// GetPtr returns the offset + sizefunc (self *Memory) GetPtr(offset, size int64) []byte {    if size == 0 {        return nil    }    if len(self.store) &gt; int(offset) {        return self.store[offset : offset+size]    }    return nil}</code></pre><h2 id="一些额外的帮助函数-在stack-table-go里面"><a href="#一些额外的帮助函数-在stack-table-go里面" class="headerlink" title="一些额外的帮助函数 在stack_table.go里面"></a>一些额外的帮助函数 在stack_table.go里面</h2><pre><code>func makeStackFunc(pop, push int) stackValidationFunc {    return func(stack *Stack) error {        if err := stack.require(pop); err != nil {            return err        }        if stack.len()+push-pop &gt; int(params.StackLimit) {            return fmt.Errorf("stack limit reached %d (%d)", stack.len(), params.StackLimit)        }        return nil    }}func makeDupStackFunc(n int) stackValidationFunc {    return makeStackFunc(n, n+1)}func makeSwapStackFunc(n int) stackValidationFunc {    return makeStackFunc(n, n)}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-eth-downloader-peer源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader-peer%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader-peer%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>peer模块包含了downloader使用的peer节点，封装了吞吐量，是否空闲，并记录了之前失败的信息。</p><h2 id="peer"><a href="#peer" class="headerlink" title="peer"></a>peer</h2><pre><code>// peerConnection represents an active peer from which hashes and blocks are retrieved.type peerConnection struct {    id string // Unique identifier of the peer    headerIdle  int32 // Current header activity state of the peer (idle = 0, active = 1) 当前的header获取的工作状态。    blockIdle   int32 // Current block activity state of the peer (idle = 0, active = 1)    当前的区块获取的工作状态    receiptIdle int32 // Current receipt activity state of the peer (idle = 0, active = 1) 当前的收据获取的工作状态    stateIdle   int32 // Current node data activity state of the peer (idle = 0, active = 1) 当前节点状态的工作状态    headerThroughput  float64 // Number of headers measured to be retrievable per second    //记录每秒能够接收多少个区块头的度量值    blockThroughput   float64 // Number of blocks (bodies) measured to be retrievable per second  //记录每秒能够接收多少个区块的度量值    receiptThroughput float64 // Number of receipts measured to be retrievable per second 记录每秒能够接收多少个收据的度量值    stateThroughput   float64 // Number of node data pieces measured to be retrievable per second  记录每秒能够接收多少个账户状态的度量值    rtt time.Duration // Request round trip time to track responsiveness (QoS)  请求回应时间    headerStarted  time.Time // Time instance when the last header fetch was started    记录最后一个header fetch的请求时间    blockStarted   time.Time // Time instance when the last block (body) fetch was started    receiptStarted time.Time // Time instance when the last receipt fetch was started    stateStarted   time.Time // Time instance when the last node data fetch was started        lacking map[common.Hash]struct{} // Set of hashes not to request (didn't have previously)  记录的Hash值不会去请求，一般是因为之前的请求失败    peer Peer            // eth的peer    version int        // Eth protocol version number to switch strategies    log     log.Logger // Contextual logger to add extra infos to peer logs    lock    sync.RWMutex}</code></pre><p>FetchXXX<br>FetchHeaders FetchBodies等函数 主要调用了eth.peer的功能来进行发送数据请求。</p><pre><code>// FetchHeaders sends a header retrieval request to the remote peer.func (p *peerConnection) FetchHeaders(from uint64, count int) error {    // Sanity check the protocol version    if p.version &lt; 62 {        panic(fmt.Sprintf("header fetch [eth/62+] requested on eth/%d", p.version))    }    // Short circuit if the peer is already fetching    if !atomic.CompareAndSwapInt32(&amp;p.headerIdle, 0, 1) {        return errAlreadyFetching    }    p.headerStarted = time.Now()    // Issue the header retrieval request (absolut upwards without gaps)    go p.peer.RequestHeadersByNumber(from, count, 0, false)    return nil}</code></pre><p>SetXXXIdle函数<br>SetHeadersIdle, SetBlocksIdle 等函数 设置peer的状态为空闲状态，允许它执行新的请求。 同时还会通过本次传输的数据的多少来重新评估链路的吞吐量。</p><pre><code>// SetHeadersIdle sets the peer to idle, allowing it to execute new header retrieval// requests. Its estimated header retrieval throughput is updated with that measured// just now.func (p *peerConnection) SetHeadersIdle(delivered int) {    p.setIdle(p.headerStarted, delivered, &amp;p.headerThroughput, &amp;p.headerIdle)}</code></pre><p>setIdle</p><pre><code>// setIdle sets the peer to idle, allowing it to execute new retrieval requests.// Its estimated retrieval throughput is updated with that measured just now.func (p *peerConnection) setIdle(started time.Time, delivered int, throughput *float64, idle *int32) {    // Irrelevant of the scaling, make sure the peer ends up idle    defer atomic.StoreInt32(idle, 0)    p.lock.Lock()    defer p.lock.Unlock()    // If nothing was delivered (hard timeout / unavailable data), reduce throughput to minimum    if delivered == 0 {        *throughput = 0        return    }    // Otherwise update the throughput with a new measurement    elapsed := time.Since(started) + 1 // +1 (ns) to ensure non-zero divisor    measured := float64(delivered) / (float64(elapsed) / float64(time.Second))        // measurementImpact = 0.1 , 新的吞吐量=老的吞吐量*0.9 + 这次的吞吐量*0.1    *throughput = (1-measurementImpact)*(*throughput) + measurementImpact*measured        // 更新RTT    p.rtt = time.Duration((1-measurementImpact)*float64(p.rtt) + measurementImpact*float64(elapsed))    p.log.Trace("Peer throughput measurements updated",        "hps", p.headerThroughput, "bps", p.blockThroughput,        "rps", p.receiptThroughput, "sps", p.stateThroughput,        "miss", len(p.lacking), "rtt", p.rtt)}</code></pre><p>XXXCapacity函数，用来返回当前的链接允许的吞吐量。</p><pre><code>// HeaderCapacity retrieves the peers header download allowance based on its// previously discovered throughput.func (p *peerConnection) HeaderCapacity(targetRTT time.Duration) int {    p.lock.RLock()    defer p.lock.RUnlock()    // 这里有点奇怪，targetRTT越大，请求的数量就越多。    return int(math.Min(1+math.Max(1, p.headerThroughput*float64(targetRTT)/float64(time.Second)), float64(MaxHeaderFetch)))}</code></pre><p>Lacks 用来标记上次是否失败，以便下次同样的请求不通过这个peer</p><pre><code>    // MarkLacking appends a new entity to the set of items (blocks, receipts, states)    // that a peer is known not to have (i.e. have been requested before). If the    // set reaches its maximum allowed capacity, items are randomly dropped off.    func (p *peerConnection) MarkLacking(hash common.Hash) {        p.lock.Lock()        defer p.lock.Unlock()            for len(p.lacking) &gt;= maxLackingHashes {            for drop := range p.lacking {                delete(p.lacking, drop)                break            }        }        p.lacking[hash] = struct{}{}    }        // Lacks retrieves whether the hash of a blockchain item is on the peers lacking    // list (i.e. whether we know that the peer does not have it).    func (p *peerConnection) Lacks(hash common.Hash) bool {        p.lock.RLock()        defer p.lock.RUnlock()            _, ok := p.lacking[hash]        return ok    }</code></pre><h2 id="peerSet"><a href="#peerSet" class="headerlink" title="peerSet"></a>peerSet</h2><pre><code>// peerSet represents the collection of active peer participating in the chain// download procedure.type peerSet struct {    peers        map[string]*peerConnection    newPeerFeed  event.Feed    peerDropFeed event.Feed    lock         sync.RWMutex}</code></pre><p>Register 和 UnRegister</p><pre><code>// Register injects a new peer into the working set, or returns an error if the// peer is already known.//// The method also sets the starting throughput values of the new peer to the// average of all existing peers, to give it a realistic chance of being used// for data retrievals.func (ps *peerSet) Register(p *peerConnection) error {    // Retrieve the current median RTT as a sane default    p.rtt = ps.medianRTT()    // Register the new peer with some meaningful defaults    ps.lock.Lock()    if _, ok := ps.peers[p.id]; ok {        ps.lock.Unlock()        return errAlreadyRegistered    }    if len(ps.peers) &gt; 0 {        p.headerThroughput, p.blockThroughput, p.receiptThroughput, p.stateThroughput = 0, 0, 0, 0        for _, peer := range ps.peers {            peer.lock.RLock()            p.headerThroughput += peer.headerThroughput            p.blockThroughput += peer.blockThroughput            p.receiptThroughput += peer.receiptThroughput            p.stateThroughput += peer.stateThroughput            peer.lock.RUnlock()        }        p.headerThroughput /= float64(len(ps.peers))        p.blockThroughput /= float64(len(ps.peers))        p.receiptThroughput /= float64(len(ps.peers))        p.stateThroughput /= float64(len(ps.peers))    }    ps.peers[p.id] = p    ps.lock.Unlock()    ps.newPeerFeed.Send(p)    return nil}// Unregister removes a remote peer from the active set, disabling any further// actions to/from that particular entity.func (ps *peerSet) Unregister(id string) error {    ps.lock.Lock()    p, ok := ps.peers[id]    if !ok {        defer ps.lock.Unlock()        return errNotRegistered    }    delete(ps.peers, id)    ps.lock.Unlock()    ps.peerDropFeed.Send(p)    return nil}</code></pre><p>XXXIdlePeers</p><pre><code>// HeaderIdlePeers retrieves a flat list of all the currently header-idle peers// within the active peer set, ordered by their reputation.func (ps *peerSet) HeaderIdlePeers() ([]*peerConnection, int) {    idle := func(p *peerConnection) bool {        return atomic.LoadInt32(&amp;p.headerIdle) == 0    }    throughput := func(p *peerConnection) float64 {        p.lock.RLock()        defer p.lock.RUnlock()        return p.headerThroughput    }    return ps.idlePeers(62, 64, idle, throughput)}// idlePeers retrieves a flat list of all currently idle peers satisfying the// protocol version constraints, using the provided function to check idleness.// The resulting set of peers are sorted by their measure throughput.func (ps *peerSet) idlePeers(minProtocol, maxProtocol int, idleCheck func(*peerConnection) bool, throughput func(*peerConnection) float64) ([]*peerConnection, int) {    ps.lock.RLock()    defer ps.lock.RUnlock()    idle, total := make([]*peerConnection, 0, len(ps.peers)), 0    for _, p := range ps.peers { //首先抽取idle的peer        if p.version &gt;= minProtocol &amp;&amp; p.version &lt;= maxProtocol {            if idleCheck(p) {                idle = append(idle, p)            }            total++        }    }    for i := 0; i &lt; len(idle); i++ { // 冒泡排序， 从吞吐量大到吞吐量小。        for j := i + 1; j &lt; len(idle); j++ {            if throughput(idle[i]) &lt; throughput(idle[j]) {                idle[i], idle[j] = idle[j], idle[i]            }        }    }    return idle, total}</code></pre><p>medianRTT,求得peerset的RTT的中位数，</p><pre><code>// medianRTT returns the median RTT of te peerset, considering only the tuning// peers if there are more peers available.func (ps *peerSet) medianRTT() time.Duration {    // Gather all the currnetly measured round trip times    ps.lock.RLock()    defer ps.lock.RUnlock()    rtts := make([]float64, 0, len(ps.peers))    for _, p := range ps.peers {        p.lock.RLock()        rtts = append(rtts, float64(p.rtt))        p.lock.RUnlock()    }    sort.Float64s(rtts)    median := rttMaxEstimate    if qosTuningPeers &lt;= len(rtts) {        median = time.Duration(rtts[qosTuningPeers/2]) // Median of our tuning peers    } else if len(rtts) &gt; 0 {        median = time.Duration(rtts[len(rtts)/2]) // Median of our connected peers (maintain even like this some baseline qos)    }    // Restrict the RTT into some QoS defaults, irrelevant of true RTT    if median &lt; rttMinEstimate {        median = rttMinEstimate    }    if median &gt; rttMaxEstimate {        median = rttMaxEstimate    }    return median}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-eth-downloader-statesync</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader-statesync/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader-statesync/</url>
      
        <content type="html"><![CDATA[<p>statesync 用来获取pivot point所指定的区块的所有的state 的trie树，也就是所有的账号的信息，包括普通账号和合约账户。</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>stateSync调度下载由给定state root所定义的特定state trie的请求。</p><pre><code>// stateSync schedules requests for downloading a particular state trie defined// by a given state root.type stateSync struct {    d *Downloader // Downloader instance to access and manage current peerset    sched  *trie.TrieSync             // State trie sync scheduler defining the tasks    keccak hash.Hash                  // Keccak256 hasher to verify deliveries with    tasks  map[common.Hash]*stateTask // Set of tasks currently queued for retrieval    numUncommitted   int    bytesUncommitted int    deliver    chan *stateReq // Delivery channel multiplexing peer responses    cancel     chan struct{}  // Channel to signal a termination request    cancelOnce sync.Once      // Ensures cancel only ever gets called once    done       chan struct{}  // Channel to signal termination completion    err        error          // Any error hit during sync (set before completion)}</code></pre><p>构造函数</p><pre><code>func newStateSync(d *Downloader, root common.Hash) *stateSync {    return &amp;stateSync{        d:       d,        sched:   state.NewStateSync(root, d.stateDB),        keccak:  sha3.NewKeccak256(),        tasks:   make(map[common.Hash]*stateTask),        deliver: make(chan *stateReq),        cancel:  make(chan struct{}),        done:    make(chan struct{}),    }}</code></pre><p>NewStateSync</p><pre><code>// NewStateSync create a new state trie download scheduler.func NewStateSync(root common.Hash, database trie.DatabaseReader) *trie.TrieSync {    var syncer *trie.TrieSync    callback := func(leaf []byte, parent common.Hash) error {        var obj Account        if err := rlp.Decode(bytes.NewReader(leaf), &amp;obj); err != nil {            return err        }        syncer.AddSubTrie(obj.Root, 64, parent, nil)        syncer.AddRawEntry(common.BytesToHash(obj.CodeHash), 64, parent)        return nil    }    syncer = trie.NewTrieSync(root, database, callback)    return syncer}</code></pre><p>syncState， 这个函数是downloader调用的。</p><pre><code>// syncState starts downloading state with the given root hash.func (d *Downloader) syncState(root common.Hash) *stateSync {    s := newStateSync(d, root)    select {    case d.stateSyncStart &lt;- s:    case &lt;-d.quitCh:        s.err = errCancelStateFetch        close(s.done)    }    return s}</code></pre><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>在downloader中启动了一个新的goroutine 来运行stateFetcher函数。 这个函数首先试图往stateSyncStart通道来以获取信息。  而syncState这个函数会给stateSyncStart通道发送数据。</p><pre><code>// stateFetcher manages the active state sync and accepts requests// on its behalf.func (d *Downloader) stateFetcher() {    for {        select {        case s := &lt;-d.stateSyncStart:            for next := s; next != nil; { // 这个for循环代表了downloader可以通过发送信号来随时改变需要同步的对象。                next = d.runStateSync(next)            }        case &lt;-d.stateCh:            // Ignore state responses while no sync is running.        case &lt;-d.quitCh:            return        }    }}</code></pre><p>我们下面看看哪里会调用syncState()函数。processFastSyncContent这个函数会在最开始发现peer的时候启动。</p><pre><code>// processFastSyncContent takes fetch results from the queue and writes them to the// database. It also controls the synchronisation of state nodes of the pivot block.func (d *Downloader) processFastSyncContent(latest *types.Header) error {    // Start syncing state of the reported head block.    // This should get us most of the state of the pivot block.    stateSync := d.syncState(latest.Root)</code></pre><p>runStateSync,这个方法从stateCh获取已经下载好的状态，然后把他投递到deliver通道上等待别人处理。</p><pre><code>// runStateSync runs a state synchronisation until it completes or another root// hash is requested to be switched over to.func (d *Downloader) runStateSync(s *stateSync) *stateSync {    var (        active   = make(map[string]*stateReq) // Currently in-flight requests        finished []*stateReq                  // Completed or failed requests        timeout  = make(chan *stateReq)       // Timed out active requests    )    defer func() {        // Cancel active request timers on exit. Also set peers to idle so they're        // available for the next sync.        for _, req := range active {            req.timer.Stop()            req.peer.SetNodeDataIdle(len(req.items))        }    }()    // Run the state sync.    // 运行状态同步    go s.run()    defer s.Cancel()    // Listen for peer departure events to cancel assigned tasks    peerDrop := make(chan *peerConnection, 1024)    peerSub := s.d.peers.SubscribePeerDrops(peerDrop)    defer peerSub.Unsubscribe()    for {        // Enable sending of the first buffered element if there is one.        var (            deliverReq   *stateReq            deliverReqCh chan *stateReq        )        if len(finished) &gt; 0 {            deliverReq = finished[0]            deliverReqCh = s.deliver        }        select {        // The stateSync lifecycle:        // 另外一个stateSync申请运行。 我们退出。        case next := &lt;-d.stateSyncStart:            return next        case &lt;-s.done:            return nil        // Send the next finished request to the current sync:        // 发送已经下载好的数据给sync        case deliverReqCh &lt;- deliverReq:            finished = append(finished[:0], finished[1:]...)        // Handle incoming state packs:        // 处理进入的数据包。 downloader接收到state的数据会发送到这个通道上面。        case pack := &lt;-d.stateCh:            // Discard any data not requested (or previsouly timed out)            req := active[pack.PeerId()]            if req == nil {                log.Debug("Unrequested node data", "peer", pack.PeerId(), "len", pack.Items())                continue            }            // Finalize the request and queue up for processing            req.timer.Stop()            req.response = pack.(*statePack).states            finished = append(finished, req)            delete(active, pack.PeerId())            // Handle dropped peer connections:        case p := &lt;-peerDrop:            // Skip if no request is currently pending            req := active[p.id]            if req == nil {                continue            }            // Finalize the request and queue up for processing            req.timer.Stop()            req.dropped = true            finished = append(finished, req)            delete(active, p.id)        // Handle timed-out requests:        case req := &lt;-timeout:            // If the peer is already requesting something else, ignore the stale timeout.            // This can happen when the timeout and the delivery happens simultaneously,            // causing both pathways to trigger.            if active[req.peer.id] != req {                continue            }            // Move the timed out data back into the download queue            finished = append(finished, req)            delete(active, req.peer.id)        // Track outgoing state requests:        case req := &lt;-d.trackStateReq:            // If an active request already exists for this peer, we have a problem. In            // theory the trie node schedule must never assign two requests to the same            // peer. In practive however, a peer might receive a request, disconnect and            // immediately reconnect before the previous times out. In this case the first            // request is never honored, alas we must not silently overwrite it, as that            // causes valid requests to go missing and sync to get stuck.            if old := active[req.peer.id]; old != nil {                log.Warn("Busy peer assigned new state fetch", "peer", old.peer.id)                // Make sure the previous one doesn't get siletly lost                old.timer.Stop()                old.dropped = true                finished = append(finished, old)            }            // Start a timer to notify the sync loop if the peer stalled.            req.timer = time.AfterFunc(req.timeout, func() {                select {                case timeout &lt;- req:                case &lt;-s.done:                    // Prevent leaking of timer goroutines in the unlikely case where a                    // timer is fired just before exiting runStateSync.                }            })            active[req.peer.id] = req        }    }}</code></pre><p>run和loop方法，获取任务，分配任务，获取结果。</p><pre><code>func (s *stateSync) run() {    s.err = s.loop()    close(s.done)}// loop is the main event loop of a state trie sync. It it responsible for the// assignment of new tasks to peers (including sending it to them) as well as// for the processing of inbound data. Note, that the loop does not directly// receive data from peers, rather those are buffered up in the downloader and// pushed here async. The reason is to decouple processing from data receipt// and timeouts.func (s *stateSync) loop() error {    // Listen for new peer events to assign tasks to them    newPeer := make(chan *peerConnection, 1024)    peerSub := s.d.peers.SubscribeNewPeers(newPeer)    defer peerSub.Unsubscribe()    // Keep assigning new tasks until the sync completes or aborts    // 一直等到 sync完成或者被被终止    for s.sched.Pending() &gt; 0 {        // 把数据从缓存里面刷新到持久化存储里面。 这也就是命令行 --cache指定的大小。        if err := s.commit(false); err != nil {            return err        }        // 指派任务，        s.assignTasks()        // Tasks assigned, wait for something to happen        select {        case &lt;-newPeer:            // New peer arrived, try to assign it download tasks        case &lt;-s.cancel:            return errCancelStateFetch        case req := &lt;-s.deliver:            // 接收到runStateSync方法投递过来的返回信息，注意 返回信息里面包含了成功请求的也包含了未成功请求的。            // Response, disconnect or timeout triggered, drop the peer if stalling            log.Trace("Received node data response", "peer", req.peer.id, "count", len(req.response), "dropped", req.dropped, "timeout", !req.dropped &amp;&amp; req.timedOut())            if len(req.items) &lt;= 2 &amp;&amp; !req.dropped &amp;&amp; req.timedOut() {                // 2 items are the minimum requested, if even that times out, we've no use of                // this peer at the moment.                log.Warn("Stalling state sync, dropping peer", "peer", req.peer.id)                s.d.dropPeer(req.peer.id)            }            // Process all the received blobs and check for stale delivery            stale, err := s.process(req)            if err != nil {                log.Warn("Node data write error", "err", err)                return err            }            // The the delivery contains requested data, mark the node idle (otherwise it's a timed out delivery)            if !stale {                req.peer.SetNodeDataIdle(len(req.response))            }        }    }    return s.commit(true)}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-eth源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>eth的源码又下面几个包</p><ul><li>downloader         主要用于和网络同步，包含了传统同步方式和快速同步方式</li><li>fetcher            主要用于基于块通知的同步，接收到当我们接收到NewBlockHashesMsg消息得时候，我们只收到了很多Block的hash值。 需要通过hash值来同步区块。</li><li>filter            提供基于RPC的过滤功能，包括实时数据的同步(PendingTx)，和历史的日志查询(Log filter)</li><li>gasprice            提供gas的价格建议， 根据过去几个区块的gasprice，来得到当前的gasprice的建议价格</li></ul><p>eth 协议部分源码分析</p><ul><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth%E4%BB%A5%E5%A4%AA%E5%9D%8A%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/" title="以太坊的网络协议大概流程">以太坊的网络协议大概流程</a></li></ul><p>fetcher部分的源码分析</p><ul><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-fetcher%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="fetch部分源码分析">fetch部分源码分析</a></li></ul><p>downloader 部分源码分析</p><ul><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8Afast%20sync%E7%AE%97%E6%B3%95/" title="节点快速同步算法">节点快速同步算法</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader-queue.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="用来提供下载任务的调度和结果组装 queue.go">用来提供下载任务的调度和结果组装 queue.go</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader-peer%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="用来代表对端，提供QoS等功能 peer.go">用来代表对端，提供QoS等功能 peer.go</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader-statesync/" title="快速同步算法 用来提供Pivot point的 state-root的同步 statesync.go">快速同步算法 用来提供Pivot point的 state-root的同步 statesync.go</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="同步的大致流程的分析">同步的大致流程的分析</a></li></ul><p>filter 部分源码分析</p><ul><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-bloombits%E5%92%8Cfilter%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="提供布隆过滤器的查询和RPC过滤功能">提供布隆过滤器的查询和RPC过滤功能</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-event源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-event%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-event%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>event包实现了同一个进程内部的事件发布和订阅模式。</p><h2 id="event-go"><a href="#event-go" class="headerlink" title="event.go"></a>event.go</h2><p>目前这部分代码被标记为Deprecated，告知用户使用Feed这个对象。 不过在代码中任然有使用。 而且这部分的代码也不多。 就简单介绍一下。</p><p>数据结构<br>TypeMux是主要的使用。 subm记录了所有的订阅者。 可以看到每中类型都可以有很多的订阅者。</p><pre><code>// TypeMuxEvent is a time-tagged notification pushed to subscribers.type TypeMuxEvent struct {    Time time.Time    Data interface{}}// A TypeMux dispatches events to registered receivers. Receivers can be// registered to handle events of certain type. Any operation// called after mux is stopped will return ErrMuxClosed.//// The zero value is ready to use.//// Deprecated: use Feedtype TypeMux struct {    mutex   sync.RWMutex    subm    map[reflect.Type][]*TypeMuxSubscription    stopped bool}</code></pre><p>创建一个订阅,可以同时订阅多种类型。</p><pre><code>// Subscribe creates a subscription for events of the given types. The// subscription's channel is closed when it is unsubscribed// or the mux is closed.func (mux *TypeMux) Subscribe(types ...interface{}) *TypeMuxSubscription {    sub := newsub(mux)    mux.mutex.Lock()    defer mux.mutex.Unlock()    if mux.stopped {        // set the status to closed so that calling Unsubscribe after this        // call will short circuit.        sub.closed = true        close(sub.postC)    } else {        if mux.subm == nil {            mux.subm = make(map[reflect.Type][]*TypeMuxSubscription)        }        for _, t := range types {            rtyp := reflect.TypeOf(t)            oldsubs := mux.subm[rtyp]            if find(oldsubs, sub) != -1 {                panic(fmt.Sprintf("event: duplicate type %s in Subscribe", rtyp))            }            subs := make([]*TypeMuxSubscription, len(oldsubs)+1)            copy(subs, oldsubs)            subs[len(oldsubs)] = sub            mux.subm[rtyp] = subs        }    }    return sub}// TypeMuxSubscription is a subscription established through TypeMux.type TypeMuxSubscription struct {    mux     *TypeMux    created time.Time    closeMu sync.Mutex    closing chan struct{}    closed  bool    // these two are the same channel. they are stored separately so    // postC can be set to nil without affecting the return value of    // Chan.    postMu sync.RWMutex    // readC 和 postC 其实是同一个channel。 不过一个是从channel读 一个只从channel写    // 单方向的channel    readC  &lt;-chan *TypeMuxEvent    postC  chan&lt;- *TypeMuxEvent}func newsub(mux *TypeMux) *TypeMuxSubscription {    c := make(chan *TypeMuxEvent)    return &amp;TypeMuxSubscription{        mux:     mux,        created: time.Now(),        readC:   c,        postC:   c,        closing: make(chan struct{}),    }}</code></pre><p>发布一个event到TypeMux上面，这个时候所有订阅了这个类型的都会收到这个消息。</p><pre><code>// Post sends an event to all receivers registered for the given type.// It returns ErrMuxClosed if the mux has been stopped.func (mux *TypeMux) Post(ev interface{}) error {    event := &amp;TypeMuxEvent{        Time: time.Now(),        Data: ev,    }    rtyp := reflect.TypeOf(ev)    mux.mutex.RLock()    if mux.stopped {        mux.mutex.RUnlock()        return ErrMuxClosed    }    subs := mux.subm[rtyp]    mux.mutex.RUnlock()    for _, sub := range subs {        // 阻塞式的投递。         sub.deliver(event)    }    return nil}func (s *TypeMuxSubscription) deliver(event *TypeMuxEvent) {    // Short circuit delivery if stale event    if s.created.After(event.Time) {        return    }    // Otherwise deliver the event    s.postMu.RLock()    defer s.postMu.RUnlock()    select {    //阻塞方式的方法    case s.postC &lt;- event:    case &lt;-s.closing:    }}</code></pre><h2 id="feed-go"><a href="#feed-go" class="headerlink" title="feed.go"></a>feed.go</h2><p>目前主要使用的对象。取代了前面说的event.go内部的TypeMux</p><p>feed数据结构</p><pre><code>// Feed implements one-to-many subscriptions where the carrier of events is a channel.// Values sent to a Feed are delivered to all subscribed channels simultaneously.// Feed 实现了 1对多的订阅模式，使用了channel来传递事件。 发送给Feed的值会同时被传递给所有订阅的channel。// Feeds can only be used with a single type. The type is determined by the first Send or// Subscribe operation. Subsequent calls to these methods panic if the type does not// match.// Feed只能被单个类型使用。这个和之前的event不同，event可以使用多个类型。 类型被第一个Send调用或者是Subscribe调用决定。 后续的调用如果类型和其不一致会panic// The zero value is ready to use.type Feed struct {    once      sync.Once        // ensures that init only runs once    sendLock  chan struct{}    // sendLock has a one-element buffer and is empty when held.It protects sendCases.    removeSub chan interface{} // interrupts Send    sendCases caseList         // the active set of select cases used by Send    // The inbox holds newly subscribed channels until they are added to sendCases.    mu     sync.Mutex    inbox  caseList    etype  reflect.Type    closed bool}</code></pre><p>初始化 初始化会被once来保护保证只会被执行一次。</p><pre><code>func (f *Feed) init() {    f.removeSub = make(chan interface{})    f.sendLock = make(chan struct{}, 1)    f.sendLock &lt;- struct{}{}    f.sendCases = caseList{{Chan: reflect.ValueOf(f.removeSub), Dir: reflect.SelectRecv}}}</code></pre><p>订阅，订阅投递了一个channel。 相对与event的不同。event的订阅是传入了需要订阅的类型，然后channel是在event的订阅代码里面构建然后返回的。 这种直接投递channel的模式可能会更加灵活。<br>然后根据传入的channel生成了SelectCase。放入inbox。 </p><pre><code>// Subscribe adds a channel to the feed. Future sends will be delivered on the channel// until the subscription is canceled. All channels added must have the same element type.//// The channel should have ample buffer space to avoid blocking other subscribers.// Slow subscribers are not dropped.func (f *Feed) Subscribe(channel interface{}) Subscription {    f.once.Do(f.init)    chanval := reflect.ValueOf(channel)    chantyp := chanval.Type()    if chantyp.Kind() != reflect.Chan || chantyp.ChanDir()&amp;reflect.SendDir == 0 { // 如果类型不是channel。 或者是channel的方向不能发送数据。那么错误退出。        panic(errBadChannel)    }    sub := &amp;feedSub{feed: f, channel: chanval, err: make(chan error, 1)}    f.mu.Lock()    defer f.mu.Unlock()    if !f.typecheck(chantyp.Elem()) {        panic(feedTypeError{op: "Subscribe", got: chantyp, want: reflect.ChanOf(reflect.SendDir, f.etype)})    }    // Add the select case to the inbox.    // The next Send will add it to f.sendCases.    cas := reflect.SelectCase{Dir: reflect.SelectSend, Chan: chanval}    f.inbox = append(f.inbox, cas)    return sub}</code></pre><p>Send方法,feed的Send方法不是遍历所有的channel然后阻塞方式的发送。这样可能导致慢的客户端影响快的客户端。 而是使用反射的方式使用SelectCase。 首先调用非阻塞方式的TrySend来尝试发送。这样如果没有慢的客户端。数据会直接全部发送完成。 如果TrySend部分客户端失败。 那么后续在循环Select的方式发送。 我猜测这也是feed会取代event的原因。</p><pre><code>// Send delivers to all subscribed channels simultaneously.// It returns the number of subscribers that the value was sent to.func (f *Feed) Send(value interface{}) (nsent int) {    f.once.Do(f.init)    &lt;-f.sendLock    // Add new cases from the inbox after taking the send lock.    f.mu.Lock()    f.sendCases = append(f.sendCases, f.inbox...)    f.inbox = nil    f.mu.Unlock()    // Set the sent value on all channels.    rvalue := reflect.ValueOf(value)    if !f.typecheck(rvalue.Type()) {        f.sendLock &lt;- struct{}{}        panic(feedTypeError{op: "Send", got: rvalue.Type(), want: f.etype})    }    for i := firstSubSendCase; i &lt; len(f.sendCases); i++ {        f.sendCases[i].Send = rvalue    }    // Send until all channels except removeSub have been chosen.    cases := f.sendCases    for {        // Fast path: try sending without blocking before adding to the select set.        // This should usually succeed if subscribers are fast enough and have free        // buffer space.        for i := firstSubSendCase; i &lt; len(cases); i++ {            if cases[i].Chan.TrySend(rvalue) {                nsent++                cases = cases.deactivate(i)                i--            }        }        if len(cases) == firstSubSendCase {            break        }        // Select on all the receivers, waiting for them to unblock.        chosen, recv, _ := reflect.Select(cases)        if chosen == 0 /* &lt;-f.removeSub */ {            index := f.sendCases.find(recv.Interface())            f.sendCases = f.sendCases.delete(index)            if index &gt;= 0 &amp;&amp; index &lt; len(cases) {                cases = f.sendCases[:len(cases)-1]            }        } else {            cases = cases.deactivate(chosen)            nsent++        }    }    // Forget about the sent value and hand off the send lock.    for i := firstSubSendCase; i &lt; len(f.sendCases); i++ {        f.sendCases[i].Send = reflect.Value{}    }    f.sendLock &lt;- struct{}{}    return nsent}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-go-ethereum源码阅读环境搭建</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-go-ethereum%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-go-ethereum%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="go-ethereum源码解析"><a href="#go-ethereum源码解析" class="headerlink" title="go-ethereum源码解析"></a>go-ethereum源码解析</h2><p>因为go ethereum是最被广泛使用的以太坊客户端， 所以后续的源码分析都从github上面的这份代码进行分析。 </p><h3 id="搭建go-ethereum调试环境"><a href="#搭建go-ethereum调试环境" class="headerlink" title="搭建go ethereum调试环境"></a>搭建go ethereum调试环境</h3><h4 id="windows-10-64bit"><a href="#windows-10-64bit" class="headerlink" title="windows 10 64bit"></a>windows 10 64bit</h4><p>首先下载go安装包进行安装，因为GO的网站被墙，所以从下面地址下载。</p><pre><code>https://studygolang.com/dl/golang/go1.9.1.windows-amd64.msi</code></pre><p>安装好之后，设置环境变量，把C:\Go\bin目录添加到你的PATH环境变量， 然后增加一个GOPATH的环境变量，GOPATH的值设置为你的GO语言下载的代码路径(我设置的是C:\GOPATH)</p><p><img src="https://raw.githubusercontent.com/wugang33/go-ethereum-code-analysis/master/picture/go_env_1.png" alt="image"></p><p>安装git工具，请参考网络上的教程安装git工具， go语言从github自动下载代码需要git工具的支持</p><p>打开命令行工具下载 go-ethereum的代码</p><pre><code>go get github.com/ethereum/go-ethereum</code></pre><p>命令执行成功之后，代码就会下载到下面这个目录，%GOPATH%\src\github.com\ethereum\go-ethereum<br>如果执行过程中出现</p><pre><code># github.com/ethereum/go-ethereum/crypto/secp256k1exec: "gcc": executable file not found in %PATH%</code></pre><p>则需要安装gcc工具，我们从下面地址下载并安装</p><pre><code>http://tdm-gcc.tdragon.net/download</code></pre><p>接下来安装IDE工具。 我是用的IDE是JetBrains的Gogland。 可以在下面地址下载</p><pre><code>https://download.jetbrains.com/go/gogland-173.2696.28.exe</code></pre><p>安装完成后打开IDE. 选择File -&gt; Open -&gt; 选择GOPATH\src\github.com\ethereum\go-ethereum目录打开。</p><p>然后打开go-ethereum/rlp/decode_test.go. 在编辑框右键选择运行， 如果运行成功，代表环境搭建完成。</p><p><img src="https://raw.githubusercontent.com/wugang33/go-ethereum-code-analysis/master/picture/go_env_2.png" alt="image"></p><h3 id="Ubuntu-16-04-64bit"><a href="#Ubuntu-16-04-64bit" class="headerlink" title="Ubuntu 16.04 64bit"></a>Ubuntu 16.04 64bit</h3><p>go安装包进行安装</p><pre><code>apt install golang-go git -y</code></pre><p>golang环境配置：</p><pre><code>编辑/etc/profile文件，在该文件中加入以下内容：export GOROOT=/usr/bin/go  export GOPATH=/root/home/goprojectexport GOBIN=/root/home/goproject/binexport GOLIB=/root/home/goproject/export PATH=$PATH:$GOBIN:$GOPATH/bin:$GOROOT/bin</code></pre><p>执行以下命令，使得环境变量生效：<br></p><pre><code># source /etc/profile</code></pre><p>下载源码：</p><pre><code>#cd  /root/home/goproject; mkdir src； cd src  #进入go项目目录，并创建src目录, 并进入src目录#git clone https://github.com/ethereum/go-ethereum</code></pre><p>使用vim或其他IDE打开即可；</p><h3 id="go-ethereum-目录大概介绍"><a href="#go-ethereum-目录大概介绍" class="headerlink" title="go ethereum 目录大概介绍"></a>go ethereum 目录大概介绍</h3><p>go-ethereum项目的组织结构基本上是按照功能模块划分的目录，下面简单介绍一下各个目录的结构，每个目录在GO语言里面又被成为一个Package,我理解跟Java里面的Package应该是差不多的意思。</p><pre><code>accounts            实现了一个高等级的以太坊账户管理bmt            二进制的默克尔树的实现build            主要是编译和构建的一些脚本和配置cmd            命令行工具，又分了很多的命令行工具，下面一个一个介绍    /abigen        Source code generator to convert Ethereum contract definitions into easy to use, compile-time type-safe Go packages    /bootnode    启动一个仅仅实现网络发现的节点    /evm        以太坊虚拟机的开发工具， 用来提供一个可配置的，受隔离的代码调试环境    /faucet            /geth        以太坊命令行客户端，最重要的一个工具    /p2psim        提供了一个工具来模拟http的API    /puppeth    创建一个新的以太坊网络的向导    /rlpdump     提供了一个RLP数据的格式化输出    /swarm        swarm网络的接入点    /util        提供了一些公共的工具    /wnode        这是一个简单的Whisper节点。 它可以用作独立的引导节点。此外，可以用于不同的测试和诊断目的。common            提供了一些公共的工具类compression        Package rle implements the run-length encoding used for Ethereum data.consensus        提供了以太坊的一些共识算法，比如ethhash, clique(proof-of-authority)console            console类contracts    core            以太坊的核心数据结构和算法(虚拟机，状态，区块链，布隆过滤器)crypto            加密和hash算法，eth            实现了以太坊的协议ethclient        提供了以太坊的RPC客户端ethdb            eth的数据库(包括实际使用的leveldb和供测试使用的内存数据库)ethstats        提供网络状态的报告event            处理实时的事件les            实现了以太坊的轻量级协议子集light            实现为以太坊轻量级客户端提供按需检索的功能log            提供对人机都友好的日志信息metrics            提供磁盘计数器miner            提供以太坊的区块创建和挖矿mobile            移动端使用的一些warppernode            以太坊的多种类型的节点p2p            以太坊p2p网络协议rlp            以太坊序列化处理rpc            远程方法调用swarm            swarm网络处理tests            测试trie            以太坊重要的数据结构Package trie implements Merkle Patricia Tries.whisper            提供了whisper节点的协议。</code></pre><p>可以看到以太坊的代码量还是挺大的，但是粗略看，代码结构还是挺好的。我希望先从一些比较独立的模块来进行分析。然后在深入分析内部的代码。重点可能集中在黄皮书里面没有涉及到的p2p网络等模块。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-node源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-node%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-node%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>node在go ethereum中代表了一个节点。 可能是全节点，可能是轻量级节点。 node可以理解为一个进程，以太坊由运行在世界各地的很多中类型的node组成。</p><p>一个典型的node就是一个p2p的节点。 运行了p2p网络协议，同时根据节点类型不同，运行了不同的业务层协议(以区别网络层协议。 参考p2p peer中的Protocol接口)。</p><p>node的结构。</p><pre><code>// Node is a container on which services can be registered.type Node struct {    eventmux *event.TypeMux // Event multiplexer used between the services of a stack    config   *Config    accman   *accounts.Manager    ephemeralKeystore string         // if non-empty, the key directory that will be removed by Stop    instanceDirLock   flock.Releaser // prevents concurrent use of instance directory    serverConfig p2p.Config    server       *p2p.Server // Currently running P2P networking layer    serviceFuncs []ServiceConstructor     // Service constructors (in dependency order)    services     map[reflect.Type]Service // Currently running services    rpcAPIs       []rpc.API   // List of APIs currently provided by the node    inprocHandler *rpc.Server // In-process RPC request handler to process the API requests    ipcEndpoint string       // IPC endpoint to listen at (empty = IPC disabled)    ipcListener net.Listener // IPC RPC listener socket to serve API requests    ipcHandler  *rpc.Server  // IPC RPC request handler to process the API requests    httpEndpoint  string       // HTTP endpoint (interface + port) to listen at (empty = HTTP disabled)    httpWhitelist []string     // HTTP RPC modules to allow through this endpoint    httpListener  net.Listener // HTTP RPC listener socket to server API requests    httpHandler   *rpc.Server  // HTTP RPC request handler to process the API requests    wsEndpoint string       // Websocket endpoint (interface + port) to listen at (empty = websocket disabled)    wsListener net.Listener // Websocket RPC listener socket to server API requests    wsHandler  *rpc.Server  // Websocket RPC request handler to process the API requests    stop chan struct{} // Channel to wait for termination notifications    lock sync.RWMutex}</code></pre><p>节点的初始化, 节点的初始化并不依赖其他的外部组件， 只依赖一个Config对象。</p><pre><code>// New creates a new P2P node, ready for protocol registration.func New(conf *Config) (*Node, error) {    // Copy config and resolve the datadir so future changes to the current    // working directory don't affect the node.    confCopy := *conf    conf = &amp;confCopy    if conf.DataDir != "" {  //转化为绝对路径。        absdatadir, err := filepath.Abs(conf.DataDir)        if err != nil {            return nil, err        }        conf.DataDir = absdatadir    }    // Ensure that the instance name doesn't cause weird conflicts with    // other files in the data directory.    if strings.ContainsAny(conf.Name, `/\`) {        return nil, errors.New(`Config.Name must not contain '/' or '\'`)    }    if conf.Name == datadirDefaultKeyStore {        return nil, errors.New(`Config.Name cannot be "` + datadirDefaultKeyStore + `"`)    }    if strings.HasSuffix(conf.Name, ".ipc") {        return nil, errors.New(`Config.Name cannot end in ".ipc"`)    }    // Ensure that the AccountManager method works before the node has started.    // We rely on this in cmd/geth.    am, ephemeralKeystore, err := makeAccountManager(conf)    if err != nil {        return nil, err    }    // Note: any interaction with Config that would create/touch files    // in the data directory or instance directory is delayed until Start.    return &amp;Node{        accman:            am,        ephemeralKeystore: ephemeralKeystore,        config:            conf,        serviceFuncs:      []ServiceConstructor{},        ipcEndpoint:       conf.IPCEndpoint(),        httpEndpoint:      conf.HTTPEndpoint(),        wsEndpoint:        conf.WSEndpoint(),        eventmux:          new(event.TypeMux),    }, nil}</code></pre><h3 id="node-服务和协议的注册"><a href="#node-服务和协议的注册" class="headerlink" title="node 服务和协议的注册"></a>node 服务和协议的注册</h3><p>因为node并没有负责具体的业务逻辑。所以具体的业务逻辑是通过注册的方式来注册到node里面来的。<br>其他模块通过Register方法来注册了一个 服务构造函数。 使用这个服务构造函数可以生成服务。</p><pre><code>// Register injects a new service into the node's stack. The service created by// the passed constructor must be unique in its type with regard to sibling ones.func (n *Node) Register(constructor ServiceConstructor) error {    n.lock.Lock()    defer n.lock.Unlock()    if n.server != nil {        return ErrNodeRunning    }    n.serviceFuncs = append(n.serviceFuncs, constructor)    return nil}</code></pre><p>服务是什么</p><pre><code>type ServiceConstructor func(ctx *ServiceContext) (Service, error)// Service is an individual protocol that can be registered into a node.//// Notes://// • Service life-cycle management is delegated to the node. The service is allowed to// initialize itself upon creation, but no goroutines should be spun up outside of the// Start method.//// • Restart logic is not required as the node will create a fresh instance// every time a service is started.// 服务的生命周期管理已经代理给node管理。该服务允许在创建时自动初始化，但是在Start方法之外不应该启动goroutines。// 重新启动逻辑不是必需的，因为节点将在每次启动服务时创建一个新的实例。type Service interface {    // Protocols retrieves the P2P protocols the service wishes to start.    // 服务希望提供的p2p协议    Protocols() []p2p.Protocol        // APIs retrieves the list of RPC descriptors the service provides    // 服务希望提供的RPC方法的描述    APIs() []rpc.API    // Start is called after all services have been constructed and the networking    // layer was also initialized to spawn any goroutines required by the service.    // 所有服务已经构建完成后，调用开始，并且网络层也被初始化以产生服务所需的任何goroutine。    Start(server *p2p.Server) error    // Stop terminates all goroutines belonging to the service, blocking until they    // are all terminated.        // Stop方法会停止这个服务拥有的所有goroutine。 需要阻塞到所有的goroutine都已经终止    Stop() error}</code></pre><h3 id="node的启动"><a href="#node的启动" class="headerlink" title="node的启动"></a>node的启动</h3><p>node的启动过程会创建和运行一个p2p的节点。</p><pre><code>// Start create a live P2P node and starts running it.func (n *Node) Start() error {    n.lock.Lock()    defer n.lock.Unlock()    // Short circuit if the node's already running    if n.server != nil {        return ErrNodeRunning    }    if err := n.openDataDir(); err != nil {        return err    }    // Initialize the p2p server. This creates the node key and    // discovery databases.    n.serverConfig = n.config.P2P    n.serverConfig.PrivateKey = n.config.NodeKey()    n.serverConfig.Name = n.config.NodeName()    if n.serverConfig.StaticNodes == nil {        // 处理配置文件static-nodes.json        n.serverConfig.StaticNodes = n.config.StaticNodes()    }    if n.serverConfig.TrustedNodes == nil {        // 处理配置文件trusted-nodes.json        n.serverConfig.TrustedNodes = n.config.TrustedNodes()    }    if n.serverConfig.NodeDatabase == "" {        n.serverConfig.NodeDatabase = n.config.NodeDB()    }    //创建了p2p服务器    running := &amp;p2p.Server{Config: n.serverConfig}    log.Info("Starting peer-to-peer node", "instance", n.serverConfig.Name)    // Otherwise copy and specialize the P2P configuration    services := make(map[reflect.Type]Service)    for _, constructor := range n.serviceFuncs {        // Create a new context for the particular service        ctx := &amp;ServiceContext{            config:         n.config,            services:       make(map[reflect.Type]Service),            EventMux:       n.eventmux,            AccountManager: n.accman,        }        for kind, s := range services { // copy needed for threaded access            ctx.services[kind] = s        }        // Construct and save the service        // 创建所有注册的服务。        service, err := constructor(ctx)        if err != nil {            return err        }        kind := reflect.TypeOf(service)        if _, exists := services[kind]; exists {            return &amp;DuplicateServiceError{Kind: kind}        }        services[kind] = service    }    // Gather the protocols and start the freshly assembled P2P server    // 收集所有的p2p的protocols并插入p2p.Rrotocols    for _, service := range services {        running.Protocols = append(running.Protocols, service.Protocols()...)    }    // 启动了p2p服务器    if err := running.Start(); err != nil {        return convertFileLockError(err)    }    // Start each of the services    // 启动每一个服务    started := []reflect.Type{}    for kind, service := range services {        // Start the next service, stopping all previous upon failure        if err := service.Start(running); err != nil {            for _, kind := range started {                services[kind].Stop()            }            running.Stop()            return err        }        // Mark the service started for potential cleanup        started = append(started, kind)    }    // Lastly start the configured RPC interfaces    // 最后启动RPC服务    if err := n.startRPC(services); err != nil {        for _, service := range services {            service.Stop()        }        running.Stop()        return err    }    // Finish initializing the startup    n.services = services    n.server = running    n.stop = make(chan struct{})    return nil}</code></pre><p>startRPC,这个方法收集所有的apis。 并依次调用启动各个RPC服务器， 默认是启动InProc和IPC。 如果指定也可以配置是否启动HTTP和websocket。</p><pre><code>// startRPC is a helper method to start all the various RPC endpoint during node// startup. It's not meant to be called at any time afterwards as it makes certain// assumptions about the state of the node.func (n *Node) startRPC(services map[reflect.Type]Service) error {    // Gather all the possible APIs to surface    apis := n.apis()    for _, service := range services {        apis = append(apis, service.APIs()...)    }    // Start the various API endpoints, terminating all in case of errors    if err := n.startInProc(apis); err != nil {        return err    }    if err := n.startIPC(apis); err != nil {        n.stopInProc()        return err    }    if err := n.startHTTP(n.httpEndpoint, apis, n.config.HTTPModules, n.config.HTTPCors); err != nil {        n.stopIPC()        n.stopInProc()        return err    }    if err := n.startWS(n.wsEndpoint, apis, n.config.WSModules, n.config.WSOrigins, n.config.WSExposeAll); err != nil {        n.stopHTTP()        n.stopIPC()        n.stopInProc()        return err    }    // All API endpoints started successfully    n.rpcAPIs = apis    return nil}</code></pre><p>startXXX 是具体的RPC的启动，流程都是大同小异。在v1.8.12 版本中 node\node.go 文件中startIPC()、startHTTP()、startWS()三个方法的具体启动方式封装到 rpc\endpoints.go 文件对应函数中</p><p>// StartWSEndpoint starts a websocket endpoint<br>func StartWSEndpoint(endpoint string, apis []API, modules []string, wsOrigins []string, exposeAll bool) (net.Listener, *Server, error) {</p><pre><code>// Generate the whitelist based on the allowed modules// 生成白名单whitelist := make(map[string]bool)for _, module := range modules {    whitelist[module] = true}// Register all the APIs exposed by the serviceshandler := NewServer()for _, api := range apis {    if exposeAll || whitelist[api.Namespace] || (len(whitelist) == 0 &amp;&amp; api.Public) {        // 只有这几种情况下才会把这个api进行注册。        if err := handler.RegisterName(api.Namespace, api.Service); err != nil {            return nil, nil, err        }        log.Debug("WebSocket registered", "service", api.Service, "namespace", api.Namespace)    }}// All APIs registered, start the HTTP listener// 所有 APIs 都已经注册，启动 HTTP 监听器var (    listener net.Listener    err      error)if listener, err = net.Listen("tcp", endpoint); err != nil {    return nil, nil, err}go NewWSServer(wsOrigins, handler).Serve(listener)return listener, handler, err</code></pre><p>}</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-p2p-database.go源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-database.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-database.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>p2p包实现了通用的p2p网络协议。包括节点的查找，节点状态的维护，节点连接的建立等p2p的功能。p2p 包实现的是通用的p2p协议。 某一种具体的协议(比如eth协议。 whisper协议。 swarm协议)被封装成特定的接口注入p2p包。所以p2p内部不包含具体协议的实现。 只完成了p2p网络应该做的事情。</p><h2 id="discover-discv5-节点发现"><a href="#discover-discv5-节点发现" class="headerlink" title="discover / discv5 节点发现"></a>discover / discv5 节点发现</h2><p>目前使用的包是discover。 discv5是最近才开发的功能，还是属于实验性质，基本上是discover包的一些优化。 这里我们暂时只分析discover的代码。 对其完成的功能做一个基本的介绍。</p><h3 id="database-go"><a href="#database-go" class="headerlink" title="database.go"></a>database.go</h3><p>顾名思义，这个文件内部主要实现了节点的持久化，因为p2p网络节点的节点发现和维护都是比较花时间的，为了反复启动的时候，能够把之前的工作继承下来，避免每次都重新发现。 所以持久化的工作是必须的。</p><p>之前我们分析了ethdb的代码和trie的代码，trie的持久化工作使用了leveldb。 这里同样也使用了leveldb。 不过p2p的leveldb实例和主要的区块链的leveldb实例不是同一个。</p><p>newNodeDB,根据参数path来看打开基于内存的数据库，还是基于文件的数据库。</p><pre><code>// newNodeDB creates a new node database for storing and retrieving infos about// known peers in the network. If no path is given, an in-memory, temporary// database is constructed.func newNodeDB(path string, version int, self NodeID) (*nodeDB, error) {    if path == "" {        return newMemoryNodeDB(self)    }    return newPersistentNodeDB(path, version, self)}// newMemoryNodeDB creates a new in-memory node database without a persistent// backend.func newMemoryNodeDB(self NodeID) (*nodeDB, error) {    db, err := leveldb.Open(storage.NewMemStorage(), nil)    if err != nil {        return nil, err    }    return &amp;nodeDB{        lvl:  db,        self: self,        quit: make(chan struct{}),    }, nil}// newPersistentNodeDB creates/opens a leveldb backed persistent node database,// also flushing its contents in case of a version mismatch.func newPersistentNodeDB(path string, version int, self NodeID) (*nodeDB, error) {    opts := &amp;opt.Options{OpenFilesCacheCapacity: 5}    db, err := leveldb.OpenFile(path, opts)    if _, iscorrupted := err.(*errors.ErrCorrupted); iscorrupted {        db, err = leveldb.RecoverFile(path, nil)    }    if err != nil {        return nil, err    }    // The nodes contained in the cache correspond to a certain protocol version.    // Flush all nodes if the version doesn't match.    currentVer := make([]byte, binary.MaxVarintLen64)    currentVer = currentVer[:binary.PutVarint(currentVer, int64(version))]    blob, err := db.Get(nodeDBVersionKey, nil)    switch err {    case leveldb.ErrNotFound:        // Version not found (i.e. empty cache), insert it        if err := db.Put(nodeDBVersionKey, currentVer, nil); err != nil {            db.Close()            return nil, err        }    case nil:        // Version present, flush if different        //版本不同，先删除所有的数据库文件，重新创建一个。        if !bytes.Equal(blob, currentVer) {            db.Close()            if err = os.RemoveAll(path); err != nil {                return nil, err            }            return newPersistentNodeDB(path, version, self)        }    }    return &amp;nodeDB{        lvl:  db,        self: self,        quit: make(chan struct{}),    }, nil}</code></pre><p>Node的存储，查询和删除    </p><pre><code>// node retrieves a node with a given id from the database.func (db *nodeDB) node(id NodeID) *Node {    blob, err := db.lvl.Get(makeKey(id, nodeDBDiscoverRoot), nil)    if err != nil {        return nil    }    node := new(Node)    if err := rlp.DecodeBytes(blob, node); err != nil {        log.Error("Failed to decode node RLP", "err", err)        return nil    }    node.sha = crypto.Keccak256Hash(node.ID[:])    return node}// updateNode inserts - potentially overwriting - a node into the peer database.func (db *nodeDB) updateNode(node *Node) error {    blob, err := rlp.EncodeToBytes(node)    if err != nil {        return err    }    return db.lvl.Put(makeKey(node.ID, nodeDBDiscoverRoot), blob, nil)}// deleteNode deletes all information/keys associated with a node.func (db *nodeDB) deleteNode(id NodeID) error {    deleter := db.lvl.NewIterator(util.BytesPrefix(makeKey(id, "")), nil)    for deleter.Next() {        if err := db.lvl.Delete(deleter.Key(), nil); err != nil {            return err        }    }    return nil}</code></pre><p>Node的结构</p><pre><code>type Node struct {    IP       net.IP // len 4 for IPv4 or 16 for IPv6    UDP, TCP uint16 // port numbers    ID       NodeID // the node's public key    // This is a cached copy of sha3(ID) which is used for node    // distance calculations. This is part of Node in order to make it    // possible to write tests that need a node at a certain distance.    // In those tests, the content of sha will not actually correspond    // with ID.    sha common.Hash    // whether this node is currently being pinged in order to replace    // it in a bucket    contested bool}</code></pre><p>节点超时处理</p><pre><code>// ensureExpirer is a small helper method ensuring that the data expiration// mechanism is running. If the expiration goroutine is already running, this// method simply returns.// ensureExpirer方法用来确保expirer方法在运行。 如果expirer已经运行，那么这个方法就直接返回。// 这个方法设置的目的是为了在网络成功启动后在开始进行数据超时丢弃的工作(以防一些潜在的有用的种子节点被丢弃)。// The goal is to start the data evacuation only after the network successfully// bootstrapped itself (to prevent dumping potentially useful seed nodes). Since// it would require significant overhead to exactly trace the first successful// convergence, it's simpler to "ensure" the correct state when an appropriate// condition occurs (i.e. a successful bonding), and discard further events.func (db *nodeDB) ensureExpirer() {    db.runner.Do(func() { go db.expirer() })}// expirer should be started in a go routine, and is responsible for looping ad// infinitum and dropping stale data from the database.func (db *nodeDB) expirer() {    tick := time.Tick(nodeDBCleanupCycle)    for {        select {        case &lt;-tick:            if err := db.expireNodes(); err != nil {                log.Error("Failed to expire nodedb items", "err", err)            }        case &lt;-db.quit:            return        }    }}// expireNodes iterates over the database and deletes all nodes that have not// been seen (i.e. received a pong from) for some allotted time.//这个方法遍历所有的节点，如果某个节点最后接收消息超过指定值，那么就删除这个节点。func (db *nodeDB) expireNodes() error {    threshold := time.Now().Add(-nodeDBNodeExpiration)    // Find discovered nodes that are older than the allowance    it := db.lvl.NewIterator(nil, nil)    defer it.Release()    for it.Next() {        // Skip the item if not a discovery node        id, field := splitKey(it.Key())        if field != nodeDBDiscoverRoot {            continue        }        // Skip the node if not expired yet (and not self)        if !bytes.Equal(id[:], db.self[:]) {            if seen := db.lastPong(id); seen.After(threshold) {                continue            }        }        // Otherwise delete all associated information        db.deleteNode(id)    }    return nil}</code></pre><p>一些状态更新函数</p><pre><code>// lastPing retrieves the time of the last ping packet send to a remote node,// requesting binding.func (db *nodeDB) lastPing(id NodeID) time.Time {    return time.Unix(db.fetchInt64(makeKey(id, nodeDBDiscoverPing)), 0)}// updateLastPing updates the last time we tried contacting a remote node.func (db *nodeDB) updateLastPing(id NodeID, instance time.Time) error {    return db.storeInt64(makeKey(id, nodeDBDiscoverPing), instance.Unix())}// lastPong retrieves the time of the last successful contact from remote node.func (db *nodeDB) lastPong(id NodeID) time.Time {    return time.Unix(db.fetchInt64(makeKey(id, nodeDBDiscoverPong)), 0)}// updateLastPong updates the last time a remote node successfully contacted.func (db *nodeDB) updateLastPong(id NodeID, instance time.Time) error {    return db.storeInt64(makeKey(id, nodeDBDiscoverPong), instance.Unix())}// findFails retrieves the number of findnode failures since bonding.func (db *nodeDB) findFails(id NodeID) int {    return int(db.fetchInt64(makeKey(id, nodeDBDiscoverFindFails)))}// updateFindFails updates the number of findnode failures since bonding.func (db *nodeDB) updateFindFails(id NodeID, fails int) error {    return db.storeInt64(makeKey(id, nodeDBDiscoverFindFails), int64(fails))}</code></pre><p>从数据库里面随机挑选合适种子节点</p><pre><code>// querySeeds retrieves random nodes to be used as potential seed nodes// for bootstrapping.func (db *nodeDB) querySeeds(n int, maxAge time.Duration) []*Node {    var (        now   = time.Now()        nodes = make([]*Node, 0, n)        it    = db.lvl.NewIterator(nil, nil)        id    NodeID    )    defer it.Release()seek:    for seeks := 0; len(nodes) &lt; n &amp;&amp; seeks &lt; n*5; seeks++ {        // Seek to a random entry. The first byte is incremented by a        // random amount each time in order to increase the likelihood        // of hitting all existing nodes in very small databases.        ctr := id[0]        rand.Read(id[:])        id[0] = ctr + id[0]%16        it.Seek(makeKey(id, nodeDBDiscoverRoot))        n := nextNode(it)        if n == nil {            id[0] = 0            continue seek // iterator exhausted        }        if n.ID == db.self {            continue seek        }        if now.Sub(db.lastPong(n.ID)) &gt; maxAge {            continue seek        }        for i := range nodes {            if nodes[i].ID == n.ID {                continue seek // duplicate            }        }        nodes = append(nodes, n)    }    return nodes}// reads the next node record from the iterator, skipping over other// database entries.func nextNode(it iterator.Iterator) *Node {    for end := false; !end; end = !it.Next() {        id, field := splitKey(it.Key())        if field != nodeDBDiscoverRoot {            continue        }        var n Node        if err := rlp.DecodeBytes(it.Value(), &amp;n); err != nil {            log.Warn("Failed to decode node RLP", "id", id, "err", err)            continue        }        return &amp;n    }    return nil}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-p2p-dial.go源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-dial.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-dial.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>dial.go在p2p里面主要负责建立链接的部分工作。 比如发现建立链接的节点。 与节点建立链接。 通过discover来查找指定节点的地址。等功能。</p><p>dial.go里面利用一个dailstate的数据结构来存储中间状态,是dial功能里面的核心数据结构。</p><pre><code>// dialstate schedules dials and discovery lookups.// it get's a chance to compute new tasks on every iteration// of the main loop in Server.run.type dialstate struct {    maxDynDials int                        //最大的动态节点链接数量    ntab        discoverTable            //discoverTable 用来做节点查询的    netrestrict *netutil.Netlist    lookupRunning bool    dialing       map[discover.NodeID]connFlag        //正在链接的节点    lookupBuf     []*discover.Node // current discovery lookup results //当前的discovery查询结果    randomNodes   []*discover.Node // filled from Table //从discoverTable随机查询的节点    static        map[discover.NodeID]*dialTask  //静态的节点。     hist          *dialHistory    start     time.Time        // time when the dialer was first used    bootnodes []*discover.Node // default dials when there are no peers //这个是内置的节点。 如果没有找到其他节点。那么使用链接这些节点。}</code></pre><p>dailstate的创建过程。</p><pre><code>func newDialState(static []*discover.Node, bootnodes []*discover.Node, ntab discoverTable, maxdyn int, netrestrict *netutil.Netlist) *dialstate {    s := &amp;dialstate{        maxDynDials: maxdyn,        ntab:        ntab,        netrestrict: netrestrict,        static:      make(map[discover.NodeID]*dialTask),        dialing:     make(map[discover.NodeID]connFlag),        bootnodes:   make([]*discover.Node, len(bootnodes)),        randomNodes: make([]*discover.Node, maxdyn/2),        hist:        new(dialHistory),    }    copy(s.bootnodes, bootnodes)    for _, n := range static {        s.addStatic(n)    }    return s}</code></pre><p>dail最重要的方法是newTasks方法。这个方法用来生成task。 task是一个接口。有一个Do的方法。</p><pre><code>type task interface {    Do(*Server)}func (s *dialstate) newTasks(nRunning int, peers map[discover.NodeID]*Peer, now time.Time) []task {    if s.start == (time.Time{}) {        s.start = now    }    var newtasks []task    //addDial是一个内部方法， 首先通过checkDial检查节点。然后设置状态，最后把节点增加到newtasks队列里面。    addDial := func(flag connFlag, n *discover.Node) bool {        if err := s.checkDial(n, peers); err != nil {            log.Trace("Skipping dial candidate", "id", n.ID, "addr", &amp;net.TCPAddr{IP: n.IP, Port: int(n.TCP)}, "err", err)            return false        }        s.dialing[n.ID] = flag        newtasks = append(newtasks, &amp;dialTask{flags: flag, dest: n})        return true    }    // Compute number of dynamic dials necessary at this point.    needDynDials := s.maxDynDials    //首先判断已经建立的连接的类型。如果是动态类型。那么需要建立动态链接数量减少。    for _, p := range peers {        if p.rw.is(dynDialedConn) {            needDynDials--        }    }    //然后再判断正在建立的链接。如果是动态类型。那么需要建立动态链接数量减少。    for _, flag := range s.dialing {        if flag&amp;dynDialedConn != 0 {            needDynDials--        }    }    // Expire the dial history on every invocation.    s.hist.expire(now)    // Create dials for static nodes if they are not connected.    //查看所有的静态类型。如果可以那么也创建链接。    for id, t := range s.static {        err := s.checkDial(t.dest, peers)        switch err {        case errNotWhitelisted, errSelf:            log.Warn("Removing static dial candidate", "id", t.dest.ID, "addr", &amp;net.TCPAddr{IP: t.dest.IP, Port: int(t.dest.TCP)}, "err", err)            delete(s.static, t.dest.ID)        case nil:            s.dialing[id] = t.flags            newtasks = append(newtasks, t)        }    }    // If we don't have any peers whatsoever, try to dial a random bootnode. This    // scenario is useful for the testnet (and private networks) where the discovery    // table might be full of mostly bad peers, making it hard to find good ones.    //如果当前还没有任何链接。 而且20秒(fallbackInterval)内没有创建任何链接。 那么就使用bootnode创建链接。    if len(peers) == 0 &amp;&amp; len(s.bootnodes) &gt; 0 &amp;&amp; needDynDials &gt; 0 &amp;&amp; now.Sub(s.start) &gt; fallbackInterval {        bootnode := s.bootnodes[0]        s.bootnodes = append(s.bootnodes[:0], s.bootnodes[1:]...)        s.bootnodes = append(s.bootnodes, bootnode)        if addDial(dynDialedConn, bootnode) {            needDynDials--        }    }    // Use random nodes from the table for half of the necessary    // dynamic dials.    //否则使用1/2的随机节点创建链接。    randomCandidates := needDynDials / 2    if randomCandidates &gt; 0 {        n := s.ntab.ReadRandomNodes(s.randomNodes)        for i := 0; i &lt; randomCandidates &amp;&amp; i &lt; n; i++ {            if addDial(dynDialedConn, s.randomNodes[i]) {                needDynDials--            }        }    }    // Create dynamic dials from random lookup results, removing tried    // items from the result buffer.    i := 0    for ; i &lt; len(s.lookupBuf) &amp;&amp; needDynDials &gt; 0; i++ {        if addDial(dynDialedConn, s.lookupBuf[i]) {            needDynDials--        }    }    s.lookupBuf = s.lookupBuf[:copy(s.lookupBuf, s.lookupBuf[i:])]    // Launch a discovery lookup if more candidates are needed.    // 如果就算这样也不能创建足够动态链接。 那么创建一个discoverTask用来再网络上查找其他的节点。放入lookupBuf    if len(s.lookupBuf) &lt; needDynDials &amp;&amp; !s.lookupRunning {        s.lookupRunning = true        newtasks = append(newtasks, &amp;discoverTask{})    }    // Launch a timer to wait for the next node to expire if all    // candidates have been tried and no task is currently active.    // This should prevent cases where the dialer logic is not ticked    // because there are no pending events.    // 如果当前没有任何任务需要做，那么创建一个睡眠的任务返回。    if nRunning == 0 &amp;&amp; len(newtasks) == 0 &amp;&amp; s.hist.Len() &gt; 0 {        t := &amp;waitExpireTask{s.hist.min().exp.Sub(now)}        newtasks = append(newtasks, t)    }    return newtasks}</code></pre><p>checkDial方法， 用来检查任务是否需要创建链接。 </p><pre><code>func (s *dialstate) checkDial(n *discover.Node, peers map[discover.NodeID]*Peer) error {    _, dialing := s.dialing[n.ID]    switch {    case dialing:                    //正在创建        return errAlreadyDialing    case peers[n.ID] != nil:        //已经链接了        return errAlreadyConnected    case s.ntab != nil &amp;&amp; n.ID == s.ntab.Self().ID:    //建立的对象不是自己        return errSelf    case s.netrestrict != nil &amp;&amp; !s.netrestrict.Contains(n.IP): //网络限制。 对方的IP地址不在白名单里面。        return errNotWhitelisted    case s.hist.contains(n.ID):    // 这个ID曾经链接过。         return errRecentlyDialed    }    return nil}</code></pre><p>taskDone方法。 这个方法再task完成之后会被调用。 查看task的类型。如果是链接任务，那么增加到hist里面。 并从正在链接的队列删除。 如果是查询任务。 把查询的记过放在lookupBuf里面。</p><pre><code>func (s *dialstate) taskDone(t task, now time.Time) {    switch t := t.(type) {    case *dialTask:        s.hist.add(t.dest.ID, now.Add(dialHistoryExpiration))        delete(s.dialing, t.dest.ID)    case *discoverTask:        s.lookupRunning = false        s.lookupBuf = append(s.lookupBuf, t.results...)    }}</code></pre><p>dialTask.Do方法，不同的task有不同的Do方法。 dailTask主要负责建立链接。 如果t.dest是没有ip地址的。 那么尝试通过resolve查询ip地址。 然后调用dial方法创建链接。 对于静态的节点。如果第一次失败，那么会尝试再次resolve静态节点。然后再尝试dial（因为静态节点的ip是配置的。 如果静态节点的ip地址变动。那么我们尝试resolve静态节点的新地址，然后调用链接。）</p><pre><code>func (t *dialTask) Do(srv *Server) {    if t.dest.Incomplete() {        if !t.resolve(srv) {            return        }    }    success := t.dial(srv, t.dest)    // Try resolving the ID of static nodes if dialing failed.    if !success &amp;&amp; t.flags&amp;staticDialedConn != 0 {        if t.resolve(srv) {            t.dial(srv, t.dest)        }    }}</code></pre><p>resolve方法。这个方法主要调用了discover网络的Resolve方法。如果失败，那么超时再试</p><pre><code>// resolve attempts to find the current endpoint for the destination// using discovery.//// Resolve operations are throttled with backoff to avoid flooding the// discovery network with useless queries for nodes that don't exist.// The backoff delay resets when the node is found.func (t *dialTask) resolve(srv *Server) bool {    if srv.ntab == nil {        log.Debug("Can't resolve node", "id", t.dest.ID, "err", "discovery is disabled")        return false    }    if t.resolveDelay == 0 {        t.resolveDelay = initialResolveDelay    }    if time.Since(t.lastResolved) &lt; t.resolveDelay {        return false    }    resolved := srv.ntab.Resolve(t.dest.ID)    t.lastResolved = time.Now()    if resolved == nil {        t.resolveDelay *= 2        if t.resolveDelay &gt; maxResolveDelay {            t.resolveDelay = maxResolveDelay        }        log.Debug("Resolving node failed", "id", t.dest.ID, "newdelay", t.resolveDelay)        return false    }    // The node was found.    t.resolveDelay = initialResolveDelay    t.dest = resolved    log.Debug("Resolved node", "id", t.dest.ID, "addr", &amp;net.TCPAddr{IP: t.dest.IP, Port: int(t.dest.TCP)})    return true}</code></pre><p>dial方法,这个方法进行了实际的网络连接操作。 主要通过srv.SetupConn方法来完成， 后续再分析Server.go的时候再分析这个方法。</p><pre><code>// dial performs the actual connection attempt.func (t *dialTask) dial(srv *Server, dest *discover.Node) bool {    fd, err := srv.Dialer.Dial(dest)    if err != nil {        log.Trace("Dial error", "task", t, "err", err)        return false    }    mfd := newMeteredConn(fd, false)    srv.SetupConn(mfd, t.flags, dest)    return true}</code></pre><p>discoverTask和waitExpireTask的Do方法，</p><pre><code>func (t *discoverTask) Do(srv *Server) {    // newTasks generates a lookup task whenever dynamic dials are    // necessary. Lookups need to take some time, otherwise the    // event loop spins too fast.    next := srv.lastLookup.Add(lookupInterval)    if now := time.Now(); now.Before(next) {        time.Sleep(next.Sub(now))    }    srv.lastLookup = time.Now()    var target discover.NodeID    rand.Read(target[:])    t.results = srv.ntab.Lookup(target)}func (t waitExpireTask) Do(*Server) {    time.Sleep(t.Duration)}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-p2p-nat源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-nat%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-nat%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>nat是网络地址转换的意思。  这部分的源码比较独立而且单一，这里就暂时不分析了。 大家了解基本的功能就行了。</p><p>nat下面有upnp和pmp两种网络协议。 </p><h3 id="upnp的应用场景-pmp是和upnp类似的协议"><a href="#upnp的应用场景-pmp是和upnp类似的协议" class="headerlink" title="upnp的应用场景(pmp是和upnp类似的协议)"></a>upnp的应用场景(pmp是和upnp类似的协议)</h3><p>如果用户是通过NAT接入Internet的，同时需要使用BC、电骡eMule等P2P这样的软件，这时UPnP功能就会带来很大的便利。利用UPnP能自动的把BC、电骡eMule等侦听的端口号映射到公网上，以便公网上的用户也能对NAT私网侧发起连接。</p><p>主要功能就是提供接口可以把内网的IP+端口 映射为  路由器的IP+端口。 这样就等于内网的程序有了外网的IP地址， 这样公网的用户就可以直接对你进行访问了。 不然就需要通过UDP打洞这种方式来进行访问。</p><h3 id="p2p中的UDP协议"><a href="#p2p中的UDP协议" class="headerlink" title="p2p中的UDP协议"></a>p2p中的UDP协议</h3><p>现在大部分用户运行的环境都是内网环境。 内网环境下监听的端口，其他公网的程序是无法直接访问的。需要经过一个打洞的过程。 双方才能联通。这就是所谓的UDP打洞。</p><p><img src="/images/ethereum/source_analysis/nat_1.png" alt="image"><br>外网希望直接访问内网上的程序是无法实现的。 因为路由器并不知道如何路由数据给内网的这个程序。</p><p>那么我们首先通过内网的程序联系外网的程序，这样路由器就会自动给内网的这个程序分配一个端口。并在路由器里面记录一条映射 192.168.1.1:3003 -&gt; 111.21.12.12:3003 。这个映射关系随着时间会老化最终消失。</p><p><img src="/images/ethereum/source_analysis/nat_2.png" alt="image"></p><p>等路由器建立这样的映射关系后。 互联网上的其他程序就可以快乐的访问111.21.12.12:3003这个端口了。因为所有送到这个端口的数据最终会被路由到192.168.1.1:3003这个端口。这就是所谓的打洞的过程。</p><p><img src="/images/ethereum/source_analysis/nat_3.png" alt="image"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-p2p-peer.go源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-peer.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-peer.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>在p2p代码里面。 peer代表了一条创建好的网络链路。在一条链路上可能运行着多个协议。比如以太坊的协议(eth)。 Swarm的协议。 或者是Whisper的协议。</p><p>peer的结构</p><pre><code>type protoRW struct {    Protocol    in     chan Msg        // receices read messages    closed &lt;-chan struct{} // receives when peer is shutting down    wstart &lt;-chan struct{} // receives when write may start    werr   chan&lt;- error    // for write results    offset uint64    w      MsgWriter}// Protocol represents a P2P subprotocol implementation.type Protocol struct {    // Name should contain the official protocol name,    // often a three-letter word.    Name string    // Version should contain the version number of the protocol.    Version uint    // Length should contain the number of message codes used    // by the protocol.    Length uint64    // Run is called in a new groutine when the protocol has been    // negotiated with a peer. It should read and write messages from    // rw. The Payload for each message must be fully consumed.    //    // The peer connection is closed when Start returns. It should return    // any protocol-level error (such as an I/O error) that is    // encountered.    Run func(peer *Peer, rw MsgReadWriter) error    // NodeInfo is an optional helper method to retrieve protocol specific metadata    // about the host node.    NodeInfo func() interface{}    // PeerInfo is an optional helper method to retrieve protocol specific metadata    // about a certain peer in the network. If an info retrieval function is set,    // but returns nil, it is assumed that the protocol handshake is still running.    PeerInfo func(id discover.NodeID) interface{}}// Peer represents a connected remote node.type Peer struct {    rw      *conn    running map[string]*protoRW   //运行的协议    log     log.Logger    created mclock.AbsTime    wg       sync.WaitGroup    protoErr chan error    closed   chan struct{}    disc     chan DiscReason    // events receives message send / receive events if set    events *event.Feed}</code></pre><p>peer的创建，根据匹配找到当前Peer支持的protomap</p><pre><code>func newPeer(conn *conn, protocols []Protocol) *Peer {    protomap := matchProtocols(protocols, conn.caps, conn)    p := &amp;Peer{        rw:       conn,        running:  protomap,        created:  mclock.Now(),        disc:     make(chan DiscReason),        protoErr: make(chan error, len(protomap)+1), // protocols + pingLoop        closed:   make(chan struct{}),        log:      log.New("id", conn.id, "conn", conn.flags),    }    return p}</code></pre><p>peer的启动， 启动了两个goroutine线程。 一个是读取。一个是执行ping操作。</p><pre><code>func (p *Peer) run() (remoteRequested bool, err error) {    var (        writeStart = make(chan struct{}, 1)  //用来控制什么时候可以写入的管道。        writeErr   = make(chan error, 1)        readErr    = make(chan error, 1)        reason     DiscReason // sent to the peer    )    p.wg.Add(2)    go p.readLoop(readErr)    go p.pingLoop()    // Start all protocol handlers.    writeStart &lt;- struct{}{}    //启动所有的协议。    p.startProtocols(writeStart, writeErr)    // Wait for an error or disconnect.loop:    for {        select {        case err = &lt;-writeErr:            // A write finished. Allow the next write to start if            // there was no error.            if err != nil {                reason = DiscNetworkError                break loop            }            writeStart &lt;- struct{}{}        case err = &lt;-readErr:            if r, ok := err.(DiscReason); ok {                remoteRequested = true                reason = r            } else {                reason = DiscNetworkError            }            break loop        case err = &lt;-p.protoErr:            reason = discReasonForError(err)            break loop        case err = &lt;-p.disc:            break loop        }    }    close(p.closed)    p.rw.close(reason)    p.wg.Wait()    return remoteRequested, err}</code></pre><p>startProtocols方法，这个方法遍历所有的协议。</p><pre><code>func (p *Peer) startProtocols(writeStart &lt;-chan struct{}, writeErr chan&lt;- error) {    p.wg.Add(len(p.running))    for _, proto := range p.running {        proto := proto        proto.closed = p.closed        proto.wstart = writeStart        proto.werr = writeErr        var rw MsgReadWriter = proto        if p.events != nil {            rw = newMsgEventer(rw, p.events, p.ID(), proto.Name)        }        p.log.Trace(fmt.Sprintf("Starting protocol %s/%d", proto.Name, proto.Version))        // 等于这里为每一个协议都开启了一个goroutine。 调用其Run方法。        go func() {            // proto.Run(p, rw)这个方法应该是一个死循环。 如果返回就说明遇到了错误。            err := proto.Run(p, rw)            if err == nil {                p.log.Trace(fmt.Sprintf("Protocol %s/%d returned", proto.Name, proto.Version))                err = errProtocolReturned            } else if err != io.EOF {                p.log.Trace(fmt.Sprintf("Protocol %s/%d failed", proto.Name, proto.Version), "err", err)            }            p.protoErr &lt;- err            p.wg.Done()        }()    }}</code></pre><p>回过头来再看看readLoop方法。 这个方法也是一个死循环。 调用p.rw来读取一个Msg(这个rw实际是之前提到的frameRLPx的对象，也就是分帧之后的对象。然后根据Msg的类型进行对应的处理，如果Msg的类型是内部运行的协议的类型。那么发送到对应协议的proto.in队列上面。</p><pre><code>func (p *Peer) readLoop(errc chan&lt;- error) {    defer p.wg.Done()    for {        msg, err := p.rw.ReadMsg()        if err != nil {            errc &lt;- err            return        }        msg.ReceivedAt = time.Now()        if err = p.handle(msg); err != nil {            errc &lt;- err            return        }    }}func (p *Peer) handle(msg Msg) error {    switch {    case msg.Code == pingMsg:        msg.Discard()        go SendItems(p.rw, pongMsg)    case msg.Code == discMsg:        var reason [1]DiscReason        // This is the last message. We don't need to discard or        // check errors because, the connection will be closed after it.        rlp.Decode(msg.Payload, &amp;reason)        return reason[0]    case msg.Code &lt; baseProtocolLength:        // ignore other base protocol messages        return msg.Discard()    default:        // it's a subprotocol message        proto, err := p.getProto(msg.Code)        if err != nil {            return fmt.Errorf("msg code out of range: %v", msg.Code)        }        select {        case proto.in &lt;- msg:            return nil        case &lt;-p.closed:            return io.EOF        }    }    return nil}</code></pre><p>在看看pingLoop。这个方法很简单。就是定时的发送pingMsg消息到对端。</p><pre><code>func (p *Peer) pingLoop() {    ping := time.NewTimer(pingInterval)    defer p.wg.Done()    defer ping.Stop()    for {        select {        case &lt;-ping.C:            if err := SendItems(p.rw, pingMsg); err != nil {                p.protoErr &lt;- err                return            }            ping.Reset(pingInterval)        case &lt;-p.closed:            return        }    }}</code></pre><p>最后再看看protoRW的read和write方法。 可以看到读取和写入都是阻塞式的。</p><pre><code>func (rw *protoRW) WriteMsg(msg Msg) (err error) {    if msg.Code &gt;= rw.Length {        return newPeerError(errInvalidMsgCode, "not handled")    }    msg.Code += rw.offset    select {    case &lt;-rw.wstart:  //等到可以写入的受在执行写入。 这难道是为了多线程控制么。        err = rw.w.WriteMsg(msg)        // Report write status back to Peer.run. It will initiate        // shutdown if the error is non-nil and unblock the next write        // otherwise. The calling protocol code should exit for errors        // as well but we don't want to rely on that.        rw.werr &lt;- err    case &lt;-rw.closed:        err = fmt.Errorf("shutting down")    }    return err}func (rw *protoRW) ReadMsg() (Msg, error) {    select {    case msg := &lt;-rw.in:        msg.Code -= rw.offset        return msg, nil    case &lt;-rw.closed:        return Msg{}, io.EOF    }}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-p2p源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>p2p的源码又下面几个包</p><ul><li>discover         包含了<a href="download/Kademlia%E5%8D%8F%E8%AE%AE%E5%8E%9F%E7%90%86%E7%AE%80%E4%BB%8B.pdf">Kademlia协议</a>。是基于UDP的p2p节点发现协议。</li><li>discv5        新的节点发现协议。 还是试验属性。本次分析没有涉及。</li><li>nat            网络地址转换的部分代码</li><li>netutil        一些工具</li><li>simulations    p2p网络的模拟。 本次分析没有涉及。</li></ul><p>discover部分的源码分析</p><ul><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-database.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="发现的节点的持久化存储 database.go">发现的节点的持久化存储 database.go</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-table.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="Kademlia协议的核心逻辑 tabel.go">Kademlia协议的核心逻辑 tabel.go</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-udp.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="UDP协议的处理逻辑udp.go">UDP协议的处理逻辑udp.go</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-nat%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="网络地址转换 nat.go">网络地址转换 nat.go</a></li></ul><p>p2p/ 部分源码分析</p><ul><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-rlpx%E8%8A%82%E7%82%B9%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8A%A0%E5%AF%86%E9%93%BE%E8%B7%AF/" title="节点之间的加密链路处理协议 rlpx.go">节点之间的加密链路处理协议 rlpx.go</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-dial.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="挑选节点然后进行连接的处理逻辑 dail.go">挑选节点然后进行连接的处理逻辑 dail.go</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-peer.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="节点和节点连接的处理以及协议的处理 peer.go">节点和节点连接的处理以及协议的处理 peer.go</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-server.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="p2p服务器的逻辑 server.go">p2p服务器的逻辑 server.go</a></li></ul><p>Kademlia协议补充材料：</p><p>虚线包含的部分就是各子树，由上到下各层的前缀分别为 0，01，000，0010。</p><blockquote><p>按照上文的理解：对于任意一个节点，都可以把这颗二叉树分解为一系列连续的，不包含自己的子树。最高层的子树，由整颗树不包含自己的树的另一半组成； 下一层子树由剩下部分不包含自己的一半组成；依此类推，直到分割完整颗树。</p></blockquote><p>虚线包含的部分就是各子树，由上到下各层的前缀分别为 1，01，000，0010。</p><p>每一个这样的列表都称之为一个 K 桶，并且每个 K 桶内部信息存放位置是根据上次看到的时间顺序排列，最近（least-recently）看到的放在头部，最后（most-recently）看到的放在尾部。每个桶都有不超过 k 个的数据项。</p><blockquote><p>最近（least-recently）与最后（most-recently）的翻译，会产生歧义</p></blockquote><p>最近最少（least-recently）访问的节点放在队列头，最近最多（most-recently）访问的节点放在队列尾部。以模拟gnutella用户行为分析的结果，最近最多访问的活跃节点，也是将来最有可能需要访问的节点</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-目录</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E7%9B%AE%E5%BD%95/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E7%9B%AE%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h1 id="以太坊源码分析"><a href="#以太坊源码分析" class="headerlink" title="以太坊源码分析"></a>以太坊源码分析</h1><p><strong>希望能够分析以太坊的代码来学习区块链技术和GO语言的使用</strong></p><p>分析<a href="https://github.com/ethereum/go-ethereum">go-ethereum</a>的过程，我希望从依赖比较少的底层技术组件开始，慢慢深入到核心逻辑。</p><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-go-ethereum%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" title="go-ethereum代码阅读环境搭建">go-ethereum代码阅读环境搭建</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E9%BB%84%E7%9A%AE%E4%B9%A6%E9%87%8C%E9%9D%A2%E5%87%BA%E7%8E%B0%E7%9A%84%E6%89%80%E6%9C%89%E7%9A%84%E7%AC%A6%E5%8F%B7%E7%B4%A2%E5%BC%95/" title="以太坊黄皮书 符号索引">以太坊黄皮书 符号索引</a></li><li><a href="/2021/04/14/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-RLP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="rlp源码解析">rlp源码解析</a></li><li><a href="/2021/05/27/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%88%86%E6%9E%90%E5%8C%85Trie/" title="trie源码分析">trie源码分析</a></li><li><a href="/2021/06/05/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-ethdb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="ethdb源码分析">ethdb源码分析</a></li><li><a href="/2021/04/14/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-RLP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="rpc源码分析">rpc源码分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="p2p源码分析">p2p源码分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="eth协议源码分析">eth协议源码分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-event%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="event源码分析">event源码分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-node%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="node源码分析">node源码分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-accounts%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="accounts源码分析">accounts源码分析</a></li><li>core源码分析<ul><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-chain_indexer%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" title="区块链索引 chain_indexer源码分析">区块链索引 chain_indexer源码分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-bloombits%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="布隆过滤器索引">布隆过滤器索引</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-state%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="state源码分析">state源码分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-state-process%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="交易执行和处理部分源码分析">交易执行和处理部分源码分析</a></li><li>vm 虚拟机源码分析<ul><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-vm-stack-memory%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="虚拟机堆栈和内存数据结构分析">虚拟机堆栈和内存数据结构分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-vm-jumptable-instruction/" title="虚拟机指令,跳转表,解释器源码分析">虚拟机指令,跳转表,解释器源码分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-vm%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="虚拟机源码分析">虚拟机源码分析</a></li></ul></li><li>待确认交易池的管理txPool<ul><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-txlist%E4%BA%A4%E6%98%93%E6%B1%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="交易池数据结构源码分析">交易池数据结构源码分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-txpool%E4%BA%A4%E6%98%93%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="交易池源码分析">交易池源码分析</a></li></ul></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-genesis%E5%88%9B%E4%B8%96%E5%8C%BA%E5%9D%97%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="创世区块的源码分析">创世区块的源码分析</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-blockchain%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" title="core-blockchain源码分析">core-blockchain源码分析</a></li></ul></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-miner%E6%8C%96%E7%9F%BF%E9%83%A8%E5%88%86%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90CPU%E6%8C%96%E7%9F%BF/" title="miner挖矿部分源码分析CPU挖矿">miner挖矿部分源码分析CPU挖矿</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-pow%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/" title="pow一致性算法">pow一致性算法</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9CClique_PoA%E4%BB%8B%E7%BB%8D/" title="以太坊测试网络Clique_PoA介绍">以太坊测试网络Clique_PoA介绍</a></li><li><a href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E9%9A%8F%E6%9C%BA%E6%95%B0%E7%94%9F%E6%88%90%E6%96%B9%E5%BC%8F/" title="以太坊随机数生成方式">以太坊随机数生成方式</a></li><li><a href="/2021/05/27/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%B0%81%E8%A3%85%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E5%B7%A5%E5%85%B7/" title="封装的一些基础工具">封装的一些基础工具</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-黄皮书里面出现的所有的符号索引</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E9%BB%84%E7%9A%AE%E4%B9%A6%E9%87%8C%E9%9D%A2%E5%87%BA%E7%8E%B0%E7%9A%84%E6%89%80%E6%9C%89%E7%9A%84%E7%AC%A6%E5%8F%B7%E7%B4%A2%E5%BC%95/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E9%BB%84%E7%9A%AE%E4%B9%A6%E9%87%8C%E9%9D%A2%E5%87%BA%E7%8E%B0%E7%9A%84%E6%89%80%E6%9C%89%E7%9A%84%E7%AC%A6%E5%8F%B7%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<p><img src="/images/ethereum/source_analysis/arch.jpg" alt="image"></p><p><img src="/images/ethereum/source_analysis/sign_state_1.png" alt="image"></p><p><img src="/images/ethereum/source_analysis/sign_state_3.png" alt="image">是t+1时刻的状态(account trie)。</p><p><img src="/images/ethereum/source_analysis/sign_state_4.png" alt="image">是状态转换函数，也可以理解为执行引擎。</p><p><img src="/images/ethereum/source_analysis/sign_state_5.png" alt="image"> 是transaction，一次交易。</p><p><img src="/images/ethereum/source_analysis/sign_state_6.png" alt="image"></p><p><img src="/images/ethereum/source_analysis/sign_state_7.png" alt="image">  是区块级别的状态转换函数。</p><p><img src="/images/ethereum/source_analysis/sign_state_8.png" alt="image">  是区块，由很多交易组成。</p><p><img src="/images/ethereum/source_analysis/sign_state_9.png" alt="image">  0号位置的交易。</p><p><img src="/images/ethereum/source_analysis/sign_state_10.png" alt="image"> 是块终结状态转换函数（一个奖励挖矿者的函数）。</p><p><img src="/images/ethereum/source_analysis/sign_ether.png" alt="image"> Ether的标识。</p><p><img src="/images/ethereum/source_analysis/sign_ether_value.png" alt="image"> Ethereum中所用到的各种单位与Wei的换算关系（例如：一个Finney对应10^15个Wei）。</p><p><img src="/images/ethereum/source_analysis/sign_machine_state.png" alt="image"> machine-state</p><h2 id="一些基本的规则"><a href="#一些基本的规则" class="headerlink" title="一些基本的规则"></a>一些基本的规则</h2><ul><li>对于大多数的函数来说，都用大写字母来标识。</li><li>元组一般用大写字母来标识</li><li>标量或者固定大小的字节数组都用小写字母标识。 比如 n 代表交易的nonce， 有一些可能有例外，比如δ代表 一个给定指令需要的堆栈数据的多少。</li><li>变长的字节数组一般用加粗的小写字母。 比如 <strong>o</strong> 代表一个message call的输出数据。对于某些重要的也可能使用加粗的大写字母</li></ul><p><img src="/images/ethereum/source_analysis/sign_set_b.png" alt="image"> 字节序列<br><img src="/images/ethereum/source_analysis/sign_set_p.png" alt="image"> 正整数<br><img src="/images/ethereum/source_analysis/sign_set_b32.png" alt="image"> 32字节长度的字节序列<br><img src="/images/ethereum/source_analysis/sign_set_p256.png" alt="image"> 小于 2^256 的正整数<br><strong>[ ]</strong> 用于索引数组里面的对应元素<br><img src="/images/ethereum/source_analysis/sign_stack.png" alt="image"> 代表机器堆栈(machine’s stack)的第一个对象<br><img src="/images/ethereum/source_analysis/sign_memory.png" alt="image"> 代表了机器内存(machine’s memory)里面的前32个元素<br><img src="/images/ethereum/source_analysis/sign_placeholder_1.png" alt="image"> 一个占位符号，可以是任意字符代表任意对象</p><p><img src="/images/ethereum/source_analysis/sign_placeholder_2.png" alt="image"> 代表这个对象被修改后的值<br><img src="/images/ethereum/source_analysis/sign_placeholder_3.png" alt="image"> 中间状态<br><img src="/images/ethereum/source_analysis/sign_placeholder_4.png" alt="image"> 中间状态2<br><img src="/images/ethereum/source_analysis/sign_func_1.png" alt="image"> <img src="/images/ethereum/source_analysis/sign_func_2.png" alt="image"> 如果前面的f代表了一个函数， 那么后面的f*代表了一个相似的函数，不过是对内部的元素依次执行f的一个函数。</p><p><img src="/images/ethereum/source_analysis/sign_last_item.png" alt="image">  代表了列表里面的最后一个元素<br><img src="/images/ethereum/source_analysis/sign_last_item_1.png" alt="image">  代表了列表里面的最后一个元素<br><img src="/images/ethereum/source_analysis/sign_seq_item.png" alt="image">   求x的长度</p><p><img src="/images/ethereum/source_analysis/sign_state_nonce.png" alt="image">  a代表某个地址，代表某个账号的nonce<br><img src="/images/ethereum/source_analysis/sign_state_balance.png" alt="image"> banlance 余额<br><img src="/images/ethereum/source_analysis/sign_state_root.png" alt="image">   storage trie 的 root hash<br><img src="/images/ethereum/source_analysis/sign_state_code.png" alt="image"> Code的hash。 如果code是b 那么KEC(b)===这个hash</p><p><img src="/images/ethereum/source_analysis/sign_l1.png" alt="image"></p><p><img src="/images/ethereum/source_analysis/sign_ls.png" alt="image">  world state collapse function<br><img src="/images/ethereum/source_analysis/sign_pa.png" alt="image"></p><p><img src="/images/ethereum/source_analysis/sign_math_any.png" alt="image">  任意的 any<br><img src="/images/ethereum/source_analysis/sign_math_or.png" alt="image">   并集 or<br><img src="/images/ethereum/source_analysis/sign_math_and.png" alt="image">  交集 and</p><p><img src="/images/ethereum/source_analysis/sign_homestead.png" alt="image"> Homestead</p><h2 id="交易"><a href="#交易" class="headerlink" title="交易"></a>交易</h2><p><img src="/images/ethereum/source_analysis/sign_t_nonce.png" alt="image"> 交易的nonce<br><img src="/images/ethereum/source_analysis/sign_t_gasprice.png" alt="image"> gasPrice<br><img src="/images/ethereum/source_analysis/sign_t_gaslimit.png" alt="image"> gasLimit<br><img src="/images/ethereum/source_analysis/sign_t_to.png" alt="image"> to<br><img src="/images/ethereum/source_analysis/sign_t_value.png" alt="image"> value</p><p><img src="/images/ethereum/source_analysis/sign_t_w.png" alt="image"><img src="/images/ethereum/source_analysis/sign_t_tr.png" alt="image"><img src="/images/ethereum/source_analysis/sign_t_ts.png" alt="image">通过者三个值可以得到sender的地址</p><p><img src="/images/ethereum/source_analysis/sign_t_ti.png" alt="image"> 合约的初始化代码<br><img src="/images/ethereum/source_analysis/sign_t_data.png" alt="image"> 方法调用的入参<br><img src="/images/ethereum/source_analysis/sign_t_lt.png" alt="image"></p><h2 id="区块头"><a href="#区块头" class="headerlink" title="区块头"></a>区块头</h2><p><img src="/images/ethereum/source_analysis/sign_h_p.png" alt="image">ParentHash<br><img src="/images/ethereum/source_analysis/sign_h_o.png" alt="image">OmmersHash<br><img src="/images/ethereum/source_analysis/sign_h_c.png" alt="image">beneficiary矿工地址<br><img src="/images/ethereum/source_analysis/sign_h_r.png" alt="image">stateRoot<br><img src="/images/ethereum/source_analysis/sign_h_t.png" alt="image">transactionRoot<br><img src="/images/ethereum/source_analysis/sign_h_e.png" alt="image">receiptRoot<br><img src="/images/ethereum/source_analysis/sign_h_b.png" alt="image">logsBloom<br><img src="/images/ethereum/source_analysis/sign_h_d.png" alt="image">难度<br><img src="/images/ethereum/source_analysis/sign_h_i.png" alt="image">number高度<br><img src="/images/ethereum/source_analysis/sign_h_l.png" alt="image">gasLimit<br><img src="/images/ethereum/source_analysis/sign_h_g.png" alt="image">gasUsed<br><img src="/images/ethereum/source_analysis/sign_h_s.png" alt="image">timestamp<br><img src="/images/ethereum/source_analysis/sign_h_x.png" alt="image">extraData<br><img src="/images/ethereum/source_analysis/sign_h_m.png" alt="image">mixHash<br><img src="/images/ethereum/source_analysis/sign_h_n.png" alt="image">nonce</p><h2 id="回执"><a href="#回执" class="headerlink" title="回执"></a>回执</h2><p><img src="/images/ethereum/source_analysis/sign_r_i.png" alt="image"> 第i个交易的receipt</p><p><img src="/images/ethereum/source_analysis/sign_receipt.png" alt="image"><br><img src="/images/ethereum/source_analysis/sign_r_state.png" alt="image"> 交易执行后的world-state<br><img src="/images/ethereum/source_analysis/sign_r_gasused.png" alt="image">交易执行后区块总的gas使用量<br><img src="/images/ethereum/source_analysis/sign_r_bloom.png" alt="image">本交易执行产生的所有log的布隆过滤数据<br><img src="/images/ethereum/source_analysis/sign_r_log.png" alt="image">交易产生的日志集合</p><p><img src="/images/ethereum/source_analysis/sign_r_logentry.png" alt="image"> Log entry Oa日志产生的地址， Ot topic Od 时间</p><h2 id="交易执行"><a href="#交易执行" class="headerlink" title="交易执行"></a>交易执行</h2><p><img src="/images/ethereum/source_analysis/sign_substate_a.png" alt="image"> substate<br><img src="/images/ethereum/source_analysis/sign_substate_as.png" alt="image"> suicide set<br><img src="/images/ethereum/source_analysis/sign_substate_al.png" alt="image"> log series<br><img src="/images/ethereum/source_analysis/sign_substate_ar.png" alt="image"> refund balance</p><p><img src="/images/ethereum/source_analysis/sign_gas_total.png" alt="image"> 交易过程中使用的总gas数量。<br><img src="/images/ethereum/source_analysis/sign_gas_log.png" alt="image">     交易产生的日志。</p><p><img src="/images/ethereum/source_analysis/sign_i_a.png" alt="image"> 执行代码的拥有者<br><img src="/images/ethereum/source_analysis/sign_i_o.png" alt="image"> 交易的发起者<br><img src="/images/ethereum/source_analysis/sign_i_p.png" alt="image"> gasPrice<br><img src="/images/ethereum/source_analysis/sign_i_d.png" alt="image"> inputdata<br><img src="/images/ethereum/source_analysis/sign_i_s.png" alt="image"> 引起代码执行的地址，如果是交易那么是交易的发起人<br><img src="/images/ethereum/source_analysis/sign_i_v.png" alt="image"> value<br><img src="/images/ethereum/source_analysis/sign_i_b.png" alt="image"> 需要执行的代码<br><img src="/images/ethereum/source_analysis/sign_i_h.png" alt="image"> 当前的区块头<br><img src="/images/ethereum/source_analysis/sign_i_e.png" alt="image"> 当前的调用深度</p><p><img src="/images/ethereum/source_analysis/sign_exec_model.png" alt="image"> 执行模型 s suicide set; l 日志集合 <strong>o</strong> 输出 ; r refund</p><p><img src="/images/ethereum/source_analysis/sign_exec_func.png" alt="image"> 执行函数</p><p><img src="/images/ethereum/source_analysis/sign_m_g.png" alt="image"> 当前可用的gas<br><img src="/images/ethereum/source_analysis/sign_u_pc.png" alt="image"> 程序计数器<br><img src="/images/ethereum/source_analysis/sign_u_m.png" alt="image"> 内存内容<br><img src="/images/ethereum/source_analysis/sign_u_i.png" alt="image"> 内存中有效的word数量<br><img src="/images/ethereum/source_analysis/sign_u_s.png" alt="image"> 堆栈内容</p><p><img src="/images/ethereum/source_analysis/sign_m_w.png" alt="image"> w代表当前需要执行的指令</p><p><img src="/images/ethereum/source_analysis/sign_stack_removed.png" alt="image"> 指令需要移除的堆栈对象个数<br><img src="/images/ethereum/source_analysis/sign_stack_added.png" alt="image"> 指令需要增加的堆栈对象个数</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-blockchain源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-blockchain%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-blockchain%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>从测试案例来看,blockchain的主要功能点有下面几点.</p><ol><li>import.</li><li>GetLastBlock的功能.</li><li>如果有多条区块链,可以选取其中难度最大的一条作为规范的区块链.</li><li>BadHashes 可以手工禁止接受一些区块的hash值.在blocks.go里面.</li><li>如果新配置了BadHashes. 那么区块启动的时候会自动禁止并进入有效状态.</li><li>错误的nonce会被拒绝.</li><li>支持Fast importing.</li><li>Light vs Fast vs Full processing 在处理区块头上面的效果相等.</li></ol><p>可以看到blockchain的主要功能是维护区块链的状态, 包括区块的验证,插入和状态查询.</p><p>名词解释:</p><p>什么是规范的区块链</p><p>因为在区块的创建过程中,可能在短时间内产生一些分叉, 在我们的数据库里面记录的其实是一颗区块树.我们会认为其中总难度最高的一条路径认为是我们的规范的区块链. 这样有很多区块虽然也能形成区块链,但是不是规范的区块链.</p><p>数据库结构:</p><pre><code>区块的hash值和区块头的hash值是同样的么。所谓的区块的Hash值其实就是Header的区块值。// key -&gt; value// + 代表连接"LastHeader"  最新的区块头 HeaderChain中使用"LastBlock"   最新的区块头 BlockChain 中使用"LastFast"    最新的快速同步的区块头"h"+num+"n" -&gt; hash  用来存储规范的区块链的高度和区块头的hash值"h" + num + hash -&gt; header 高度+hash值 -&gt; 区块头"h" + num + hash + "t" -&gt; td  高度+hash值 -&gt; 总难度"H" + hash -&gt; num  区块体hash -&gt; 高度"b" + num + hash -&gt; block body   高度+hash值 -&gt; 区块体"r" + num + hash -&gt; block receipts  高度 + hash值 -&gt; 区块收据"l" + hash -&gt; transaction/receipt lookup metadata</code></pre><table><thead><tr><th>key</th><th>value</th><th>说明</th><th>插入</th><th>删除</th></tr></thead><tbody><tr><td>“LastHeader”</td><td>hash</td><td>最新的区块头 HeaderChain中使用</td><td>当区块被认为是当前最新的一个规范的区块链头</td><td>当有了更新的区块链头或者是分叉的兄弟区块链替代了它</td></tr><tr><td>“LastBlock”</td><td>hash</td><td>最新的区块头 BlockChain中使用</td><td>当区块被认为是当前最新的一个规范的区块链头</td><td>当有了更新的区块链头或者是分叉的兄弟区块链替代了它</td></tr><tr><td>“LastFast”</td><td>hash</td><td>最新的区块头 BlockChain中使用</td><td>当区块被认为是当前最新的规范的区块链头</td><td>当有了更新的区块链头或者是分叉的兄弟区块链替代了它</td></tr><tr><td>“h”+num+”n”</td><td>hash</td><td>用来存储规范的区块链的高度和区块头的hash值 在HeaderChain中使用</td><td>当区块在规范的区块链中</td><td>当区块不在规范的区块链中</td></tr><tr><td>“h” + num + hash + “t”</td><td>td</td><td>总难度</td><td>WriteBlockAndState当验证并执行完一个区块之后(不管是不是规范的)</td><td>SetHead方法会调用。这种方法只会在两种情况下被调用，1是当前区块链包含了badhashs，需要删除所有从badhashs开始的区块， 2.是当前区块的状态错误，需要Reset到genesis。</td></tr><tr><td>“H” + hash</td><td>num</td><td>区块的高度 在HeaderChain中使用</td><td>WriteBlockAndState当验证并执行完一个区块之后</td><td>SetHead中被调用，同上</td></tr><tr><td>“b” + num + hash</td><td>block body</td><td>区块数据</td><td>WriteBlockAndState or InsertReceiptChain</td><td>SetHead中被删除，同上</td></tr><tr><td>“r” + num + hash</td><td>block receipts</td><td>区块收据</td><td>WriteBlockAndState or InsertReceiptChain</td><td>同上</td></tr><tr><td>“l” + txHash</td><td>{hash,num,TxIndex</td><td>交易hash可以找到区块和交易</td><td>当区块加入规范的区块链</td><td>当区块从规范的区块链移除</td></tr></tbody></table><p>数据结构</p><pre><code>// BlockChain represents the canonical chain given a database with a genesis// block. The Blockchain manages chain imports, reverts, chain reorganisations.// BlockChain 表示了一个规范的链,这个链通过一个包含了创世区块的数据库指定. BlockChain管理了链的插入,还原,重建等操作.// Importing blocks in to the block chain happens according to the set of rules// defined by the two stage Validator. Processing of blocks is done using the// Processor which processes the included transaction. The validation of the state// is done in the second part of the Validator. Failing results in aborting of// the import.// 插入一个区块需要通过一系列指定的规则指定的两阶段的验证器. // 使用Processor来对区块的交易进行处理. 状态的验证是第二阶段的验证器. 错误将导致插入终止.// The BlockChain also helps in returning blocks from **any** chain included// in the database as well as blocks that represents the canonical chain. It's// important to note that GetBlock can return any block and does not need to be// included in the canonical one where as GetBlockByNumber always represents the// canonical chain.// 需要注意的是GetBlock可能返回任意不在当前规范区块链中的区块, // 但是GetBlockByNumber 总是返回当前规范区块链中的区块.type BlockChain struct {    config *params.ChainConfig // chain &amp; network configuration    hc            *HeaderChain        // 只包含了区块头的区块链    chainDb       ethdb.Database    // 底层数据库    rmLogsFeed    event.Feed        // 下面是很多消息通知的组件    chainFeed     event.Feed    chainSideFeed event.Feed    chainHeadFeed event.Feed    logsFeed      event.Feed    scope         event.SubscriptionScope    genesisBlock  *types.Block        // 创世区块    mu      sync.RWMutex // global mutex for locking chain operations    chainmu sync.RWMutex // blockchain insertion lock    procmu  sync.RWMutex // block processor lock    checkpoint       int          // checkpoint counts towards the new checkpoint    currentBlock     *types.Block // Current head of the block chain 当前的区块头    currentFastBlock *types.Block // Current head of the fast-sync chain (may be above the block chain!) 当前的快速同步的区块头.    stateCache   state.Database // State database to reuse between imports (contains state cache)    bodyCache    *lru.Cache     // Cache for the most recent block bodies    bodyRLPCache *lru.Cache     // Cache for the most recent block bodies in RLP encoded format    blockCache   *lru.Cache     // Cache for the most recent entire blocks    futureBlocks *lru.Cache     // future blocks are blocks added for later processing  暂时还不能插入的区块存放位置.    quit    chan struct{} // blockchain quit channel    running int32         // running must be called atomically    // procInterrupt must be atomically called    procInterrupt int32          // interrupt signaler for block processing    wg            sync.WaitGroup // chain processing wait group for shutting down    engine    consensus.Engine    // 一致性引擎    processor Processor // block processor interface  // 区块处理器接口    validator Validator // block and state validator interface // 区块和状态验证器接口    vmConfig  vm.Config //虚拟机的配置    badBlocks *lru.Cache // Bad block cache  错误区块的缓存.}</code></pre><p>构造,NewBlockChain 使用数据库里面的可用信息构造了一个初始化好的区块链. 同时初始化了以太坊默认的 验证器和处理器 (Validator and Processor)</p><pre><code>// NewBlockChain returns a fully initialised block chain using information// available in the database. It initialises the default Ethereum Validator and// Processor.func NewBlockChain(chainDb ethdb.Database, config *params.ChainConfig, engine consensus.Engine, vmConfig vm.Config) (*BlockChain, error) {    bodyCache, _ := lru.New(bodyCacheLimit)    bodyRLPCache, _ := lru.New(bodyCacheLimit)    blockCache, _ := lru.New(blockCacheLimit)    futureBlocks, _ := lru.New(maxFutureBlocks)    badBlocks, _ := lru.New(badBlockLimit)    bc := &amp;BlockChain{        config:       config,        chainDb:      chainDb,        stateCache:   state.NewDatabase(chainDb),        quit:         make(chan struct{}),        bodyCache:    bodyCache,        bodyRLPCache: bodyRLPCache,        blockCache:   blockCache,        futureBlocks: futureBlocks,        engine:       engine,        vmConfig:     vmConfig,        badBlocks:    badBlocks,    }    bc.SetValidator(NewBlockValidator(config, bc, engine))    bc.SetProcessor(NewStateProcessor(config, bc, engine))    var err error    bc.hc, err = NewHeaderChain(chainDb, config, engine, bc.getProcInterrupt)    if err != nil {        return nil, err    }    bc.genesisBlock = bc.GetBlockByNumber(0)  // 拿到创世区块    if bc.genesisBlock == nil {        return nil, ErrNoGenesis    }    if err := bc.loadLastState(); err != nil { //加载最新的状态        return nil, err    }    // Check the current state of the block hashes and make sure that we do not have any of the bad blocks in our chain    // 检查当前的状态,确认我们的区块链上面没有非法的区块.    // BadHashes是一些手工配置的区块hash值, 用来硬分叉使用的.    for hash := range BadHashes {        if header := bc.GetHeaderByHash(hash); header != nil {            // get the canonical block corresponding to the offending header's number            // 获取规范的区块链上面同样高度的区块头,如果这个区块头确实是在我们的规范的区块链上的话,我们需要回滚到这个区块头的高度 - 1            headerByNumber := bc.GetHeaderByNumber(header.Number.Uint64())            // make sure the headerByNumber (if present) is in our current canonical chain            if headerByNumber != nil &amp;&amp; headerByNumber.Hash() == header.Hash() {                log.Error("Found bad hash, rewinding chain", "number", header.Number, "hash", header.ParentHash)                bc.SetHead(header.Number.Uint64() - 1)                log.Error("Chain rewind was successful, resuming normal operation")            }        }    }    // Take ownership of this particular state    go bc.update()    return bc, nil}</code></pre><p>loadLastState, 加载数据库里面的最新的我们知道的区块链状态. 这个方法假设已经获取到锁了.</p><pre><code>// loadLastState loads the last known chain state from the database. This method// assumes that the chain manager mutex is held.func (bc *BlockChain) loadLastState() error {    // Restore the last known head block    // 返回我们知道的最新的区块的hash    head := GetHeadBlockHash(bc.chainDb)    if head == (common.Hash{}) { // 如果获取到了空.那么认为数据库已经被破坏.那么设置区块链为创世区块.        // Corrupt or empty database, init from scratch        log.Warn("Empty database, resetting chain")        return bc.Reset()    }    // Make sure the entire head block is available    // 根据blockHash 来查找block    currentBlock := bc.GetBlockByHash(head)    if currentBlock == nil {        // Corrupt or empty database, init from scratch        log.Warn("Head block missing, resetting chain", "hash", head)        return bc.Reset()    }    // Make sure the state associated with the block is available    // 确认和这个区块的world state是否正确.    if _, err := state.New(currentBlock.Root(), bc.stateCache); err != nil {        // Dangling block without a state associated, init from scratch        log.Warn("Head state missing, resetting chain", "number", currentBlock.Number(), "hash", currentBlock.Hash())        return bc.Reset()    }    // Everything seems to be fine, set as the head block    bc.currentBlock = currentBlock    // Restore the last known head header    // 获取最新的区块头的hash    currentHeader := bc.currentBlock.Header()    if head := GetHeadHeaderHash(bc.chainDb); head != (common.Hash{}) {        if header := bc.GetHeaderByHash(head); header != nil {            currentHeader = header        }    }    // header chain 设置为当前的区块头.    bc.hc.SetCurrentHeader(currentHeader)    // Restore the last known head fast block    bc.currentFastBlock = bc.currentBlock    if head := GetHeadFastBlockHash(bc.chainDb); head != (common.Hash{}) {        if block := bc.GetBlockByHash(head); block != nil {            bc.currentFastBlock = block        }    }    // Issue a status log for the user 用来打印日志.    headerTd := bc.GetTd(currentHeader.Hash(), currentHeader.Number.Uint64())    blockTd := bc.GetTd(bc.currentBlock.Hash(), bc.currentBlock.NumberU64())    fastTd := bc.GetTd(bc.currentFastBlock.Hash(), bc.currentFastBlock.NumberU64())    log.Info("Loaded most recent local header", "number", currentHeader.Number, "hash", currentHeader.Hash(), "td", headerTd)    log.Info("Loaded most recent local full block", "number", bc.currentBlock.Number(), "hash", bc.currentBlock.Hash(), "td", blockTd)    log.Info("Loaded most recent local fast block", "number", bc.currentFastBlock.Number(), "hash", bc.currentFastBlock.Hash(), "td", fastTd)    return nil}</code></pre><p>goroutine update的处理非常简单. 定时处理future blocks.</p><pre><code>func (bc *BlockChain) update() {    futureTimer := time.Tick(5 * time.Second)    for {        select {        case &lt;-futureTimer:            bc.procFutureBlocks()        case &lt;-bc.quit:            return        }    }}</code></pre><p>Reset 方法 重置区块链. </p><pre><code>// Reset purges the entire blockchain, restoring it to its genesis state.func (bc *BlockChain) Reset() error {    return bc.ResetWithGenesisBlock(bc.genesisBlock)}// ResetWithGenesisBlock purges the entire blockchain, restoring it to the// specified genesis state.func (bc *BlockChain) ResetWithGenesisBlock(genesis *types.Block) error {    // Dump the entire block chain and purge the caches    // 把整个区块链转储并清楚缓存    if err := bc.SetHead(0); err != nil {        return err    }    bc.mu.Lock()    defer bc.mu.Unlock()    // Prepare the genesis block and reinitialise the chain    // 使用创世区块重新初始化区块链    if err := bc.hc.WriteTd(genesis.Hash(), genesis.NumberU64(), genesis.Difficulty()); err != nil {        log.Crit("Failed to write genesis block TD", "err", err)    }    if err := WriteBlock(bc.chainDb, genesis); err != nil {        log.Crit("Failed to write genesis block", "err", err)    }    bc.genesisBlock = genesis    bc.insert(bc.genesisBlock)    bc.currentBlock = bc.genesisBlock    bc.hc.SetGenesis(bc.genesisBlock.Header())    bc.hc.SetCurrentHeader(bc.genesisBlock.Header())    bc.currentFastBlock = bc.genesisBlock    return nil}</code></pre><p>SetHead将本地链回卷到新的头部。 在给定新header之上的所有内容都将被删除，新的header将被设置。 如果块体丢失（快速同步之后的非归档节点），头部可能被进一步倒回。</p><pre><code>// SetHead rewinds the local chain to a new head. In the case of headers, everything// above the new head will be deleted and the new one set. In the case of blocks// though, the head may be further rewound if block bodies are missing (non-archive// nodes after a fast sync).func (bc *BlockChain) SetHead(head uint64) error {    log.Warn("Rewinding blockchain", "target", head)    bc.mu.Lock()    defer bc.mu.Unlock()    // Rewind the header chain, deleting all block bodies until then    delFn := func(hash common.Hash, num uint64) {        DeleteBody(bc.chainDb, hash, num)    }    bc.hc.SetHead(head, delFn)    currentHeader := bc.hc.CurrentHeader()    // Clear out any stale content from the caches    bc.bodyCache.Purge()    bc.bodyRLPCache.Purge()    bc.blockCache.Purge()    bc.futureBlocks.Purge()    // Rewind the block chain, ensuring we don't end up with a stateless head block    if bc.currentBlock != nil &amp;&amp; currentHeader.Number.Uint64() &lt; bc.currentBlock.NumberU64() {        bc.currentBlock = bc.GetBlock(currentHeader.Hash(), currentHeader.Number.Uint64())    }    if bc.currentBlock != nil {        if _, err := state.New(bc.currentBlock.Root(), bc.stateCache); err != nil {            // Rewound state missing, rolled back to before pivot, reset to genesis            bc.currentBlock = nil        }    }    // Rewind the fast block in a simpleton way to the target head    if bc.currentFastBlock != nil &amp;&amp; currentHeader.Number.Uint64() &lt; bc.currentFastBlock.NumberU64() {        bc.currentFastBlock = bc.GetBlock(currentHeader.Hash(), currentHeader.Number.Uint64())    }    // If either blocks reached nil, reset to the genesis state    if bc.currentBlock == nil {        bc.currentBlock = bc.genesisBlock    }    if bc.currentFastBlock == nil {        bc.currentFastBlock = bc.genesisBlock    }    if err := WriteHeadBlockHash(bc.chainDb, bc.currentBlock.Hash()); err != nil {        log.Crit("Failed to reset head full block", "err", err)    }    if err := WriteHeadFastBlockHash(bc.chainDb, bc.currentFastBlock.Hash()); err != nil {        log.Crit("Failed to reset head fast block", "err", err)    }    return bc.loadLastState()}</code></pre><p>InsertChain,插入区块链, 插入区块链尝试把给定的区块插入到规范的链条,或者是创建一个分叉. 如果发生错误,那么会返回错误发生时候的index和具体的错误信息.</p><pre><code>// InsertChain attempts to insert the given batch of blocks in to the canonical// chain or, otherwise, create a fork. If an error is returned it will return// the index number of the failing block as well an error describing what went// wrong.//// After insertion is done, all accumulated events will be fired.// 在插入完成之后,所有累计的事件将被触发.func (bc *BlockChain) InsertChain(chain types.Blocks) (int, error) {    n, events, logs, err := bc.insertChain(chain)    bc.PostChainEvents(events, logs)    return n, err}</code></pre><p>insertChain方法会执行区块链插入,并收集事件信息. 因为需要使用defer来处理解锁,所以把这个方法作为一个单独的方法.</p><pre><code>// insertChain will execute the actual chain insertion and event aggregation. The// only reason this method exists as a separate one is to make locking cleaner// with deferred statements.func (bc *BlockChain) insertChain(chain types.Blocks) (int, []interface{}, []*types.Log, error) {    // Do a sanity check that the provided chain is actually ordered and linked    // 做一个健全的检查，提供的链实际上是有序的和相互链接的    for i := 1; i &lt; len(chain); i++ {        if chain[i].NumberU64() != chain[i-1].NumberU64()+1 || chain[i].ParentHash() != chain[i-1].Hash() {            // Chain broke ancestry, log a messge (programming error) and skip insertion            log.Error("Non contiguous block insert", "number", chain[i].Number(), "hash", chain[i].Hash(),                "parent", chain[i].ParentHash(), "prevnumber", chain[i-1].Number(), "prevhash", chain[i-1].Hash())            return 0, nil, nil, fmt.Errorf("non contiguous insert: item %d is #%d [%x…], item %d is #%d [%x…] (parent [%x…])", i-1, chain[i-1].NumberU64(),                chain[i-1].Hash().Bytes()[:4], i, chain[i].NumberU64(), chain[i].Hash().Bytes()[:4], chain[i].ParentHash().Bytes()[:4])        }    }    // Pre-checks passed, start the full block imports    bc.wg.Add(1)    defer bc.wg.Done()    bc.chainmu.Lock()    defer bc.chainmu.Unlock()    // A queued approach to delivering events. This is generally    // faster than direct delivery and requires much less mutex    // acquiring.    var (        stats         = insertStats{startTime: mclock.Now()}        events        = make([]interface{}, 0, len(chain))        lastCanon     *types.Block        coalescedLogs []*types.Log    )    // Start the parallel header verifier    headers := make([]*types.Header, len(chain))    seals := make([]bool, len(chain))    for i, block := range chain {        headers[i] = block.Header()        seals[i] = true    }    // 调用一致性引擎来验证区块头是有效的.    abort, results := bc.engine.VerifyHeaders(bc, headers, seals)    defer close(abort)    // Iterate over the blocks and insert when the verifier permits    for i, block := range chain {        // If the chain is terminating, stop processing blocks        if atomic.LoadInt32(&amp;bc.procInterrupt) == 1 {            log.Debug("Premature abort during blocks processing")            break        }        // If the header is a banned one, straight out abort        // 如果区块头被禁止了.         if BadHashes[block.Hash()] {            bc.reportBlock(block, nil, ErrBlacklistedHash)            return i, events, coalescedLogs, ErrBlacklistedHash        }        // Wait for the block's verification to complete        bstart := time.Now()        err := &lt;-results        if err == nil { // 如果没有错误. 验证body            err = bc.Validator().ValidateBody(block)        }        if err != nil {            if err == ErrKnownBlock { // 如果区块已经插入, 直接继续                stats.ignored++                continue            }            if err == consensus.ErrFutureBlock {                 // Allow up to MaxFuture second in the future blocks. If this limit                // is exceeded the chain is discarded and processed at a later time                // if given.                // 如果是未来的区块, 而且区块的时间距离现在不是很久远. 那么存放起来.                max := big.NewInt(time.Now().Unix() + maxTimeFutureBlocks)                if block.Time().Cmp(max) &gt; 0 {                    return i, events, coalescedLogs, fmt.Errorf("future block: %v &gt; %v", block.Time(), max)                }                bc.futureBlocks.Add(block.Hash(), block)                stats.queued++                continue            }            if err == consensus.ErrUnknownAncestor &amp;&amp; bc.futureBlocks.Contains(block.ParentHash()) { 如果区块没有找到祖先 而在future blocks 包含了这个区块的祖先,那么也存放在future                bc.futureBlocks.Add(block.Hash(), block)                stats.queued++                continue            }            bc.reportBlock(block, nil, err)            return i, events, coalescedLogs, err        }        // Create a new statedb using the parent block and report an        // error if it fails.        var parent *types.Block        if i == 0 {            parent = bc.GetBlock(block.ParentHash(), block.NumberU64()-1)        } else {            parent = chain[i-1]        }        state, err := state.New(parent.Root(), bc.stateCache)        if err != nil {            return i, events, coalescedLogs, err        }        // Process block using the parent state as reference point.        // 处理区块,生成交易,收据,日志等信息.         // 实际上调用了state_processor.go 里面的 Process方法.        receipts, logs, usedGas, err := bc.processor.Process(block, state, bc.vmConfig)        if err != nil {            bc.reportBlock(block, receipts, err)            return i, events, coalescedLogs, err        }        // Validate the state using the default validator        // 二次验证,验证状态是否合法        err = bc.Validator().ValidateState(block, parent, state, receipts, usedGas)        if err != nil {            bc.reportBlock(block, receipts, err)            return i, events, coalescedLogs, err        }        // Write the block to the chain and get the status                // 写入区块和状态.        status, err := bc.WriteBlockAndState(block, receipts, state)        if err != nil {            return i, events, coalescedLogs, err        }        switch status {        case CanonStatTy:  // 插入了新的区块.            log.Debug("Inserted new block", "number", block.Number(), "hash", block.Hash(), "uncles", len(block.Uncles()),                "txs", len(block.Transactions()), "gas", block.GasUsed(), "elapsed", common.PrettyDuration(time.Since(bstart)))            coalescedLogs = append(coalescedLogs, logs...)            blockInsertTimer.UpdateSince(bstart)            events = append(events, ChainEvent{block, block.Hash(), logs})            lastCanon = block        case SideStatTy:  // 插入了一个forked 区块            log.Debug("Inserted forked block", "number", block.Number(), "hash", block.Hash(), "diff", block.Difficulty(), "elapsed",                common.PrettyDuration(time.Since(bstart)), "txs", len(block.Transactions()), "gas", block.GasUsed(), "uncles", len(block.Uncles()))            blockInsertTimer.UpdateSince(bstart)            events = append(events, ChainSideEvent{block})        }        stats.processed++        stats.usedGas += usedGas.Uint64()        stats.report(chain, i)    }    // Append a single chain head event if we've progressed the chain    // 如果我们生成了一个新的区块头, 而且最新的区块头等于lastCanon    // 那么我们公布一个新的 ChainHeadEvent    if lastCanon != nil &amp;&amp; bc.LastBlockHash() == lastCanon.Hash() {        events = append(events, ChainHeadEvent{lastCanon})    }    return 0, events, coalescedLogs, nil}</code></pre><p>WriteBlockAndState,把区块写入区块链. </p><pre><code>// WriteBlock writes the block to the chain.func (bc *BlockChain) WriteBlockAndState(block *types.Block, receipts []*types.Receipt, state *state.StateDB) (status WriteStatus, err error) {    bc.wg.Add(1)    defer bc.wg.Done()    // Calculate the total difficulty of the block    // 计算待插入的区块的总难度    ptd := bc.GetTd(block.ParentHash(), block.NumberU64()-1)    if ptd == nil {        return NonStatTy, consensus.ErrUnknownAncestor    }    // Make sure no inconsistent state is leaked during insertion    // 确保在插入过程中没有不一致的状态泄漏    bc.mu.Lock()    defer bc.mu.Unlock()    // 计算当前区块的区块链的总难度.    localTd := bc.GetTd(bc.currentBlock.Hash(), bc.currentBlock.NumberU64())    // 计算新的区块链的总难度    externTd := new(big.Int).Add(block.Difficulty(), ptd)    // Irrelevant of the canonical status, write the block itself to the database    // 和规范区块没有关系的状态, 写入数据库.  写入区块的hash 高度和对应的总难度.    if err := bc.hc.WriteTd(block.Hash(), block.NumberU64(), externTd); err != nil {        return NonStatTy, err    }    // Write other block data using a batch.    batch := bc.chainDb.NewBatch()    if err := WriteBlock(batch, block); err != nil { // 写入区块        return NonStatTy, err    }    if _, err := state.CommitTo(batch, bc.config.IsEIP158(block.Number())); err != nil {  //Commit        return NonStatTy, err    }    if err := WriteBlockReceipts(batch, block.Hash(), block.NumberU64(), receipts); err != nil { // 写入区块收据        return NonStatTy, err    }    // If the total difficulty is higher than our known, add it to the canonical chain    // Second clause in the if statement reduces the vulnerability to selfish mining.    // Please refer to http://www.cs.cornell.edu/~ie53/publications/btcProcFC.pdf    // 如果新的区块的总难度高于我们当前的区块, 把这个区块设置为规范的区块.    // 第二个表达式 ((externTd.Cmp(localTd) == 0 &amp;&amp; mrand.Float64() &lt; 0.5))     // 是为了减少自私挖矿的可能性.    if externTd.Cmp(localTd) &gt; 0 || (externTd.Cmp(localTd) == 0 &amp;&amp; mrand.Float64() &lt; 0.5) {        // Reorganise the chain if the parent is not the head block        // 如果这个区块的父区块不是当前的区块, 说明存在一个分叉.需要调用reorg重新组织区块链.        if block.ParentHash() != bc.currentBlock.Hash() {            if err := bc.reorg(bc.currentBlock, block); err != nil {                return NonStatTy, err            }        }        // Write the positional metadata for transaction and receipt lookups        // "l" + txHash -&gt; {blockHash,blockNum,txIndex}        // 根据交易的hash值来找到对应的区块以及对应的交易。        if err := WriteTxLookupEntries(batch, block); err != nil {            return NonStatTy, err        }        // Write hash preimages        // hash(Keccak-256) -&gt; 对应的数据 这个功能是用来测试的。如果开启了dev模式，        // 或者是 vmdebug参数， 如果执行 SHA3 指令就会添加Preimage        if err := WritePreimages(bc.chainDb, block.NumberU64(), state.Preimages()); err != nil {            return NonStatTy, err        }        status = CanonStatTy    } else {        status = SideStatTy    }    if err := batch.Write(); err != nil {        return NonStatTy, err    }    // Set new head.    if status == CanonStatTy {        bc.insert(block)    }    bc.futureBlocks.Remove(block.Hash())    return status, nil}</code></pre><p>reorgs方法是在新的链的总难度大于本地链的总难度的情况下，需要用新的区块链来替换本地的区块链为规范链。</p><pre><code>// reorgs takes two blocks, an old chain and a new chain and will reconstruct the blocks and inserts them// to be part of the new canonical chain and accumulates potential missing transactions and post an// event about them// reorgs 接受两个区块作为参数，一个是老的区块链，一个新的区块链，这个方法会把他们插入// 以便重新构建出一条规范的区块链。 同时会累计潜在会丢失的交易并把它们作为事件发布出去。func (bc *BlockChain) reorg(oldBlock, newBlock *types.Block) error {    var (        newChain    types.Blocks        oldChain    types.Blocks        commonBlock *types.Block        deletedTxs  types.Transactions        deletedLogs []*types.Log        // collectLogs collects the logs that were generated during the        // processing of the block that corresponds with the given hash.        // These logs are later announced as deleted.        // collectLogs 会收集我们已经生成的日志信息，这些日志稍后会被声明删除(实际上在数据库中并没有被删除)。        collectLogs = func(h common.Hash) {            // Coalesce logs and set 'Removed'.            receipts := GetBlockReceipts(bc.chainDb, h, bc.hc.GetBlockNumber(h))            for _, receipt := range receipts {                for _, log := range receipt.Logs {                    del := *log                    del.Removed = true                    deletedLogs = append(deletedLogs, &amp;del)                }            }        }    )    // first reduce whoever is higher bound    if oldBlock.NumberU64() &gt; newBlock.NumberU64() {        // reduce old chain 如果老的链比新的链高。那么需要减少老的链，让它和新链一样高        for ; oldBlock != nil &amp;&amp; oldBlock.NumberU64() != newBlock.NumberU64(); oldBlock = bc.GetBlock(oldBlock.ParentHash(), oldBlock.NumberU64()-1) {            oldChain = append(oldChain, oldBlock)            deletedTxs = append(deletedTxs, oldBlock.Transactions()...)            collectLogs(oldBlock.Hash())        }    } else {        // reduce new chain and append new chain blocks for inserting later on        // 如果新链比老链要高，那么减少新链。        for ; newBlock != nil &amp;&amp; newBlock.NumberU64() != oldBlock.NumberU64(); newBlock = bc.GetBlock(newBlock.ParentHash(), newBlock.NumberU64()-1) {            newChain = append(newChain, newBlock)        }    }    if oldBlock == nil {        return fmt.Errorf("Invalid old chain")    }    if newBlock == nil {        return fmt.Errorf("Invalid new chain")    }    for { //这个for循环里面需要找到共同的祖先。        if oldBlock.Hash() == newBlock.Hash() {            commonBlock = oldBlock            break        }        oldChain = append(oldChain, oldBlock)        newChain = append(newChain, newBlock)        deletedTxs = append(deletedTxs, oldBlock.Transactions()...)        collectLogs(oldBlock.Hash())        oldBlock, newBlock = bc.GetBlock(oldBlock.ParentHash(), oldBlock.NumberU64()-1), bc.GetBlock(newBlock.ParentHash(), newBlock.NumberU64()-1)        if oldBlock == nil {            return fmt.Errorf("Invalid old chain")        }        if newBlock == nil {            return fmt.Errorf("Invalid new chain")        }    }    // Ensure the user sees large reorgs    if len(oldChain) &gt; 0 &amp;&amp; len(newChain) &gt; 0 {        logFn := log.Debug        if len(oldChain) &gt; 63 {            logFn = log.Warn        }        logFn("Chain split detected", "number", commonBlock.Number(), "hash", commonBlock.Hash(),            "drop", len(oldChain), "dropfrom", oldChain[0].Hash(), "add", len(newChain), "addfrom", newChain[0].Hash())    } else {        log.Error("Impossible reorg, please file an issue", "oldnum", oldBlock.Number(), "oldhash", oldBlock.Hash(), "newnum", newBlock.Number(), "newhash", newBlock.Hash())    }    var addedTxs types.Transactions    // insert blocks. Order does not matter. Last block will be written in ImportChain itself which creates the new head properly    for _, block := range newChain {        // insert the block in the canonical way, re-writing history        // 插入区块 更新记录规范区块链的key        bc.insert(block)        // write lookup entries for hash based transaction/receipt searches        // 写入交易的查询信息。        if err := WriteTxLookupEntries(bc.chainDb, block); err != nil {            return err        }        addedTxs = append(addedTxs, block.Transactions()...)    }    // calculate the difference between deleted and added transactions    diff := types.TxDifference(deletedTxs, addedTxs)    // When transactions get deleted from the database that means the    // receipts that were created in the fork must also be deleted    // 删除那些需要删除的交易查询信息。     // 这里并没有删除那些需要删除的区块，区块头，收据等信息。    for _, tx := range diff {        DeleteTxLookupEntry(bc.chainDb, tx.Hash())    }    if len(deletedLogs) &gt; 0 { // 发送消息通知        go bc.rmLogsFeed.Send(RemovedLogsEvent{deletedLogs})    }    if len(oldChain) &gt; 0 {        go func() {            for _, block := range oldChain { // 发送消息通知。                bc.chainSideFeed.Send(ChainSideEvent{Block: block})            }        }()    }    return nil}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-state源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-state%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-state%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>core/state 包主要为以太坊的state trie提供了一层缓存层(cache)</p><p>state的结构主要如下图</p><p><img src="/images/ethereum/source_analysis/state_1.png" alt="image"></p><p>蓝色的矩形代表本模块， 灰色的矩形代表外部模块。</p><ul><li>database主要提供了trie树的抽象，提供trie树的缓存和合约代码长度的缓存。</li><li>journal主要提供了操作日志，以及操作回滚的功能。 </li><li>state_object是account对象的抽象，提供了账户的一些功能。 </li><li>statedb主要是提供了state trie的部分功能。</li></ul><h2 id="database-go"><a href="#database-go" class="headerlink" title="database.go"></a>database.go</h2><p>database.go 提供了一个数据库的抽象。</p><p>数据结构</p><pre><code>// Database wraps access to tries and contract code.type Database interface {    // Accessing tries:    // OpenTrie opens the main account trie.    // OpenStorageTrie opens the storage trie of an account.    // OpenTrie 打开了主账号的trie树    // OpenStorageTrie 打开了一个账号的storage trie    OpenTrie(root common.Hash) (Trie, error)    OpenStorageTrie(addrHash, root common.Hash) (Trie, error)    // Accessing contract code:    // 访问合约代码    ContractCode(addrHash, codeHash common.Hash) ([]byte, error)    // 访问合约的大小。 这个方法可能经常被调用。因为有缓存。    ContractCodeSize(addrHash, codeHash common.Hash) (int, error)    // CopyTrie returns an independent copy of the given trie.    // CopyTrie 返回了一个指定trie的独立的copy    CopyTrie(Trie) Trie}// NewDatabase creates a backing store for state. The returned database is safe for// concurrent use and retains cached trie nodes in memory.func NewDatabase(db ethdb.Database) Database {    csc, _ := lru.New(codeSizeCacheSize)    return &amp;cachingDB{db: db, codeSizeCache: csc}}type cachingDB struct {    db            ethdb.Database    mu            sync.Mutex    pastTries     []*trie.SecureTrie  //trie树的缓存    codeSizeCache *lru.Cache          //合约代码大小的缓存}</code></pre><p>OpenTrie，从缓存里面查找。如果找到了返回缓存的trie的copy， 否则重新构建一颗树返回。</p><pre><code>func (db *cachingDB) OpenTrie(root common.Hash) (Trie, error) {    db.mu.Lock()    defer db.mu.Unlock()    for i := len(db.pastTries) - 1; i &gt;= 0; i-- {        if db.pastTries[i].Hash() == root {            return cachedTrie{db.pastTries[i].Copy(), db}, nil        }    }    tr, err := trie.NewSecure(root, db.db, MaxTrieCacheGen)    if err != nil {        return nil, err    }    return cachedTrie{tr, db}, nil}func (db *cachingDB) OpenStorageTrie(addrHash, root common.Hash) (Trie, error) {    return trie.NewSecure(root, db.db, 0)}</code></pre><p>ContractCode 和 ContractCodeSize, ContractCodeSize有缓存。</p><pre><code>func (db *cachingDB) ContractCode(addrHash, codeHash common.Hash) ([]byte, error) {    code, err := db.db.Get(codeHash[:])    if err == nil {        db.codeSizeCache.Add(codeHash, len(code))    }    return code, err}func (db *cachingDB) ContractCodeSize(addrHash, codeHash common.Hash) (int, error) {    if cached, ok := db.codeSizeCache.Get(codeHash); ok {        return cached.(int), nil    }    code, err := db.ContractCode(addrHash, codeHash)    if err == nil {        db.codeSizeCache.Add(codeHash, len(code))    }    return len(code), err}</code></pre><p>cachedTrie的结构和commit方法，commit的时候会调用pushTrie方法把之前的Trie树缓存起来。</p><pre><code>// cachedTrie inserts its trie into a cachingDB on commit.type cachedTrie struct {    *trie.SecureTrie    db *cachingDB}func (m cachedTrie) CommitTo(dbw trie.DatabaseWriter) (common.Hash, error) {    root, err := m.SecureTrie.CommitTo(dbw)    if err == nil {        m.db.pushTrie(m.SecureTrie)    }    return root, err}func (db *cachingDB) pushTrie(t *trie.SecureTrie) {    db.mu.Lock()    defer db.mu.Unlock()    if len(db.pastTries) &gt;= maxPastTries {        copy(db.pastTries, db.pastTries[1:])        db.pastTries[len(db.pastTries)-1] = t    } else {        db.pastTries = append(db.pastTries, t)    }}</code></pre><h2 id="journal-go"><a href="#journal-go" class="headerlink" title="journal.go"></a>journal.go</h2><p>journal代表了操作日志， 并针对各种操作的日志提供了对应的回滚功能。 可以基于这个日志来做一些事务类型的操作。</p><p>类型定义，定义了journalEntry这个接口，提供了undo的功能。 journal 就是journalEntry的列表。</p><pre><code>type journalEntry interface {    undo(*StateDB)}type journal []journalEntry</code></pre><p>各种不同的日志类型以及undo方法。</p><pre><code>createObjectChange struct {  //创建对象的日志。 undo方法就是从StateDB中删除创建的对象。    account *common.Address}func (ch createObjectChange) undo(s *StateDB) {    delete(s.stateObjects, *ch.account)    delete(s.stateObjectsDirty, *ch.account)}// 对于stateObject的修改， undo方法就是把值改为原来的对象。resetObjectChange struct {    prev *stateObject}func (ch resetObjectChange) undo(s *StateDB) {    s.setStateObject(ch.prev)}// 自杀的更改。自杀应该是删除账号，但是如果没有commit的化，对象还没有从stateDB删除。suicideChange struct {    account     *common.Address    prev        bool // whether account had already suicided    prevbalance *big.Int}func (ch suicideChange) undo(s *StateDB) {    obj := s.getStateObject(*ch.account)    if obj != nil {        obj.suicided = ch.prev        obj.setBalance(ch.prevbalance)    }}// Changes to individual accounts.balanceChange struct {    account *common.Address    prev    *big.Int}nonceChange struct {    account *common.Address    prev    uint64}storageChange struct {    account       *common.Address    key, prevalue common.Hash}codeChange struct {    account            *common.Address    prevcode, prevhash []byte}func (ch balanceChange) undo(s *StateDB) {    s.getStateObject(*ch.account).setBalance(ch.prev)}func (ch nonceChange) undo(s *StateDB) {    s.getStateObject(*ch.account).setNonce(ch.prev)}func (ch codeChange) undo(s *StateDB) {    s.getStateObject(*ch.account).setCode(common.BytesToHash(ch.prevhash), ch.prevcode)}func (ch storageChange) undo(s *StateDB) {    s.getStateObject(*ch.account).setState(ch.key, ch.prevalue)}// 我理解是DAO事件的退款处理refundChange struct {    prev *big.Int}func (ch refundChange) undo(s *StateDB) {    s.refund = ch.prev}// 增加了日志的修改addLogChange struct {    txhash common.Hash}func (ch addLogChange) undo(s *StateDB) {    logs := s.logs[ch.txhash]    if len(logs) == 1 {        delete(s.logs, ch.txhash)    } else {        s.logs[ch.txhash] = logs[:len(logs)-1]    }    s.logSize--}// 这个是增加 VM看到的 SHA3的 原始byte[], 增加SHA3 hash -&gt; byte[] 的对应关系addPreimageChange struct {    hash common.Hash}func (ch addPreimageChange) undo(s *StateDB) {    delete(s.preimages, ch.hash)}touchChange struct {    account   *common.Address    prev      bool    prevDirty bool}var ripemd = common.HexToAddress("0000000000000000000000000000000000000003")func (ch touchChange) undo(s *StateDB) {    if !ch.prev &amp;&amp; *ch.account != ripemd {        s.getStateObject(*ch.account).touched = ch.prev        if !ch.prevDirty {            delete(s.stateObjectsDirty, *ch.account)        }    }}</code></pre><h2 id="state-object-go"><a href="#state-object-go" class="headerlink" title="state_object.go"></a>state_object.go</h2><p>stateObject表示正在修改的以太坊帐户。</p><p>数据结构</p><pre><code>type Storage map[common.Hash]common.Hash// stateObject represents an Ethereum account which is being modified.// stateObject表示正在修改的以太坊帐户。// The usage pattern is as follows:// First you need to obtain a state object.// Account values can be accessed and modified through the object.// Finally, call CommitTrie to write the modified storage trie into a database.使用模式如下：首先你需要获得一个state_object。帐户值可以通过对象访问和修改。最后，调用CommitTrie将修改后的存储trie写入数据库。type stateObject struct {    address  common.Address    addrHash common.Hash // hash of ethereum address of the account 以太坊账号地址的hash值    data     Account  // 这个是实际的以太坊账号的信息    db       *StateDB //状态数据库    // DB error.    // State objects are used by the consensus core and VM which are    // unable to deal with database-level errors. Any error that occurs    // during a database read is memoized here and will eventually be returned    // by StateDB.Commit.    //     数据库错误。    stateObject会被共识算法的核心和VM使用，在这些代码内部无法处理数据库级别的错误。     在数据库读取期间发生的任何错误都会在这里被存储，最终将由StateDB.Commit返回。    dbErr error    // Write caches.  写缓存    trie Trie // storage trie, which becomes non-nil on first access 用户的存储trie ，在第一次访问的时候变得非空    code Code // contract bytecode, which gets set when code is loaded 合约代码，当代码被加载的时候被设置    cachedStorage Storage // Storage entry cache to avoid duplicate reads 用户存储对象的缓存，用来避免重复读    dirtyStorage  Storage // Storage entries that need to be flushed to disk 需要刷入磁盘的用户存储对象    // Cache flags.  Cache 标志    // When an object is marked suicided it will be delete from the trie    // during the "update" phase of the state transition.    // 当一个对象被标记为自杀时，它将在状态转换的“更新”阶段期间从树中删除。    dirtyCode bool // true if the code was updated 如果代码被更新，会设置为true    suicided  bool    touched   bool    deleted   bool    onDirty   func(addr common.Address) // Callback method to mark a state object newly dirty  第一次被设置为drity的时候会被调用。}// Account is the Ethereum consensus representation of accounts.// These objects are stored in the main account trie.// 帐户是以太坊共识表示的帐户。 这些对象存储在main account trie。type Account struct {    Nonce    uint64    Balance  *big.Int    Root     common.Hash // merkle root of the storage trie    CodeHash []byte}</code></pre><p>构造函数</p><pre><code>// newObject creates a state object.func newObject(db *StateDB, address common.Address, data Account, onDirty func(addr common.Address)) *stateObject {    if data.Balance == nil {        data.Balance = new(big.Int)    }    if data.CodeHash == nil {        data.CodeHash = emptyCodeHash    }    return &amp;stateObject{        db:            db,        address:       address,        addrHash:      crypto.Keccak256Hash(address[:]),        data:          data,        cachedStorage: make(Storage),        dirtyStorage:  make(Storage),        onDirty:       onDirty,    }}</code></pre><p>RLP的编码方式，只会编码 Account对象。</p><pre><code>// EncodeRLP implements rlp.Encoder.func (c *stateObject) EncodeRLP(w io.Writer) error {    return rlp.Encode(w, c.data)}</code></pre><p>一些状态改变的函数。</p><pre><code>func (self *stateObject) markSuicided() {    self.suicided = true    if self.onDirty != nil {        self.onDirty(self.Address())        self.onDirty = nil    }}func (c *stateObject) touch() {    c.db.journal = append(c.db.journal, touchChange{        account:   &amp;c.address,        prev:      c.touched,        prevDirty: c.onDirty == nil,    })    if c.onDirty != nil {        c.onDirty(c.Address())        c.onDirty = nil    }    c.touched = true}</code></pre><p>Storage的处理</p><pre><code>// getTrie返回账户的Storage Triefunc (c *stateObject) getTrie(db Database) Trie {    if c.trie == nil {        var err error        c.trie, err = db.OpenStorageTrie(c.addrHash, c.data.Root)        if err != nil {            c.trie, _ = db.OpenStorageTrie(c.addrHash, common.Hash{})            c.setError(fmt.Errorf("can't create storage trie: %v", err))        }    }    return c.trie}// GetState returns a value in account storage.// GetState 返回account storage 的一个值，这个值的类型是Hash类型。// 说明account storage里面只能存储hash值？// 如果缓存里面存在就从缓存里查找，否则从数据库里面查询。然后存储到缓存里面。func (self *stateObject) GetState(db Database, key common.Hash) common.Hash {    value, exists := self.cachedStorage[key]    if exists {        return value    }    // Load from DB in case it is missing.    enc, err := self.getTrie(db).TryGet(key[:])    if err != nil {        self.setError(err)        return common.Hash{}    }    if len(enc) &gt; 0 {        _, content, _, err := rlp.Split(enc)        if err != nil {            self.setError(err)        }        value.SetBytes(content)    }    if (value != common.Hash{}) {        self.cachedStorage[key] = value    }    return value}// SetState updates a value in account storage.// 往 account storeage 里面设置一个值 key value 的类型都是Hash类型。func (self *stateObject) SetState(db Database, key, value common.Hash) {    self.db.journal = append(self.db.journal, storageChange{        account:  &amp;self.address,        key:      key,        prevalue: self.GetState(db, key),    })    self.setState(key, value)}func (self *stateObject) setState(key, value common.Hash) {    self.cachedStorage[key] = value    self.dirtyStorage[key] = value    if self.onDirty != nil {        self.onDirty(self.Address())        self.onDirty = nil    }}</code></pre><p>提交 Commit</p><pre><code>// CommitTrie the storage trie of the object to dwb.// This updates the trie root.// 步骤，首先打开，然后修改，然后提交或者回滚func (self *stateObject) CommitTrie(db Database, dbw trie.DatabaseWriter) error {    self.updateTrie(db) // updateTrie把修改过的缓存写入Trie树    if self.dbErr != nil {        return self.dbErr    }    root, err := self.trie.CommitTo(dbw)    if err == nil {        self.data.Root = root    }    return err}// updateTrie writes cached storage modifications into the object's storage trie.func (self *stateObject) updateTrie(db Database) Trie {    tr := self.getTrie(db)    for key, value := range self.dirtyStorage {        delete(self.dirtyStorage, key)        if (value == common.Hash{}) {            self.setError(tr.TryDelete(key[:]))            continue        }        // Encoding []byte cannot fail, ok to ignore the error.        v, _ := rlp.EncodeToBytes(bytes.TrimLeft(value[:], "\x00"))        self.setError(tr.TryUpdate(key[:], v))    }    return tr}// UpdateRoot sets the trie root to the current root hash of// 把账号的root设置为当前的trie树的跟。func (self *stateObject) updateRoot(db Database) {    self.updateTrie(db)    self.data.Root = self.trie.Hash()}</code></pre><p>额外的一些功能 ，deepCopy提供了state_object的深拷贝。</p><pre><code>func (self *stateObject) deepCopy(db *StateDB, onDirty func(addr common.Address)) *stateObject {    stateObject := newObject(db, self.address, self.data, onDirty)    if self.trie != nil {        stateObject.trie = db.db.CopyTrie(self.trie)    }    stateObject.code = self.code    stateObject.dirtyStorage = self.dirtyStorage.Copy()    stateObject.cachedStorage = self.dirtyStorage.Copy()    stateObject.suicided = self.suicided    stateObject.dirtyCode = self.dirtyCode    stateObject.deleted = self.deleted    return stateObject}</code></pre><h2 id="statedb-go"><a href="#statedb-go" class="headerlink" title="statedb.go"></a>statedb.go</h2><p>stateDB用来存储以太坊中关于merkle trie的所有内容。 StateDB负责缓存和存储嵌套状态。 这是检索合约和账户的一般查询界面：</p><p>数据结构</p><pre><code>type StateDB struct {    db   Database  // 后端的数据库    trie Trie       // trie树 main account trie    // This map holds 'live' objects, which will get modified while processing a state transition.    // 下面的Map用来存储当前活动的对象，这些对象在状态转换的时候会被修改。    // stateObjects 用来缓存对象    // stateObjectsDirty用来缓存被修改过的对象。    stateObjects      map[common.Address]*stateObject    stateObjectsDirty map[common.Address]struct{}    // DB error.    // State objects are used by the consensus core and VM which are    // unable to deal with database-level errors. Any error that occurs    // during a database read is memoized here and will eventually be returned    // by StateDB.Commit.    dbErr error    // The refund counter, also used by state transitioning.    // refund计数器。 暂时还不清楚功能。    refund *big.Int    thash, bhash common.Hash  //当前的transaction hash 和block hash     txIndex      int          // 当前的交易的index    logs         map[common.Hash][]*types.Log // 日志 key是交易的hash值    logSize      uint    preimages map[common.Hash][]byte  // EVM计算的 SHA3-&gt;byte[]的映射关系    // Journal of state modifications. This is the backbone of    // Snapshot and RevertToSnapshot.    // 状态修改日志。 这是Snapshot和RevertToSnapshot的支柱。    journal        journal    validRevisions []revision    nextRevisionId int    lock sync.Mutex}</code></pre><p>构造函数</p><pre><code>// 一般的用法 statedb, _ := state.New(common.Hash{}, state.NewDatabase(db))// Create a new state from a given triefunc New(root common.Hash, db Database) (*StateDB, error) {    tr, err := db.OpenTrie(root)    if err != nil {        return nil, err    }    return &amp;StateDB{        db:                db,        trie:              tr,        stateObjects:      make(map[common.Address]*stateObject),        stateObjectsDirty: make(map[common.Address]struct{}),        refund:            new(big.Int),        logs:              make(map[common.Hash][]*types.Log),        preimages:         make(map[common.Hash][]byte),    }, nil}</code></pre><h3 id="对于Log的处理"><a href="#对于Log的处理" class="headerlink" title="对于Log的处理"></a>对于Log的处理</h3><p>state提供了Log的处理，这比较意外，因为Log实际上是存储在区块链中的，并没有存储在state trie中, state提供Log的处理， 使用了基于下面的几个函数。  奇怪的是暂时没看到如何删除logs里面的信息，如果不删除的话，应该会越积累越多。 TODO logs 删除</p><p>Prepare函数，在交易执行开始被执行。</p><p>AddLog函数，在交易执行过程中被VM执行。添加日志。同时把日志和交易关联起来，添加部分交易的信息。</p><p>GetLogs函数，交易完成取走。</p><pre><code>// Prepare sets the current transaction hash and index and block hash which is// used when the EVM emits new state logs.func (self *StateDB) Prepare(thash, bhash common.Hash, ti int) {    self.thash = thash    self.bhash = bhash    self.txIndex = ti}func (self *StateDB) AddLog(log *types.Log) {    self.journal = append(self.journal, addLogChange{txhash: self.thash})    log.TxHash = self.thash    log.BlockHash = self.bhash    log.TxIndex = uint(self.txIndex)    log.Index = self.logSize    self.logs[self.thash] = append(self.logs[self.thash], log)    self.logSize++}func (self *StateDB) GetLogs(hash common.Hash) []*types.Log {    return self.logs[hash]}func (self *StateDB) Logs() []*types.Log {    var logs []*types.Log    for _, lgs := range self.logs {        logs = append(logs, lgs...)    }    return logs}</code></pre><h3 id="stateObject处理"><a href="#stateObject处理" class="headerlink" title="stateObject处理"></a>stateObject处理</h3><p>getStateObject,首先从缓存里面获取，如果没有就从trie树里面获取，并加载到缓存。</p><pre><code>// Retrieve a state object given my the address. Returns nil if not found.func (self *StateDB) getStateObject(addr common.Address) (stateObject *stateObject) {    // Prefer 'live' objects.    if obj := self.stateObjects[addr]; obj != nil {        if obj.deleted {            return nil        }        return obj    }    // Load the object from the database.    enc, err := self.trie.TryGet(addr[:])    if len(enc) == 0 {        self.setError(err)        return nil    }    var data Account    if err := rlp.DecodeBytes(enc, &amp;data); err != nil {        log.Error("Failed to decode state object", "addr", addr, "err", err)        return nil    }    // Insert into the live set.    obj := newObject(self, addr, data, self.MarkStateObjectDirty)    self.setStateObject(obj)    return obj}</code></pre><p>MarkStateObjectDirty， 设置一个stateObject为Dirty。 直接往stateObjectDirty对应的地址插入一个空结构体。</p><pre><code>// MarkStateObjectDirty adds the specified object to the dirty map to avoid costly// state object cache iteration to find a handful of modified ones.func (self *StateDB) MarkStateObjectDirty(addr common.Address) {    self.stateObjectsDirty[addr] = struct{}{}}</code></pre><h3 id="快照和回滚功能"><a href="#快照和回滚功能" class="headerlink" title="快照和回滚功能"></a>快照和回滚功能</h3><p>Snapshot可以创建一个快照， 然后通过    RevertToSnapshot可以回滚到哪个状态，这个功能是通过journal来做到的。 每一步的修改都会往journal里面添加一个undo日志。 如果需要回滚只需要执行undo日志就行了。</p><pre><code>// Snapshot returns an identifier for the current revision of the state.func (self *StateDB) Snapshot() int {    id := self.nextRevisionId    self.nextRevisionId++    self.validRevisions = append(self.validRevisions, revision{id, len(self.journal)})    return id}// RevertToSnapshot reverts all state changes made since the given revision.func (self *StateDB) RevertToSnapshot(revid int) {    // Find the snapshot in the stack of valid snapshots.    idx := sort.Search(len(self.validRevisions), func(i int) bool {        return self.validRevisions[i].id &gt;= revid    })    if idx == len(self.validRevisions) || self.validRevisions[idx].id != revid {        panic(fmt.Errorf("revision id %v cannot be reverted", revid))    }    snapshot := self.validRevisions[idx].journalIndex    // Replay the journal to undo changes.    for i := len(self.journal) - 1; i &gt;= snapshot; i-- {        self.journal[i].undo(self)    }    self.journal = self.journal[:snapshot]    // Remove invalidated snapshots from the stack.    self.validRevisions = self.validRevisions[:idx]}</code></pre><h3 id="获取中间状态的-root-hash值"><a href="#获取中间状态的-root-hash值" class="headerlink" title="获取中间状态的 root hash值"></a>获取中间状态的 root hash值</h3><p>IntermediateRoot 用来计算当前的state trie的root的hash值。这个方法会在交易执行的过程中被调用。会被存入 transaction receipt</p><p>Finalise方法会调用update方法把存放在cache层的修改写入到trie数据库里面。 但是这个时候还没有写入底层的数据库。 还没有调用commit，数据还在内存里面，还没有落地成文件。</p><pre><code>// Finalise finalises the state by removing the self destructed objects// and clears the journal as well as the refunds.func (s *StateDB) Finalise(deleteEmptyObjects bool) {    for addr := range s.stateObjectsDirty {        stateObject := s.stateObjects[addr]        if stateObject.suicided || (deleteEmptyObjects &amp;&amp; stateObject.empty()) {            s.deleteStateObject(stateObject)        } else {            stateObject.updateRoot(s.db)            s.updateStateObject(stateObject)        }    }    // Invalidate journal because reverting across transactions is not allowed.    s.clearJournalAndRefund()}// IntermediateRoot computes the current root hash of the state trie.// It is called in between transactions to get the root hash that// goes into transaction receipts.func (s *StateDB) IntermediateRoot(deleteEmptyObjects bool) common.Hash {    s.Finalise(deleteEmptyObjects)    return s.trie.Hash()}</code></pre><h3 id="commit方法"><a href="#commit方法" class="headerlink" title="commit方法"></a>commit方法</h3><p>CommitTo用来提交更改。</p><pre><code>// CommitTo writes the state to the given database.func (s *StateDB) CommitTo(dbw trie.DatabaseWriter, deleteEmptyObjects bool) (root common.Hash, err error) {    defer s.clearJournalAndRefund()    // Commit objects to the trie.    for addr, stateObject := range s.stateObjects {        _, isDirty := s.stateObjectsDirty[addr]        switch {        case stateObject.suicided || (isDirty &amp;&amp; deleteEmptyObjects &amp;&amp; stateObject.empty()):            // If the object has been removed, don't bother syncing it            // and just mark it for deletion in the trie.            s.deleteStateObject(stateObject)        case isDirty:            // Write any contract code associated with the state object            if stateObject.code != nil &amp;&amp; stateObject.dirtyCode {                if err := dbw.Put(stateObject.CodeHash(), stateObject.code); err != nil {                    return common.Hash{}, err                }                stateObject.dirtyCode = false            }            // Write any storage changes in the state object to its storage trie.            if err := stateObject.CommitTrie(s.db, dbw); err != nil {                return common.Hash{}, err            }            // Update the object in the main account trie.            s.updateStateObject(stateObject)        }        delete(s.stateObjectsDirty, addr)    }    // Write trie changes.    root, err = s.trie.CommitTo(dbw)    log.Debug("Trie cache stats after commit", "misses", trie.CacheMisses(), "unloads", trie.CacheUnloads())    return root, err}</code></pre><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>state包提供了用户和合约的状态管理的功能。 管理了状态和合约的各种状态转换。 cache， trie， 数据库。  日志和回滚功能。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-txlist交易池的一些数据结构源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-txlist%E4%BA%A4%E6%98%93%E6%B1%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-txlist%E4%BA%A4%E6%98%93%E6%B1%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="nonceHeap"><a href="#nonceHeap" class="headerlink" title="nonceHeap"></a>nonceHeap</h2><p>nonceHeap实现了一个heap.Interface的数据结构，用来实现了一个堆的数据结构。 在heap.Interface的文档介绍中，默认实现的是最小堆。</p><p>如果h是一个数组，只要数组中的数据满足下面的要求。那么就认为h是一个最小堆。</p><pre><code>!h.Less(j, i) for 0 &lt;= i &lt; h.Len() and 2*i+1 &lt;= j &lt;= 2*i+2 and j &lt; h.Len()// 把数组看成是一颗满的二叉树，第一个元素是树根，第二和第三个元素是树根的两个树枝，// 这样依次推下去 那么如果树根是  i 那么它的两个树枝就是 2*i+2 和 2*i + 2。// 最小堆的定义是 任意的树根不能比它的两个树枝大。 也就是上面的代码描述的定义。heap.Interface的定义我们只需要定义满足下面接口的数据结构，就能够使用heap的一些方法来实现为堆结构。type Interface interface {    sort.Interface    Push(x interface{}) // add x as element Len() 把x增加到最后    Pop() interface{}   //  remove and return element Len() - 1. 移除并返回最后的一个元素}</code></pre><p>nonceHeap的代码分析。</p><pre><code>// nonceHeap is a heap.Interface implementation over 64bit unsigned integers for// retrieving sorted transactions from the possibly gapped future queue.type nonceHeap []uint64func (h nonceHeap) Len() int           { return len(h) }func (h nonceHeap) Less(i, j int) bool { return h[i] &lt; h[j] }func (h nonceHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }func (h *nonceHeap) Push(x interface{}) {    *h = append(*h, x.(uint64))}func (h *nonceHeap) Pop() interface{} {    old := *h    n := len(old)    x := old[n-1]    *h = old[0 : n-1]    return x}</code></pre><h2 id="txSortedMap"><a href="#txSortedMap" class="headerlink" title="txSortedMap"></a>txSortedMap</h2><p>txSortedMap,存储的是同一个账号下面的所有的交易。</p><p>结构</p><pre><code>// txSortedMap is a nonce-&gt;transaction hash map with a heap based index to allow// iterating over the contents in a nonce-incrementing way.// txSortedMap是一个具有基于堆的索引的nonce-&gt;交易 的hashmap，// 允许以nonce递增的方式迭代内容。type Transactions []*Transaction type txSortedMap struct {    items map[uint64]*types.Transaction // Hash map storing the transaction data    index *nonceHeap                    // Heap of nonces of all the stored transactions (non-strict mode)    cache types.Transactions            // Cache of the transactions already sorted 用来缓存已经排好序的交易。}</code></pre><p>Put 和 Get, Get用于获取指定nonce的交易， Put用来把交易插入到map中。</p><pre><code>// Get retrieves the current transactions associated with the given nonce.func (m *txSortedMap) Get(nonce uint64) *types.Transaction {    return m.items[nonce]}// Put inserts a new transaction into the map, also updating the map's nonce// index. If a transaction already exists with the same nonce, it's overwritten.// 把一个新的事务插入到map中，同时更新map的nonce索引。 如果一个事务已经存在，就把它覆盖。 同时任何缓存的数据会被删除。func (m *txSortedMap) Put(tx *types.Transaction) {    nonce := tx.Nonce()    if m.items[nonce] == nil {        heap.Push(m.index, nonce)    }    m.items[nonce], m.cache = tx, nil}</code></pre><p>Forward用于删除所有nonce小于threshold的交易。 然后返回所有被移除的交易。</p><pre><code>// Forward removes all transactions from the map with a nonce lower than the// provided threshold. Every removed transaction is returned for any post-removal// maintenance.func (m *txSortedMap) Forward(threshold uint64) types.Transactions {    var removed types.Transactions    // Pop off heap items until the threshold is reached    for m.index.Len() &gt; 0 &amp;&amp; (*m.index)[0] &lt; threshold {        nonce := heap.Pop(m.index).(uint64)        removed = append(removed, m.items[nonce])        delete(m.items, nonce)    }    // If we had a cached order, shift the front    // cache是排好序的交易。     if m.cache != nil {        m.cache = m.cache[len(removed):]    }    return removed}</code></pre><p>Filter, 删除所有令filter函数调用返回true的交易，并返回那些交易。</p><pre><code>// Filter iterates over the list of transactions and removes all of them for which// the specified function evaluates to true.func (m *txSortedMap) Filter(filter func(*types.Transaction) bool) types.Transactions {    var removed types.Transactions    // Collect all the transactions to filter out    for nonce, tx := range m.items {        if filter(tx) {            removed = append(removed, tx)            delete(m.items, nonce)        }    }    // If transactions were removed, the heap and cache are ruined    // 如果事务被删除，堆和缓存被毁坏    if len(removed) &gt; 0 {        *m.index = make([]uint64, 0, len(m.items))        for nonce := range m.items {            *m.index = append(*m.index, nonce)        }        // 需要重建堆        heap.Init(m.index)        // 设置cache为nil        m.cache = nil    }    return removed}</code></pre><p>Cap 对items里面的数量有限制，返回超过限制的所有交易。</p><pre><code>// Cap places a hard limit on the number of items, returning all transactions// exceeding that limit.// Cap 对items里面的数量有限制，返回超过限制的所有交易。func (m *txSortedMap) Cap(threshold int) types.Transactions {    // Short circuit if the number of items is under the limit    if len(m.items) &lt;= threshold {        return nil    }    // Otherwise gather and drop the highest nonce'd transactions    var drops types.Transactions    sort.Sort(*m.index) //从小到大排序 从尾部删除。    for size := len(m.items); size &gt; threshold; size-- {        drops = append(drops, m.items[(*m.index)[size-1]])        delete(m.items, (*m.index)[size-1])    }    *m.index = (*m.index)[:threshold]    // 重建堆    heap.Init(m.index)    // If we had a cache, shift the back    if m.cache != nil {        m.cache = m.cache[:len(m.cache)-len(drops)]    }    return drops}</code></pre><p>Remove</p><pre><code>// Remove deletes a transaction from the maintained map, returning whether the// transaction was found.// func (m *txSortedMap) Remove(nonce uint64) bool {    // Short circuit if no transaction is present    _, ok := m.items[nonce]    if !ok {        return false    }    // Otherwise delete the transaction and fix the heap index    for i := 0; i &lt; m.index.Len(); i++ {        if (*m.index)[i] == nonce {            heap.Remove(m.index, i)            break        }    }    delete(m.items, nonce)    m.cache = nil    return true}</code></pre><p>Ready函数    </p><pre><code>// Ready retrieves a sequentially increasing list of transactions starting at the// provided nonce that is ready for processing. The returned transactions will be// removed from the list.// Ready 返回一个从指定nonce开始，连续的交易。 返回的交易会被删除。// Note, all transactions with nonces lower than start will also be returned to// prevent getting into and invalid state. This is not something that should ever// happen but better to be self correcting than failing!// 注意，请注意，所有具有低于start的nonce的交易也将被返回，以防止进入和无效状态。 // 这不是应该发生的事情，而是自我纠正而不是失败！func (m *txSortedMap) Ready(start uint64) types.Transactions {    // Short circuit if no transactions are available    if m.index.Len() == 0 || (*m.index)[0] &gt; start {        return nil    }    // Otherwise start accumulating incremental transactions    var ready types.Transactions    // 从最小的开始，一个一个的增加，    for next := (*m.index)[0]; m.index.Len() &gt; 0 &amp;&amp; (*m.index)[0] == next; next++ {        ready = append(ready, m.items[next])        delete(m.items, next)        heap.Pop(m.index)    }    m.cache = nil    return ready}</code></pre><p>Flatten,返回一个基于nonce排序的交易列表。并缓存到cache字段里面，以便在没有修改的情况下反复使用。</p><pre><code>// Len returns the length of the transaction map.func (m *txSortedMap) Len() int {    return len(m.items)}// Flatten creates a nonce-sorted slice of transactions based on the loosely// sorted internal representation. The result of the sorting is cached in case// it's requested again before any modifications are made to the contents.func (m *txSortedMap) Flatten() types.Transactions {    // If the sorting was not cached yet, create and cache it    if m.cache == nil {        m.cache = make(types.Transactions, 0, len(m.items))        for _, tx := range m.items {            m.cache = append(m.cache, tx)        }        sort.Sort(types.TxByNonce(m.cache))    }    // Copy the cache to prevent accidental modifications    txs := make(types.Transactions, len(m.cache))    copy(txs, m.cache)    return txs}</code></pre><h2 id="txList"><a href="#txList" class="headerlink" title="txList"></a>txList</h2><p>txList 是属于同一个账号的交易列表， 按照nonce排序。可以用来存储连续的可执行的交易。对于非连续的交易,有一些小的不同的行为。</p><p>结构</p><pre><code>// txList is a "list" of transactions belonging to an account, sorted by account// nonce. The same type can be used both for storing contiguous transactions for// the executable/pending queue; and for storing gapped transactions for the non-// executable/future queue, with minor behavioral changes.type txList struct {    strict bool         // Whether nonces are strictly continuous or not nonces是严格连续的还是非连续的    txs    *txSortedMap // Heap indexed sorted hash map of the transactions 基于堆索引的交易的hashmap    costcap *big.Int // Price of the highest costing transaction (reset only if exceeds balance)  所有交易里面，GasPrice * GasLimit最高的值    gascap  *big.Int // Gas limit of the highest spending transaction (reset only if exceeds block limit) 所有交易里面， GasPrice最高的值}</code></pre><p>Overlaps 返回给定的交易是否有具有相同nonce的交易存在。</p><pre><code>// Overlaps returns whether the transaction specified has the same nonce as one// already contained within the list.// func (l *txList) Overlaps(tx *types.Transaction) bool {    return l.txs.Get(tx.Nonce()) != nil}</code></pre><p>Add 执行这样的操作，如果新的交易比老的交易的GasPrice值要高出一定的比值priceBump，那么会替换老的交易。</p><pre><code>// Add tries to insert a new transaction into the list, returning whether the// transaction was accepted, and if yes, any previous transaction it replaced.// Add 尝试插入一个新的交易，返回交易是否被接收，如果被接收，那么任意之前的交易会被替换。// If the new transaction is accepted into the list, the lists' cost and gas// thresholds are also potentially updated.// 如果新的交易被接收，那么总的cost和gas限制会被更新。func (l *txList) Add(tx *types.Transaction, priceBump uint64) (bool, *types.Transaction) {    // If there's an older better transaction, abort    // 如果存在老的交易。 而且新的交易的价格比老的高出一定的数量。那么替换。    old := l.txs.Get(tx.Nonce())    if old != nil {        threshold := new(big.Int).Div(new(big.Int).Mul(old.GasPrice(), big.NewInt(100+int64(priceBump))), big.NewInt(100))        if threshold.Cmp(tx.GasPrice()) &gt;= 0 {            return false, nil        }    }    // Otherwise overwrite the old transaction with the current one    l.txs.Put(tx)    if cost := tx.Cost(); l.costcap.Cmp(cost) &lt; 0 {        l.costcap = cost    }    if gas := tx.Gas(); l.gascap.Cmp(gas) &lt; 0 {        l.gascap = gas    }    return true, old}</code></pre><p>Forward 删除nonce小于某个值的所有交易。</p><pre><code>// Forward removes all transactions from the list with a nonce lower than the// provided threshold. Every removed transaction is returned for any post-removal// maintenance.func (l *txList) Forward(threshold uint64) types.Transactions {    return l.txs.Forward(threshold)}</code></pre><p>Filter,</p><pre><code>// Filter removes all transactions from the list with a cost or gas limit higher// than the provided thresholds. Every removed transaction is returned for any// post-removal maintenance. Strict-mode invalidated transactions are also// returned.// Filter 移除所有比提供的cost或者gasLimit的值更高的交易。 被移除的交易会返回以便进一步处理。 在严格模式下，所有无效的交易同样被返回。// // This method uses the cached costcap and gascap to quickly decide if there's even// a point in calculating all the costs or if the balance covers all. If the threshold// is lower than the costgas cap, the caps will be reset to a new high after removing// the newly invalidated transactions.// 这个方法会使用缓存的costcap和gascap以便快速的决定是否需要遍历所有的交易。如果限制小于缓存的costcap和gascap，那么在移除不合法的交易之后会更新costcap和gascap的值。func (l *txList) Filter(costLimit, gasLimit *big.Int) (types.Transactions, types.Transactions) {    // If all transactions are below the threshold, short circuit    // 如果所有的交易都小于限制，那么直接返回。    if l.costcap.Cmp(costLimit) &lt;= 0 &amp;&amp; l.gascap.Cmp(gasLimit) &lt;= 0 {        return nil, nil    }    l.costcap = new(big.Int).Set(costLimit) // Lower the caps to the thresholds    l.gascap = new(big.Int).Set(gasLimit)    // Filter out all the transactions above the account's funds    removed := l.txs.Filter(func(tx *types.Transaction) bool { return tx.Cost().Cmp(costLimit) &gt; 0 || tx.Gas().Cmp(gasLimit) &gt; 0 })    // If the list was strict, filter anything above the lowest nonce    var invalids types.Transactions    if l.strict &amp;&amp; len(removed) &gt; 0 {        // 所有的nonce大于 最小的被移除的nonce的交易都被任务是无效的。        // 在严格模式下，这种交易也被移除。        lowest := uint64(math.MaxUint64)        for _, tx := range removed {            if nonce := tx.Nonce(); lowest &gt; nonce {                lowest = nonce            }        }        invalids = l.txs.Filter(func(tx *types.Transaction) bool { return tx.Nonce() &gt; lowest })    }    return removed, invalids}</code></pre><p>Cap函数用来返回超过数量的交易。 如果交易的数量超过threshold,那么把之后的交易移除并返回。</p><pre><code>// Cap places a hard limit on the number of items, returning all transactions// exceeding that limit.func (l *txList) Cap(threshold int) types.Transactions {    return l.txs.Cap(threshold)}</code></pre><p>Remove,删除给定Nonce的交易，如果在严格模式下，还删除所有nonce大于给定Nonce的交易，并返回。</p><pre><code>// Remove deletes a transaction from the maintained list, returning whether the// transaction was found, and also returning any transaction invalidated due to// the deletion (strict mode only).func (l *txList) Remove(tx *types.Transaction) (bool, types.Transactions) {    // Remove the transaction from the set    nonce := tx.Nonce()    if removed := l.txs.Remove(nonce); !removed {        return false, nil    }    // In strict mode, filter out non-executable transactions    if l.strict {        return true, l.txs.Filter(func(tx *types.Transaction) bool { return tx.Nonce() &gt; nonce })    }    return true, nil}</code></pre><p>Ready， len, Empty, Flatten 直接调用了txSortedMap的对应方法。</p><pre><code>// Ready retrieves a sequentially increasing list of transactions starting at the// provided nonce that is ready for processing. The returned transactions will be// removed from the list.//// Note, all transactions with nonces lower than start will also be returned to// prevent getting into and invalid state. This is not something that should ever// happen but better to be self correcting than failing!func (l *txList) Ready(start uint64) types.Transactions {    return l.txs.Ready(start)}// Len returns the length of the transaction list.func (l *txList) Len() int {    return l.txs.Len()}// Empty returns whether the list of transactions is empty or not.func (l *txList) Empty() bool {    return l.Len() == 0}// Flatten creates a nonce-sorted slice of transactions based on the loosely// sorted internal representation. The result of the sorting is cached in case// it's requested again before any modifications are made to the contents.func (l *txList) Flatten() types.Transactions {    return l.txs.Flatten()}</code></pre><h2 id="priceHeap"><a href="#priceHeap" class="headerlink" title="priceHeap"></a>priceHeap</h2><p>priceHeap是一个最小堆， 按照价格的大小来建堆。</p><pre><code>// priceHeap is a heap.Interface implementation over transactions for retrieving// price-sorted transactions to discard when the pool fills up.type priceHeap []*types.Transactionfunc (h priceHeap) Len() int           { return len(h) }func (h priceHeap) Less(i, j int) bool { return h[i].GasPrice().Cmp(h[j].GasPrice()) &lt; 0 }func (h priceHeap) Swap(i, j int)      { h[i], h[j] = h[j], h[i] }func (h *priceHeap) Push(x interface{}) {    *h = append(*h, x.(*types.Transaction))}func (h *priceHeap) Pop() interface{} {    old := *h    n := len(old)    x := old[n-1]    *h = old[0 : n-1]    return x}</code></pre><h2 id="txPricedList"><a href="#txPricedList" class="headerlink" title="txPricedList"></a>txPricedList</h2><p>数据结构和构建,txPricedList 是基于价格排序的堆，允许按照价格递增的方式处理交易。</p><pre><code>// txPricedList is a price-sorted heap to allow operating on transactions pool// contents in a price-incrementing way.type txPricedList struct {    all    *map[common.Hash]*types.Transaction // Pointer to the map of all transactions 这是一个指针，指向了所有交易的map    items  *priceHeap                          // Heap of prices of all the stored transactions    stales int                                 // Number of stale price points to (re-heap trigger)}// newTxPricedList creates a new price-sorted transaction heap.func newTxPricedList(all *map[common.Hash]*types.Transaction) *txPricedList {    return &amp;txPricedList{        all:   all,        items: new(priceHeap),    }}</code></pre><p>Put</p><pre><code>// Put inserts a new transaction into the heap.func (l *txPricedList) Put(tx *types.Transaction) {    heap.Push(l.items, tx)}</code></pre><p>Removed</p><pre><code>// Removed notifies the prices transaction list that an old transaction dropped// from the pool. The list will just keep a counter of stale objects and update// the heap if a large enough ratio of transactions go stale.// Removed 用来通知txPricedList有一个老的交易被删除. txPricedList使用一个计数器来决定何时更新堆信息.func (l *txPricedList) Removed() {    // Bump the stale counter, but exit if still too low (&lt; 25%)    l.stales++    if l.stales &lt;= len(*l.items)/4 {        return    }    // Seems we've reached a critical number of stale transactions, reheap    reheap := make(priceHeap, 0, len(*l.all))    l.stales, l.items = 0, &amp;reheap    for _, tx := range *l.all {        *l.items = append(*l.items, tx)    }    heap.Init(l.items)}</code></pre><p>Cap 用来找到所有低于给定价格阈值的交易. 把他们从priceList删除并返回.</p><pre><code>// Cap finds all the transactions below the given price threshold, drops them// from the priced list and returs them for further removal from the entire pool.func (l *txPricedList) Cap(threshold *big.Int, local *accountSet) types.Transactions {    drop := make(types.Transactions, 0, 128) // Remote underpriced transactions to drop    save := make(types.Transactions, 0, 64)  // Local underpriced transactions to keep    for len(*l.items) &gt; 0 {        // Discard stale transactions if found during cleanup        tx := heap.Pop(l.items).(*types.Transaction)        if _, ok := (*l.all)[tx.Hash()]; !ok {            // 如果发现一个已经删除的,那么更新states计数器            l.stales--            continue        }        // Stop the discards if we've reached the threshold        if tx.GasPrice().Cmp(threshold) &gt;= 0 {            // 如果价格不小于阈值, 那么退出            save = append(save, tx)            break        }        // Non stale transaction found, discard unless local        if local.containsTx(tx) {  //本地的交易不会删除            save = append(save, tx)        } else {            drop = append(drop, tx)        }    }    for _, tx := range save {        heap.Push(l.items, tx)    }    return drop}</code></pre><p>Underpriced, 检查 tx是否比 当前txPricedList里面最便宜的交易还要便宜或者是同样便宜.</p><pre><code>// Underpriced checks whether a transaction is cheaper than (or as cheap as) the// lowest priced transaction currently being tracked.func (l *txPricedList) Underpriced(tx *types.Transaction, local *accountSet) bool {    // Local transactions cannot be underpriced    if local.containsTx(tx) {        return false    }    // Discard stale price points if found at the heap start    for len(*l.items) &gt; 0 {        head := []*types.Transaction(*l.items)[0]        if _, ok := (*l.all)[head.Hash()]; !ok {            l.stales--            heap.Pop(l.items)            continue        }        break    }    // Check if the transaction is underpriced or not    if len(*l.items) == 0 {        log.Error("Pricing query for empty pool") // This cannot happen, print to catch programming errors        return false    }    cheapest := []*types.Transaction(*l.items)[0]    return cheapest.GasPrice().Cmp(tx.GasPrice()) &gt;= 0}</code></pre><p>Discard,查找一定数量的最便宜的交易,把他们从当前的列表删除并返回.</p><pre><code>// Discard finds a number of most underpriced transactions, removes them from the// priced list and returns them for further removal from the entire pool.func (l *txPricedList) Discard(count int, local *accountSet) types.Transactions {    drop := make(types.Transactions, 0, count) // Remote underpriced transactions to drop    save := make(types.Transactions, 0, 64)    // Local underpriced transactions to keep    for len(*l.items) &gt; 0 &amp;&amp; count &gt; 0 {        // Discard stale transactions if found during cleanup        tx := heap.Pop(l.items).(*types.Transaction)        if _, ok := (*l.all)[tx.Hash()]; !ok {            l.stales--            continue        }        // Non stale transaction found, discard unless local        if local.containsTx(tx) {            save = append(save, tx)        } else {            drop = append(drop, tx)            count--        }    }    for _, tx := range save {        heap.Push(l.items, tx)    }    return drop}</code></pre><h2 id="accountSet"><a href="#accountSet" class="headerlink" title="accountSet"></a>accountSet</h2><p>accountSet 就是一个账号的集合和一个处理签名的对象.</p><pre><code>// accountSet is simply a set of addresses to check for existence, and a signer// capable of deriving addresses from transactions.type accountSet struct {    accounts map[common.Address]struct{}    signer   types.Signer}// newAccountSet creates a new address set with an associated signer for sender// derivations.func newAccountSet(signer types.Signer) *accountSet {    return &amp;accountSet{        accounts: make(map[common.Address]struct{}),        signer:   signer,    }}// contains checks if a given address is contained within the set.func (as *accountSet) contains(addr common.Address) bool {    _, exist := as.accounts[addr]    return exist}// containsTx checks if the sender of a given tx is within the set. If the sender// cannot be derived, this method returns false.// containsTx检查给定tx的发送者是否在集合内。 如果发件人无法被计算出，则此方法返回false。func (as *accountSet) containsTx(tx *types.Transaction) bool {    if addr, err := types.Sender(as.signer, tx); err == nil {        return as.contains(addr)    }    return false}// add inserts a new address into the set to track.func (as *accountSet) add(addr common.Address) {    as.accounts[addr] = struct{}{}}</code></pre><h2 id="txJournal"><a href="#txJournal" class="headerlink" title="txJournal"></a>txJournal</h2><p>txJournal是交易的一个循环日志，其目的是存储本地创建的事务，以允许未执行的事务在节点重新启动后继续运行。<br>结构</p><pre><code>// txJournal is a rotating log of transactions with the aim of storing locally// created transactions to allow non-executed ones to survive node restarts.type txJournal struct {    path   string         // Filesystem path to store the transactions at 用来存储交易的文件系统路径.    writer io.WriteCloser // Output stream to write new transactions into 用来写入新交易的输出流.}</code></pre><p>newTxJournal,用来创建新的交易日志.</p><pre><code>// newTxJournal creates a new transaction journal tofunc newTxJournal(path string) *txJournal {    return &amp;txJournal{        path: path,    }}</code></pre><p>load方法从磁盘解析交易,然后调用add回调方法.    </p><pre><code>// load parses a transaction journal dump from disk, loading its contents into// the specified pool.func (journal *txJournal) load(add func(*types.Transaction) error) error {    // Skip the parsing if the journal file doens't exist at all    if _, err := os.Stat(journal.path); os.IsNotExist(err) {        return nil    }    // Open the journal for loading any past transactions    input, err := os.Open(journal.path)    if err != nil {        return err    }    defer input.Close()    // Inject all transactions from the journal into the pool    stream := rlp.NewStream(input, 0)    total, dropped := 0, 0    var failure error    for {        // Parse the next transaction and terminate on error        tx := new(types.Transaction)        if err = stream.Decode(tx); err != nil {            if err != io.EOF {                failure = err            }            break        }        // Import the transaction and bump the appropriate progress counters        total++        if err = add(tx); err != nil {            log.Debug("Failed to add journaled transaction", "err", err)            dropped++            continue        }    }    log.Info("Loaded local transaction journal", "transactions", total, "dropped", dropped)    return failure}</code></pre><p>insert方法,调用rlp.Encode写入writer</p><pre><code>// insert adds the specified transaction to the local disk journal.func (journal *txJournal) insert(tx *types.Transaction) error {    if journal.writer == nil {        return errNoActiveJournal    }    if err := rlp.Encode(journal.writer, tx); err != nil {        return err    }    return nil}</code></pre><p>rotate方法基于当前的交易池重新生成交易,</p><pre><code>// rotate regenerates the transaction journal based on the current contents of// the transaction pool.func (journal *txJournal) rotate(all map[common.Address]types.Transactions) error {    // Close the current journal (if any is open)    if journal.writer != nil {        if err := journal.writer.Close(); err != nil {            return err        }        journal.writer = nil    }    // Generate a new journal with the contents of the current pool    replacement, err := os.OpenFile(journal.path+".new", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0755)    if err != nil {        return err    }    journaled := 0    for _, txs := range all {        for _, tx := range txs {            if err = rlp.Encode(replacement, tx); err != nil {                replacement.Close()                return err            }        }        journaled += len(txs)    }    replacement.Close()    // Replace the live journal with the newly generated one    if err = os.Rename(journal.path+".new", journal.path); err != nil {        return err    }    sink, err := os.OpenFile(journal.path, os.O_WRONLY|os.O_APPEND, 0755)    if err != nil {        return err    }    journal.writer = sink    log.Info("Regenerated local transaction journal", "transactions", journaled, "accounts", len(all))    return nil}</code></pre><p>close</p><pre><code>// close flushes the transaction journal contents to disk and closes the file.func (journal *txJournal) close() error {    var err error    if journal.writer != nil {        err = journal.writer.Close()        journal.writer = nil    }    return err}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-vm源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-vm%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-vm%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="contract-go"><a href="#contract-go" class="headerlink" title="contract.go"></a>contract.go</h2><p>contract 代表了以太坊 state database里面的一个合约。包含了合约代码，调用参数。</p><p>结构</p><pre><code>// ContractRef is a reference to the contract's backing objecttype ContractRef interface {    Address() common.Address}// AccountRef implements ContractRef.//// Account references are used during EVM initialisation and// it's primary use is to fetch addresses. Removing this object// proves difficult because of the cached jump destinations which// are fetched from the parent contract (i.e. the caller), which// is a ContractRef.type AccountRef common.Address// Address casts AccountRef to a Addressfunc (ar AccountRef) Address() common.Address { return (common.Address)(ar) }// Contract represents an ethereum contract in the state database. It contains// the the contract code, calling arguments. Contract implements ContractReftype Contract struct {    // CallerAddress is the result of the caller which initialised this    // contract. However when the "call method" is delegated this value    // needs to be initialised to that of the caller's caller.    // CallerAddress是初始化这个合约的人。 如果是delegate，这个值被设置为调用者的调用者。    CallerAddress common.Address    caller        ContractRef    self          ContractRef    jumpdests destinations // result of JUMPDEST analysis.  JUMPDEST指令的分析    Code     []byte  //代码    CodeHash common.Hash  //代码的HASH    CodeAddr *common.Address //代码地址    Input    []byte     // 入参    Gas   uint64          // 合约还有多少Gas    value *big.Int          Args []byte  //好像没有使用    DelegateCall bool  }</code></pre><p>构造</p><pre><code>// NewContract returns a new contract environment for the execution of EVM.func NewContract(caller ContractRef, object ContractRef, value *big.Int, gas uint64) *Contract {    c := &amp;Contract{CallerAddress: caller.Address(), caller: caller, self: object, Args: nil}    if parent, ok := caller.(*Contract); ok {        // Reuse JUMPDEST analysis from parent context if available.        // 如果 caller 是一个合约，说明是合约调用了我们。 jumpdests设置为caller的jumpdests        c.jumpdests = parent.jumpdests    } else {        c.jumpdests = make(destinations)    }    // Gas should be a pointer so it can safely be reduced through the run    // This pointer will be off the state transition    c.Gas = gas    // ensures a value is set    c.value = value    return c}</code></pre><p>AsDelegate将合约设置为委托调用并返回当前合同（用于链式调用）</p><pre><code>// AsDelegate sets the contract to be a delegate call and returns the current// contract (for chaining calls)func (c *Contract) AsDelegate() *Contract {    c.DelegateCall = true    // NOTE: caller must, at all times be a contract. It should never happen    // that caller is something other than a Contract.    parent := c.caller.(*Contract)    c.CallerAddress = parent.CallerAddress    c.value = parent.value    return c}    </code></pre><p>GetOp  用来获取下一跳指令</p><pre><code>// GetOp returns the n'th element in the contract's byte arrayfunc (c *Contract) GetOp(n uint64) OpCode {    return OpCode(c.GetByte(n))}// GetByte returns the n'th byte in the contract's byte arrayfunc (c *Contract) GetByte(n uint64) byte {    if n &lt; uint64(len(c.Code)) {        return c.Code[n]    }    return 0}// Caller returns the caller of the contract.//// Caller will recursively call caller when the contract is a delegate// call, including that of caller's caller.func (c *Contract) Caller() common.Address {    return c.CallerAddress}</code></pre><p>UseGas使用Gas。 </p><pre><code>// UseGas attempts the use gas and subtracts it and returns true on successfunc (c *Contract) UseGas(gas uint64) (ok bool) {    if c.Gas &lt; gas {        return false    }    c.Gas -= gas    return true}// Address returns the contracts addressfunc (c *Contract) Address() common.Address {    return c.self.Address()}// Value returns the contracts value (sent to it from it's caller)func (c *Contract) Value() *big.Int {    return c.value}</code></pre><p>SetCode    ，SetCallCode 设置代码。</p><pre><code>// SetCode sets the code to the contractfunc (self *Contract) SetCode(hash common.Hash, code []byte) {    self.Code = code    self.CodeHash = hash}// SetCallCode sets the code of the contract and address of the backing data// objectfunc (self *Contract) SetCallCode(addr *common.Address, hash common.Hash, code []byte) {    self.Code = code    self.CodeHash = hash    self.CodeAddr = addr}</code></pre><h2 id="evm-go"><a href="#evm-go" class="headerlink" title="evm.go"></a>evm.go</h2><p>结构</p><pre><code>// Context provides the EVM with auxiliary information. Once provided// it shouldn't be modified.// 上下文为EVM提供辅助信息。 一旦提供，不应该修改。type Context struct {    // CanTransfer returns whether the account contains    // sufficient ether to transfer the value    // CanTransfer 函数返回账户是否有足够的ether用来转账    CanTransfer CanTransferFunc    // Transfer transfers ether from one account to the other    // Transfer 用来从一个账户给另一个账户转账    Transfer TransferFunc    // GetHash returns the hash corresponding to n    // GetHash用来返回入参n对应的hash值    GetHash GetHashFunc    // Message information    // 用来提供Origin的信息 sender的地址    Origin   common.Address // Provides information for ORIGIN    // 用来提供GasPrice信息    GasPrice *big.Int       // Provides information for GASPRICE    // Block information    Coinbase    common.Address // Provides information for COINBASE    GasLimit    *big.Int       // Provides information for GASLIMIT    BlockNumber *big.Int       // Provides information for NUMBER    Time        *big.Int       // Provides information for TIME    Difficulty  *big.Int       // Provides information for DIFFICULTY}// EVM is the Ethereum Virtual Machine base object and provides// the necessary tools to run a contract on the given state with// the provided context. It should be noted that any error// generated through any of the calls should be considered a// revert-state-and-consume-all-gas operation, no checks on// specific errors should ever be performed. The interpreter makes// sure that any errors generated are to be considered faulty code.// EVM是以太坊虚拟机基础对象，并提供必要的工具，以使用提供的上下文运行给定状态的合约。// 应该指出的是，任何调用产生的任何错误都应该被认为是一种回滚修改状态和消耗所有GAS操作，// 不应该执行对具体错误的检查。 解释器确保生成的任何错误都被认为是错误的代码。// The EVM should never be reused and is not thread safe.type EVM struct {    // Context provides auxiliary blockchain related information    Context    // StateDB gives access to the underlying state    StateDB StateDB    // Depth is the current call stack    // 当前的调用堆栈    depth int    // chainConfig contains information about the current chain    // 包含了当前的区块链的信息    chainConfig *params.ChainConfig    // chain rules contains the chain rules for the current epoch    chainRules params.Rules    // virtual machine configuration options used to initialise the    // evm.    vmConfig Config    // global (to this context) ethereum virtual machine    // used throughout the execution of the tx.    interpreter *Interpreter    // abort is used to abort the EVM calling operations    // NOTE: must be set atomically    abort int32}</code></pre><p>构造函数</p><pre><code>// NewEVM retutrns a new EVM . The returned EVM is not thread safe and should// only ever be used *once*.func NewEVM(ctx Context, statedb StateDB, chainConfig *params.ChainConfig, vmConfig Config) *EVM {    evm := &amp;EVM{        Context:     ctx,        StateDB:     statedb,        vmConfig:    vmConfig,        chainConfig: chainConfig,        chainRules:  chainConfig.Rules(ctx.BlockNumber),    }    evm.interpreter = NewInterpreter(evm, vmConfig)    return evm}// Cancel cancels any running EVM operation. This may be called concurrently and// it's safe to be called multiple times.func (evm *EVM) Cancel() {    atomic.StoreInt32(&amp;evm.abort, 1)}</code></pre><p>合约创建 Create 会创建一个新的合约。</p><pre><code>// Create creates a new contract using code as deployment code.func (evm *EVM) Create(caller ContractRef, code []byte, gas uint64, value *big.Int) (ret []byte, contractAddr common.Address, leftOverGas uint64, err error) {    // Depth check execution. Fail if we're trying to execute above the    // limit.    if evm.depth &gt; int(params.CallCreateDepth) {        return nil, common.Address{}, gas, ErrDepth    }    if !evm.CanTransfer(evm.StateDB, caller.Address(), value) {        return nil, common.Address{}, gas, ErrInsufficientBalance    }    // Ensure there's no existing contract already at the designated address    // 确保特定的地址没有合约存在    nonce := evm.StateDB.GetNonce(caller.Address())    evm.StateDB.SetNonce(caller.Address(), nonce+1)    contractAddr = crypto.CreateAddress(caller.Address(), nonce)    contractHash := evm.StateDB.GetCodeHash(contractAddr)    if evm.StateDB.GetNonce(contractAddr) != 0 || (contractHash != (common.Hash{}) &amp;&amp; contractHash != emptyCodeHash) { //如果已经存在        return nil, common.Address{}, 0, ErrContractAddressCollision    }    // Create a new account on the state    snapshot := evm.StateDB.Snapshot()  //创建一个StateDB的快照，以便回滚    evm.StateDB.CreateAccount(contractAddr) //创建账户    if evm.ChainConfig().IsEIP158(evm.BlockNumber) {        evm.StateDB.SetNonce(contractAddr, 1) //设置nonce    }    evm.Transfer(evm.StateDB, caller.Address(), contractAddr, value)  //转账    // initialise a new contract and set the code that is to be used by the    // E The contract is a scoped evmironment for this execution context    // only.    contract := NewContract(caller, AccountRef(contractAddr), value, gas)    contract.SetCallCode(&amp;contractAddr, crypto.Keccak256Hash(code), code)    if evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 {        return nil, contractAddr, gas, nil    }    ret, err = run(evm, snapshot, contract, nil) //执行合约的初始化代码    // check whether the max code size has been exceeded    // 检查初始化生成的代码的长度不超过限制    maxCodeSizeExceeded := evm.ChainConfig().IsEIP158(evm.BlockNumber) &amp;&amp; len(ret) &gt; params.MaxCodeSize    // if the contract creation ran successfully and no errors were returned    // calculate the gas required to store the code. If the code could not    // be stored due to not enough gas set an error and let it be handled    // by the error checking condition below.    //如果合同创建成功并且没有错误返回，则计算存储代码所需的GAS。 如果由于没有足够的GAS而导致代码不能被存储设置错误，并通过下面的错误检查条件来处理。    if err == nil &amp;&amp; !maxCodeSizeExceeded {        createDataGas := uint64(len(ret)) * params.CreateDataGas        if contract.UseGas(createDataGas) {            evm.StateDB.SetCode(contractAddr, ret)        } else {            err = ErrCodeStoreOutOfGas        }    }    // When an error was returned by the EVM or when setting the creation code    // above we revert to the snapshot and consume any gas remaining. Additionally    // when we're in homestead this also counts for code storage gas errors.    // 当错误返回我们回滚修改，    if maxCodeSizeExceeded || (err != nil &amp;&amp; (evm.ChainConfig().IsHomestead(evm.BlockNumber) || err != ErrCodeStoreOutOfGas)) {        evm.StateDB.RevertToSnapshot(snapshot)        if err != errExecutionReverted {            contract.UseGas(contract.Gas)        }    }    // Assign err if contract code size exceeds the max while the err is still empty.    if maxCodeSizeExceeded &amp;&amp; err == nil {        err = errMaxCodeSizeExceeded    }    return ret, contractAddr, contract.Gas, err}</code></pre><p>Call方法, 无论我们转账或者是执行合约代码都会调用到这里， 同时合约里面的call指令也会执行到这里。</p><pre><code>// Call executes the contract associated with the addr with the given input as// parameters. It also handles any necessary value transfer required and takes// the necessary steps to create accounts and reverses the state in case of an// execution error or failed value transfer.// Call 执行与给定的input作为参数与addr相关联的合约。 // 它还处理所需的任何必要的转账操作，并采取必要的步骤来创建帐户// 并在任意错误的情况下回滚所做的操作。func (evm *EVM) Call(caller ContractRef, addr common.Address, input []byte, gas uint64, value *big.Int) (ret []byte, leftOverGas uint64, err error) {    if evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 {        return nil, gas, nil    }    // Fail if we're trying to execute above the call depth limit    //  调用深度最多1024    if evm.depth &gt; int(params.CallCreateDepth) {        return nil, gas, ErrDepth    }    // Fail if we're trying to transfer more than the available balance    // 查看我们的账户是否有足够的金钱。    if !evm.Context.CanTransfer(evm.StateDB, caller.Address(), value) {        return nil, gas, ErrInsufficientBalance    }    var (        to       = AccountRef(addr)        snapshot = evm.StateDB.Snapshot()    )    if !evm.StateDB.Exist(addr) { // 查看指定地址是否存在        // 如果地址不存在，查看是否是 native go的合约， native go的合约在        // contracts.go 文件里面        precompiles := PrecompiledContractsHomestead        if evm.ChainConfig().IsByzantium(evm.BlockNumber) {            precompiles = PrecompiledContractsByzantium        }        if precompiles[addr] == nil &amp;&amp; evm.ChainConfig().IsEIP158(evm.BlockNumber) &amp;&amp; value.Sign() == 0 {            // 如果不是指定的合约地址， 并且value的值为0那么返回正常，而且这次调用没有消耗Gas            return nil, gas, nil        }        // 负责在本地状态创建addr        evm.StateDB.CreateAccount(addr)    }    // 执行转账    evm.Transfer(evm.StateDB, caller.Address(), to.Address(), value)    // initialise a new contract and set the code that is to be used by the    // E The contract is a scoped environment for this execution context    // only.    contract := NewContract(caller, to, value, gas)    contract.SetCallCode(&amp;addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr))    ret, err = run(evm, snapshot, contract, input)    // When an error was returned by the EVM or when setting the creation code    // above we revert to the snapshot and consume any gas remaining. Additionally    // when we're in homestead this also counts for code storage gas errors.    if err != nil {        evm.StateDB.RevertToSnapshot(snapshot)        if err != errExecutionReverted {             // 如果是由revert指令触发的错误，因为ICO一般设置了人数限制或者资金限制            // 在大家抢购的时候很可能会触发这些限制条件，导致被抽走不少钱。这个时候            // 又不能设置比较低的GasPrice和GasLimit。因为要速度快。            // 那么不会使用剩下的全部Gas，而是只会使用代码执行的Gas            // 不然会被抽走 GasLimit *GasPrice的钱，那可不少。            contract.UseGas(contract.Gas)        }    }    return ret, contract.Gas, err}</code></pre><p>剩下的三个函数 CallCode, DelegateCall, 和 StaticCall，这三个函数不能由外部调用，只能由Opcode触发。</p><p>CallCode</p><pre><code>// CallCode differs from Call in the sense that it executes the given address'// code with the caller as context.// CallCode与Call不同的地方在于它使用caller的context来执行给定地址的代码。func (evm *EVM) CallCode(caller ContractRef, addr common.Address, input []byte, gas uint64, value *big.Int) (ret []byte, leftOverGas uint64, err error) {    if evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 {        return nil, gas, nil    }    // Fail if we're trying to execute above the call depth limit    if evm.depth &gt; int(params.CallCreateDepth) {        return nil, gas, ErrDepth    }    // Fail if we're trying to transfer more than the available balance    if !evm.CanTransfer(evm.StateDB, caller.Address(), value) {        return nil, gas, ErrInsufficientBalance    }    var (        snapshot = evm.StateDB.Snapshot()        to       = AccountRef(caller.Address())  //这里是最不同的地方 to的地址被修改为caller的地址了 而且没有转账的行为    )    // initialise a new contract and set the code that is to be used by the    // E The contract is a scoped evmironment for this execution context    // only.    contract := NewContract(caller, to, value, gas)    contract.SetCallCode(&amp;addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr))    ret, err = run(evm, snapshot, contract, input)    if err != nil {        evm.StateDB.RevertToSnapshot(snapshot)        if err != errExecutionReverted {            contract.UseGas(contract.Gas)        }    }    return ret, contract.Gas, err}</code></pre><p>DelegateCall</p><pre><code>// DelegateCall differs from CallCode in the sense that it executes the given address'// code with the caller as context and the caller is set to the caller of the caller.// DelegateCall 和 CallCode不同的地方在于 caller被设置为 caller的callerfunc (evm *EVM) DelegateCall(caller ContractRef, addr common.Address, input []byte, gas uint64) (ret []byte, leftOverGas uint64, err error) {    if evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 {        return nil, gas, nil    }    // Fail if we're trying to execute above the call depth limit    if evm.depth &gt; int(params.CallCreateDepth) {        return nil, gas, ErrDepth    }    var (        snapshot = evm.StateDB.Snapshot()        to       = AccountRef(caller.Address())     )    // Initialise a new contract and make initialise the delegate values    // 标识为AsDelete()    contract := NewContract(caller, to, nil, gas).AsDelegate()     contract.SetCallCode(&amp;addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr))    ret, err = run(evm, snapshot, contract, input)    if err != nil {        evm.StateDB.RevertToSnapshot(snapshot)        if err != errExecutionReverted {            contract.UseGas(contract.Gas)        }    }    return ret, contract.Gas, err}// StaticCall executes the contract associated with the addr with the given input// as parameters while disallowing any modifications to the state during the call.// Opcodes that attempt to perform such modifications will result in exceptions// instead of performing the modifications.// StaticCall不允许执行任何修改状态的操作，func (evm *EVM) StaticCall(caller ContractRef, addr common.Address, input []byte, gas uint64) (ret []byte, leftOverGas uint64, err error) {    if evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 {        return nil, gas, nil    }    // Fail if we're trying to execute above the call depth limit    if evm.depth &gt; int(params.CallCreateDepth) {        return nil, gas, ErrDepth    }    // Make sure the readonly is only set if we aren't in readonly yet    // this makes also sure that the readonly flag isn't removed for    // child calls.    if !evm.interpreter.readOnly {        evm.interpreter.readOnly = true        defer func() { evm.interpreter.readOnly = false }()    }    var (        to       = AccountRef(addr)        snapshot = evm.StateDB.Snapshot()    )    // Initialise a new contract and set the code that is to be used by the    // EVM. The contract is a scoped environment for this execution context    // only.    contract := NewContract(caller, to, new(big.Int), gas)    contract.SetCallCode(&amp;addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr))    // When an error was returned by the EVM or when setting the creation code    // above we revert to the snapshot and consume any gas remaining. Additionally    // when we're in Homestead this also counts for code storage gas errors.    ret, err = run(evm, snapshot, contract, input)    if err != nil {        evm.StateDB.RevertToSnapshot(snapshot)        if err != errExecutionReverted {            contract.UseGas(contract.Gas)        }    }    return ret, contract.Gas, err}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-eth-bloombits和filter源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-bloombits%E5%92%8Cfilter%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-bloombits%E5%92%8Cfilter%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="以太坊的布隆过滤器"><a href="#以太坊的布隆过滤器" class="headerlink" title="以太坊的布隆过滤器"></a>以太坊的布隆过滤器</h2><p>以太坊的区块头中包含了一个叫做logsBloom的区域。 这个区域存储了当前区块中所有的收据的日志的布隆过滤器，一共是2048个bit。也就是256个字节。</p><p>而我们的一个交易的收据包含了很多的日志记录。 每个日志记录包含了 合约的地址， 多个Topic。 而在我们的收据中也存在一个布隆过滤器，这个布隆过滤器记录了所有的日志记录的信息。</p><p><img src="/images/ethereum/source_analysis/bloom_1.png" alt="image"></p><p>如果我们看黄皮书里面对日志记录的形式化定义。</p><p>O代表我们的日志记录，Oa代表logger的地址，Oto,Ot1代表日志的Topics， Od代表时间。</p><p><img src="/images/ethereum/source_analysis/bloom_2.png" alt="image"></p><p>Oa是20个字节，Ot是32个字节，Od是很多字节</p><p><img src="/images/ethereum/source_analysis/bloom_3.png" alt="image"></p><p>我们定义了一个布隆过滤器函数M，用来把一个日志对象转换成256字节的hash</p><p><img src="/images/ethereum/source_analysis/bloom_4.png" alt="image"></p><p>M3:2045是一个特别的函数，用来设置2048个bit位中的三位为1。 具体的方法请参考下面的公式。</p><p><img src="/images/ethereum/source_analysis/bloom_5.png" alt="image"></p><p>对于任意的输入值，首先求他的KEC输出， 然后通过取KEC输出的 [0,1] [2,3],[4,5] 这几位的值 对2048取模， 得到三个值， 这三个值就是输出的2048中需要置位的下标。 也就是说对于任何一个输入，如果它对应的三个下标的值不都为1，那么它肯定不在这个区块中。 当如如果对应的三位都为1，也不能说明一定在这个区块中。 这就是布隆过滤器的特性。</p><p>收据中的布隆过滤器就是所有的日志的布隆过滤器输出的并集。</p><p>同时区块头中的logBloom，就是所有的收据的布隆过滤器的并集。</p><h2 id="ChainIndexer-和-BloomIndexer"><a href="#ChainIndexer-和-BloomIndexer" class="headerlink" title="ChainIndexer 和 BloomIndexer"></a>ChainIndexer 和 BloomIndexer</h2><p>最开始看到ChainIndexer，不是很明白是什么功能。 其实从名字中可以看到，是Chain的索引。 在 eth中我们有看到BloomIndexer,这个就是布隆过滤器的索引。</p><p>在我们的协议中提供了查找指定Log的功能。 </p><p>用户可以通过传递下面的参数来查找指定的Log,开始的区块号，结束的区块号， 根据合约 Addresses指定的地址过滤，根据指定的Topics来过滤。</p><pre><code>// FilterCriteria represents a request to create a new filter.type FilterCriteria struct {    FromBlock *big.Int    ToBlock   *big.Int    Addresses []common.Address    Topics    [][]common.Hash}</code></pre><p>如果开始和结束之间间隔很大，那么如果直接依次检索每个区块头的logBloom区域是比较低效的。 因为每个区块头都是分开存储的， 可能需要非常多的磁盘随机访问。</p><p>所以以太坊协议在本地维护了一套索引，用来加速这个过程。 </p><p>大致原理是。 每4096个区块称为一个Section，一个Section里面的logBloom会存储在一起。对于每个Section, 用一个二维数据，A[2048][4096]来存储。 第一维2048代表了bloom过滤器的长度2048个字节。 第二维4096代表了一个Section里面的所有区块，每一个位置按照顺序代表了其中的一个区块。</p><ul><li>A[0][0]=blockchain[section*4096+0].logBloom[0],</li><li>A[0][1]=blockchain[section*4096+1].logBloom[0],</li><li>A[0][4096]=blockchain[section*4096+1].logBloom[0],</li><li>A[1][0]=blockchain[section*4096+0].logBloom[1],</li><li>A[1][1024]=blockchain[section*4096+1024].logBloom[1],</li><li>A[2047][1]=blockchain[section*4096+1].logBloom[2047],</li></ul><p>如果Section填充完毕，那么会写成2048个KV。<br><img src="/images/ethereum/source_analysis/bloom_6.png" alt="image"></p><h2 id="bloombit-go-代码分析"><a href="#bloombit-go-代码分析" class="headerlink" title="bloombit.go 代码分析"></a>bloombit.go 代码分析</h2><p>这个代码相对不是很独立，如果单独看这个代码，有点摸不着头脑的感觉， 因为它只是实现了一些接口，具体的处理逻辑并不在这里，而是在core里面。 不过这里我先结合之前讲到的信息分析一下。 后续更详细的逻辑在分析core的代码的时候再详细分析。</p><p>服务线程startBloomHandlers,这个方法是为了响应具体的查询请求， 给定指定的Section和bit来从levelDB里面查询然后返回出去。 单独看这里有点摸不着头脑。 这个方法的调用比较复杂。 涉及到core里面的很多逻辑。 这里先不细说了。 直到有这个方法就行了。</p><pre><code>type Retrieval struct {    Bit      uint            //Bit的取值 0-2047 代表了想要获取哪一位的值    Sections []uint64        // 那些Section    Bitsets  [][]byte        // 返回值 查询出来的结果。}// startBloomHandlers starts a batch of goroutines to accept bloom bit database// retrievals from possibly a range of filters and serving the data to satisfy.func (eth *Ethereum) startBloomHandlers() {    for i := 0; i &lt; bloomServiceThreads; i++ {        go func() {            for {                select {                case &lt;-eth.shutdownChan:                    return                case request := &lt;-eth.bloomRequests: // request是一个通道                    task := &lt;-request //从通道里面获取一个task                    task.Bitsets = make([][]byte, len(task.Sections))                    for i, section := range task.Sections {                        head := core.GetCanonicalHash(eth.chainDb, (section+1)*params.BloomBitsBlocks-1)                        blob, err := bitutil.DecompressBytes(core.GetBloomBits(eth.chainDb, task.Bit, section, head), int(params.BloomBitsBlocks)/8)                        if err != nil {                            panic(err)                        }                        task.Bitsets[i] = blob                    }                    request &lt;- task //通过request通道返回结果                }            }        }()    }}</code></pre><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>BloomIndexer对象主要用户构建索引的过程，是core.ChainIndexer的一个接口实现，所以只实现了一些必须的接口。对于创建索引的逻辑还在core.ChainIndexer里面。</p><pre><code>// BloomIndexer implements a core.ChainIndexer, building up a rotated bloom bits index// for the Ethereum header bloom filters, permitting blazing fast filtering.type BloomIndexer struct {    size uint64 // section size to generate bloombits for    db  ethdb.Database       // database instance to write index data and metadata into    gen *bloombits.Generator // generator to rotate the bloom bits crating the bloom index    section uint64      // Section is the section number being processed currently  当前的section    head    common.Hash // Head is the hash of the last header processed}// NewBloomIndexer returns a chain indexer that generates bloom bits data for the// canonical chain for fast logs filtering.func NewBloomIndexer(db ethdb.Database, size uint64) *core.ChainIndexer {    backend := &amp;BloomIndexer{        db:   db,        size: size,    }    table := ethdb.NewTable(db, string(core.BloomBitsIndexPrefix))    return core.NewChainIndexer(db, table, backend, size, bloomConfirms, bloomThrottling, "bloombits")}</code></pre><p>Reset实现了ChainIndexerBackend的方法，启动一个新的section</p><pre><code>// Reset implements core.ChainIndexerBackend, starting a new bloombits index// section.func (b *BloomIndexer) Reset(section uint64) {    gen, err := bloombits.NewGenerator(uint(b.size))    if err != nil {        panic(err)    }    b.gen, b.section, b.head = gen, section, common.Hash{}}</code></pre><p>Process实现了ChainIndexerBackend， 增加一个新的区块头到index</p><pre><code>// Process implements core.ChainIndexerBackend, adding a new header's bloom into// the index.func (b *BloomIndexer) Process(header *types.Header) {    b.gen.AddBloom(uint(header.Number.Uint64()-b.section*b.size), header.Bloom)    b.head = header.Hash()}</code></pre><p>Commit方法实现了ChainIndexerBackend，持久化并写入数据库。</p><pre><code>// Commit implements core.ChainIndexerBackend, finalizing the bloom section and// writing it out into the database.func (b *BloomIndexer) Commit() error {    batch := b.db.NewBatch()    for i := 0; i &lt; types.BloomBitLength; i++ {        bits, err := b.gen.Bitset(uint(i))        if err != nil {            return err        }        core.WriteBloomBits(batch, uint(i), b.section, b.head, bitutil.CompressBytes(bits))    }    return batch.Write()}</code></pre><h2 id="filter-api-go-源码分析"><a href="#filter-api-go-源码分析" class="headerlink" title="filter/api.go 源码分析"></a>filter/api.go 源码分析</h2><p>eth/filter 包 包含了给用户提供过滤的功能，用户可以通过调用对交易或者区块进行过滤，然后持续的获取结果，如果5分钟没有操作，这个过滤器会被删除。</p><p>过滤器的结构。</p><pre><code>var (    deadline = 5 * time.Minute // consider a filter inactive if it has not been polled for within deadline)// filter is a helper struct that holds meta information over the filter type// and associated subscription in the event system.type filter struct {    typ      Type            // 过滤器的类型， 过滤什么类型的数据    deadline *time.Timer // filter is inactiv when deadline triggers 当计时器响起的时候，会触发定时器。    hashes   []common.Hash //过滤出来的hash结果    crit     FilterCriteria    //过滤条件    logs     []*types.Log    //过滤出来的Log信息    s        *Subscription // associated subscription in event system 事件系统中的订阅器。}</code></pre><p>构造方法</p><pre><code>// PublicFilterAPI offers support to create and manage filters. This will allow external clients to retrieve various// information related to the Ethereum protocol such als blocks, transactions and logs.// PublicFilterAPI用来创建和管理过滤器。 允许外部的客户端获取以太坊协议的一些信息，比如区块信息，交易信息和日志信息。type PublicFilterAPI struct {    backend   Backend    mux       *event.TypeMux    quit      chan struct{}    chainDb   ethdb.Database    events    *EventSystem    filtersMu sync.Mutex    filters   map[rpc.ID]*filter}// NewPublicFilterAPI returns a new PublicFilterAPI instance.func NewPublicFilterAPI(backend Backend, lightMode bool) *PublicFilterAPI {    api := &amp;PublicFilterAPI{        backend: backend,        mux:     backend.EventMux(),        chainDb: backend.ChainDb(),        events:  NewEventSystem(backend.EventMux(), backend, lightMode),        filters: make(map[rpc.ID]*filter),    }    go api.timeoutLoop()    return api}</code></pre><h3 id="超时检查"><a href="#超时检查" class="headerlink" title="超时检查"></a>超时检查</h3><pre><code>// timeoutLoop runs every 5 minutes and deletes filters that have not been recently used.// Tt is started when the api is created.// 每隔5分钟检查一下。 如果过期的过滤器，删除。func (api *PublicFilterAPI) timeoutLoop() {    ticker := time.NewTicker(5 * time.Minute)    for {        &lt;-ticker.C        api.filtersMu.Lock()        for id, f := range api.filters {            select {            case &lt;-f.deadline.C:                f.s.Unsubscribe()                delete(api.filters, id)            default:                continue            }        }        api.filtersMu.Unlock()    }}</code></pre><p>NewPendingTransactionFilter,用来创建一个PendingTransactionFilter。  这种方式是用来给那种无法创建长连接的通道使用的(比如HTTP), 如果对于可以建立长链接的通道(比如WebSocket)可以使用rpc提供的发送订阅模式来处理，就不用持续的轮询了</p><pre><code>// NewPendingTransactionFilter creates a filter that fetches pending transaction hashes// as transactions enter the pending state.//// It is part of the filter package because this filter can be used throug the// `eth_getFilterChanges` polling method that is also used for log filters.//// https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_newpendingtransactionfilterfunc (api *PublicFilterAPI) NewPendingTransactionFilter() rpc.ID {    var (        pendingTxs   = make(chan common.Hash)        // 在事件系统订阅这种消息        pendingTxSub = api.events.SubscribePendingTxEvents(pendingTxs)    )    api.filtersMu.Lock()    api.filters[pendingTxSub.ID] = &amp;filter{typ: PendingTransactionsSubscription, deadline: time.NewTimer(deadline), hashes: make([]common.Hash, 0), s: pendingTxSub}    api.filtersMu.Unlock()    go func() {        for {            select {            case ph := &lt;-pendingTxs: // 接收到pendingTxs，存储在过滤器的hashes容器里面。                api.filtersMu.Lock()                if f, found := api.filters[pendingTxSub.ID]; found {                    f.hashes = append(f.hashes, ph)                }                api.filtersMu.Unlock()            case &lt;-pendingTxSub.Err():                api.filtersMu.Lock()                delete(api.filters, pendingTxSub.ID)                api.filtersMu.Unlock()                return            }        }    }()    return pendingTxSub.ID}</code></pre><p>轮询: GetFilterChanges</p><pre><code>// GetFilterChanges returns the logs for the filter with the given id since// last time it was called. This can be used for polling.// GetFilterChanges 用来返回从上次调用到现在的所有的指定id的所有过滤信息。这个可以用来轮询。// For pending transaction and block filters the result is []common.Hash.// (pending)Log filters return []Log.// 对于pending transaction和block的过滤器，返回结果类型是[]common.Hash. 对于pending Log 过滤器，返回的是 []Log// https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_getfilterchangesfunc (api *PublicFilterAPI) GetFilterChanges(id rpc.ID) (interface{}, error) {    api.filtersMu.Lock()    defer api.filtersMu.Unlock()    if f, found := api.filters[id]; found {        if !f.deadline.Stop() { // 如果定时器已经触发，但是filter还没有移除，那么我们先接收定时器的值，然后重置定时器            // timer expired but filter is not yet removed in timeout loop            // receive timer value and reset timer            &lt;-f.deadline.C        }        f.deadline.Reset(deadline)        switch f.typ {        case PendingTransactionsSubscription, BlocksSubscription:            hashes := f.hashes            f.hashes = nil            return returnHashes(hashes), nil        case LogsSubscription:            logs := f.logs            f.logs = nil            return returnLogs(logs), nil        }    }    return []interface{}{}, fmt.Errorf("filter not found")}</code></pre><p>对于可以建立长连接的通道，可以直接使用rpc的发送订阅模式， 这样客户端就可以直接接收到过滤信息，不用调用轮询的方式了。 可以看到这种模式下面并没有添加到filters这个容器，也没有超时管理了。也就是说支持两种模式。</p><pre><code>// NewPendingTransactions creates a subscription that is triggered each time a transaction// enters the transaction pool and was signed from one of the transactions this nodes manages.func (api *PublicFilterAPI) NewPendingTransactions(ctx context.Context) (*rpc.Subscription, error) {    notifier, supported := rpc.NotifierFromContext(ctx)    if !supported {        return &amp;rpc.Subscription{}, rpc.ErrNotificationsUnsupported    }    rpcSub := notifier.CreateSubscription()    go func() {        txHashes := make(chan common.Hash)        pendingTxSub := api.events.SubscribePendingTxEvents(txHashes)        for {            select {            case h := &lt;-txHashes:                notifier.Notify(rpcSub.ID, h)            case &lt;-rpcSub.Err():                pendingTxSub.Unsubscribe()                return            case &lt;-notifier.Closed():                pendingTxSub.Unsubscribe()                return            }        }    }()    return rpcSub, nil}</code></pre><p>日志过滤功能，根据FilterCriteria指定的参数，来对日志进行过滤，开始区块，结束区块，地址和Topics，这里面引入了一个新的对象filter</p><pre><code>// FilterCriteria represents a request to create a new filter.type FilterCriteria struct {    FromBlock *big.Int    ToBlock   *big.Int    Addresses []common.Address    Topics    [][]common.Hash}    // GetLogs returns logs matching the given argument that are stored within the state.//// https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_getlogsfunc (api *PublicFilterAPI) GetLogs(ctx context.Context, crit FilterCriteria) ([]*types.Log, error) {    // Convert the RPC block numbers into internal representations    if crit.FromBlock == nil {        crit.FromBlock = big.NewInt(rpc.LatestBlockNumber.Int64())    }    if crit.ToBlock == nil {        crit.ToBlock = big.NewInt(rpc.LatestBlockNumber.Int64())    }    // Create and run the filter to get all the logs    // 创建了一个Filter对象 然后调用filter.Logs    filter := New(api.backend, crit.FromBlock.Int64(), crit.ToBlock.Int64(), crit.Addresses, crit.Topics)    logs, err := filter.Logs(ctx)    if err != nil {        return nil, err    }    return returnLogs(logs), err}</code></pre><h2 id="filter-go"><a href="#filter-go" class="headerlink" title="filter.go"></a>filter.go</h2><p>fiter.go里面定义了一个Filter对象。这个对象主要用来根据 区块的BloomIndexer和布隆过滤器等来执行日志的过滤功能。</p><h3 id="数据结构-1"><a href="#数据结构-1" class="headerlink" title="数据结构"></a>数据结构</h3><pre><code>// 后端， 这个后端其实是在core里面实现的。 布隆过滤器的主要算法在core里面实现了。type Backend interface {    ChainDb() ethdb.Database    EventMux() *event.TypeMux    HeaderByNumber(ctx context.Context, blockNr rpc.BlockNumber) (*types.Header, error)    GetReceipts(ctx context.Context, blockHash common.Hash) (types.Receipts, error)    SubscribeTxPreEvent(chan&lt;- core.TxPreEvent) event.Subscription    SubscribeChainEvent(ch chan&lt;- core.ChainEvent) event.Subscription    SubscribeRemovedLogsEvent(ch chan&lt;- core.RemovedLogsEvent) event.Subscription    SubscribeLogsEvent(ch chan&lt;- []*types.Log) event.Subscription    BloomStatus() (uint64, uint64)    ServiceFilter(ctx context.Context, session *bloombits.MatcherSession)}// Filter can be used to retrieve and filter logs.type Filter struct {    backend Backend                // 后端    db         ethdb.Database    // 数据库    begin, end int64            // 开始结束区块    addresses  []common.Address    // 筛选地址    topics     [][]common.Hash    // 筛选主题    matcher *bloombits.Matcher    // 布隆过滤器的匹配器}</code></pre><p>构造函数把address和topic都加入到filters容器。然后构建了一个bloombits.NewMatcher(size, filters)。这个函数在core里面实现， 暂时不会讲解。</p><pre><code>// New creates a new filter which uses a bloom filter on blocks to figure out whether// a particular block is interesting or not.func New(backend Backend, begin, end int64, addresses []common.Address, topics [][]common.Hash) *Filter {    // Flatten the address and topic filter clauses into a single bloombits filter    // system. Since the bloombits are not positional, nil topics are permitted,    // which get flattened into a nil byte slice.    var filters [][][]byte    if len(addresses) &gt; 0 {        filter := make([][]byte, len(addresses))        for i, address := range addresses {            filter[i] = address.Bytes()        }        filters = append(filters, filter)    }    for _, topicList := range topics {        filter := make([][]byte, len(topicList))        for i, topic := range topicList {            filter[i] = topic.Bytes()        }        filters = append(filters, filter)    }    // Assemble and return the filter    size, _ := backend.BloomStatus()    return &amp;Filter{        backend:   backend,        begin:     begin,        end:       end,        addresses: addresses,        topics:    topics,        db:        backend.ChainDb(),        matcher:   bloombits.NewMatcher(size, filters),    }}</code></pre><p>Logs 执行过滤</p><pre><code>// Logs searches the blockchain for matching log entries, returning all from the// first block that contains matches, updating the start of the filter accordingly.func (f *Filter) Logs(ctx context.Context) ([]*types.Log, error) {    // Figure out the limits of the filter range    header, _ := f.backend.HeaderByNumber(ctx, rpc.LatestBlockNumber)    if header == nil {        return nil, nil    }    head := header.Number.Uint64()    if f.begin == -1 {        f.begin = int64(head)    }    end := uint64(f.end)    if f.end == -1 {        end = head    }    // Gather all indexed logs, and finish with non indexed ones    var (        logs []*types.Log        err  error    )    size, sections := f.backend.BloomStatus()    // indexed 是指创建了索引的区块的最大值。 如果过滤的范围落在了创建了索引的部分。    // 那么执行索引搜索。    if indexed := sections * size; indexed &gt; uint64(f.begin) {        if indexed &gt; end {            logs, err = f.indexedLogs(ctx, end)        } else {            logs, err = f.indexedLogs(ctx, indexed-1)        }        if err != nil {            return logs, err        }    }    // 对于剩下的部分执行非索引的搜索。    rest, err := f.unindexedLogs(ctx, end)    logs = append(logs, rest...)    return logs, err}</code></pre><p>索引搜索</p><pre><code>// indexedLogs returns the logs matching the filter criteria based on the bloom// bits indexed available locally or via the network.func (f *Filter) indexedLogs(ctx context.Context, end uint64) ([]*types.Log, error) {    // Create a matcher session and request servicing from the backend    matches := make(chan uint64, 64)    // 启动matcher    session, err := f.matcher.Start(uint64(f.begin), end, matches)    if err != nil {        return nil, err    }    defer session.Close(time.Second)    // 进行过滤服务。 这些都在core里面。后续分析core的代码会进行分析。        f.backend.ServiceFilter(ctx, session)    // Iterate over the matches until exhausted or context closed    var logs []*types.Log    for {        select {        case number, ok := &lt;-matches:            // Abort if all matches have been fulfilled            if !ok {  // 没有接收到值并且channel已经被关闭                f.begin = int64(end) + 1  //更新begin。以便于下面的非索引搜索                return logs, nil            }            // Retrieve the suggested block and pull any truly matching logs            header, err := f.backend.HeaderByNumber(ctx, rpc.BlockNumber(number))            if header == nil || err != nil {                return logs, err            }            found, err := f.checkMatches(ctx, header) //查找匹配的值            if err != nil {                return logs, err            }            logs = append(logs, found...)        case &lt;-ctx.Done():            return logs, ctx.Err()        }    }}</code></pre><p>checkMatches,拿到所有的收据，并从收据中拿到所有的日志。 执行filterLogs方法。</p><pre><code>// checkMatches checks if the receipts belonging to the given header contain any log events that// match the filter criteria. This function is called when the bloom filter signals a potential match.func (f *Filter) checkMatches(ctx context.Context, header *types.Header) (logs []*types.Log, err error) {    // Get the logs of the block    receipts, err := f.backend.GetReceipts(ctx, header.Hash())    if err != nil {        return nil, err    }    var unfiltered []*types.Log    for _, receipt := range receipts {        unfiltered = append(unfiltered, ([]*types.Log)(receipt.Logs)...)    }    logs = filterLogs(unfiltered, nil, nil, f.addresses, f.topics)    if len(logs) &gt; 0 {        return logs, nil    }    return nil, nil}</code></pre><p>filterLogs,这个方法从给定的logs里面找到能够匹配上的。并返回。</p><pre><code>// filterLogs creates a slice of logs matching the given criteria.func filterLogs(logs []*types.Log, fromBlock, toBlock *big.Int, addresses []common.Address, topics [][]common.Hash) []*types.Log {    var ret []*types.LogLogs:    for _, log := range logs {        if fromBlock != nil &amp;&amp; fromBlock.Int64() &gt;= 0 &amp;&amp; fromBlock.Uint64() &gt; log.BlockNumber {            continue        }        if toBlock != nil &amp;&amp; toBlock.Int64() &gt;= 0 &amp;&amp; toBlock.Uint64() &lt; log.BlockNumber {            continue        }        if len(addresses) &gt; 0 &amp;&amp; !includes(addresses, log.Address) {            continue        }        // If the to filtered topics is greater than the amount of topics in logs, skip.        if len(topics) &gt; len(log.Topics) {            continue Logs        }        for i, topics := range topics {            match := len(topics) == 0 // empty rule set == wildcard            for _, topic := range topics {                if log.Topics[i] == topic {                    match = true                    break                }            }            if !match {                continue Logs            }        }        ret = append(ret, log)    }    return ret}</code></pre><p>unindexedLogs,非索引查询，循环遍历所有的区块。 首先用区块里面的header.Bloom来看是否有可能存在，如果有可能存在， 再使用checkMatches来检索所有的匹配。</p><pre><code>// indexedLogs returns the logs matching the filter criteria based on raw block// iteration and bloom matching.func (f *Filter) unindexedLogs(ctx context.Context, end uint64) ([]*types.Log, error) {    var logs []*types.Log    for ; f.begin &lt;= int64(end); f.begin++ {        header, err := f.backend.HeaderByNumber(ctx, rpc.BlockNumber(f.begin))        if header == nil || err != nil {            return logs, err        }        if bloomFilter(header.Bloom, f.addresses, f.topics) {            found, err := f.checkMatches(ctx, header)            if err != nil {                return logs, err            }            logs = append(logs, found...)        }    }    return logs, nil}</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>filter源码包主要实现了两个功能， </p><ul><li>提供了 发布订阅模式的filter RPC。用来给rpc客户端提供实时的交易，区块，日志等的过滤</li><li>提供了 基于bloomIndexer的日志过滤模式，这种模式下，可以快速的对大量区块执行布隆过滤操作。 还提供了历史的日志的过滤操作。 </li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-eth-downloader-queue.go源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader-queue.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader-queue.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>queue给downloader提供了调度功能和限流的功能。 通过调用Schedule/ScheduleSkeleton来申请对任务进行调度，然后调用ReserveXXX方法来领取调度完成的任务，并在downloader里面的线程来执行，调用DeliverXXX方法把下载完的数据给queue。 最后通过WaitResults来获取已经完成的任务。中间还有一些对任务的额外控制，ExpireXXX用来控制任务是否超时， CancelXXX用来取消任务。</p><h2 id="Schedule方法"><a href="#Schedule方法" class="headerlink" title="Schedule方法"></a>Schedule方法</h2><p>Schedule调用申请对一些区块头进行下载调度。可以看到做了一些合法性检查之后，把任务插入了blockTaskPool，receiptTaskPool，receiptTaskQueue，receiptTaskPool。<br>TaskPool是Map，用来记录header的hash是否存在。 TaskQueue是优先级队列，优先级是区块的高度的负数， 这样区块高度越小的优先级越高，就实现了首先调度小的任务的功能。</p><pre><code>// Schedule adds a set of headers for the download queue for scheduling, returning// the new headers encountered.// from表示headers里面第一个元素的区块高度。 返回值返回了所有被接收的headerfunc (q *queue) Schedule(headers []*types.Header, from uint64) []*types.Header {    q.lock.Lock()    defer q.lock.Unlock()    // Insert all the headers prioritised by the contained block number    inserts := make([]*types.Header, 0, len(headers))    for _, header := range headers {        // Make sure chain order is honoured and preserved throughout        hash := header.Hash()        if header.Number == nil || header.Number.Uint64() != from {            log.Warn("Header broke chain ordering", "number", header.Number, "hash", hash, "expected", from)            break        }        //headerHead存储了最后一个插入的区块头， 检查当前区块是否正确的链接。        if q.headerHead != (common.Hash{}) &amp;&amp; q.headerHead != header.ParentHash {            log.Warn("Header broke chain ancestry", "number", header.Number, "hash", hash)            break        }        // Make sure no duplicate requests are executed        // 检查重复，这里直接continue了，那不是from对不上了。        if _, ok := q.blockTaskPool[hash]; ok {            log.Warn("Header  already scheduled for block fetch", "number", header.Number, "hash", hash)            continue        }        if _, ok := q.receiptTaskPool[hash]; ok {            log.Warn("Header already scheduled for receipt fetch", "number", header.Number, "hash", hash)            continue        }        // Queue the header for content retrieval        q.blockTaskPool[hash] = header        q.blockTaskQueue.Push(header, -float32(header.Number.Uint64()))        if q.mode == FastSync &amp;&amp; header.Number.Uint64() &lt;= q.fastSyncPivot {            // Fast phase of the fast sync, retrieve receipts too            // 如果是快速同步模式，而且区块高度也小于pivot point. 那么还要获取receipt            q.receiptTaskPool[hash] = header            q.receiptTaskQueue.Push(header, -float32(header.Number.Uint64()))        }        inserts = append(inserts, header)        q.headerHead = hash        from++    }    return inserts}</code></pre><h2 id="ReserveXXX"><a href="#ReserveXXX" class="headerlink" title="ReserveXXX"></a>ReserveXXX</h2><p>ReserveXXX方法用来从queue里面领取一些任务来执行。downloader里面的goroutine会调用这个方法来领取一些任务来执行。 这个方法直接调用了reserveHeaders方法。 所有的ReserveXXX方法都会调用reserveHeaders方法，除了传入的参数有一些区别。</p><pre><code>// ReserveBodies reserves a set of body fetches for the given peer, skipping any// previously failed downloads. Beside the next batch of needed fetches, it also// returns a flag whether empty blocks were queued requiring processing.func (q *queue) ReserveBodies(p *peerConnection, count int) (*fetchRequest, bool, error) {    isNoop := func(header *types.Header) bool {        return header.TxHash == types.EmptyRootHash &amp;&amp; header.UncleHash == types.EmptyUncleHash    }    q.lock.Lock()    defer q.lock.Unlock()    return q.reserveHeaders(p, count, q.blockTaskPool, q.blockTaskQueue, q.blockPendPool, q.blockDonePool, isNoop)}</code></pre><p>reserveHeaders</p><pre><code>// reserveHeaders reserves a set of data download operations for a given peer,// skipping any previously failed ones. This method is a generic version used// by the individual special reservation functions.// reserveHeaders为指定的peer保留一些下载操作，跳过之前的任意错误。 这个方法单独被指定的保留方法调用。// Note, this method expects the queue lock to be already held for writing. The// reason the lock is not obtained in here is because the parameters already need// to access the queue, so they already need a lock anyway.// 这个方法调用的时候，假设已经获取到锁，这个方法里面没有锁的原因是参数已经传入到函数里面了，所以调用的时候就需要获取锁。func (q *queue) reserveHeaders(p *peerConnection, count int, taskPool map[common.Hash]*types.Header, taskQueue *prque.Prque,    pendPool map[string]*fetchRequest, donePool map[common.Hash]struct{}, isNoop func(*types.Header) bool) (*fetchRequest, bool, error) {    // Short circuit if the pool has been depleted, or if the peer's already    // downloading something (sanity check not to corrupt state)    if taskQueue.Empty() {        return nil, false, nil    }    // 如果这个peer还有下载任务没有完成。    if _, ok := pendPool[p.id]; ok {        return nil, false, nil    }    // Calculate an upper limit on the items we might fetch (i.e. throttling)    // 计算我们需要获取的上限。    space := len(q.resultCache) - len(donePool)    // 还需要减去正在下载的数量。    for _, request := range pendPool {        space -= len(request.Headers)    }    // Retrieve a batch of tasks, skipping previously failed ones    send := make([]*types.Header, 0, count)    skip := make([]*types.Header, 0)    progress := false    for proc := 0; proc &lt; space &amp;&amp; len(send) &lt; count &amp;&amp; !taskQueue.Empty(); proc++ {        header := taskQueue.PopItem().(*types.Header)        // If we're the first to request this task, initialise the result container        index := int(header.Number.Int64() - int64(q.resultOffset))        // index 是结果应该存储在resultCache的哪一部分。        if index &gt;= len(q.resultCache) || index &lt; 0 {            common.Report("index allocation went beyond available resultCache space")            return nil, false, errInvalidChain        }        if q.resultCache[index] == nil { // 第一次调度 有可能多次调度。 那这里可能就是非空的。            components := 1            if q.mode == FastSync &amp;&amp; header.Number.Uint64() &lt;= q.fastSyncPivot {                // 如果是快速同步，那么需要下载的组件还有 收据receipt                components = 2            }            q.resultCache[index] = &amp;fetchResult{                Pending: components,                Header:  header,            }        }        // If this fetch task is a noop, skip this fetch operation        if isNoop(header) {            // 如果header的区块中没有包含交易，那么不需要获取区块头            donePool[header.Hash()] = struct{}{}            delete(taskPool, header.Hash())            space, proc = space-1, proc-1            q.resultCache[index].Pending--            progress = true            continue        }        // Otherwise unless the peer is known not to have the data, add to the retrieve list        // Lacks代表节点之前明确表示过没有这个hash的数据。        if p.Lacks(header.Hash()) {            skip = append(skip, header)        } else {            send = append(send, header)        }    }    // Merge all the skipped headers back    for _, header := range skip {        taskQueue.Push(header, -float32(header.Number.Uint64()))    }    if progress {        // Wake WaitResults, resultCache was modified        // 通知WaitResults， resultCache有改变        q.active.Signal()    }    // Assemble and return the block download request    if len(send) == 0 {        return nil, progress, nil    }    request := &amp;fetchRequest{        Peer:    p,        Headers: send,        Time:    time.Now(),    }    pendPool[p.id] = request    return request, progress, nil}</code></pre><p>ReserveReceipts 可以看到和ReserveBodys差不多。不过是队列换了而已。</p><pre><code>// ReserveReceipts reserves a set of receipt fetches for the given peer, skipping// any previously failed downloads. Beside the next batch of needed fetches, it// also returns a flag whether empty receipts were queued requiring importing.func (q *queue) ReserveReceipts(p *peerConnection, count int) (*fetchRequest, bool, error) {    isNoop := func(header *types.Header) bool {        return header.ReceiptHash == types.EmptyRootHash    }    q.lock.Lock()    defer q.lock.Unlock()    return q.reserveHeaders(p, count, q.receiptTaskPool, q.receiptTaskQueue, q.receiptPendPool, q.receiptDonePool, isNoop)}</code></pre><h2 id="DeliverXXX"><a href="#DeliverXXX" class="headerlink" title="DeliverXXX"></a>DeliverXXX</h2><p>Deliver方法在数据下载完之后会被调用。</p><pre><code>// DeliverBodies injects a block body retrieval response into the results queue.// The method returns the number of blocks bodies accepted from the delivery and// also wakes any threads waiting for data delivery.// DeliverBodies把一个 请求区块体的返回值插入到results队列// 这个方法返回被delivery的区块体数量，同时会唤醒等待数据的线程func (q *queue) DeliverBodies(id string, txLists [][]*types.Transaction, uncleLists [][]*types.Header) (int, error) {    q.lock.Lock()    defer q.lock.Unlock()    reconstruct := func(header *types.Header, index int, result *fetchResult) error {        if types.DeriveSha(types.Transactions(txLists[index])) != header.TxHash || types.CalcUncleHash(uncleLists[index]) != header.UncleHash {            return errInvalidBody        }        result.Transactions = txLists[index]        result.Uncles = uncleLists[index]        return nil    }    return q.deliver(id, q.blockTaskPool, q.blockTaskQueue, q.blockPendPool, q.blockDonePool, bodyReqTimer, len(txLists), reconstruct)}</code></pre><p>deliver方法</p><pre><code>func (q *queue) deliver(id string, taskPool map[common.Hash]*types.Header, taskQueue *prque.Prque,    pendPool map[string]*fetchRequest, donePool map[common.Hash]struct{}, reqTimer metrics.Timer,    results int, reconstruct func(header *types.Header, index int, result *fetchResult) error) (int, error) {    // Short circuit if the data was never requested    // 检查 数据是否从来没有请求过。    request := pendPool[id]    if request == nil {        return 0, errNoFetchesPending    }    reqTimer.UpdateSince(request.Time)    delete(pendPool, id)    // If no data items were retrieved, mark them as unavailable for the origin peer    if results == 0 {        //如果结果为空。 那么标识这个peer没有这些数据。        for _, header := range request.Headers {            request.Peer.MarkLacking(header.Hash())        }    }    // Assemble each of the results with their headers and retrieved data parts    var (        accepted int        failure  error        useful   bool    )    for i, header := range request.Headers {        // Short circuit assembly if no more fetch results are found        if i &gt;= results {            break        }        // Reconstruct the next result if contents match up        index := int(header.Number.Int64() - int64(q.resultOffset))        if index &gt;= len(q.resultCache) || index &lt; 0 || q.resultCache[index] == nil {            failure = errInvalidChain            break        }        // 调用传入的函数对数据进行构建        if err := reconstruct(header, i, q.resultCache[index]); err != nil {            failure = err            break        }        donePool[header.Hash()] = struct{}{}        q.resultCache[index].Pending--        useful = true        accepted++        // Clean up a successful fetch        // 从taskPool删除。加入donePool        request.Headers[i] = nil        delete(taskPool, header.Hash())    }    // Return all failed or missing fetches to the queue    // 所有没有成功的请求加入taskQueue    for _, header := range request.Headers {        if header != nil {            taskQueue.Push(header, -float32(header.Number.Uint64()))        }    }    // Wake up WaitResults    // 如果结果有变更，通知WaitResults线程启动。    if accepted &gt; 0 {        q.active.Signal()    }    // If none of the data was good, it's a stale delivery    switch {    case failure == nil || failure == errInvalidChain:        return accepted, failure    case useful:        return accepted, fmt.Errorf("partial failure: %v", failure)    default:        return accepted, errStaleDelivery    }}</code></pre><h2 id="ExpireXXX-and-CancelXXX"><a href="#ExpireXXX-and-CancelXXX" class="headerlink" title="ExpireXXX and CancelXXX"></a>ExpireXXX and CancelXXX</h2><h3 id="ExpireXXX"><a href="#ExpireXXX" class="headerlink" title="ExpireXXX"></a>ExpireXXX</h3><p>ExpireBodies函数获取了锁，然后直接调用了expire函数。 </p><pre><code>// ExpireBodies checks for in flight block body requests that exceeded a timeout// allowance, canceling them and returning the responsible peers for penalisation.func (q *queue) ExpireBodies(timeout time.Duration) map[string]int {    q.lock.Lock()    defer q.lock.Unlock()    return q.expire(timeout, q.blockPendPool, q.blockTaskQueue, bodyTimeoutMeter)}</code></pre><p>expire函数，</p><pre><code>// expire is the generic check that move expired tasks from a pending pool back// into a task pool, returning all entities caught with expired tasks.// expire是通用检查，将过期任务从待处理池移回任务池，返回所有捕获已到期任务的实体。func (q *queue) expire(timeout time.Duration, pendPool map[string]*fetchRequest, taskQueue *prque.Prque, timeoutMeter metrics.Meter) map[string]int {    // Iterate over the expired requests and return each to the queue    expiries := make(map[string]int)    for id, request := range pendPool {        if time.Since(request.Time) &gt; timeout {            // Update the metrics with the timeout            timeoutMeter.Mark(1)            // Return any non satisfied requests to the pool            if request.From &gt; 0 {                taskQueue.Push(request.From, -float32(request.From))            }            for hash, index := range request.Hashes {                taskQueue.Push(hash, float32(index))            }            for _, header := range request.Headers {                taskQueue.Push(header, -float32(header.Number.Uint64()))            }            // Add the peer to the expiry report along the the number of failed requests            expirations := len(request.Hashes)            if expirations &lt; len(request.Headers) {                expirations = len(request.Headers)            }            expiries[id] = expirations        }    }    // Remove the expired requests from the pending pool    for id := range expiries {        delete(pendPool, id)    }    return expiries}</code></pre><h3 id="CancelXXX"><a href="#CancelXXX" class="headerlink" title="CancelXXX"></a>CancelXXX</h3><p>Cancle函数取消已经分配的任务， 把任务重新加入到任务池。</p><pre><code>// CancelBodies aborts a body fetch request, returning all pending headers to the// task queue.func (q *queue) CancelBodies(request *fetchRequest) {    q.cancel(request, q.blockTaskQueue, q.blockPendPool)}// Cancel aborts a fetch request, returning all pending hashes to the task queue.func (q *queue) cancel(request *fetchRequest, taskQueue *prque.Prque, pendPool map[string]*fetchRequest) {    q.lock.Lock()    defer q.lock.Unlock()    if request.From &gt; 0 {        taskQueue.Push(request.From, -float32(request.From))    }    for hash, index := range request.Hashes {        taskQueue.Push(hash, float32(index))    }    for _, header := range request.Headers {        taskQueue.Push(header, -float32(header.Number.Uint64()))    }    delete(pendPool, request.Peer.id)}</code></pre><h2 id="ScheduleSkeleton"><a href="#ScheduleSkeleton" class="headerlink" title="ScheduleSkeleton"></a>ScheduleSkeleton</h2><p>Schedule方法传入的是已经fetch好的header。Schedule(headers []*types.Header, from uint64)。而ScheduleSkeleton函数的参数是一个骨架， 然后请求对骨架进行填充。所谓的骨架是指我首先每隔192个区块请求一个区块头，然后把返回的header传入ScheduleSkeleton。 在Schedule函数中只需要queue调度区块体和回执的下载，而在ScheduleSkeleton函数中，还需要调度那些缺失的区块头的下载。</p><pre><code>// ScheduleSkeleton adds a batch of header retrieval tasks to the queue to fill// up an already retrieved header skeleton.func (q *queue) ScheduleSkeleton(from uint64, skeleton []*types.Header) {    q.lock.Lock()    defer q.lock.Unlock()    // No skeleton retrieval can be in progress, fail hard if so (huge implementation bug)    if q.headerResults != nil {        panic("skeleton assembly already in progress")    }    // Shedule all the header retrieval tasks for the skeleton assembly    // 因为这个方法在skeleton为false的时候不会调用。 所以一些初始化工作放在这里执行。    q.headerTaskPool = make(map[uint64]*types.Header)    q.headerTaskQueue = prque.New()    q.headerPeerMiss = make(map[string]map[uint64]struct{}) // Reset availability to correct invalid chains    q.headerResults = make([]*types.Header, len(skeleton)*MaxHeaderFetch)    q.headerProced = 0    q.headerOffset = from    q.headerContCh = make(chan bool, 1)    for i, header := range skeleton {        index := from + uint64(i*MaxHeaderFetch)        // 每隔MaxHeaderFetch这么远有一个header        q.headerTaskPool[index] = header        q.headerTaskQueue.Push(index, -float32(index))    }}</code></pre><h3 id="ReserveHeaders"><a href="#ReserveHeaders" class="headerlink" title="ReserveHeaders"></a>ReserveHeaders</h3><p>这个方法只skeleton的模式下才会被调用。 用来给peer保留fetch 区块头的任务。</p><pre><code>// ReserveHeaders reserves a set of headers for the given peer, skipping any// previously failed batches.func (q *queue) ReserveHeaders(p *peerConnection, count int) *fetchRequest {    q.lock.Lock()    defer q.lock.Unlock()    // Short circuit if the peer's already downloading something (sanity check to    // not corrupt state)    if _, ok := q.headerPendPool[p.id]; ok {        return nil    }    // Retrieve a batch of hashes, skipping previously failed ones    // 从队列中获取一个，跳过之前失败过的节点。    send, skip := uint64(0), []uint64{}    for send == 0 &amp;&amp; !q.headerTaskQueue.Empty() {        from, _ := q.headerTaskQueue.Pop()        if q.headerPeerMiss[p.id] != nil {            if _, ok := q.headerPeerMiss[p.id][from.(uint64)]; ok {                skip = append(skip, from.(uint64))                continue            }        }        send = from.(uint64)    }    // Merge all the skipped batches back    for _, from := range skip {        q.headerTaskQueue.Push(from, -float32(from))    }    // Assemble and return the block download request    if send == 0 {        return nil    }    request := &amp;fetchRequest{        Peer: p,        From: send,        Time: time.Now(),    }    q.headerPendPool[p.id] = request    return request}</code></pre><h3 id="DeliverHeaders"><a href="#DeliverHeaders" class="headerlink" title="DeliverHeaders"></a>DeliverHeaders</h3><pre><code>// DeliverHeaders injects a header retrieval response into the header results// cache. This method either accepts all headers it received, or none of them// if they do not map correctly to the skeleton.// 这个方法对于所有的区块头，要么全部接收，要么全部拒绝(如果不能映射到一个skeleton上面)// If the headers are accepted, the method makes an attempt to deliver the set// of ready headers to the processor to keep the pipeline full. However it will// not block to prevent stalling other pending deliveries.// 如果区块头被接收，这个方法会试图把他们投递到headerProcCh管道上面。 不过这个方法不会阻塞式的投递。而是尝试投递，如果不能投递就返回。func (q *queue) DeliverHeaders(id string, headers []*types.Header, headerProcCh chan []*types.Header) (int, error) {    q.lock.Lock()    defer q.lock.Unlock()    // Short circuit if the data was never requested    request := q.headerPendPool[id]    if request == nil {        return 0, errNoFetchesPending    }    headerReqTimer.UpdateSince(request.Time)    delete(q.headerPendPool, id)    // Ensure headers can be mapped onto the skeleton chain    target := q.headerTaskPool[request.From].Hash()    accepted := len(headers) == MaxHeaderFetch    if accepted { //首先长度需要匹配， 然后检查区块号和最后一块区块的Hash值是否能够对应上。        if headers[0].Number.Uint64() != request.From {            log.Trace("First header broke chain ordering", "peer", id, "number", headers[0].Number, "hash", headers[0].Hash(), request.From)            accepted = false        } else if headers[len(headers)-1].Hash() != target {            log.Trace("Last header broke skeleton structure ", "peer", id, "number", headers[len(headers)-1].Number, "hash", headers[len(headers)-1].Hash(), "expected", target)            accepted = false        }    }    if accepted {// 依次检查每一块区块的区块号， 以及链接是否正确。        for i, header := range headers[1:] {            hash := header.Hash()            if want := request.From + 1 + uint64(i); header.Number.Uint64() != want {                log.Warn("Header broke chain ordering", "peer", id, "number", header.Number, "hash", hash, "expected", want)                accepted = false                break            }            if headers[i].Hash() != header.ParentHash {                log.Warn("Header broke chain ancestry", "peer", id, "number", header.Number, "hash", hash)                accepted = false                break            }        }    }    // If the batch of headers wasn't accepted, mark as unavailable    if !accepted { // 如果不被接收，那么标记这个peer在这个任务上的失败。下次请求就不会投递给这个peer        log.Trace("Skeleton filling not accepted", "peer", id, "from", request.From)        miss := q.headerPeerMiss[id]        if miss == nil {            q.headerPeerMiss[id] = make(map[uint64]struct{})            miss = q.headerPeerMiss[id]        }        miss[request.From] = struct{}{}        q.headerTaskQueue.Push(request.From, -float32(request.From))        return 0, errors.New("delivery not accepted")    }    // Clean up a successful fetch and try to deliver any sub-results    copy(q.headerResults[request.From-q.headerOffset:], headers)    delete(q.headerTaskPool, request.From)    ready := 0    for q.headerProced+ready &lt; len(q.headerResults) &amp;&amp; q.headerResults[q.headerProced+ready] != nil {//计算这次到来的header可以让headerResults有多少数据可以投递了。        ready += MaxHeaderFetch    }    if ready &gt; 0 {        // Headers are ready for delivery, gather them and push forward (non blocking)        process := make([]*types.Header, ready)        copy(process, q.headerResults[q.headerProced:q.headerProced+ready])        // 尝试投递        select {        case headerProcCh &lt;- process:            log.Trace("Pre-scheduled new headers", "peer", id, "count", len(process), "from", process[0].Number)            q.headerProced += len(process)        default:        }    }    // Check for termination and return    if len(q.headerTaskPool) == 0 {        // 这个通道比较重要， 如果这个通道接收到数据，说明所有的header任务已经完成。        q.headerContCh &lt;- false    }    return len(headers), nil}</code></pre><p>RetrieveHeaders，ScheduleSkeleton函数在上次调度还没有做完的情况下是不会调用的。 所以上次调用完成之后，会使用这个方法来获取结果，重置状态。</p><pre><code>// RetrieveHeaders retrieves the header chain assemble based on the scheduled// skeleton.func (q *queue) RetrieveHeaders() ([]*types.Header, int) {    q.lock.Lock()    defer q.lock.Unlock()    headers, proced := q.headerResults, q.headerProced    q.headerResults, q.headerProced = nil, 0    return headers, proced}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-eth-fetcher源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-fetcher%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-fetcher%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>fetcher包含基于块通知的同步。当我们接收到NewBlockHashesMsg消息得时候，我们只收到了很多Block的hash值。 需要通过hash值来同步区块，然后更新本地区块链。 fetcher就提供了这样的功能。</p><p>数据结构</p><pre><code>// announce is the hash notification of the availability of a new block in the// network.// announce 是一个hash通知，表示网络上有合适的新区块出现。type announce struct {    hash   common.Hash   // Hash of the block being announced //新区块的hash值    number uint64        // Number of the block being announced (0 = unknown | old protocol) 区块的高度值，    header *types.Header // Header of the block partially reassembled (new protocol)    重新组装的区块头    time   time.Time     // Timestamp of the announcement    origin string // Identifier of the peer originating the notification    fetchHeader headerRequesterFn // Fetcher function to retrieve the header of an announced block  获取区块头的函数指针， 里面包含了peer的信息。就是说找谁要这个区块头    fetchBodies bodyRequesterFn   // Fetcher function to retrieve the body of an announced block 获取区块体的函数指针}// headerFilterTask represents a batch of headers needing fetcher filtering.type headerFilterTask struct {    peer    string          // The source peer of block headers    headers []*types.Header // Collection of headers to filter    time    time.Time       // Arrival time of the headers}// headerFilterTask represents a batch of block bodies (transactions and uncles)// needing fetcher filtering.type bodyFilterTask struct {    peer         string                 // The source peer of block bodies    transactions [][]*types.Transaction // Collection of transactions per block bodies    uncles       [][]*types.Header      // Collection of uncles per block bodies    time         time.Time              // Arrival time of the blocks' contents}// inject represents a schedules import operation. // 当节点收到NewBlockMsg的消息时候，会插入一个区块type inject struct {    origin string    block  *types.Block}// Fetcher is responsible for accumulating block announcements from various peers// and scheduling them for retrieval.type Fetcher struct {    // Various event channels    notify chan *announce    //announce的通道，    inject chan *inject        //inject的通道    blockFilter  chan chan []*types.Block     //通道的通道？    headerFilter chan chan *headerFilterTask    bodyFilter   chan chan *bodyFilterTask    done chan common.Hash    quit chan struct{}    // Announce states    announces  map[string]int              // Per peer announce counts to prevent memory exhaustion key是peer的名字， value是announce的count， 为了避免内存占用太大。    announced  map[common.Hash][]*announce // Announced blocks, scheduled for fetching 等待调度fetching的announce    fetching   map[common.Hash]*announce   // Announced blocks, currently fetching 正在fetching的announce    fetched    map[common.Hash][]*announce // Blocks with headers fetched, scheduled for body retrieval // 已经获取区块头的，等待获取区块body    completing map[common.Hash]*announce   // Blocks with headers, currently body-completing  //头和体都已经获取完成的announce    // Block cache    queue  *prque.Prque            // Queue containing the import operations (block number sorted) //包含了import操作的队列(按照区块号排列)    queues map[string]int          // Per peer block counts to prevent memory exhaustion key是peer，value是block数量。 避免内存消耗太多。    queued map[common.Hash]*inject // Set of already queued blocks (to dedup imports)  已经放入队列的区块。 为了去重。    // Callbacks  依赖了一些回调函数。    getBlock       blockRetrievalFn   // Retrieves a block from the local chain    verifyHeader   headerVerifierFn   // Checks if a block's headers have a valid proof of work    broadcastBlock blockBroadcasterFn // Broadcasts a block to connected peers    chainHeight    chainHeightFn      // Retrieves the current chain's height    insertChain    chainInsertFn      // Injects a batch of blocks into the chain    dropPeer       peerDropFn         // Drops a peer for misbehaving    // Testing hooks  仅供测试使用。    announceChangeHook func(common.Hash, bool) // Method to call upon adding or deleting a hash from the announce list    queueChangeHook    func(common.Hash, bool) // Method to call upon adding or deleting a block from the import queue    fetchingHook       func([]common.Hash)     // Method to call upon starting a block (eth/61) or header (eth/62) fetch    completingHook     func([]common.Hash)     // Method to call upon starting a block body fetch (eth/62)    importedHook       func(*types.Block)      // Method to call upon successful block import (both eth/61 and eth/62)}</code></pre><p>启动fetcher， 直接启动了一个goroutine来处理。 这个函数有点长。 后续再分析。</p><pre><code>// Start boots up the announcement based synchroniser, accepting and processing// hash notifications and block fetches until termination requested.func (f *Fetcher) Start() {    go f.loop()}</code></pre><p>loop函数函数太长。 我先帖一个省略版本的出来。fetcher通过四个map(announced,fetching,fetched,completing )记录了announce的状态(等待fetch,正在fetch,fetch完头等待fetch body, fetch完成)。 loop其实通过定时器和各种消息来对各种map里面的announce进行状态转换。</p><pre><code>// Loop is the main fetcher loop, checking and processing various notification// events.func (f *Fetcher) loop() {    // Iterate the block fetching until a quit is requested    fetchTimer := time.NewTimer(0)  //fetch的定时器。    completeTimer := time.NewTimer(0) // compelte的定时器。    for {        // Clean up any expired block fetches        // 如果fetching的时间超过5秒，那么放弃掉这个fetching        for hash, announce := range f.fetching {            if time.Since(announce.time) &gt; fetchTimeout {                f.forgetHash(hash)            }        }        // Import any queued blocks that could potentially fit        // 这个fetcher.queue里面缓存了已经完成fetch的block等待按照顺序插入到本地的区块链中        //fetcher.queue是一个优先级队列。 优先级别就是他们的区块号的负数，这样区块数小的排在最前面。        height := f.chainHeight()        for !f.queue.Empty() { //             op := f.queue.PopItem().(*inject)            if f.queueChangeHook != nil {                f.queueChangeHook(op.block.Hash(), false)            }            // If too high up the chain or phase, continue later            number := op.block.NumberU64()            if number &gt; height+1 { //当前的区块的高度太高，还不能import                f.queue.Push(op, -float32(op.block.NumberU64()))                if f.queueChangeHook != nil {                    f.queueChangeHook(op.block.Hash(), true)                }                break            }            // Otherwise if fresh and still unknown, try and import            hash := op.block.Hash()            if number+maxUncleDist &lt; height || f.getBlock(hash) != nil {                // 区块的高度太低 低于当前的height-maxUncleDist                // 或者区块已经被import了                f.forgetBlock(hash)                continue            }            // 插入区块            f.insert(op.origin, op.block)        }        // Wait for an outside event to occur        select {        case &lt;-f.quit:            // Fetcher terminating, abort all operations            return        case notification := &lt;-f.notify: //在接收到NewBlockHashesMsg的时候，对于本地区块链还没有的区块的hash值会调用fetcher的Notify方法发送到notify通道。            ...        case op := &lt;-f.inject: // 在接收到NewBlockMsg的时候会调用fetcher的Enqueue方法，这个方法会把当前接收到的区块发送到inject通道。            ...            f.enqueue(op.origin, op.block)        case hash := &lt;-f.done: //当完成一个区块的import的时候会发送该区块的hash值到done通道。            ...        case &lt;-fetchTimer.C: // fetchTimer定时器，定期对需要fetch的区块头进行fetch            ...        case &lt;-completeTimer.C: // completeTimer定时器定期对需要fetch的区块体进行fetch            ...        case filter := &lt;-f.headerFilter: //当接收到BlockHeadersMsg的消息的时候(接收到一些区块头),会把这些消息投递到headerFilter队列。 这边会把属于fetcher请求的数据留下，其他的会返回出来，给其他系统使用。            ...        case filter := &lt;-f.bodyFilter: //当接收到BlockBodiesMsg消息的时候，会把这些消息投递给bodyFilter队列。这边会把属于fetcher请求的数据留下，其他的会返回出来，给其他系统使用。            ...        }    }}</code></pre><h3 id="区块头的过滤流程"><a href="#区块头的过滤流程" class="headerlink" title="区块头的过滤流程"></a>区块头的过滤流程</h3><h4 id="FilterHeaders请求"><a href="#FilterHeaders请求" class="headerlink" title="FilterHeaders请求"></a>FilterHeaders请求</h4><p>FilterHeaders方法在接收到BlockHeadersMsg的时候被调用。这个方法首先投递了一个channel filter到headerFilter。 然后往filter投递了一个headerFilterTask的任务。然后阻塞等待filter队列返回消息。</p><pre><code>// FilterHeaders extracts all the headers that were explicitly requested by the fetcher,// returning those that should be handled differently.func (f *Fetcher) FilterHeaders(peer string, headers []*types.Header, time time.Time) []*types.Header {    log.Trace("Filtering headers", "peer", peer, "headers", len(headers))    // Send the filter channel to the fetcher    filter := make(chan *headerFilterTask)    select {    case f.headerFilter &lt;- filter:    case &lt;-f.quit:        return nil    }    // Request the filtering of the header list    select {    case filter &lt;- &amp;headerFilterTask{peer: peer, headers: headers, time: time}:    case &lt;-f.quit:        return nil    }    // Retrieve the headers remaining after filtering    select {    case task := &lt;-filter:        return task.headers    case &lt;-f.quit:        return nil    }}</code></pre><h4 id="headerFilter的处理"><a href="#headerFilter的处理" class="headerlink" title="headerFilter的处理"></a>headerFilter的处理</h4><p>这个处理在loop()的goroutine中。</p><pre><code>case filter := &lt;-f.headerFilter:            // Headers arrived from a remote peer. Extract those that were explicitly            // requested by the fetcher, and return everything else so it's delivered            // to other parts of the system.            var task *headerFilterTask            select {            case task = &lt;-filter:            case &lt;-f.quit:                return            }            headerFilterInMeter.Mark(int64(len(task.headers)))            // Split the batch of headers into unknown ones (to return to the caller),            // known incomplete ones (requiring body retrievals) and completed blocks.            unknown, incomplete, complete := []*types.Header{}, []*announce{}, []*types.Block{}            for _, header := range task.headers {                hash := header.Hash()                // Filter fetcher-requested headers from other synchronisation algorithms                // 根据情况看这个是否是我们的请求返回的信息。                if announce := f.fetching[hash]; announce != nil &amp;&amp; announce.origin == task.peer &amp;&amp; f.fetched[hash] == nil &amp;&amp; f.completing[hash] == nil &amp;&amp; f.queued[hash] == nil {                    // If the delivered header does not match the promised number, drop the announcer                    // 如果返回的header的区块高度和我们请求的不同，那么删除掉返回这个header的peer。 并且忘记掉这个hash(以便于重新获取区块信息)                    if header.Number.Uint64() != announce.number {                        log.Trace("Invalid block number fetched", "peer", announce.origin, "hash", header.Hash(), "announced", announce.number, "provided", header.Number)                        f.dropPeer(announce.origin)                        f.forgetHash(hash)                        continue                    }                    // Only keep if not imported by other means                    if f.getBlock(hash) == nil {                        announce.header = header                        announce.time = task.time                        // If the block is empty (header only), short circuit into the final import queue                        // 根据区块头查看，如果这个区块不包含任何交易或者是Uncle区块。那么我们就不用获取区块的body了。 那么直接插入完成列表。                        if header.TxHash == types.DeriveSha(types.Transactions{}) &amp;&amp; header.UncleHash == types.CalcUncleHash([]*types.Header{}) {                            log.Trace("Block empty, skipping body retrieval", "peer", announce.origin, "number", header.Number, "hash", header.Hash())                            block := types.NewBlockWithHeader(header)                            block.ReceivedAt = task.time                            complete = append(complete, block)                            f.completing[hash] = announce                            continue                        }                        // Otherwise add to the list of blocks needing completion                        // 否则，插入到未完成列表等待fetch blockbody                        incomplete = append(incomplete, announce)                    } else {                        log.Trace("Block already imported, discarding header", "peer", announce.origin, "number", header.Number, "hash", header.Hash())                        f.forgetHash(hash)                    }                } else {                    // Fetcher doesn't know about it, add to the return list                    // Fetcher并不知道这个header。 增加到返回列表等待返回。                    unknown = append(unknown, header)                }            }            headerFilterOutMeter.Mark(int64(len(unknown)))            select {            // 把返回结果返回。            case filter &lt;- &amp;headerFilterTask{headers: unknown, time: task.time}:            case &lt;-f.quit:                return            }            // Schedule the retrieved headers for body completion            for _, announce := range incomplete {                hash := announce.header.Hash()                if _, ok := f.completing[hash]; ok { //如果已经在其他的地方完成                    continue                }                // 放到等待获取body的map等待处理。                f.fetched[hash] = append(f.fetched[hash], announce)                if len(f.fetched) == 1 { //如果fetched map只有刚刚加入的一个元素。 那么重置计时器。                    f.rescheduleComplete(completeTimer)                }            }            // Schedule the header-only blocks for import            // 这些只有header的区块放入queue等待import            for _, block := range complete {                if announce := f.completing[block.Hash()]; announce != nil {                    f.enqueue(announce.origin, block)                }            }</code></pre><h4 id="bodyFilter的处理"><a href="#bodyFilter的处理" class="headerlink" title="bodyFilter的处理"></a>bodyFilter的处理</h4><p>和上面的处理类似。</p><pre><code>    case filter := &lt;-f.bodyFilter:        // Block bodies arrived, extract any explicitly requested blocks, return the rest        var task *bodyFilterTask        select {        case task = &lt;-filter:        case &lt;-f.quit:            return        }        bodyFilterInMeter.Mark(int64(len(task.transactions)))        blocks := []*types.Block{}        for i := 0; i &lt; len(task.transactions) &amp;&amp; i &lt; len(task.uncles); i++ {            // Match up a body to any possible completion request            matched := false            for hash, announce := range f.completing {                if f.queued[hash] == nil {                    txnHash := types.DeriveSha(types.Transactions(task.transactions[i]))                    uncleHash := types.CalcUncleHash(task.uncles[i])                    if txnHash == announce.header.TxHash &amp;&amp; uncleHash == announce.header.UncleHash &amp;&amp; announce.origin == task.peer {                        // Mark the body matched, reassemble if still unknown                        matched = true                                                if f.getBlock(hash) == nil {                            block := types.NewBlockWithHeader(announce.header).WithBody(task.transactions[i], task.uncles[i])                            block.ReceivedAt = task.time                            blocks = append(blocks, block)                        } else {                            f.forgetHash(hash)                        }                    }                }            }            if matched {                task.transactions = append(task.transactions[:i], task.transactions[i+1:]...)                task.uncles = append(task.uncles[:i], task.uncles[i+1:]...)                i--                continue            }        }        bodyFilterOutMeter.Mark(int64(len(task.transactions)))        select {        case filter &lt;- task:        case &lt;-f.quit:            return        }        // Schedule the retrieved blocks for ordered import        for _, block := range blocks {            if announce := f.completing[block.Hash()]; announce != nil {                f.enqueue(announce.origin, block)            }        }</code></pre><h4 id="notification的处理"><a href="#notification的处理" class="headerlink" title="notification的处理"></a>notification的处理</h4><p>在接收到NewBlockHashesMsg的时候，对于本地区块链还没有的区块的hash值会调用fetcher的Notify方法发送到notify通道。</p><pre><code>// Notify announces the fetcher of the potential availability of a new block in// the network.func (f *Fetcher) Notify(peer string, hash common.Hash, number uint64, time time.Time,    headerFetcher headerRequesterFn, bodyFetcher bodyRequesterFn) error {    block := &amp;announce{        hash:        hash,        number:      number,        time:        time,        origin:      peer,        fetchHeader: headerFetcher,        fetchBodies: bodyFetcher,    }    select {    case f.notify &lt;- block:        return nil    case &lt;-f.quit:        return errTerminated    }}</code></pre><p>在loop中的处理，主要是检查一下然后加入了announced这个容器等待定时处理。</p><pre><code>case notification := &lt;-f.notify:        // A block was announced, make sure the peer isn't DOSing us        propAnnounceInMeter.Mark(1)        count := f.announces[notification.origin] + 1        if count &gt; hashLimit {  //hashLimit 256 一个远端最多只存在256个announces            log.Debug("Peer exceeded outstanding announces", "peer", notification.origin, "limit", hashLimit)            propAnnounceDOSMeter.Mark(1)            break        }        // If we have a valid block number, check that it's potentially useful        // 查看是潜在是否有用。 根据这个区块号和本地区块链的距离， 太大和太小对于我们都没有意义。        if notification.number &gt; 0 {            if dist := int64(notification.number) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist {                log.Debug("Peer discarded announcement", "peer", notification.origin, "number", notification.number, "hash", notification.hash, "distance", dist)                propAnnounceDropMeter.Mark(1)                break            }        }        // All is well, schedule the announce if block's not yet downloading        // 检查我们是否已经存在了。        if _, ok := f.fetching[notification.hash]; ok {            break        }        if _, ok := f.completing[notification.hash]; ok {            break        }        f.announces[notification.origin] = count        f.announced[notification.hash] = append(f.announced[notification.hash], notification)        if f.announceChangeHook != nil &amp;&amp; len(f.announced[notification.hash]) == 1 {            f.announceChangeHook(notification.hash, true)        }        if len(f.announced) == 1 {            f.rescheduleFetch(fetchTimer)        }</code></pre><h4 id="Enqueue处理"><a href="#Enqueue处理" class="headerlink" title="Enqueue处理"></a>Enqueue处理</h4><p>在接收到NewBlockMsg的时候会调用fetcher的Enqueue方法，这个方法会把当前接收到的区块发送到inject通道。 可以看到这个方法生成了一个inject对象然后发送到inject通道</p><pre><code>// Enqueue tries to fill gaps the the fetcher's future import queue.func (f *Fetcher) Enqueue(peer string, block *types.Block) error {    op := &amp;inject{        origin: peer,        block:  block,    }    select {    case f.inject &lt;- op:        return nil    case &lt;-f.quit:        return errTerminated    }}</code></pre><p>inject通道处理非常简单，直接加入到队列等待import</p><pre><code>case op := &lt;-f.inject:        // A direct block insertion was requested, try and fill any pending gaps        propBroadcastInMeter.Mark(1)        f.enqueue(op.origin, op.block)</code></pre><p>enqueue</p><pre><code>// enqueue schedules a new future import operation, if the block to be imported// has not yet been seen.func (f *Fetcher) enqueue(peer string, block *types.Block) {    hash := block.Hash()    // Ensure the peer isn't DOSing us    count := f.queues[peer] + 1    if count &gt; blockLimit { blockLimit 64 如果缓存的对方的block太多。        log.Debug("Discarded propagated block, exceeded allowance", "peer", peer, "number", block.Number(), "hash", hash, "limit", blockLimit)        propBroadcastDOSMeter.Mark(1)        f.forgetHash(hash)        return    }    // Discard any past or too distant blocks    // 距离我们的区块链太远。    if dist := int64(block.NumberU64()) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist {         log.Debug("Discarded propagated block, too far away", "peer", peer, "number", block.Number(), "hash", hash, "distance", dist)        propBroadcastDropMeter.Mark(1)        f.forgetHash(hash)        return    }    // Schedule the block for future importing    // 插入到队列。    if _, ok := f.queued[hash]; !ok {        op := &amp;inject{            origin: peer,            block:  block,        }        f.queues[peer] = count        f.queued[hash] = op        f.queue.Push(op, -float32(block.NumberU64()))        if f.queueChangeHook != nil {            f.queueChangeHook(op.block.Hash(), true)        }        log.Debug("Queued propagated block", "peer", peer, "number", block.Number(), "hash", hash, "queued", f.queue.Size())    }}</code></pre><h4 id="定时器的处理"><a href="#定时器的处理" class="headerlink" title="定时器的处理"></a>定时器的处理</h4><p>一共存在两个定时器。fetchTimer和completeTimer，分别负责获取区块头和获取区块body。</p><p>状态转换 announced  –fetchTimer(fetch header)—&gt; fetching  –(headerFilter)–&gt; fetched –completeTimer(fetch body)–&gt;completing –(bodyFilter)–&gt; enqueue –task.done–&gt; forgetHash</p><p>发现一个问题。 completing的容器有可能泄露。如果发送了一个hash的body请求。 但是请求失败，对方并没有返回。 这个时候completing容器没有清理。 是否有可能导致问题。</p><pre><code>    case &lt;-fetchTimer.C:        // At least one block's timer ran out, check for needing retrieval        request := make(map[string][]common.Hash)        for hash, announces := range f.announced {            // TODO 这里的时间限制是什么意思            // 最早收到的announce，并经过arriveTimeout-gatherSlack这么长的时间。            if time.Since(announces[0].time) &gt; arriveTimeout-gatherSlack {                // Pick a random peer to retrieve from, reset all others                // announces代表了同一个区块的来自多个peer的多个announce                announce := announces[rand.Intn(len(announces))]                f.forgetHash(hash)                // If the block still didn't arrive, queue for fetching                if f.getBlock(hash) == nil {                    request[announce.origin] = append(request[announce.origin], hash)                    f.fetching[hash] = announce                }            }        }        // Send out all block header requests        // 发送所有的请求。        for peer, hashes := range request {            log.Trace("Fetching scheduled headers", "peer", peer, "list", hashes)            // Create a closure of the fetch and schedule in on a new thread            fetchHeader, hashes := f.fetching[hashes[0]].fetchHeader, hashes            go func() {                if f.fetchingHook != nil {                    f.fetchingHook(hashes)                }                for _, hash := range hashes {                    headerFetchMeter.Mark(1)                    fetchHeader(hash) // Suboptimal, but protocol doesn't allow batch header retrievals                }            }()        }        // Schedule the next fetch if blocks are still pending        f.rescheduleFetch(fetchTimer)    case &lt;-completeTimer.C:        // At least one header's timer ran out, retrieve everything        request := make(map[string][]common.Hash)        for hash, announces := range f.fetched {            // Pick a random peer to retrieve from, reset all others            announce := announces[rand.Intn(len(announces))]            f.forgetHash(hash)            // If the block still didn't arrive, queue for completion            if f.getBlock(hash) == nil {                request[announce.origin] = append(request[announce.origin], hash)                f.completing[hash] = announce            }        }        // Send out all block body requests        for peer, hashes := range request {            log.Trace("Fetching scheduled bodies", "peer", peer, "list", hashes)            // Create a closure of the fetch and schedule in on a new thread            if f.completingHook != nil {                f.completingHook(hashes)            }            bodyFetchMeter.Mark(int64(len(hashes)))            go f.completing[hashes[0]].fetchBodies(hashes)        }        // Schedule the next fetch if blocks are still pending        f.rescheduleComplete(completeTimer)</code></pre><h4 id="其他的一些方法"><a href="#其他的一些方法" class="headerlink" title="其他的一些方法"></a>其他的一些方法</h4><p>fetcher insert方法。 这个方法把给定的区块插入本地的区块链。</p><pre><code>// insert spawns a new goroutine to run a block insertion into the chain. If the// block's number is at the same height as the current import phase, if updates// the phase states accordingly.func (f *Fetcher) insert(peer string, block *types.Block) {    hash := block.Hash()    // Run the import on a new thread    log.Debug("Importing propagated block", "peer", peer, "number", block.Number(), "hash", hash)    go func() {        defer func() { f.done &lt;- hash }()        // If the parent's unknown, abort insertion        parent := f.getBlock(block.ParentHash())        if parent == nil {            log.Debug("Unknown parent of propagated block", "peer", peer, "number", block.Number(), "hash", hash, "parent", block.ParentHash())            return        }        // Quickly validate the header and propagate the block if it passes        // 如果区块头通过验证，那么马上对区块进行广播。 NewBlockMsg        switch err := f.verifyHeader(block.Header()); err {        case nil:            // All ok, quickly propagate to our peers            propBroadcastOutTimer.UpdateSince(block.ReceivedAt)            go f.broadcastBlock(block, true)        case consensus.ErrFutureBlock:            // Weird future block, don't fail, but neither propagate        default:            // Something went very wrong, drop the peer            log.Debug("Propagated block verification failed", "peer", peer, "number", block.Number(), "hash", hash, "err", err)            f.dropPeer(peer)            return        }        // Run the actual import and log any issues        if _, err := f.insertChain(types.Blocks{block}); err != nil {            log.Debug("Propagated block import failed", "peer", peer, "number", block.Number(), "hash", hash, "err", err)            return        }        // If import succeeded, broadcast the block        // 如果插入成功， 那么广播区块， 第二个参数为false。那么只会对区块的hash进行广播。NewBlockHashesMsg        propAnnounceOutTimer.UpdateSince(block.ReceivedAt)        go f.broadcastBlock(block, false)        // Invoke the testing hook if needed        if f.importedHook != nil {            f.importedHook(block)        }    }()}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-p2p-rlpx节点之间的加密链路</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-rlpx%E8%8A%82%E7%82%B9%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8A%A0%E5%AF%86%E9%93%BE%E8%B7%AF/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-rlpx%E8%8A%82%E7%82%B9%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8A%A0%E5%AF%86%E9%93%BE%E8%B7%AF/</url>
      
        <content type="html"><![CDATA[<p>RLPx Encryption(RLPx加密)</p><p>之前介绍的discover节点发现协议， 因为承载的数据不是很重要，基本是明文传输的。 </p><p>每一个节点会开启两个同样的端口，一个是UDP端口，用来节点发现，一个是TCP端口，用来承载业务数据。 UDP的端口和TCP的端口的端口号是同样的。 这样只要通过UDP发现了端口，就等于可以用TCP来连接到对应的端口。</p><p>RLPx协议就定义了TCP链接的加密过程。</p><p>RLPx使用了(Perfect Forward Secrecy), 简单来说。 链接的两方生成生成随机的私钥，通过随机的私钥得到公钥。 然后双方交换各自的公钥， 这样双方都可以通过自己随机的私钥和对方的公钥来生成一个同样的共享密钥(shared-secret)。后续的通讯使用这个共享密钥作为对称加密算法的密钥。 这样来说。如果有一天一方的私钥被泄露，也只会影响泄露之后的消息的安全性， 对于之前的通讯是安全的(因为通讯的密钥是随机生成的，用完后就消失了)。</p><h2 id="前向安全性-引用自维基百科"><a href="#前向安全性-引用自维基百科" class="headerlink" title="前向安全性(引用自维基百科)"></a>前向安全性(引用自维基百科)</h2><p>前向安全或前向保密（英语：Forward Secrecy，缩写：FS），有时也被称为完美前向安全[1]（英语：Perfect Forward Secrecy，缩写：PFS），是密码学中通讯协议的安全属性，指的是长期使用的主密钥泄漏不会导致过去的会话密钥泄漏。[2]前向安全能够保护过去进行的通讯不受密码或密钥在未来暴露的威胁。[3]如果系统具有前向安全性，就可以保证万一密码或密钥在某个时刻不慎泄露，过去已经进行的通讯依然是安全，不会受到任何影响，即使系统遭到主动攻击也是如此。</p><h3 id="迪菲-赫尔曼密钥交换"><a href="#迪菲-赫尔曼密钥交换" class="headerlink" title="迪菲-赫尔曼密钥交换"></a>迪菲-赫尔曼密钥交换</h3><p>迪菲-赫尔曼密钥交换（英语：Diffie–Hellman key exchange，缩写为D-H） 是一种安全协议。它可以让双方在完全没有对方任何预先信息的条件下通过不安全信道创建起一个密钥。这个密钥可以在后续的通讯中作为对称密钥来加密通讯内容。公钥交换的概念最早由瑞夫·墨克（Ralph C. Merkle）提出，而这个密钥交换方法，由惠特菲尔德·迪菲（Bailey Whitfield Diffie）和马丁·赫尔曼（Martin Edward Hellman）在1976年首次发表。马丁·赫尔曼曾主张这个密钥交换方法，应被称为迪菲-赫尔曼-墨克密钥交换（英语：Diffie–Hellman–Merkle key exchange）。</p><ul><li>迪菲－赫尔曼密钥交换的同义词包括:</li><li>迪菲－赫尔曼密钥协商</li><li>迪菲－赫尔曼密钥创建</li><li>指数密钥交换</li><li>迪菲－赫尔曼协议</li></ul><p>虽然迪菲－赫尔曼密钥交换本身是一个匿名（无认证）的密钥交换协议，它却是很多认证协议的基础，并且被用来提供传输层安全协议的短暂模式中的完备的前向安全性。</p><h4 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h4><p>迪菲－赫尔曼通过公共信道交换一个信息，就可以创建一个可以用于在公共信道上安全通信的共享秘密（shared secret）。<br>以下解释它的过程（包括算法的数学部分）：<br><img src="/images/ethereum/source_analysis/rlpx_1.png" alt="image"></p><p>最简单，最早提出的这个协议使用一个质数p的整数模n乘法群以及其原根g。下面展示这个算法，绿色表示非秘密信息, 红色粗体表示秘密信息：<br><img src="/images/ethereum/source_analysis/rlpx_2.png" alt="image"><br><img src="/images/ethereum/source_analysis/rlpx_3.png" alt="image"></p><h2 id="p2p-rlpx-go源码解读"><a href="#p2p-rlpx-go源码解读" class="headerlink" title="p2p/rlpx.go源码解读"></a>p2p/rlpx.go源码解读</h2><p>这个文件实现了RLPx的链路协议。</p><p>链接联系的大致流程如下：</p><ol><li>doEncHandshake() 通过这个方法来完成交换密钥，创建加密信道的流程。如果失败，那么链接关闭。</li><li>doProtoHandshake() 这个方法来进行协议特性之间的协商，比如双方的协议版本，是否支持Snappy加密方式等操作。</li></ol><p>链接经过这两次处理之后，就算建立起来了。因为TCP是流式的协议。所有RLPx协议定义了分帧的方式。所有的数据都可以理解为一个接一个的rlpxFrame。 rlpx的读写都是通过rlpxFrameRW对象来进行处理。</p><h3 id="doEncHandshake"><a href="#doEncHandshake" class="headerlink" title="doEncHandshake"></a>doEncHandshake</h3><p>链接的发起者被称为initiator。链接的被动接受者被成为receiver。 这两种模式下处理的流程是不同的。完成握手后。 生成了一个sec.可以理解为拿到了对称加密的密钥。 然后创建了一个newRLPXFrameRW帧读写器。完成加密信道的创建过程。</p><pre><code>func (t *rlpx) doEncHandshake(prv *ecdsa.PrivateKey, dial *discover.Node) (discover.NodeID, error) {    var (        sec secrets        err error    )    if dial == nil {        sec, err = receiverEncHandshake(t.fd, prv, nil)    } else {        sec, err = initiatorEncHandshake(t.fd, prv, dial.ID, nil)    }    if err != nil {        return discover.NodeID{}, err    }    t.wmu.Lock()    t.rw = newRLPXFrameRW(t.fd, sec)    t.wmu.Unlock()    return sec.RemoteID, nil}</code></pre><p>initiatorEncHandshake 首先看看链接的发起者的操作。首先通过makeAuthMsg创建了authMsg。 然后通过网络发送给对端。然后通过readHandshakeMsg读取对端的回应。 最后调用secrets创建了共享秘密。</p><pre><code>// initiatorEncHandshake negotiates a session token on conn.// it should be called on the dialing side of the connection.//// prv is the local client's private key.func initiatorEncHandshake(conn io.ReadWriter, prv *ecdsa.PrivateKey, remoteID discover.NodeID, token []byte) (s secrets, err error) {    h := &amp;encHandshake{initiator: true, remoteID: remoteID}    authMsg, err := h.makeAuthMsg(prv, token)    if err != nil {        return s, err    }    authPacket, err := sealEIP8(authMsg, h)    if err != nil {        return s, err    }    if _, err = conn.Write(authPacket); err != nil {        return s, err    }    authRespMsg := new(authRespV4)    authRespPacket, err := readHandshakeMsg(authRespMsg, encAuthRespLen, prv, conn)    if err != nil {        return s, err    }    if err := h.handleAuthResp(authRespMsg); err != nil {        return s, err    }    return h.secrets(authPacket, authRespPacket)}</code></pre><p>makeAuthMsg。这个方法创建了initiator的handshake message。 首先对端的公钥可以通过对端的ID来获取。所以对端的公钥对于发起连接的人来说是知道的。 但是对于被连接的人来说，对端的公钥应该是不知道的。</p><pre><code>// makeAuthMsg creates the initiator handshake message.func (h *encHandshake) makeAuthMsg(prv *ecdsa.PrivateKey, token []byte) (*authMsgV4, error) {    rpub, err := h.remoteID.Pubkey()    if err != nil {        return nil, fmt.Errorf("bad remoteID: %v", err)    }    h.remotePub = ecies.ImportECDSAPublic(rpub)    // Generate random initiator nonce.    // 生成一个随机的初始值， 是为了避免重放攻击么？ 还是为了避免通过多次连接猜测密钥？    h.initNonce = make([]byte, shaLen)    if _, err := rand.Read(h.initNonce); err != nil {        return nil, err    }    // Generate random keypair to for ECDH.    //生成一个随机的私钥    h.randomPrivKey, err = ecies.GenerateKey(rand.Reader, crypto.S256(), nil)    if err != nil {        return nil, err    }    // Sign known message: static-shared-secret ^ nonce    // 这个地方应该是直接使用了静态的共享秘密。 使用自己的私钥和对方的公钥生成的一个共享秘密。    token, err = h.staticSharedSecret(prv)    if err != nil {        return nil, err    }    //这里我理解用共享秘密来加密这个initNonce。     signed := xor(token, h.initNonce)    // 使用随机的私钥来加密这个信息。    signature, err := crypto.Sign(signed, h.randomPrivKey.ExportECDSA())    if err != nil {        return nil, err    }    msg := new(authMsgV4)    copy(msg.Signature[:], signature)    //这里把发起者的公钥告知对方。 这样对方使用自己的私钥和这个公钥可以生成静态的共享秘密。    copy(msg.InitiatorPubkey[:], crypto.FromECDSAPub(&amp;prv.PublicKey)[1:])    copy(msg.Nonce[:], h.initNonce)    msg.Version = 4    return msg, nil}// staticSharedSecret returns the static shared secret, the result// of key agreement between the local and remote static node key.func (h *encHandshake) staticSharedSecret(prv *ecdsa.PrivateKey) ([]byte, error) {    return ecies.ImportECDSA(prv).GenerateShared(h.remotePub, sskLen, sskLen)}</code></pre><p>sealEIP8方法，这个方法是一个组包方法，对msg进行rlp的编码。 填充一些数据。 然后使用对方的公钥把数据进行加密。 这意味着只有对方的私钥才能解密这段信息。</p><pre><code>func sealEIP8(msg interface{}, h *encHandshake) ([]byte, error) {    buf := new(bytes.Buffer)    if err := rlp.Encode(buf, msg); err != nil {        return nil, err    }    // pad with random amount of data. the amount needs to be at least 100 bytes to make    // the message distinguishable from pre-EIP-8 handshakes.    pad := padSpace[:mrand.Intn(len(padSpace)-100)+100]    buf.Write(pad)    prefix := make([]byte, 2)    binary.BigEndian.PutUint16(prefix, uint16(buf.Len()+eciesOverhead))    enc, err := ecies.Encrypt(rand.Reader, h.remotePub, buf.Bytes(), nil, prefix)    return append(prefix, enc...), err}</code></pre><p>readHandshakeMsg这个方法会从两个地方调用。 一个是在initiatorEncHandshake。一个就是在receiverEncHandshake。 这个方法比较简单。 首先用一种格式尝试解码。如果不行就换另外一种。应该是一种兼容性的设置。 基本上就是使用自己的私钥进行解码然后调用rlp解码成结构体。 结构体的描述就是下面的authRespV4,里面最重要的就是对端的随机公钥。 双方通过自己的私钥和对端的随机公钥可以得到一样的共享秘密。 而这个共享秘密是第三方拿不到的。</p><pre><code>// RLPx v4 handshake response (defined in EIP-8).type authRespV4 struct {    RandomPubkey [pubLen]byte    Nonce        [shaLen]byte    Version      uint    // Ignore additional fields (forward-compatibility)    Rest []rlp.RawValue `rlp:"tail"`}func readHandshakeMsg(msg plainDecoder, plainSize int, prv *ecdsa.PrivateKey, r io.Reader) ([]byte, error) {    buf := make([]byte, plainSize)    if _, err := io.ReadFull(r, buf); err != nil {        return buf, err    }    // Attempt decoding pre-EIP-8 "plain" format.    key := ecies.ImportECDSA(prv)    if dec, err := key.Decrypt(rand.Reader, buf, nil, nil); err == nil {        msg.decodePlain(dec)        return buf, nil    }    // Could be EIP-8 format, try that.    prefix := buf[:2]    size := binary.BigEndian.Uint16(prefix)    if size &lt; uint16(plainSize) {        return buf, fmt.Errorf("size underflow, need at least %d bytes", plainSize)    }    buf = append(buf, make([]byte, size-uint16(plainSize)+2)...)    if _, err := io.ReadFull(r, buf[plainSize:]); err != nil {        return buf, err    }    dec, err := key.Decrypt(rand.Reader, buf[2:], nil, prefix)    if err != nil {        return buf, err    }    // Can't use rlp.DecodeBytes here because it rejects    // trailing data (forward-compatibility).    s := rlp.NewStream(bytes.NewReader(dec), 0)    return buf, s.Decode(msg)}</code></pre><p>handleAuthResp这个方法非常简单。</p><pre><code>func (h *encHandshake) handleAuthResp(msg *authRespV4) (err error) {    h.respNonce = msg.Nonce[:]    h.remoteRandomPub, err = importPublicKey(msg.RandomPubkey[:])    return err}</code></pre><p>最后是secrets函数，这个函数是在handshake完成之后调用。它通过自己的随机私钥和对端的公钥来生成一个共享秘密,这个共享秘密是瞬时的(只在当前这个链接中存在)。所以当有一天私钥被破解。 之前的消息还是安全的。</p><pre><code>// secrets is called after the handshake is completed.// It extracts the connection secrets from the handshake values.func (h *encHandshake) secrets(auth, authResp []byte) (secrets, error) {    ecdheSecret, err := h.randomPrivKey.GenerateShared(h.remoteRandomPub, sskLen, sskLen)    if err != nil {        return secrets{}, err    }    // derive base secrets from ephemeral key agreement    sharedSecret := crypto.Keccak256(ecdheSecret, crypto.Keccak256(h.respNonce, h.initNonce))    aesSecret := crypto.Keccak256(ecdheSecret, sharedSecret)    // 实际上这个MAC保护了ecdheSecret这个共享秘密。respNonce和initNonce这三个值    s := secrets{        RemoteID: h.remoteID,        AES:      aesSecret,        MAC:      crypto.Keccak256(ecdheSecret, aesSecret),    }    // setup sha3 instances for the MACs    mac1 := sha3.NewKeccak256()    mac1.Write(xor(s.MAC, h.respNonce))    mac1.Write(auth)    mac2 := sha3.NewKeccak256()    mac2.Write(xor(s.MAC, h.initNonce))    mac2.Write(authResp)    //收到的每个包都会检查其MAC值是否满足计算的结果。如果不满足说明有问题。    if h.initiator {        s.EgressMAC, s.IngressMAC = mac1, mac2    } else {        s.EgressMAC, s.IngressMAC = mac2, mac1    }    return s, nil}</code></pre><p>receiverEncHandshake函数和initiatorEncHandshake的内容大致相同。 但是顺序有些不一样。</p><pre><code>// receiverEncHandshake negotiates a session token on conn.// it should be called on the listening side of the connection.//// prv is the local client's private key.// token is the token from a previous session with this node.func receiverEncHandshake(conn io.ReadWriter, prv *ecdsa.PrivateKey, token []byte) (s secrets, err error) {    authMsg := new(authMsgV4)    authPacket, err := readHandshakeMsg(authMsg, encAuthMsgLen, prv, conn)    if err != nil {        return s, err    }    h := new(encHandshake)    if err := h.handleAuthMsg(authMsg, prv); err != nil {        return s, err    }    authRespMsg, err := h.makeAuthResp()    if err != nil {        return s, err    }    var authRespPacket []byte    if authMsg.gotPlain {        authRespPacket, err = authRespMsg.sealPlain(h)    } else {        authRespPacket, err = sealEIP8(authRespMsg, h)    }    if err != nil {        return s, err    }    if _, err = conn.Write(authRespPacket); err != nil {        return s, err    }    return h.secrets(authPacket, authRespPacket)}</code></pre><h3 id="doProtocolHandshake"><a href="#doProtocolHandshake" class="headerlink" title="doProtocolHandshake"></a>doProtocolHandshake</h3><p>这个方法比较简单， 加密信道已经创建完毕。 我们看到这里只是约定了是否使用Snappy加密然后就退出了。</p><pre><code>// doEncHandshake runs the protocol handshake using authenticated// messages. the protocol handshake is the first authenticated message// and also verifies whether the encryption handshake 'worked' and the// remote side actually provided the right public key.func (t *rlpx) doProtoHandshake(our *protoHandshake) (their *protoHandshake, err error) {    // Writing our handshake happens concurrently, we prefer    // returning the handshake read error. If the remote side    // disconnects us early with a valid reason, we should return it    // as the error so it can be tracked elsewhere.    werr := make(chan error, 1)    go func() { werr &lt;- Send(t.rw, handshakeMsg, our) }()    if their, err = readProtocolHandshake(t.rw, our); err != nil {        &lt;-werr // make sure the write terminates too        return nil, err    }    if err := &lt;-werr; err != nil {        return nil, fmt.Errorf("write error: %v", err)    }    // If the protocol version supports Snappy encoding, upgrade immediately    t.rw.snappy = their.Version &gt;= snappyProtocolVersion    return their, nil}</code></pre><h3 id="rlpxFrameRW-数据分帧"><a href="#rlpxFrameRW-数据分帧" class="headerlink" title="rlpxFrameRW 数据分帧"></a>rlpxFrameRW 数据分帧</h3><p>数据分帧主要通过rlpxFrameRW类来完成的。</p><pre><code>// rlpxFrameRW implements a simplified version of RLPx framing.// chunked messages are not supported and all headers are equal to// zeroHeader.//// rlpxFrameRW is not safe for concurrent use from multiple goroutines.type rlpxFrameRW struct {    conn io.ReadWriter    enc  cipher.Stream    dec  cipher.Stream    macCipher  cipher.Block    egressMAC  hash.Hash    ingressMAC hash.Hash    snappy bool}</code></pre><p>我们在完成两次握手之后。调用newRLPXFrameRW方法创建了这个对象。</p><pre><code>t.rw = newRLPXFrameRW(t.fd, sec)</code></pre><p>然后提供ReadMsg和WriteMsg方法。这两个方法直接调用了rlpxFrameRW的ReadMsg和WriteMsg</p><pre><code>func (t *rlpx) ReadMsg() (Msg, error) {    t.rmu.Lock()    defer t.rmu.Unlock()    t.fd.SetReadDeadline(time.Now().Add(frameReadTimeout))    return t.rw.ReadMsg()}func (t *rlpx) WriteMsg(msg Msg) error {    t.wmu.Lock()    defer t.wmu.Unlock()    t.fd.SetWriteDeadline(time.Now().Add(frameWriteTimeout))    return t.rw.WriteMsg(msg)}</code></pre><p>WriteMsg</p><pre><code>func (rw *rlpxFrameRW) WriteMsg(msg Msg) error {    ptype, _ := rlp.EncodeToBytes(msg.Code)    // if snappy is enabled, compress message now    if rw.snappy {        if msg.Size &gt; maxUint24 {            return errPlainMessageTooLarge        }        payload, _ := ioutil.ReadAll(msg.Payload)        payload = snappy.Encode(nil, payload)        msg.Payload = bytes.NewReader(payload)        msg.Size = uint32(len(payload))    }    // write header    headbuf := make([]byte, 32)    fsize := uint32(len(ptype)) + msg.Size    if fsize &gt; maxUint24 {        return errors.New("message size overflows uint24")    }    putInt24(fsize, headbuf) // TODO: check overflow    copy(headbuf[3:], zeroHeader)    rw.enc.XORKeyStream(headbuf[:16], headbuf[:16]) // first half is now encrypted    // write header MAC    copy(headbuf[16:], updateMAC(rw.egressMAC, rw.macCipher, headbuf[:16]))    if _, err := rw.conn.Write(headbuf); err != nil {        return err    }    // write encrypted frame, updating the egress MAC hash with    // the data written to conn.    tee := cipher.StreamWriter{S: rw.enc, W: io.MultiWriter(rw.conn, rw.egressMAC)}    if _, err := tee.Write(ptype); err != nil {        return err    }    if _, err := io.Copy(tee, msg.Payload); err != nil {        return err    }    if padding := fsize % 16; padding &gt; 0 {        if _, err := tee.Write(zero16[:16-padding]); err != nil {            return err        }    }    // write frame MAC. egress MAC hash is up to date because    // frame content was written to it as well.    fmacseed := rw.egressMAC.Sum(nil)    mac := updateMAC(rw.egressMAC, rw.macCipher, fmacseed)    _, err := rw.conn.Write(mac)    return err}</code></pre><p>ReadMsg</p><pre><code>func (rw *rlpxFrameRW) ReadMsg() (msg Msg, err error) {    // read the header    headbuf := make([]byte, 32)    if _, err := io.ReadFull(rw.conn, headbuf); err != nil {        return msg, err    }    // verify header mac    shouldMAC := updateMAC(rw.ingressMAC, rw.macCipher, headbuf[:16])    if !hmac.Equal(shouldMAC, headbuf[16:]) {        return msg, errors.New("bad header MAC")    }    rw.dec.XORKeyStream(headbuf[:16], headbuf[:16]) // first half is now decrypted    fsize := readInt24(headbuf)    // ignore protocol type for now    // read the frame content    var rsize = fsize // frame size rounded up to 16 byte boundary    if padding := fsize % 16; padding &gt; 0 {        rsize += 16 - padding    }    framebuf := make([]byte, rsize)    if _, err := io.ReadFull(rw.conn, framebuf); err != nil {        return msg, err    }    // read and validate frame MAC. we can re-use headbuf for that.    rw.ingressMAC.Write(framebuf)    fmacseed := rw.ingressMAC.Sum(nil)    if _, err := io.ReadFull(rw.conn, headbuf[:16]); err != nil {        return msg, err    }    shouldMAC = updateMAC(rw.ingressMAC, rw.macCipher, fmacseed)    if !hmac.Equal(shouldMAC, headbuf[:16]) {        return msg, errors.New("bad frame MAC")    }    // decrypt frame content    rw.dec.XORKeyStream(framebuf, framebuf)    // decode message code    content := bytes.NewReader(framebuf[:fsize])    if err := rlp.Decode(content, &amp;msg.Code); err != nil {        return msg, err    }    msg.Size = uint32(content.Len())    msg.Payload = content    // if snappy is enabled, verify and decompress message    if rw.snappy {        payload, err := ioutil.ReadAll(msg.Payload)        if err != nil {            return msg, err        }        size, err := snappy.DecodedLen(payload)        if err != nil {            return msg, err        }        if size &gt; int(maxUint24) {            return msg, errPlainMessageTooLarge        }        payload, err = snappy.Decode(nil, payload)        if err != nil {            return msg, err        }        msg.Size, msg.Payload = uint32(size), bytes.NewReader(payload)    }    return msg, nil}</code></pre><p>帧结构</p><pre><code>  normal = not chunked  chunked-0 = First frame of a multi-frame packet  chunked-n = Subsequent frames for multi-frame packet  || is concatenate  ^ is xorSingle-frame packet:header || header-mac || frame || frame-macMulti-frame packet:header || header-mac || frame-0 ||[ header || header-mac || frame-n || ... || ]header || header-mac || frame-last || frame-macheader: frame-size || header-data || paddingframe-size: 3-byte integer size of frame, big endian encoded (excludes padding)header-data:    normal: rlp.list(protocol-type[, context-id])    chunked-0: rlp.list(protocol-type, context-id, total-packet-size)    chunked-n: rlp.list(protocol-type, context-id)    values:        protocol-type: &lt; 2**16        context-id: &lt; 2**16 (optional for normal frames)        total-packet-size: &lt; 2**32padding: zero-fill to 16-byte boundaryheader-mac: right128 of egress-mac.update(aes(mac-secret,egress-mac) ^ header-ciphertext).digestframe:    normal: rlp(packet-type) [|| rlp(packet-data)] || padding    chunked-0: rlp(packet-type) || rlp(packet-data...)    chunked-n: rlp(...packet-data) || paddingpadding: zero-fill to 16-byte boundary (only necessary for last frame)frame-mac: right128 of egress-mac.update(aes(mac-secret,egress-mac) ^ right128(egress-mac.update(frame-ciphertext).digest))egress-mac: h256, continuously updated with egress-bytes*ingress-mac: h256, continuously updated with ingress-bytes*</code></pre><p>因为加密解密算法我也不是很熟，所以这里的分析还不是很彻底。 暂时只是分析了大致的流程。还有很多细节没有确认。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-p2p-server.go源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-server.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-server.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>server是p2p的最主要的部分。集合了所有之前的组件。</p><p>首先看看Server的结构</p><pre><code>// Server manages all peer connections.type Server struct {    // Config fields may not be modified while the server is running.    Config    // Hooks for testing. These are useful because we can inhibit    // the whole protocol stack.    newTransport func(net.Conn) transport    newPeerHook  func(*Peer)    lock    sync.Mutex // protects running    running bool    ntab         discoverTable    listener     net.Listener    ourHandshake *protoHandshake    lastLookup   time.Time    DiscV5       *discv5.Network    // These are for Peers, PeerCount (and nothing else).    peerOp     chan peerOpFunc    peerOpDone chan struct{}    quit          chan struct{}    addstatic     chan *discover.Node    removestatic  chan *discover.Node    posthandshake chan *conn    addpeer       chan *conn    delpeer       chan peerDrop    loopWG        sync.WaitGroup // loop, listenLoop    peerFeed      event.Feed}// conn wraps a network connection with information gathered// during the two handshakes.type conn struct {    fd net.Conn    transport    flags connFlag    cont  chan error      // The run loop uses cont to signal errors to SetupConn.    id    discover.NodeID // valid after the encryption handshake    caps  []Cap           // valid after the protocol handshake    name  string          // valid after the protocol handshake}type transport interface {    // The two handshakes.    doEncHandshake(prv *ecdsa.PrivateKey, dialDest *discover.Node) (discover.NodeID, error)    doProtoHandshake(our *protoHandshake) (*protoHandshake, error)    // The MsgReadWriter can only be used after the encryption    // handshake has completed. The code uses conn.id to track this    // by setting it to a non-nil value after the encryption handshake.    MsgReadWriter    // transports must provide Close because we use MsgPipe in some of    // the tests. Closing the actual network connection doesn't do    // anything in those tests because NsgPipe doesn't use it.    close(err error)}</code></pre><p>并不存在一个newServer的方法。 初始化的工作放在Start()方法中。</p><pre><code>// Start starts running the server.// Servers can not be re-used after stopping.func (srv *Server) Start() (err error) {    srv.lock.Lock()    defer srv.lock.Unlock()    if srv.running { //避免多次启动。 srv.lock为了避免多线程重复启动        return errors.New("server already running")    }    srv.running = true    log.Info("Starting P2P networking")    // static fields    if srv.PrivateKey == nil {        return fmt.Errorf("Server.PrivateKey must be set to a non-nil key")    }    if srv.newTransport == nil {        //这里注意的是Transport使用了newRLPX 使用了rlpx.go中的网络协议。        srv.newTransport = newRLPX    }    if srv.Dialer == nil { //使用了TCLPDialer        srv.Dialer = TCPDialer{&amp;net.Dialer{Timeout: defaultDialTimeout}}    }    srv.quit = make(chan struct{})    srv.addpeer = make(chan *conn)    srv.delpeer = make(chan peerDrop)    srv.posthandshake = make(chan *conn)    srv.addstatic = make(chan *discover.Node)    srv.removestatic = make(chan *discover.Node)    srv.peerOp = make(chan peerOpFunc)    srv.peerOpDone = make(chan struct{})    // node table    if !srv.NoDiscovery {  //启动discover网络。 开启UDP的监听。        ntab, err := discover.ListenUDP(srv.PrivateKey, srv.ListenAddr, srv.NAT, srv.NodeDatabase, srv.NetRestrict)        if err != nil {            return err        }        //设置最开始的启动节点。当找不到其他的节点的时候。 那么就连接这些启动节点。这些节点的信息是写死在配置文件里面的。        if err := ntab.SetFallbackNodes(srv.BootstrapNodes); err != nil {            return err        }        srv.ntab = ntab    }    if srv.DiscoveryV5 {//这是新的节点发现协议。 暂时还没有使用。  这里暂时没有分析。        ntab, err := discv5.ListenUDP(srv.PrivateKey, srv.DiscoveryV5Addr, srv.NAT, "", srv.NetRestrict) //srv.NodeDatabase)        if err != nil {            return err        }        if err := ntab.SetFallbackNodes(srv.BootstrapNodesV5); err != nil {            return err        }        srv.DiscV5 = ntab    }    dynPeers := (srv.MaxPeers + 1) / 2    if srv.NoDiscovery {        dynPeers = 0    }        //创建dialerstate。     dialer := newDialState(srv.StaticNodes, srv.BootstrapNodes, srv.ntab, dynPeers, srv.NetRestrict)    // handshake    //我们自己的协议的handShake     srv.ourHandshake = &amp;protoHandshake{Version: baseProtocolVersion, Name: srv.Name, ID: discover.PubkeyID(&amp;srv.PrivateKey.PublicKey)}    for _, p := range srv.Protocols {//增加所有的协议的Caps        srv.ourHandshake.Caps = append(srv.ourHandshake.Caps, p.cap())    }    // listen/dial    if srv.ListenAddr != "" {        //开始监听TCP端口        if err := srv.startListening(); err != nil {            return err        }    }    if srv.NoDial &amp;&amp; srv.ListenAddr == "" {        log.Warn("P2P server will be useless, neither dialing nor listening")    }    srv.loopWG.Add(1)    //启动goroutine 来处理程序。    go srv.run(dialer)    srv.running = true    return nil}</code></pre><p>启动监听。 可以看到是TCP协议。 这里的监听端口和UDP的端口是一样的。 默认都是30303</p><pre><code>func (srv *Server) startListening() error {    // Launch the TCP listener.    listener, err := net.Listen("tcp", srv.ListenAddr)    if err != nil {        return err    }    laddr := listener.Addr().(*net.TCPAddr)    srv.ListenAddr = laddr.String()    srv.listener = listener    srv.loopWG.Add(1)    go srv.listenLoop()    // Map the TCP listening port if NAT is configured.    if !laddr.IP.IsLoopback() &amp;&amp; srv.NAT != nil {        srv.loopWG.Add(1)        go func() {            nat.Map(srv.NAT, srv.quit, "tcp", laddr.Port, laddr.Port, "ethereum p2p")            srv.loopWG.Done()        }()    }    return nil}</code></pre><p>listenLoop()。 这是一个死循环的goroutine。 会监听端口并接收外部的请求。</p><pre><code>// listenLoop runs in its own goroutine and accepts// inbound connections.func (srv *Server) listenLoop() {    defer srv.loopWG.Done()    log.Info("RLPx listener up", "self", srv.makeSelf(srv.listener, srv.ntab))    // This channel acts as a semaphore limiting    // active inbound connections that are lingering pre-handshake.    // If all slots are taken, no further connections are accepted.    tokens := maxAcceptConns    if srv.MaxPendingPeers &gt; 0 {        tokens = srv.MaxPendingPeers    }    //创建maxAcceptConns个槽位。 我们只同时处理这么多连接。 多了也不要。    slots := make(chan struct{}, tokens)    //把槽位填满。    for i := 0; i &lt; tokens; i++ {        slots &lt;- struct{}{}    }    for {        // Wait for a handshake slot before accepting.        &lt;-slots        var (            fd  net.Conn            err error        )        for {            fd, err = srv.listener.Accept()            if tempErr, ok := err.(tempError); ok &amp;&amp; tempErr.Temporary() {                log.Debug("Temporary read error", "err", err)                continue            } else if err != nil {                log.Debug("Read error", "err", err)                return            }            break        }        // Reject connections that do not match NetRestrict.        // 白名单。 如果不在白名单里面。那么关闭连接。        if srv.NetRestrict != nil {            if tcp, ok := fd.RemoteAddr().(*net.TCPAddr); ok &amp;&amp; !srv.NetRestrict.Contains(tcp.IP) {                log.Debug("Rejected conn (not whitelisted in NetRestrict)", "addr", fd.RemoteAddr())                fd.Close()                slots &lt;- struct{}{}                continue            }        }        fd = newMeteredConn(fd, true)        log.Trace("Accepted connection", "addr", fd.RemoteAddr())        // Spawn the handler. It will give the slot back when the connection        // has been established.        go func() {            //看来只要连接建立完成之后。 槽位就会归还。 SetupConn这个函数我们记得再dialTask.Do里面也有调用， 这个函数主要是执行连接的几次握手。            srv.SetupConn(fd, inboundConn, nil)            slots &lt;- struct{}{}        }()    }}</code></pre><p>SetupConn,这个函数执行握手协议，并尝试把连接创建位一个peer对象。</p><pre><code>// SetupConn runs the handshakes and attempts to add the connection// as a peer. It returns when the connection has been added as a peer// or the handshakes have failed.func (srv *Server) SetupConn(fd net.Conn, flags connFlag, dialDest *discover.Node) {    // Prevent leftover pending conns from entering the handshake.    srv.lock.Lock()    running := srv.running    srv.lock.Unlock()    //创建了一个conn对象。 newTransport指针实际上指向的newRLPx方法。 实际上是把fd用rlpx协议包装了一下。    c := &amp;conn{fd: fd, transport: srv.newTransport(fd), flags: flags, cont: make(chan error)}    if !running {        c.close(errServerStopped)        return    }    // Run the encryption handshake.    var err error    //这里实际上执行的是rlpx.go里面的doEncHandshake.因为transport是conn的一个匿名字段。 匿名字段的方法会直接作为conn的一个方法。    if c.id, err = c.doEncHandshake(srv.PrivateKey, dialDest); err != nil {        log.Trace("Failed RLPx handshake", "addr", c.fd.RemoteAddr(), "conn", c.flags, "err", err)        c.close(err)        return    }    clog := log.New("id", c.id, "addr", c.fd.RemoteAddr(), "conn", c.flags)    // For dialed connections, check that the remote public key matches.    // 如果连接握手的ID和对应的ID不匹配    if dialDest != nil &amp;&amp; c.id != dialDest.ID {        c.close(DiscUnexpectedIdentity)        clog.Trace("Dialed identity mismatch", "want", c, dialDest.ID)        return    }    // 这个checkpoint其实就是把第一个参数发送给第二个参数指定的队列。然后从c.cout接收返回信息。 是一个同步的方法。    //至于这里，后续的操作只是检查了一下连接是否合法就返回了。    if err := srv.checkpoint(c, srv.posthandshake); err != nil {        clog.Trace("Rejected peer before protocol handshake", "err", err)        c.close(err)        return    }    // Run the protocol handshake    phs, err := c.doProtoHandshake(srv.ourHandshake)    if err != nil {        clog.Trace("Failed proto handshake", "err", err)        c.close(err)        return    }    if phs.ID != c.id {        clog.Trace("Wrong devp2p handshake identity", "err", phs.ID)        c.close(DiscUnexpectedIdentity)        return    }    c.caps, c.name = phs.Caps, phs.Name    // 这里两次握手都已经完成了。 把c发送给addpeer队列。 后台处理这个队列的时候，会处理这个连接    if err := srv.checkpoint(c, srv.addpeer); err != nil {        clog.Trace("Rejected peer", "err", err)        c.close(err)        return    }    // If the checks completed successfully, runPeer has now been    // launched by run.}</code></pre><p>上面说到的流程是listenLoop的流程，listenLoop主要是用来接收外部主动连接者的。 还有部分情况是节点需要主动发起连接来连接外部节点的流程。  以及处理刚才上面的checkpoint队列信息的流程。这部分代码都在server.run这个goroutine里面。</p><pre><code>func (srv *Server) run(dialstate dialer) {    defer srv.loopWG.Done()    var (        peers        = make(map[discover.NodeID]*Peer)        trusted      = make(map[discover.NodeID]bool, len(srv.TrustedNodes))        taskdone     = make(chan task, maxActiveDialTasks)        runningTasks []task        queuedTasks  []task // tasks that can't run yet    )    // Put trusted nodes into a map to speed up checks.    // Trusted peers are loaded on startup and cannot be    // modified while the server is running.    // 被信任的节点又这样一个特性， 如果连接太多，那么其他节点会被拒绝掉。但是被信任的节点会被接收。    for _, n := range srv.TrustedNodes {        trusted[n.ID] = true    }    // removes t from runningTasks    // 定义了一个函数，用来从runningTasks队列删除某个Task    delTask := func(t task) {        for i := range runningTasks {            if runningTasks[i] == t {                runningTasks = append(runningTasks[:i], runningTasks[i+1:]...)                break            }        }    }    // starts until max number of active tasks is satisfied    // 同时开始连接的节点数量是16个。 遍历 runningTasks队列，并启动这些任务。    startTasks := func(ts []task) (rest []task) {        i := 0        for ; len(runningTasks) &lt; maxActiveDialTasks &amp;&amp; i &lt; len(ts); i++ {            t := ts[i]            log.Trace("New dial task", "task", t)            go func() { t.Do(srv); taskdone &lt;- t }()            runningTasks = append(runningTasks, t)        }        return ts[i:]    }    scheduleTasks := func() {        // Start from queue first.        // 首先调用startTasks启动一部分，把剩下的返回给queuedTasks.        queuedTasks = append(queuedTasks[:0], startTasks(queuedTasks)...)        // Query dialer for new tasks and start as many as possible now.        // 调用newTasks来生成任务，并尝试用startTasks启动。并把暂时无法启动的放入queuedTasks队列        if len(runningTasks) &lt; maxActiveDialTasks {            nt := dialstate.newTasks(len(runningTasks)+len(queuedTasks), peers, time.Now())            queuedTasks = append(queuedTasks, startTasks(nt)...)        }    }running:    for {        //调用 dialstate.newTasks来生成新任务。 并调用startTasks启动新任务。        //如果 dialTask已经全部启动，那么会生成一个睡眠超时任务。        scheduleTasks()        select {        case &lt;-srv.quit:            // The server was stopped. Run the cleanup logic.            break running        case n := &lt;-srv.addstatic:            // This channel is used by AddPeer to add to the            // ephemeral static peer list. Add it to the dialer,            // it will keep the node connected.            log.Debug("Adding static node", "node", n)            dialstate.addStatic(n)        case n := &lt;-srv.removestatic:            // This channel is used by RemovePeer to send a            // disconnect request to a peer and begin the            // stop keeping the node connected            log.Debug("Removing static node", "node", n)            dialstate.removeStatic(n)            if p, ok := peers[n.ID]; ok {                p.Disconnect(DiscRequested)            }        case op := &lt;-srv.peerOp:            // This channel is used by Peers and PeerCount.            op(peers)            srv.peerOpDone &lt;- struct{}{}        case t := &lt;-taskdone:            // A task got done. Tell dialstate about it so it            // can update its state and remove it from the active            // tasks list.            log.Trace("Dial task done", "task", t)            dialstate.taskDone(t, time.Now())            delTask(t)        case c := &lt;-srv.posthandshake:            // A connection has passed the encryption handshake so            // the remote identity is known (but hasn't been verified yet).            // 记得之前调用checkpoint方法，会把连接发送给这个channel。            if trusted[c.id] {                // Ensure that the trusted flag is set before checking against MaxPeers.                c.flags |= trustedConn            }            // TODO: track in-progress inbound node IDs (pre-Peer) to avoid dialing them.            select {            case c.cont &lt;- srv.encHandshakeChecks(peers, c):            case &lt;-srv.quit:                break running            }        case c := &lt;-srv.addpeer:            // At this point the connection is past the protocol handshake.            // Its capabilities are known and the remote identity is verified.            // 两次握手之后会调用checkpoint把连接发送到addpeer这个channel。            // 然后通过newPeer创建了Peer对象。             // 启动一个goroutine 启动peer对象。 调用了peer.run方法。            err := srv.protoHandshakeChecks(peers, c)            if err == nil {                // The handshakes are done and it passed all checks.                p := newPeer(c, srv.Protocols)                // If message events are enabled, pass the peerFeed                // to the peer                if srv.EnableMsgEvents {                    p.events = &amp;srv.peerFeed                }                name := truncateName(c.name)                log.Debug("Adding p2p peer", "id", c.id, "name", name, "addr", c.fd.RemoteAddr(), "peers", len(peers)+1)                peers[c.id] = p                go srv.runPeer(p)            }            // The dialer logic relies on the assumption that            // dial tasks complete after the peer has been added or            // discarded. Unblock the task last.            select {            case c.cont &lt;- err:            case &lt;-srv.quit:                break running            }        case pd := &lt;-srv.delpeer:            // A peer disconnected.            d := common.PrettyDuration(mclock.Now() - pd.created)            pd.log.Debug("Removing p2p peer", "duration", d, "peers", len(peers)-1, "req", pd.requested, "err", pd.err)            delete(peers, pd.ID())        }    }    log.Trace("P2P networking is spinning down")    // Terminate discovery. If there is a running lookup it will terminate soon.    if srv.ntab != nil {        srv.ntab.Close()    }    if srv.DiscV5 != nil {        srv.DiscV5.Close()    }    // Disconnect all peers.    for _, p := range peers {        p.Disconnect(DiscQuitting)    }    // Wait for peers to shut down. Pending connections and tasks are    // not handled here and will terminate soon-ish because srv.quit    // is closed.    for len(peers) &gt; 0 {        p := &lt;-srv.delpeer        p.log.Trace("&lt;-delpeer (spindown)", "remainingTasks", len(runningTasks))        delete(peers, p.ID())    }}</code></pre><p>runPeer方法</p><pre><code>// runPeer runs in its own goroutine for each peer.// it waits until the Peer logic returns and removes// the peer.func (srv *Server) runPeer(p *Peer) {    if srv.newPeerHook != nil {        srv.newPeerHook(p)    }    // broadcast peer add    srv.peerFeed.Send(&amp;PeerEvent{        Type: PeerEventTypeAdd,        Peer: p.ID(),    })    // run the protocol    remoteRequested, err := p.run()    // broadcast peer drop    srv.peerFeed.Send(&amp;PeerEvent{        Type:  PeerEventTypeDrop,        Peer:  p.ID(),        Error: err.Error(),    })    // Note: run waits for existing peers to be sent on srv.delpeer    // before returning, so this send should not select on srv.quit.    srv.delpeer &lt;- peerDrop{p, err, remoteRequested}}</code></pre><p>总结：</p><p>server对象主要完成的工作把之前介绍的所有组件组合在一起。 使用rlpx.go来处理加密链路。 使用discover来处理节点发现和查找。  使用dial来生成和连接需要连接的节点。 使用peer对象来处理每个连接。</p><p>server启动了一个listenLoop来监听和接收新的连接。 启动一个run的goroutine来调用dialstate生成新的dial任务并进行连接。 goroutine之间使用channel来进行通讯和配合。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-p2p-table.go源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-table.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-table.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>table.go主要实现了p2p的Kademlia协议。</p><h3 id="Kademlia协议简介-建议阅读references里面的pdf文档"><a href="#Kademlia协议简介-建议阅读references里面的pdf文档" class="headerlink" title="Kademlia协议简介(建议阅读references里面的pdf文档)"></a>Kademlia协议简介(建议阅读references里面的pdf文档)</h3><p>Kademlia协议（以下简称Kad） 是美国纽约大学的PetarP. Maymounkov和David Mazieres.<br>在2002年发布的一项研究结果《Kademlia: A peerto -peer information system based on<br>the XOR metric》。<br>简单的说， Kad 是一种分布式哈希表（ DHT） 技术， 不过和其他 DHT 实现技术比较，如<br>Chord、 CAN、 Pastry 等， Kad 通过独特的以异或算法（ XOR）为距离度量基础，建立了一种<br>全新的 DHT 拓扑结构，相比于其他算法，大大提高了路由查询速度。</p><h3 id="table的结构和字段"><a href="#table的结构和字段" class="headerlink" title="table的结构和字段"></a>table的结构和字段</h3><pre><code>const (    alpha      = 3  // Kademlia concurrency factor    bucketSize = 16 // Kademlia bucket size    hashBits   = len(common.Hash{}) * 8    nBuckets   = hashBits + 1 // Number of buckets    maxBondingPingPongs = 16    maxFindnodeFailures = 5    autoRefreshInterval = 1 * time.Hour    seedCount           = 30    seedMaxAge          = 5 * 24 * time.Hour)type Table struct {    mutex   sync.Mutex        // protects buckets, their content, and nursery    buckets [nBuckets]*bucket // index of known nodes by distance    nursery []*Node           // bootstrap nodes    db      *nodeDB           // database of known nodes    refreshReq chan chan struct{}    closeReq   chan struct{}    closed     chan struct{}    bondmu    sync.Mutex    bonding   map[NodeID]*bondproc    bondslots chan struct{} // limits total number of active bonding processes    nodeAddedHook func(*Node) // for testing    net  transport    self *Node // metadata of the local node}</code></pre><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><pre><code>func newTable(t transport, ourID NodeID, ourAddr *net.UDPAddr, nodeDBPath string) (*Table, error) {    // If no node database was given, use an in-memory one    //这个在之前的database.go里面有介绍。 打开leveldb。如果path为空。那么打开一个基于内存的db    db, err := newNodeDB(nodeDBPath, Version, ourID)    if err != nil {        return nil, err    }    tab := &amp;Table{        net:        t,        db:         db,        self:       NewNode(ourID, ourAddr.IP, uint16(ourAddr.Port), uint16(ourAddr.Port)),        bonding:    make(map[NodeID]*bondproc),        bondslots:  make(chan struct{}, maxBondingPingPongs),        refreshReq: make(chan chan struct{}),        closeReq:   make(chan struct{}),        closed:     make(chan struct{}),    }    for i := 0; i &lt; cap(tab.bondslots); i++ {        tab.bondslots &lt;- struct{}{}    }    for i := range tab.buckets {        tab.buckets[i] = new(bucket)    }    go tab.refreshLoop()    return tab, nil}</code></pre><p>上面的初始化启动了一个goroutine refreshLoop()，这个函数主要完成以下的工作。</p><ol><li>每一个小时进行一次刷新工作(autoRefreshInterval)</li><li>如果接收到refreshReq请求。那么进行刷新工作。</li><li>如果接收到关闭消息。那么进行关闭。</li></ol><p>所以函数主要的工作就是启动刷新工作。doRefresh</p><pre><code>// refreshLoop schedules doRefresh runs and coordinates shutdown.func (tab *Table) refreshLoop() {    var (        timer   = time.NewTicker(autoRefreshInterval)        waiting []chan struct{} // accumulates waiting callers while doRefresh runs        done    chan struct{}   // where doRefresh reports completion    )loop:    for {        select {        case &lt;-timer.C:            if done == nil {                done = make(chan struct{})                go tab.doRefresh(done)            }        case req := &lt;-tab.refreshReq:            waiting = append(waiting, req)            if done == nil {                done = make(chan struct{})                go tab.doRefresh(done)            }        case &lt;-done:            for _, ch := range waiting {                close(ch)            }            waiting = nil            done = nil        case &lt;-tab.closeReq:            break loop        }    }    if tab.net != nil {        tab.net.close()    }    if done != nil {        &lt;-done    }    for _, ch := range waiting {        close(ch)    }    tab.db.close()    close(tab.closed)}</code></pre><p>doRefresh函数</p><pre><code>// doRefresh performs a lookup for a random target to keep buckets// full. seed nodes are inserted if the table is empty (initial// bootstrap or discarded faulty peers).// doRefresh 随机查找一个目标，以便保持buckets是满的。如果table是空的，那么种子节点会插入。 （比如最开始的启动或者是删除错误的节点之后）func (tab *Table) doRefresh(done chan struct{}) {    defer close(done)    // The Kademlia paper specifies that the bucket refresh should    // perform a lookup in the least recently used bucket. We cannot    // adhere to this because the findnode target is a 512bit value    // (not hash-sized) and it is not easily possible to generate a    // sha3 preimage that falls into a chosen bucket.    // We perform a lookup with a random target instead.    //这里暂时没看懂    var target NodeID    rand.Read(target[:])    result := tab.lookup(target, false) //lookup是查找距离target最近的k个节点    if len(result) &gt; 0 {  //如果结果不为0 说明表不是空的，那么直接返回。        return    }    // The table is empty. Load nodes from the database and insert    // them. This should yield a few previously seen nodes that are    // (hopefully) still alive.    //querySeeds函数在database.go章节有介绍，从数据库里面随机的查找可用的种子节点。    //在最开始启动的时候数据库是空白的。也就是最开始的时候这个seeds返回的是空的。    seeds := tab.db.querySeeds(seedCount, seedMaxAge)    //调用bondall函数。会尝试联系这些节点，并插入到表中。    //tab.nursery是在命令行中指定的种子节点。    //最开始启动的时候。 tab.nursery的值是内置在代码里面的。 这里是有值的。    //C:\GOPATH\src\github.com\ethereum\go-ethereum\mobile\params.go    //这里面写死了值。 这个值是通过SetFallbackNodes方法写入的。 这个方法后续会分析。    //这里会进行双向的pingpong交流。 然后把结果存储在数据库。    seeds = tab.bondall(append(seeds, tab.nursery...))    if len(seeds) == 0 { //没有种子节点被发现， 可能需要等待下一次刷新。        log.Debug("No discv4 seed nodes found")    }    for _, n := range seeds {        age := log.Lazy{Fn: func() time.Duration { return time.Since(tab.db.lastPong(n.ID)) }}        log.Trace("Found seed node in database", "id", n.ID, "addr", n.addr(), "age", age)    }    tab.mutex.Lock()    //这个方法把所有经过bond的seed加入到bucket(前提是bucket未满)    tab.stuff(seeds)     tab.mutex.Unlock()    // Finally, do a self lookup to fill up the buckets.    tab.lookup(tab.self.ID, false) // 有了种子节点。那么查找自己来填充buckets。}</code></pre><p>bondall方法，这个方法就是多线程的调用bond方法。 </p><pre><code>// bondall bonds with all given nodes concurrently and returns// those nodes for which bonding has probably succeeded.func (tab *Table) bondall(nodes []*Node) (result []*Node) {    rc := make(chan *Node, len(nodes))    for i := range nodes {        go func(n *Node) {            nn, _ := tab.bond(false, n.ID, n.addr(), uint16(n.TCP))            rc &lt;- nn        }(nodes[i])    }    for range nodes {        if n := &lt;-rc; n != nil {            result = append(result, n)        }    }    return result}</code></pre><p>bond方法。记得在udp.go中。当我们收到一个ping方法的时候，也有可能会调用这个方法</p><pre><code>// bond ensures the local node has a bond with the given remote node.// It also attempts to insert the node into the table if bonding succeeds.// The caller must not hold tab.mutex.// bond确保本地节点与给定的远程节点具有绑定。(远端的ID和远端的IP)。// 如果绑定成功，它也会尝试将节点插入表中。调用者必须持有tab.mutex锁// A bond is must be established before sending findnode requests.// Both sides must have completed a ping/pong exchange for a bond to// exist. The total number of active bonding processes is limited in// order to restrain network use.// 发送findnode请求之前必须建立一个绑定。    双方为了完成一个bond必须完成双向的ping/pong过程。// 为了节约网路资源。 同时存在的bonding处理流程的总数量是受限的。    // bond is meant to operate idempotently in that bonding with a remote// node which still remembers a previously established bond will work.// The remote node will simply not send a ping back, causing waitping// to time out.// bond 是幂等的操作，跟一个任然记得之前的bond的远程节点进行bond也可以完成。 远程节点会简单的不会发送ping。 等待waitping超时。// If pinged is true, the remote node has just pinged us and one half// of the process can be skipped.//    如果pinged是true。 那么远端节点已经给我们发送了ping消息。这样一半的流程可以跳过。func (tab *Table) bond(pinged bool, id NodeID, addr *net.UDPAddr, tcpPort uint16) (*Node, error) {    if id == tab.self.ID {        return nil, errors.New("is self")    }    // Retrieve a previously known node and any recent findnode failures    node, fails := tab.db.node(id), 0    if node != nil {        fails = tab.db.findFails(id)    }    // If the node is unknown (non-bonded) or failed (remotely unknown), bond from scratch    var result error    age := time.Since(tab.db.lastPong(id))    if node == nil || fails &gt; 0 || age &gt; nodeDBNodeExpiration {        //如果数据库没有这个节点。 或者错误数量大于0或者节点超时。        log.Trace("Starting bonding ping/pong", "id", id, "known", node != nil, "failcount", fails, "age", age)        tab.bondmu.Lock()        w := tab.bonding[id]        if w != nil {            // Wait for an existing bonding process to complete.            tab.bondmu.Unlock()            &lt;-w.done        } else {            // Register a new bonding process.            w = &amp;bondproc{done: make(chan struct{})}            tab.bonding[id] = w            tab.bondmu.Unlock()            // Do the ping/pong. The result goes into w.            tab.pingpong(w, pinged, id, addr, tcpPort)            // Unregister the process after it's done.            tab.bondmu.Lock()            delete(tab.bonding, id)            tab.bondmu.Unlock()        }        // Retrieve the bonding results        result = w.err        if result == nil {            node = w.n        }    }    if node != nil {        // Add the node to the table even if the bonding ping/pong        // fails. It will be relaced quickly if it continues to be        // unresponsive.        //这个方法比较重要。 如果对应的bucket有空间，会直接插入buckets。如果buckets满了。 会用ping操作来测试buckets中的节点试图腾出空间。        tab.add(node)        tab.db.updateFindFails(id, 0)    }    return node, result}</code></pre><p>pingpong方法</p><pre><code>func (tab *Table) pingpong(w *bondproc, pinged bool, id NodeID, addr *net.UDPAddr, tcpPort uint16) {    // Request a bonding slot to limit network usage    &lt;-tab.bondslots    defer func() { tab.bondslots &lt;- struct{}{} }()    // Ping the remote side and wait for a pong.    // Ping远程节点。并等待一个pong消息    if w.err = tab.ping(id, addr); w.err != nil {        close(w.done)        return    }    //这个在udp收到一个ping消息的时候被设置为真。这个时候我们已经收到对方的ping消息了。    //那么我们就不同等待ping消息了。 否则需要等待对方发送过来的ping消息(我们主动发起ping消息)。    if !pinged {        // Give the remote node a chance to ping us before we start        // sending findnode requests. If they still remember us,        // waitping will simply time out.        tab.net.waitping(id)    }    // Bonding succeeded, update the node database.    // 完成bond过程。 把节点插入数据库。 数据库操作在这里完成。 bucket的操作在tab.add里面完成。 buckets是内存的操作。 数据库是持久化的seeds节点。用来加速启动过程的。    w.n = NewNode(id, addr.IP, uint16(addr.Port), tcpPort)    tab.db.updateNode(w.n)    close(w.done)}</code></pre><p>tab.add方法</p><pre><code>// add attempts to add the given node its corresponding bucket. If the// bucket has space available, adding the node succeeds immediately.// Otherwise, the node is added if the least recently active node in// the bucket does not respond to a ping packet.// add试图把给定的节点插入对应的bucket。 如果bucket有空间，那么直接插入。 否则，如果bucket中最近活动的节点没有响应ping操作，那么我们就使用这个节点替换它。// The caller must not hold tab.mutex.func (tab *Table) add(new *Node) {    b := tab.buckets[logdist(tab.self.sha, new.sha)]    tab.mutex.Lock()    defer tab.mutex.Unlock()    if b.bump(new) { //如果节点存在。那么更新它的值。然后退出。        return    }    var oldest *Node    if len(b.entries) == bucketSize {        oldest = b.entries[bucketSize-1]        if oldest.contested {            // The node is already being replaced, don't attempt            // to replace it.            // 如果别的goroutine正在对这个节点进行测试。 那么取消替换， 直接退出。            // 因为ping的时间比较长。所以这段时间是没有加锁的。 用了contested这个状态来标识这种情况。             return        }        oldest.contested = true        // Let go of the mutex so other goroutines can access        // the table while we ping the least recently active node.        tab.mutex.Unlock()        err := tab.ping(oldest.ID, oldest.addr())        tab.mutex.Lock()        oldest.contested = false        if err == nil {            // The node responded, don't replace it.            return        }    }    added := b.replace(new, oldest)    if added &amp;&amp; tab.nodeAddedHook != nil {        tab.nodeAddedHook(new)    }}</code></pre><p>stuff方法比较简单。  找到对应节点应该插入的bucket。 如果这个bucket没有满，那么就插入这个bucket。否则什么也不做。 需要说一下的是logdist()这个方法。这个方法对两个值进行按照位置异或，然后返回最高位的下标。  比如   logdist(101,010) = 3   logdist(100, 100) = 0 logdist(100,110) = 2</p><pre><code>// stuff adds nodes the table to the end of their corresponding bucket// if the bucket is not full. The caller must hold tab.mutex.func (tab *Table) stuff(nodes []*Node) {outer:    for _, n := range nodes {        if n.ID == tab.self.ID {            continue // don't add self        }        bucket := tab.buckets[logdist(tab.self.sha, n.sha)]        for i := range bucket.entries {            if bucket.entries[i].ID == n.ID {                continue outer // already in bucket            }        }        if len(bucket.entries) &lt; bucketSize {            bucket.entries = append(bucket.entries, n)            if tab.nodeAddedHook != nil {                tab.nodeAddedHook(n)            }        }    }}</code></pre><p>在看看之前的Lookup函数。 这个函数用来查询一个指定节点的信息。  这个函数首先从本地拿到距离这个节点最近的所有16个节点。 然后给所有的节点发送findnode的请求。 然后对返回的界定进行bondall处理。 然后返回所有的节点。</p><pre><code>func (tab *Table) lookup(targetID NodeID, refreshIfEmpty bool) []*Node {    var (        target         = crypto.Keccak256Hash(targetID[:])        asked          = make(map[NodeID]bool)        seen           = make(map[NodeID]bool)        reply          = make(chan []*Node, alpha)        pendingQueries = 0        result         *nodesByDistance    )    // don't query further if we hit ourself.    // unlikely to happen often in practice.    asked[tab.self.ID] = true    不会询问我们自己    for {        tab.mutex.Lock()        // generate initial result set        result = tab.closest(target, bucketSize)        //求取和target最近的16个节点        tab.mutex.Unlock()        if len(result.entries) &gt; 0 || !refreshIfEmpty {            break        }        // The result set is empty, all nodes were dropped, refresh.        // We actually wait for the refresh to complete here. The very        // first query will hit this case and run the bootstrapping        // logic.        &lt;-tab.refresh()        refreshIfEmpty = false    }    for {        // ask the alpha closest nodes that we haven't asked yet        // 这里会并发的查询，每次3个goroutine并发(通过pendingQueries参数进行控制)        // 每次迭代会查询result中和target距离最近的三个节点。        for i := 0; i &lt; len(result.entries) &amp;&amp; pendingQueries &lt; alpha; i++ {            n := result.entries[i]            if !asked[n.ID] { //如果没有查询过 //因为这个result.entries会被重复循环很多次。 所以用这个变量控制那些已经处理过了。                asked[n.ID] = true                pendingQueries++                go func() {                    // Find potential neighbors to bond with                    r, err := tab.net.findnode(n.ID, n.addr(), targetID)                    if err != nil {                        // Bump the failure counter to detect and evacuate non-bonded entries                        fails := tab.db.findFails(n.ID) + 1                        tab.db.updateFindFails(n.ID, fails)                        log.Trace("Bumping findnode failure counter", "id", n.ID, "failcount", fails)                        if fails &gt;= maxFindnodeFailures {                            log.Trace("Too many findnode failures, dropping", "id", n.ID, "failcount", fails)                            tab.delete(n)                        }                    }                    reply &lt;- tab.bondall(r)                }()            }        }        if pendingQueries == 0 {            // we have asked all closest nodes, stop the search            break        }        // wait for the next reply        for _, n := range &lt;-reply {            if n != nil &amp;&amp; !seen[n.ID] { //因为不同的远方节点可能返回相同的节点。所有用seen[]来做排重。                seen[n.ID] = true                //这个地方需要注意的是, 查找出来的结果又会加入result这个队列。也就是说这是一个循环查找的过程， 只要result里面不断加入新的节点。这个循环就不会终止。                result.push(n, bucketSize)            }        }        pendingQueries--    }    return result.entries}// closest returns the n nodes in the table that are closest to the// given id. The caller must hold tab.mutex.func (tab *Table) closest(target common.Hash, nresults int) *nodesByDistance {    // This is a very wasteful way to find the closest nodes but    // obviously correct. I believe that tree-based buckets would make    // this easier to implement efficiently.    close := &amp;nodesByDistance{target: target}    for _, b := range tab.buckets {        for _, n := range b.entries {            close.push(n, nresults)        }    }    return close}</code></pre><p>result.push方法，这个方法会根据 所有的节点对于target的距离进行排序。 按照从近到远的方式决定新节点的插入顺序。(队列中最大会包含16个元素)。 这样会导致队列里面的元素和target的距离越来越近。距离相对远的会被踢出队列。</p><pre><code>// nodesByDistance is a list of nodes, ordered by// distance to target.type nodesByDistance struct {    entries []*Node    target  common.Hash}// push adds the given node to the list, keeping the total size below maxElems.func (h *nodesByDistance) push(n *Node, maxElems int) {    ix := sort.Search(len(h.entries), func(i int) bool {        return distcmp(h.target, h.entries[i].sha, n.sha) &gt; 0    })    if len(h.entries) &lt; maxElems {        h.entries = append(h.entries, n)    }    if ix == len(h.entries) {        // farther away than all nodes we already have.        // if there was room for it, the node is now the last element.    } else {        // slide existing entries down to make room        // this will overwrite the entry we just appended.        copy(h.entries[ix+1:], h.entries[ix:])        h.entries[ix] = n    }}</code></pre><h3 id="table-go-导出的一些方法"><a href="#table-go-导出的一些方法" class="headerlink" title="table.go 导出的一些方法"></a>table.go 导出的一些方法</h3><p>Resolve方法和Lookup方法</p><pre><code>// Resolve searches for a specific node with the given ID.// It returns nil if the node could not be found.//Resolve方法用来获取一个指定ID的节点。 如果节点在本地。那么返回本地节点。 否则执行//Lookup在网络上查询一次。 如果查询到节点。那么返回。否则返回nilfunc (tab *Table) Resolve(targetID NodeID) *Node {    // If the node is present in the local table, no    // network interaction is required.    hash := crypto.Keccak256Hash(targetID[:])    tab.mutex.Lock()    cl := tab.closest(hash, 1)    tab.mutex.Unlock()    if len(cl.entries) &gt; 0 &amp;&amp; cl.entries[0].ID == targetID {        return cl.entries[0]    }    // Otherwise, do a network lookup.    result := tab.Lookup(targetID)    for _, n := range result {        if n.ID == targetID {            return n        }    }    return nil}// Lookup performs a network search for nodes close// to the given target. It approaches the target by querying// nodes that are closer to it on each iteration.// The given target does not need to be an actual node// identifier.func (tab *Table) Lookup(targetID NodeID) []*Node {    return tab.lookup(targetID, true)}</code></pre><p>SetFallbackNodes方法，这个方法设置初始化的联系节点。 在table是空而且数据库里面也没有已知的节点，这些节点可以帮助连接上网络，</p><pre><code>// SetFallbackNodes sets the initial points of contact. These nodes// are used to connect to the network if the table is empty and there// are no known nodes in the database.func (tab *Table) SetFallbackNodes(nodes []*Node) error {    for _, n := range nodes {        if err := n.validateComplete(); err != nil {            return fmt.Errorf("bad bootstrap/fallback node %q (%v)", n, err)        }    }    tab.mutex.Lock()    tab.nursery = make([]*Node, 0, len(nodes))    for _, n := range nodes {        cpy := *n        // Recompute cpy.sha because the node might not have been        // created by NewNode or ParseNode.        cpy.sha = crypto.Keccak256Hash(n.ID[:])        tab.nursery = append(tab.nursery, &amp;cpy)    }    tab.mutex.Unlock()    tab.refresh()    return nil}</code></pre><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这样， p2p网络的Kademlia协议就完结了。 基本上是按照论文进行实现。 udp进行网络通信。数据库存储链接过的节点。 table实现了Kademlia的核心。 根据异或距离来进行节点的查找。 节点的发现和更新等流程。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-p2p-udp.go源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-udp.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-p2p-udp.go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>p2p的网络发现协议使用了Kademlia protocol 来处理网络的节点发现。节点查找和节点更新。Kademlia protocol使用了UDP协议来进行网络通信。</p><p>阅读这部分的代码建议先看看references里面的Kademlia协议简介来看看什么是Kademlia协议。</p><p>首先看看数据结构。 网络传输了4种数据包(UDP协议是基于报文的协议。传输的是一个一个数据包)，分别是ping,pong,findnode和neighbors。 下面分别定义了4种报文的格式。 </p><pre><code>// RPC packet typesconst (    pingPacket = iota + 1 // zero is 'reserved'    pongPacket    findnodePacket    neighborsPacket)// RPC request structurestype (    ping struct {        Version    uint             //协议版本        From, To   rpcEndpoint        //源IP地址 目的IP地址        Expiration uint64            //超时时间        // Ignore additional fields (for forward compatibility).        //可以忽略的字段。 为了向前兼容        Rest []rlp.RawValue `rlp:"tail"`    }    // pong is the reply to ping.    // ping包的回应    pong struct {        // This field should mirror the UDP envelope address        // of the ping packet, which provides a way to discover the        // the external address (after NAT).        // 目的IP地址        To rpcEndpoint        // 说明这个pong包是回应那个ping包的。 包含了ping包的hash值        ReplyTok   []byte // This contains the hash of the ping packet.        //包超时的绝对时间。 如果收到包的时候超过了这个时间，那么包被认为是超时的。        Expiration uint64 // Absolute timestamp at which the packet becomes invalid.        // Ignore additional fields (for forward compatibility).        Rest []rlp.RawValue `rlp:"tail"`    }    // findnode 是用来查询距离target比较近的节点    // findnode is a query for nodes close to the given target.    findnode struct {        // 目的节点        Target     NodeID // doesn't need to be an actual public key        Expiration uint64        // Ignore additional fields (for forward compatibility).        Rest []rlp.RawValue `rlp:"tail"`    }    // reply to findnode    // findnode的回应    neighbors struct {        //距离target比较近的节点值。        Nodes      []rpcNode        Expiration uint64        // Ignore additional fields (for forward compatibility).        Rest []rlp.RawValue `rlp:"tail"`    }    rpcNode struct {        IP  net.IP // len 4 for IPv4 or 16 for IPv6        UDP uint16 // for discovery protocol        TCP uint16 // for RLPx protocol        ID  NodeID    }    rpcEndpoint struct {        IP  net.IP // len 4 for IPv4 or 16 for IPv6        UDP uint16 // for discovery protocol        TCP uint16 // for RLPx protocol    })</code></pre><p>定义了两个接口类型，packet接口类型应该是给4种不同类型的包分派不同的handle方法。 conn接口定义了一个udp的连接的功能。</p><pre><code>type packet interface {    handle(t *udp, from *net.UDPAddr, fromID NodeID, mac []byte) error    name() string}type conn interface {    ReadFromUDP(b []byte) (n int, addr *net.UDPAddr, err error)    WriteToUDP(b []byte, addr *net.UDPAddr) (n int, err error)    Close() error    LocalAddr() net.Addr}</code></pre><p>udp的结构， 需要注意的是最后一个字段*Table是go里面的匿名字段。  也就是说udp可以直接调用匿名字段Table的方法。</p><pre><code>// udp implements the RPC protocol.type udp struct {    conn        conn                    //网络连接    netrestrict *netutil.Netlist    priv        *ecdsa.PrivateKey        //私钥，自己的ID是通过这个来生成的。    ourEndpoint rpcEndpoint    addpending chan *pending            //用来申请一个pending    gotreply   chan reply                //用来获取回应的队列    closing chan struct{}                //用来关闭的队列    nat     nat.Interface                    *Table}</code></pre><p>pending 和reply 结构。 这两个结构用户内部的go routine之间进行通信的结构体。</p><pre><code>// pending represents a pending reply.// some implementations of the protocol wish to send more than one// reply packet to findnode. in general, any neighbors packet cannot// be matched up with a specific findnode packet.// our implementation handles this by storing a callback function for// each pending reply. incoming packets from a node are dispatched// to all the callback functions for that node.// pending结构 代表正在等待一个reply// 我们通过为每一个pending reply 存储一个callback来实现这个功能。从一个节点来的所有数据包都会分配到这个节点对应的callback上面。type pending struct {    // these fields must match in the reply.    from  NodeID    ptype byte    // time when the request must complete    deadline time.Time    // callback is called when a matching reply arrives. if it returns    // true, the callback is removed from the pending reply queue.    // if it returns false, the reply is considered incomplete and    // the callback will be invoked again for the next matching reply.    //如果返回值是true。那么callback会从队列里面移除。 如果返回false,那么认为reply还没有完成，会继续等待下一次reply.    callback func(resp interface{}) (done bool)    // errc receives nil when the callback indicates completion or an    // error if no further reply is received within the timeout.    errc chan&lt;- error}type reply struct {    from  NodeID    ptype byte    data  interface{}    // loop indicates whether there was    // a matching request by sending on this channel.    //通过往这个channel上面发送消息来表示匹配到一个请求。    matched chan&lt;- bool}</code></pre><p>UDP的创建</p><pre><code>// ListenUDP returns a new table that listens for UDP packets on laddr.func ListenUDP(priv *ecdsa.PrivateKey, laddr string, natm nat.Interface, nodeDBPath string, netrestrict *netutil.Netlist) (*Table, error) {    addr, err := net.ResolveUDPAddr("udp", laddr)    if err != nil {        return nil, err    }    conn, err := net.ListenUDP("udp", addr)    if err != nil {        return nil, err    }    tab, _, err := newUDP(priv, conn, natm, nodeDBPath, netrestrict)    if err != nil {        return nil, err    }    log.Info("UDP listener up", "self", tab.self)    return tab, nil}func newUDP(priv *ecdsa.PrivateKey, c conn, natm nat.Interface, nodeDBPath string, netrestrict *netutil.Netlist) (*Table, *udp, error) {    udp := &amp;udp{        conn:        c,        priv:        priv,        netrestrict: netrestrict,        closing:     make(chan struct{}),        gotreply:    make(chan reply),        addpending:  make(chan *pending),    }    realaddr := c.LocalAddr().(*net.UDPAddr)    if natm != nil {   //natm nat mapping 用来获取外网地址        if !realaddr.IP.IsLoopback() {  //如果地址是本地环回地址            go nat.Map(natm, udp.closing, "udp", realaddr.Port, realaddr.Port, "ethereum discovery")        }        // TODO: react to external IP changes over time.        if ext, err := natm.ExternalIP(); err == nil {            realaddr = &amp;net.UDPAddr{IP: ext, Port: realaddr.Port}        }    }    // TODO: separate TCP port    udp.ourEndpoint = makeEndpoint(realaddr, uint16(realaddr.Port))    //创建一个table 后续会介绍。 Kademlia的主要逻辑在这个类里面实现。    tab, err := newTable(udp, PubkeyID(&amp;priv.PublicKey), realaddr, nodeDBPath)    if err != nil {        return nil, nil, err    }    udp.Table = tab   //匿名字段的赋值        go udp.loop()        //go routine     go udp.readLoop()    //用来网络数据读取。    return udp.Table, udp, nil}</code></pre><p>ping方法与pending的处理，之前谈到了pending是等待一个reply。 这里通过代码来分析是如何实现等待reply的。</p><p>pending方法把pending结构体发送给addpending. 然后等待消息的处理和接收。</p><pre><code>// ping sends a ping message to the given node and waits for a reply.func (t *udp) ping(toid NodeID, toaddr *net.UDPAddr) error {    // TODO: maybe check for ReplyTo field in callback to measure RTT    errc := t.pending(toid, pongPacket, func(interface{}) bool { return true })    t.send(toaddr, pingPacket, &amp;ping{        Version:    Version,        From:       t.ourEndpoint,        To:         makeEndpoint(toaddr, 0), // TODO: maybe use known TCP port from DB        Expiration: uint64(time.Now().Add(expiration).Unix()),    })    return &lt;-errc}// pending adds a reply callback to the pending reply queue.// see the documentation of type pending for a detailed explanation.func (t *udp) pending(id NodeID, ptype byte, callback func(interface{}) bool) &lt;-chan error {    ch := make(chan error, 1)    p := &amp;pending{from: id, ptype: ptype, callback: callback, errc: ch}    select {    case t.addpending &lt;- p:        // loop will handle it    case &lt;-t.closing:        ch &lt;- errClosed    }    return ch}</code></pre><p>addpending消息的处理。 之前创建udp的时候调用了newUDP方法。里面启动了两个goroutine。 其中的loop()就是用来处理pending消息的。</p><pre><code>// loop runs in its own goroutine. it keeps track of// the refresh timer and the pending reply queue.func (t *udp) loop() {    var (        plist        = list.New()        timeout      = time.NewTimer(0)        nextTimeout  *pending // head of plist when timeout was last reset        contTimeouts = 0      // number of continuous timeouts to do NTP checks        ntpWarnTime  = time.Unix(0, 0)    )    &lt;-timeout.C // ignore first timeout    defer timeout.Stop()    resetTimeout := func() {          //这个方法的主要功能是查看队列里面是否有需要超时的pending消息。 如果有。那么        //根据最先超时的时间设置超时醒来。         if plist.Front() == nil || nextTimeout == plist.Front().Value {            return        }        // Start the timer so it fires when the next pending reply has expired.        now := time.Now()        for el := plist.Front(); el != nil; el = el.Next() {            nextTimeout = el.Value.(*pending)            if dist := nextTimeout.deadline.Sub(now); dist &lt; 2*respTimeout {                timeout.Reset(dist)                return            }            // Remove pending replies whose deadline is too far in the            // future. These can occur if the system clock jumped            // backwards after the deadline was assigned.            //如果有消息的deadline在很远的未来，那么直接设置超时，然后移除。            //这种情况在修改系统时间的时候有可能发生，如果不处理可能导致堵塞太长时间。            nextTimeout.errc &lt;- errClockWarp            plist.Remove(el)        }        nextTimeout = nil        timeout.Stop()    }    for {        resetTimeout()  //首先处理超时。        select {        case &lt;-t.closing:  //收到关闭信息。 超时所有的堵塞的队列            for el := plist.Front(); el != nil; el = el.Next() {                el.Value.(*pending).errc &lt;- errClosed            }            return        case p := &lt;-t.addpending:  //增加一个pending 设置deadline            p.deadline = time.Now().Add(respTimeout)            plist.PushBack(p)        case r := &lt;-t.gotreply:  //收到一个reply 寻找匹配的pending            var matched bool            for el := plist.Front(); el != nil; el = el.Next() {                p := el.Value.(*pending)                if p.from == r.from &amp;&amp; p.ptype == r.ptype { //如果来自同一个人。 而且类型相同                    matched = true                    // Remove the matcher if its callback indicates                    // that all replies have been received. This is                    // required for packet types that expect multiple                    // reply packets.                    if p.callback(r.data) { //如果callback返回值是true 。说明pending已经完成。 给p.errc写入nil。 pending完成。                        p.errc &lt;- nil                        plist.Remove(el)                    }                    // Reset the continuous timeout counter (time drift detection)                    contTimeouts = 0                }            }            r.matched &lt;- matched //写入reply的matched        case now := &lt;-timeout.C:   //处理超时信息            nextTimeout = nil            // Notify and remove callbacks whose deadline is in the past.            for el := plist.Front(); el != nil; el = el.Next() {                p := el.Value.(*pending)                if now.After(p.deadline) || now.Equal(p.deadline) { //如果超时写入超时信息并移除                    p.errc &lt;- errTimeout                    plist.Remove(el)                    contTimeouts++                }            }            // If we've accumulated too many timeouts, do an NTP time sync check            if contTimeouts &gt; ntpFailureThreshold {                //如果连续超时很多次。 那么查看是否是时间不同步。 和NTP服务器进行同步。                if time.Since(ntpWarnTime) &gt;= ntpWarningCooldown {                    ntpWarnTime = time.Now()                    go checkClockDrift()                }                contTimeouts = 0            }        }    }}</code></pre><p>上面看到了pending的处理。 不过loop()方法种还有一个gotreply的处理。 这个实在readLoop()这个goroutine中产生的。</p><pre><code>// readLoop runs in its own goroutine. it handles incoming UDP packets.func (t *udp) readLoop() {    defer t.conn.Close()    // Discovery packets are defined to be no larger than 1280 bytes.    // Packets larger than this size will be cut at the end and treated    // as invalid because their hash won't match.    buf := make([]byte, 1280)    for {        nbytes, from, err := t.conn.ReadFromUDP(buf)        if netutil.IsTemporaryError(err) {            // Ignore temporary read errors.            log.Debug("Temporary UDP read error", "err", err)            continue        } else if err != nil {            // Shut down the loop for permament errors.            log.Debug("UDP read error", "err", err)            return        }        t.handlePacket(from, buf[:nbytes])    }}func (t *udp) handlePacket(from *net.UDPAddr, buf []byte) error {    packet, fromID, hash, err := decodePacket(buf)    if err != nil {        log.Debug("Bad discv4 packet", "addr", from, "err", err)        return err    }    err = packet.handle(t, from, fromID, hash)    log.Trace("&lt;&lt; "+packet.name(), "addr", from, "err", err)    return err}func (req *ping) handle(t *udp, from *net.UDPAddr, fromID NodeID, mac []byte) error {    if expired(req.Expiration) {        return errExpired    }    t.send(from, pongPacket, &amp;pong{        To:         makeEndpoint(from, req.From.TCP),        ReplyTok:   mac,        Expiration: uint64(time.Now().Add(expiration).Unix()),    })    if !t.handleReply(fromID, pingPacket, req) {        // Note: we're ignoring the provided IP address right now        go t.bond(true, fromID, from, req.From.TCP)    }    return nil}func (t *udp) handleReply(from NodeID, ptype byte, req packet) bool {    matched := make(chan bool, 1)    select {    case t.gotreply &lt;- reply{from, ptype, req, matched}:        // loop will handle it        return &lt;-matched    case &lt;-t.closing:        return false    }}</code></pre><p>上面介绍了udp的大致处理的流程。 下面介绍下udp的主要处理的业务。 udp主要发送两种请求，对应的也会接收别人发送的这两种请求， 对应这两种请求又会产生两种回应。</p><p>ping请求，可以看到ping请求希望得到一个pong回答。 然后返回。</p><pre><code>// ping sends a ping message to the given node and waits for a reply.func (t *udp) ping(toid NodeID, toaddr *net.UDPAddr) error {    // TODO: maybe check for ReplyTo field in callback to measure RTT    errc := t.pending(toid, pongPacket, func(interface{}) bool { return true })    t.send(toaddr, pingPacket, &amp;ping{        Version:    Version,        From:       t.ourEndpoint,        To:         makeEndpoint(toaddr, 0), // TODO: maybe use known TCP port from DB        Expiration: uint64(time.Now().Add(expiration).Unix()),    })    return &lt;-errc}</code></pre><p>pong回答,如果pong回答没有匹配到一个对应的ping请求。那么返回errUnsolicitedReply异常。</p><pre><code>func (req *pong) handle(t *udp, from *net.UDPAddr, fromID NodeID, mac []byte) error {    if expired(req.Expiration) {        return errExpired    }    if !t.handleReply(fromID, pongPacket, req) {        return errUnsolicitedReply    }    return nil}</code></pre><p>findnode请求, 发送findnode请求，然后等待node回应 k个邻居。</p><pre><code>// findnode sends a findnode request to the given node and waits until// the node has sent up to k neighbors.func (t *udp) findnode(toid NodeID, toaddr *net.UDPAddr, target NodeID) ([]*Node, error) {    nodes := make([]*Node, 0, bucketSize)    nreceived := 0    errc := t.pending(toid, neighborsPacket, func(r interface{}) bool {        reply := r.(*neighbors)        for _, rn := range reply.Nodes {            nreceived++            n, err := t.nodeFromRPC(toaddr, rn)            if err != nil {                log.Trace("Invalid neighbor node received", "ip", rn.IP, "addr", toaddr, "err", err)                continue            }            nodes = append(nodes, n)        }        return nreceived &gt;= bucketSize    })    t.send(toaddr, findnodePacket, &amp;findnode{        Target:     target,        Expiration: uint64(time.Now().Add(expiration).Unix()),    })    err := &lt;-errc    return nodes, err}</code></pre><p>neighbors回应, 很简单。 把回应发送给gotreply队列。 如果没有找到匹配的findnode请求。返回errUnsolicitedReply错误</p><pre><code>func (req *neighbors) handle(t *udp, from *net.UDPAddr, fromID NodeID, mac []byte) error {    if expired(req.Expiration) {        return errExpired    }    if !t.handleReply(fromID, neighborsPacket, req) {        return errUnsolicitedReply    }    return nil}</code></pre><p>收到别的节点发送的ping请求，发送pong回答。 如果没有匹配上一个pending(说明不是自己方请求的结果)。 就调用bond方法把这个节点加入自己的bucket缓存。(这部分原理在table.go里面会详细介绍)</p><pre><code>func (req *ping) handle(t *udp, from *net.UDPAddr, fromID NodeID, mac []byte) error {    if expired(req.Expiration) {        return errExpired    }    t.send(from, pongPacket, &amp;pong{        To:         makeEndpoint(from, req.From.TCP),        ReplyTok:   mac,        Expiration: uint64(time.Now().Add(expiration).Unix()),    })    if !t.handleReply(fromID, pingPacket, req) {        // Note: we're ignoring the provided IP address right now        go t.bond(true, fromID, from, req.From.TCP)    }    return nil}</code></pre><p>收到别人发送的findnode请求。这个请求希望把和target距离相近的k个节点发送回去。 算法的详细请参考references目录下面的pdf文档。</p><pre><code>func (req *findnode) handle(t *udp, from *net.UDPAddr, fromID NodeID, mac []byte) error {    if expired(req.Expiration) {        return errExpired    }    if t.db.node(fromID) == nil {        // No bond exists, we don't process the packet. This prevents        // an attack vector where the discovery protocol could be used        // to amplify traffic in a DDOS attack. A malicious actor        // would send a findnode request with the IP address and UDP        // port of the target as the source address. The recipient of        // the findnode packet would then send a neighbors packet        // (which is a much bigger packet than findnode) to the victim.        return errUnknownNode    }    target := crypto.Keccak256Hash(req.Target[:])    t.mutex.Lock()    //获取bucketSize个和target距离相近的节点。 这个方法在table.go内部实现。后续会详细介绍    closest := t.closest(target, bucketSize).entries    t.mutex.Unlock()    p := neighbors{Expiration: uint64(time.Now().Add(expiration).Unix())}    // Send neighbors in chunks with at most maxNeighbors per packet    // to stay below the 1280 byte limit.    for i, n := range closest {        if netutil.CheckRelayIP(from.IP, n.IP) != nil {            continue        }        p.Nodes = append(p.Nodes, nodeToRPC(n))        if len(p.Nodes) == maxNeighbors || i == len(closest)-1 {            t.send(from, neighborsPacket, &amp;p)            p.Nodes = p.Nodes[:0]        }    }    return nil}</code></pre><h3 id="udp信息加密和安全问题"><a href="#udp信息加密和安全问题" class="headerlink" title="udp信息加密和安全问题"></a>udp信息加密和安全问题</h3><p>discover协议因为没有承载什么敏感数据，所以数据是以明文传输，但是为了确保数据的完整性和不被篡改，所以在数据包的包头加上了数字签名。</p><pre><code>func encodePacket(priv *ecdsa.PrivateKey, ptype byte, req interface{}) ([]byte, error) {    b := new(bytes.Buffer)    b.Write(headSpace)    b.WriteByte(ptype)    if err := rlp.Encode(b, req); err != nil {        log.Error("Can't encode discv4 packet", "err", err)        return nil, err    }    packet := b.Bytes()    sig, err := crypto.Sign(crypto.Keccak256(packet[headSize:]), priv)    if err != nil {        log.Error("Can't sign discv4 packet", "err", err)        return nil, err    }    copy(packet[macSize:], sig)    // add the hash to the front. Note: this doesn't protect the    // packet in any way. Our public key will be part of this hash in    // The future.    copy(packet, crypto.Keccak256(packet[macSize:]))    return packet, nil}func decodePacket(buf []byte) (packet, NodeID, []byte, error) {    if len(buf) &lt; headSize+1 {        return nil, NodeID{}, nil, errPacketTooSmall    }    hash, sig, sigdata := buf[:macSize], buf[macSize:headSize], buf[headSize:]    shouldhash := crypto.Keccak256(buf[macSize:])    if !bytes.Equal(hash, shouldhash) {        return nil, NodeID{}, nil, errBadHash    }    fromID, err := recoverNodeID(crypto.Keccak256(buf[headSize:]), sig)    if err != nil {        return nil, NodeID{}, hash, err    }    var req packet    switch ptype := sigdata[0]; ptype {    case pingPacket:        req = new(ping)    case pongPacket:        req = new(pong)    case findnodePacket:        req = new(findnode)    case neighborsPacket:        req = new(neighbors)    default:        return nil, fromID, hash, fmt.Errorf("unknown type: %d", ptype)    }    s := rlp.NewStream(bytes.NewReader(sigdata[1:]), 0)    err = s.Decode(req)    return req, fromID, hash, err}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-pow一致性算法</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-pow%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-pow%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="eth-PoW分析"><a href="#eth-PoW分析" class="headerlink" title="eth PoW分析"></a>eth PoW分析</h2><h3 id="共识引擎描述"><a href="#共识引擎描述" class="headerlink" title="共识引擎描述"></a>共识引擎描述</h3><p>在CPU挖矿部分，CpuAgent的mine函数，执行挖矿操作的时候调用了self.engine.Seal函数。这里的engine是就是共识引擎。Seal为其中很重要的一个接口。它实现了nonce值的寻找和hash的计算。并且该函数是保证共识并且不能伪造的一个重要的函数。<br>再PoW共识算法中，Seal函数实现了工作证明。该部分源码在consensus/ethhash下。</p><h3 id="共识引擎接口"><a href="#共识引擎接口" class="headerlink" title="共识引擎接口"></a>共识引擎接口</h3><pre><code class="go">type Engine interface {    // 获取区块挖掘者, 即coinbase    Author(header *types.Header) (common.Address, error)    // VerifyHeader 用于校验区块头，通过共识规则来校验，验证区块可以在这里进行也科通通过VerifySeal方法    VerifyHeader(chain ChainReader, header *types.Header, seal bool) error    // VerifyHeaders与VerifyHeader相似,同时这个用于批量操作校验头。这个方法返回一个退出信号    // 用于终止操作，用于异步校验。    VerifyHeaders(chain ChainReader, headers []*types.Header, seals []bool) (chan&lt;- struct{}, &lt;-chan error)    // VerifyUncles 用于校验叔块以符合共识引擎的规则    VerifyUncles(chain ChainReader, block *types.Block) error    // VerifySeal根据共识算法的规则校验区块头    VerifySeal(chain ChainReader, header *types.Header) error    // Prepare 用于初始化区块头的共识字段根据共识引擎。这些改变都是内联执行的。    Prepare(chain ChainReader, header *types.Header) error    // Finalize 完成所有的状态修改，并最终组装成块。    // 区块头和状态数据库在最终确认的时候可以被更新使之符合共识规则。    Finalize(chain ChainReader, header *types.Header, state *state.StateDB, txs []*types.Transaction,        uncles []*types.Header, receipts []*types.Receipt) (*types.Block, error)    // Seal 根据输入区块打包生产一个新的区块    Seal(chain ChainReader, block *types.Block, stop &lt;-chan struct{}) (*types.Block, error)    // CalcDifficulty 是难度调整算法，它返回新的区块的难度值。    CalcDifficulty(chain ChainReader, time uint64, parent *types.Header) *big.Int    // APIs 返回由共识引擎提供的RPC APIs     APIs(chain ChainReader) []rpc.API}</code></pre><h3 id="ethhash-实现分析"><a href="#ethhash-实现分析" class="headerlink" title="ethhash 实现分析"></a>ethhash 实现分析</h3><h4 id="ethhash-结构体"><a href="#ethhash-结构体" class="headerlink" title="ethhash 结构体"></a>ethhash 结构体</h4><pre><code class="go">type Ethash struct {    config Config    // 缓存    caches   *lru // In memory caches to avoid regenerating too often    // 内存数据集    datasets *lru // In memory datasets to avoid regenerating too often    // Mining related fields    rand     *rand.Rand    // Properly seeded random source for nonces    // 挖矿线程数量    threads  int           // Number of threads to mine on if mining    // channel 用于更新挖矿通知    update   chan struct{} // Notification channel to update mining parameters    hashrate metrics.Meter // Meter tracking the average hashrate    // 测试网络相关参数    // The fields below are hooks for testing    shared    *Ethash       // Shared PoW verifier to avoid cache regeneration    fakeFail  uint64        // Block number which fails PoW check even in fake mode    fakeDelay time.Duration // Time delay to sleep for before returning from verify    lock sync.Mutex // Ensures thread safety for the in-memory caches and mining fields}</code></pre><p>Ethhash是实现PoW的具体实现，由于要使用到大量的数据集，所以有两个指向lru的指针。并且通过threads控制挖矿线程数。并在测试模式或fake模式下，简单快速处理，使之快速得到结果。</p><p>Author方法获取了挖出这个块的矿工地址。</p><pre><code class="go">func (ethash *Ethash) Author(header *types.Header) (common.Address, error) {    return header.Coinbase, nil}</code></pre><p>VerifyHeader 用于校验区块头部信息是否符合ethash共识引擎规则。</p><pre><code class="go">// VerifyHeader checks whether a header conforms to the consensus rules of the// stock Ethereum ethash engine.func (ethash *Ethash) VerifyHeader(chain consensus.ChainReader, header *types.Header, seal bool) error {    // 当处于ModeFullFake模式时，任意头部信息都接受    if ethash.config.PowMode == ModeFullFake {        return nil    }    // 如果该头部是已知的，不用校验，直接返回。    number := header.Number.Uint64()    if chain.GetHeader(header.Hash(), number) != nil {        return nil    }    parent := chain.GetHeader(header.ParentHash, number-1)    if parent == nil {  // 获取父结点失败        return consensus.ErrUnknownAncestor    }    // 进一步进行头部校验    return ethash.verifyHeader(chain, header, parent, false, seal)}</code></pre><p>然后再看看verifyHeader的实现,</p><pre><code class="go">func (ethash *Ethash) verifyHeader(chain consensus.ChainReader, header, parent *types.Header, uncle bool, seal bool) error {    // 确保额外数据段具有合理的长度    if uint64(len(header.Extra)) &gt; params.MaximumExtraDataSize {        return fmt.Errorf("extra-data too long: %d &gt; %d", len(header.Extra), params.MaximumExtraDataSize)    }    // 校验时间戳    if uncle {        if header.Time.Cmp(math.MaxBig256) &gt; 0 {            return errLargeBlockTime        }    } else {        if header.Time.Cmp(big.NewInt(time.Now().Add(allowedFutureBlockTime).Unix())) &gt; 0 {            return consensus.ErrFutureBlock        }    }    if header.Time.Cmp(parent.Time) &lt;= 0 {        return errZeroBlockTime    }    // 根据时间戳和父级块的难度校验块的难度。    expected := ethash.CalcDifficulty(chain, header.Time.Uint64(), parent)    if expected.Cmp(header.Difficulty) != 0 {        return fmt.Errorf("invalid difficulty: have %v, want %v", header.Difficulty, expected)    }    // 校验gas limit &lt;= 2^63-1    cap := uint64(0x7fffffffffffffff)    if header.GasLimit &gt; cap {        return fmt.Errorf("invalid gasLimit: have %v, max %v", header.GasLimit, cap)    }    // 校验 gasUsed &lt;= gasLimit    if header.GasUsed &gt; header.GasLimit {        return fmt.Errorf("invalid gasUsed: have %d, gasLimit %d", header.GasUsed, header.GasLimit)    }    // gas limit 是否在允许范围内    diff := int64(parent.GasLimit) - int64(header.GasLimit)    if diff &lt; 0 {        diff *= -1    }    limit := parent.GasLimit / params.GasLimitBoundDivisor    if uint64(diff) &gt;= limit || header.GasLimit &lt; params.MinGasLimit {        return fmt.Errorf("invalid gas limit: have %d, want %d += %d", header.GasLimit, parent.GasLimit, limit)    }    // 校验区块号应该是父块区块号 +1    if diff := new(big.Int).Sub(header.Number, parent.Number); diff.Cmp(big.NewInt(1)) != 0 {        return consensus.ErrInvalidNumber    }    // 校验特定的块是否符合要求    if seal {        if err := ethash.VerifySeal(chain, header); err != nil {            return err        }    }    // 如果所有检查通过，则验证硬分叉的特殊字段。    if err := misc.VerifyDAOHeaderExtraData(chain.Config(), header); err != nil {        return err    }    if err := misc.VerifyForkHashes(chain.Config(), header, uncle); err != nil {        return err    }    return nil}</code></pre><p>Ethash通过CalcDifficulty函数计算下一个区块难度，分别为不同阶段的难度创建了不同的难度计算方法，这里暂不展开描述</p><pre><code class="go">func (ethash *Ethash) CalcDifficulty(chain consensus.ChainReader, time uint64, parent *types.Header) *big.Int {    return CalcDifficulty(chain.Config(), time, parent)}func CalcDifficulty(config *params.ChainConfig, time uint64, parent *types.Header) *big.Int {    next := new(big.Int).Add(parent.Number, big1)    switch {    case config.IsByzantium(next):        return calcDifficultyByzantium(time, parent)    case config.IsHomestead(next):        return calcDifficultyHomestead(time, parent)    default:        return calcDifficultyFrontier(time, parent)    }}</code></pre><p>VerifyHeaders和VerifyHeader类似，只是VerifyHeaders进行批量校验操作。创建多个goroutine用于执行校验操作，再创建一个goroutine用于赋值控制任务分配和结果获取。最后返回一个结果channel</p><pre><code class="go">func (ethash *Ethash) VerifyHeaders(chain consensus.ChainReader, headers []*types.Header, seals []bool) (chan&lt;- struct{}, &lt;-chan error) {    // If we're running a full engine faking, accept any input as valid    if ethash.config.PowMode == ModeFullFake || len(headers) == 0 {        abort, results := make(chan struct{}), make(chan error, len(headers))        for i := 0; i &lt; len(headers); i++ {            results &lt;- nil        }        return abort, results    }    // Spawn as many workers as allowed threads    workers := runtime.GOMAXPROCS(0)    if len(headers) &lt; workers {        workers = len(headers)    }    // Create a task channel and spawn the verifiers    var (        inputs = make(chan int)        done   = make(chan int, workers)        errors = make([]error, len(headers))        abort  = make(chan struct{})    )    // 产生workers个goroutine用于校验头    for i := 0; i &lt; workers; i++ {        go func() {            for index := range inputs {                errors[index] = ethash.verifyHeaderWorker(chain, headers, seals, index)                done &lt;- index            }        }()    }    errorsOut := make(chan error, len(headers))    // goroutine 用于发送任务到workers个goroutine上    go func() {        defer close(inputs)        var (            in, out = 0, 0            checked = make([]bool, len(headers))            inputs  = inputs        )        for {            select {            case inputs &lt;- in:                if in++; in == len(headers) {                    // Reached end of headers. Stop sending to workers.                    inputs = nil                }            // 统计结果,并把错误消息发送到errorsOut上            case index := &lt;-done:                for checked[index] = true; checked[out]; out++ {                    errorsOut &lt;- errors[out]                    if out == len(headers)-1 {                        return                    }                }            case &lt;-abort:                return            }        }    }()    return abort, errorsOut}</code></pre><p>VerifyHeaders在校验单个区块头的时候使用了verifyHeaderWorker，该函数获取父区块后，调用verifyHeader进行校验</p><pre><code class="go">func (ethash *Ethash) verifyHeaderWorker(chain consensus.ChainReader, headers []*types.Header, seals []bool, index int) error {    var parent *types.Header    if index == 0 {        parent = chain.GetHeader(headers[0].ParentHash, headers[0].Number.Uint64()-1)    } else if headers[index-1].Hash() == headers[index].ParentHash {        parent = headers[index-1]    }    if parent == nil {        return consensus.ErrUnknownAncestor    }    if chain.GetHeader(headers[index].Hash(), headers[index].Number.Uint64()) != nil {        return nil // known block    }    return ethash.verifyHeader(chain, headers[index], parent, false, seals[index])}</code></pre><p>VerifyUncles用于叔块的校验。和校验区块头类似，叔块校验在ModeFullFake模式下直接返回校验成功。获取所有的叔块，然后遍历校验，校验失败即终止，或者校验完成返回。</p><pre><code class="go">func (ethash *Ethash) VerifyUncles(chain consensus.ChainReader, block *types.Block) error {    // If we're running a full engine faking, accept any input as valid    if ethash.config.PowMode == ModeFullFake {        return nil    }    // Verify that there are at most 2 uncles included in this block    if len(block.Uncles()) &gt; maxUncles {        return errTooManyUncles    }    // 收集叔块及其祖先    uncles, ancestors := set.New(), make(map[common.Hash]*types.Header)    number, parent := block.NumberU64()-1, block.ParentHash()    for i := 0; i &lt; 7; i++ {        ancestor := chain.GetBlock(parent, number)        if ancestor == nil {            break        }        ancestors[ancestor.Hash()] = ancestor.Header()        for _, uncle := range ancestor.Uncles() {            uncles.Add(uncle.Hash())        }        parent, number = ancestor.ParentHash(), number-1    }    ancestors[block.Hash()] = block.Header()    uncles.Add(block.Hash())    // 校验每个叔块    for _, uncle := range block.Uncles() {        // Make sure every uncle is rewarded only once        hash := uncle.Hash()        if uncles.Has(hash) {            return errDuplicateUncle        }        uncles.Add(hash)        // Make sure the uncle has a valid ancestry        if ancestors[hash] != nil {            return errUncleIsAncestor        }        if ancestors[uncle.ParentHash] == nil || uncle.ParentHash == block.ParentHash() {            return errDanglingUncle        }        if err := ethash.verifyHeader(chain, uncle, ancestors[uncle.ParentHash], true, true); err != nil {            return err        }    }    return nil}</code></pre><p>Prepare实现共识引擎的Prepare接口，用于填充区块头的难度字段，使之符合ethash协议。这个改变是在线的。</p><pre><code class="go">func (ethash *Ethash) Prepare(chain consensus.ChainReader, header *types.Header) error {    parent := chain.GetHeader(header.ParentHash, header.Number.Uint64()-1)    if parent == nil {        return consensus.ErrUnknownAncestor    }    header.Difficulty = ethash.CalcDifficulty(chain, header.Time.Uint64(), parent)    return nil}</code></pre><p>Finalize实现共识引擎的Finalize接口,奖励挖到区块账户和叔块账户，并填充状态树的根的值。并返回新的区块。</p><pre><code class="go">func (ethash *Ethash) Finalize(chain consensus.ChainReader, header *types.Header, state *state.StateDB, txs []*types.Transaction, uncles []*types.Header, receipts []*types.Receipt) (*types.Block, error) {    // Accumulate any block and uncle rewards and commit the final state root    accumulateRewards(chain.Config(), state, header, uncles)    header.Root = state.IntermediateRoot(chain.Config().IsEIP158(header.Number))    // Header seems complete, assemble into a block and return    return types.NewBlock(header, txs, uncles, receipts), nil}func accumulateRewards(config *params.ChainConfig, state *state.StateDB, header *types.Header, uncles []*types.Header) {    // Select the correct block reward based on chain progression    blockReward := FrontierBlockReward    if config.IsByzantium(header.Number) {        blockReward = ByzantiumBlockReward    }    // Accumulate the rewards for the miner and any included uncles    reward := new(big.Int).Set(blockReward)    r := new(big.Int)    // 奖励叔块账户    for _, uncle := range uncles {        r.Add(uncle.Number, big8)        r.Sub(r, header.Number)        r.Mul(r, blockReward)        r.Div(r, big8)        state.AddBalance(uncle.Coinbase, r)        r.Div(blockReward, big32)        reward.Add(reward, r)    }    // 奖励coinbase账户    state.AddBalance(header.Coinbase, reward)}</code></pre><h4 id="Seal函数实现分析"><a href="#Seal函数实现分析" class="headerlink" title="Seal函数实现分析"></a>Seal函数实现分析</h4><p>在CPU挖矿部分，CpuAgent的mine函数，执行挖矿操作的时候调用了Seal函数。Seal函数尝试找出一个满足区块难度的nonce值。<br>在ModeFake和ModeFullFake模式下，快速返回，并且直接将nonce值取0。<br>在shared PoW模式下，使用shared的Seal函数。<br>开启threads个goroutine进行挖矿(查找符合条件的nonce值)。</p><pre><code class="go">// Seal implements consensus.Engine, attempting to find a nonce that satisfies// the block's difficulty requirements.func (ethash *Ethash) Seal(chain consensus.ChainReader, block *types.Block, stop &lt;-chan struct{}) (*types.Block, error) {    // 在ModeFake和ModeFullFake模式下，快速返回，并且直接将nonce值取0。    if ethash.config.PowMode == ModeFake || ethash.config.PowMode == ModeFullFake {        header := block.Header()        header.Nonce, header.MixDigest = types.BlockNonce{}, common.Hash{}        return block.WithSeal(header), nil    }    // 在shared PoW模式下，使用shared的Seal函数。    if ethash.shared != nil {        return ethash.shared.Seal(chain, block, stop)    }    // Create a runner and the multiple search threads it directs    abort := make(chan struct{})    found := make(chan *types.Block)    ethash.lock.Lock()    threads := ethash.threads    if ethash.rand == nil {        seed, err := crand.Int(crand.Reader, big.NewInt(math.MaxInt64))        if err != nil {            ethash.lock.Unlock()            return nil, err        }        ethash.rand = rand.New(rand.NewSource(seed.Int64()))    }    ethash.lock.Unlock()    if threads == 0 {        threads = runtime.NumCPU()    }    if threads &lt; 0 {        threads = 0 // Allows disabling local mining without extra logic around local/remote    }    var pend sync.WaitGroup    for i := 0; i &lt; threads; i++ {        pend.Add(1)        go func(id int, nonce uint64) {            defer pend.Done()            ethash.mine(block, id, nonce, abort, found)        }(i, uint64(ethash.rand.Int63()))    }    // Wait until sealing is terminated or a nonce is found    var result *types.Block    select {    case &lt;-stop:        // Outside abort, stop all miner threads        close(abort)    case result = &lt;-found:        // One of the threads found a block, abort all others        close(abort)    case &lt;-ethash.update:        // Thread count was changed on user request, restart        close(abort)        pend.Wait()        return ethash.Seal(chain, block, stop)    }    // 等待所有的挖矿goroutine返回    pend.Wait()    return result, nil}</code></pre><p>mine是真正的查找nonce值的函数，它不断遍历查找nonce值，并计算PoW值与目标值进行比较。<br>其原理可以简述为下：</p><pre><code>                                RAND(h, n)  &lt;=  M / d</code></pre><p>这里M表示一个极大的数，这里是2^256-1；d表示Header成员Difficulty。RAND()是一个概念函数，它代表了一系列复杂的运算，并最终产生一个类似随机的数。这个函数包括两个基本入参：h是Header的哈希值(Header.HashNoNonce())，n表示Header成员Nonce。整个关系式可以大致理解为，在最大不超过M的范围内，以某个方式试图找到一个数，如果这个数符合条件(&lt;=M/d)，那么就认为Seal()成功。<br>由上面的公式可以得知，M恒定，d越大则可取范围越小。所以当难度值增加时，挖出区块的难度也在增加。</p><pre><code class="go">func (ethash *Ethash) mine(block *types.Block, id int, seed uint64, abort chan struct{}, found chan *types.Block) {    // 从区块头中获取一些数据    var (        header  = block.Header()        hash    = header.HashNoNonce().Bytes()        // target 即查找的PoW的上限 target = maxUint256/Difficulty        // 其中maxUint256 = 2^256-1  Difficulty即难度值        target  = new(big.Int).Div(maxUint256, header.Difficulty)        number  = header.Number.Uint64()        dataset = ethash.dataset(number)    )    // 尝试查找一个nonce值，直到终止或者找到目标值    var (        attempts = int64(0)        nonce    = seed    )    logger := log.New("miner", id)    logger.Trace("Started ethash search for new nonces", "seed", seed)search:    for {        select {        case &lt;-abort:            // 终止挖矿            logger.Trace("Ethash nonce search aborted", "attempts", nonce-seed)            ethash.hashrate.Mark(attempts)            break search        default:            // 不必在每个nonce值都更新hash rate，每2^x个nonce值更新一次hash rate            attempts++            if (attempts % (1 &lt;&lt; 15)) == 0 {                ethash.hashrate.Mark(attempts)                attempts = 0            }            // 用这个nonce计算PoW值            digest, result := hashimotoFull(dataset.dataset, hash, nonce)            // 将计算的结果与目标值比较，如果小于目标值，则查找成功。            if new(big.Int).SetBytes(result).Cmp(target) &lt;= 0 {                // 查找到nonce值，更新区块头                header = types.CopyHeader(header)                header.Nonce = types.EncodeNonce(nonce)                header.MixDigest = common.BytesToHash(digest)                // 打包区块头并返回                select {                // WithSeal 将新的区块头替换旧的区块头                case found &lt;- block.WithSeal(header):                    logger.Trace("Ethash nonce found and reported", "attempts", nonce-seed, "nonce", nonce)                case &lt;-abort:                    logger.Trace("Ethash nonce found but discarded", "attempts", nonce-seed, "nonce", nonce)                }                break search            }            nonce++        }    }    // Datasets are unmapped in a finalizer. Ensure that the dataset stays live    // during sealing so it's not unmapped while being read.    runtime.KeepAlive(dataset)}</code></pre><p>上诉函数调用了hashimotoFull函数用来计算PoW的值。</p><pre><code class="go">func hashimotoFull(dataset []uint32, hash []byte, nonce uint64) ([]byte, []byte) {    lookup := func(index uint32) []uint32 {        offset := index * hashWords        return dataset[offset : offset+hashWords]    }    return hashimoto(hash, nonce, uint64(len(dataset))*4, lookup)}</code></pre><p>hashimoto用于聚合数据以产生特定的后部的hash和nonce值。<br><img src="/../../../images/ethereum/source_analysis/pow_hashimoto.png" alt="图片来源：https://blog.csdn.net/metal1/article/details/79682636"><br>简述该部分流程:</p><ul><li><p>首先，hashimoto()函数将入参@hash和@nonce合并成一个40 bytes长的数组，取它的SHA-512哈希值取名seed，长度为64 bytes。</p></li><li><p>然后，将seed[]转化成以uint32为元素的数组mix[]，注意一个uint32数等于4 bytes，故而seed[]只能转化成16个uint32数，而mix[]数组长度32，所以此时mix[]数组前后各半是等值的。</p></li><li><p>接着，lookup()函数登场。用一个循环，不断调用lookup()从外部数据集中取出uint32元素类型数组，向mix[]数组中混入未知的数据。循环的次数可用参数调节，目前设为64次。每次循环中，变化生成参数index，从而使得每次调用lookup()函数取出的数组都各不相同。这里混入数据的方式是一种类似向量“异或”的操作，来自于FNV算法。<br>待混淆数据完成后，得到一个基本上面目全非的mix[]，长度为32的uint32数组。这时，将其折叠(压缩)成一个长度缩小成原长1/4的uint32数组，折叠的操作方法还是来自FNV算法。</p></li><li><p>最后，将折叠后的mix[]由长度为8的uint32型数组直接转化成一个长度32的byte数组，这就是返回值@digest；同时将之前的seed[]数组与digest合并再取一次SHA-256哈希值，得到的长度32的byte数组，即返回值@result。(转自<a href="https://blog.csdn.net/metal1/article/details/79682636">https://blog.csdn.net/metal1/article/details/79682636</a>)</p><pre><code class="go">func hashimoto(hash []byte, nonce uint64, size uint64, lookup func(index uint32) []uint32) ([]byte, []byte) {  // 计算理论行数  rows := uint32(size / mixBytes)  // 将 header+nonce into 装换为64字节的seed  seed := make([]byte, 40)  copy(seed, hash)  binary.LittleEndian.PutUint64(seed[32:], nonce)  seed = crypto.Keccak512(seed)  seedHead := binary.LittleEndian.Uint32(seed)  // 将seed[]转化成以uint32为元素的数组mix[]  mix := make([]uint32, mixBytes/4)  for i := 0; i &lt; len(mix); i++ {      mix[i] = binary.LittleEndian.Uint32(seed[i%16*4:])  }  // 向mix[]数组中混入未知的数据  temp := make([]uint32, len(mix))  for i := 0; i &lt; loopAccesses; i++ {      parent := fnv(uint32(i)^seedHead, mix[i%len(mix)]) % rows      for j := uint32(0); j &lt; mixBytes/hashBytes; j++ {          copy(temp[j*hashWords:], lookup(2*parent+j))      }      fnvHash(mix, temp)  }  // 压缩成一个长度缩小成原长1/4的uint32数组  for i := 0; i &lt; len(mix); i += 4 {      mix[i/4] = fnv(fnv(fnv(mix[i], mix[i+1]), mix[i+2]), mix[i+3])  }  mix = mix[:len(mix)/4]  digest := make([]byte, common.HashLength)  for i, val := range mix {      binary.LittleEndian.PutUint32(digest[i*4:], val)  }  return digest, crypto.Keccak256(append(seed, digest...))}</code></pre><h4 id="VerifySeal函数实现分析"><a href="#VerifySeal函数实现分析" class="headerlink" title="VerifySeal函数实现分析"></a>VerifySeal函数实现分析</h4><p>VerifySeal用于校验区块的nonce值是否满足PoW难度要求。</p><pre><code class="go">func (ethash *Ethash) VerifySeal(chain consensus.ChainReader, header *types.Header) error {  // ModeFake、ModeFullFake模式不校验，直接验证通过。  if ethash.config.PowMode == ModeFake || ethash.config.PowMode == ModeFullFake {      time.Sleep(ethash.fakeDelay)      if ethash.fakeFail == header.Number.Uint64() {          return errInvalidPoW      }      return nil  }  // shared PoW下，用shared的校验方法  if ethash.shared != nil {      return ethash.shared.VerifySeal(chain, header)  }  // Ensure that we have a valid difficulty for the block  if header.Difficulty.Sign() &lt;= 0 {      return errInvalidDifficulty  }  // 计算digest和PoW值并校验区块头  number := header.Number.Uint64()  cache := ethash.cache(number)  size := datasetSize(number)  if ethash.config.PowMode == ModeTest {      size = 32 * 1024  }  digest, result := hashimotoLight(size, cache.cache, header.HashNoNonce().Bytes(), header.Nonce.Uint64())  // Caches are unmapped in a finalizer. Ensure that the cache stays live  // until after the call to hashimotoLight so it's not unmapped while being used.  runtime.KeepAlive(cache)  if !bytes.Equal(header.MixDigest[:], digest) {      return errInvalidMixDigest  }  target := new(big.Int).Div(maxUint256, header.Difficulty)  // 比较是否满足目标难度要求  if new(big.Int).SetBytes(result).Cmp(target) &gt; 0 {      return errInvalidPoW  }  return nil}</code></pre><p>hashimotoLight和hashimotoFull功能类似，只是hashimotoLight使用了占用内存更小的缓存。</p><pre><code class="go">func hashimotoLight(size uint64, cache []uint32, hash []byte, nonce uint64) ([]byte, []byte) {  keccak512 := makeHasher(sha3.NewKeccak512())  lookup := func(index uint32) []uint32 {      rawData := generateDatasetItem(cache, index, keccak512)      data := make([]uint32, len(rawData)/4)      for i := 0; i &lt; len(data); i++ {          data[i] = binary.LittleEndian.Uint32(rawData[i*4:])      }      return data  }  return hashimoto(hash, nonce, size, lookup)}</code></pre></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-以太坊fast sync算法</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8Afast%20sync%E7%AE%97%E6%B3%95/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8Afast%20sync%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>翻译内容来自 ( <a href="https://github.com/ethereum/go-ethereum/pull/1889">https://github.com/ethereum/go-ethereum/pull/1889</a> )</p><p>This PR aggregates a lot of small modifications to core, trie, eth and other packages to collectively implement the eth/63 fast synchronization algorithm. In short, geth –fast.</p><p>这个提交请求包含了对core，trie,eth和其他一些package的微小的修改，来共同实现eth/63的快速同步算法。 简单来说， geth –fast.</p><h2 id="Algorithm-算法"><a href="#Algorithm-算法" class="headerlink" title="Algorithm 算法"></a>Algorithm 算法</h2><p>The goal of the the fast sync algorithm is to exchange processing power for bandwidth usage. Instead of processing the entire block-chain one link at a time, and replay all transactions that ever happened in history, fast syncing downloads the transaction receipts along the blocks, and pulls an entire recent state database. This allows a fast synced node to still retain its status an an archive node containing all historical data for user queries (and thus not influence the network’s health in general), but at the same time to reassemble a recent network state at a fraction of the time it would take full block processing.</p><p>快速同步算法的目标是用带宽换计算。 快速同步不是通过一个链接处理整个区块链，而是重放历史上发生的所有事务，快速同步会沿着这些块下载事务处理单据，然后拉取整个最近的状态数据库。 这允许快速同步的节点仍然保持其包含用于用户查询的所有历史数据的存档节点的状态（并且因此不会一般地影响网络的健康状况），对于最新的区块状态更改，会使用全量的区块处理方式。</p><p>An outline of the fast sync algorithm would be:</p><ul><li>Similarly to classical sync, download the block headers and bodies that make up the blockchain</li><li>Similarly to classical sync, verify the header chain’s consistency (POW, total difficulty, etc)</li><li>Instead of processing the blocks, download the transaction receipts as defined by the header</li><li>Store the downloaded blockchain, along with the receipt chain, enabling all historical queries</li><li>When the chain reaches a recent enough state (head - 1024 blocks), pause for state sync:<ul><li>Retrieve the entire Merkel Patricia state trie defined by the root hash of the pivot point</li><li>For every account found in the trie, retrieve it’s contract code and internal storage state trie</li></ul></li><li>Upon successful trie download, mark the pivot point (head - 1024 blocks) as the current head</li><li>Import all remaining blocks (1024) by fully processing them as in the classical sync</li></ul><p>快速同步算法的概要：</p><ul><li>与原有的同步类似，下载组成区块链的区块头和区块body</li><li>类似于原有的同步，验证区块头的一致性（POW，总难度等）</li><li>下载由区块头定义的交易收据,而不是处理区块。</li><li>存储下载的区块链和收据链，启用所有历史查询</li><li>当链条达到最近的状态（头部 - 1024个块）时，暂停状态同步：<ul><li>获取由 pivot point定义的区块的完整的Merkel Patricia Trie状态</li><li>对于Merkel Patricia Trie里面的每个账户，获取他的合约代码和中间存储的Trie</li></ul></li><li>当Merkel Patricia Trie下载成功后，将pivot point定义的区块作为当前的区块头</li><li>通过像原有的同步一样对其进行完全处理，导入所有剩余的块（1024）</li></ul><h2 id="分析-Analysis"><a href="#分析-Analysis" class="headerlink" title="分析 Analysis"></a>分析 Analysis</h2><p>By downloading and verifying the entire header chain, we can guarantee with all the security of the classical sync, that the hashes (receipts, state tries, etc) contained within the headers are valid. Based on those hashes, we can confidently download transaction receipts and the entire state trie afterwards. Additionally, by placing the pivoting point (where fast sync switches to block processing) a bit below the current head (1024 blocks), we can ensure that even larger chain reorganizations can be handled without the need of a new sync (as we have all the state going that many blocks back).</p><p>通过下载和验证整个头部链，我们可以保证传统同步的所有安全性，头部中包含的哈希（收据，状态尝试等）是有效的。 基于这些哈希，我们可以自信地下载交易收据和整个状态树。 另外，通过将pivoting point（快速同步切换到区块处理）放置在当前区块头（1024块）的下方一点，我们可以确保甚至可以处理更大的区块链重组，而不需要新的同步（因为我们有所有的状态 TODO）。</p><h2 id="注意事项-Caveats"><a href="#注意事项-Caveats" class="headerlink" title="注意事项 Caveats"></a>注意事项 Caveats</h2><p>The historical block-processing based synchronization mechanism has two (approximately similarly costing) bottlenecks: transaction processing and PoW verification. The baseline fast sync algorithm successfully circumvents the transaction processing, skipping the need to iterate over every single state the system ever was in. However, verifying the proof of work associated with each header is still a notably CPU intensive operation.</p><p>基于历史块处理的同步机制具有两个（近似相似成本）瓶颈：交易处理和PoW验证。 基线快速同步算法成功地绕开了事务处理，跳过了对系统曾经处于的每一个状态进行迭代的需要。但是，验证与每个头相关联的工作证明仍然是CPU密集型操作。</p><p>However, we can notice an interesting phenomenon during header verification. With a negligible probability of error, we can still guarantee the validity of the chain, only by verifying every K-th header, instead of each and every one. By selecting a single header at random out of every K headers to verify, we guarantee the validity of an N-length chain with the probability of (1/K)^(N/K) (i.e. we have 1/K chance to spot a forgery in K blocks, a verification that’s repeated N/K times).</p><p>但是，我们可以在区块头验证期间注意到一个有趣的现象 由于错误概率可以忽略不计，我们仍然可以保证链的有效性，只需要验证每个第K个头，而不是每个头。 通过从每个K头中随机选择一个头来验证，我们保证N长度链的可能会被伪造的概率为（1 / K）^（N / K）（在K块中我们有1 / K的机会发现一个伪造，而验证经行了N/K次。）。</p><p>Let’s define the negligible probability Pn as the probability of obtaining a 256 bit SHA3 collision (i.e. the hash Ethereum is built upon): 1/2^128. To honor the Ethereum security requirements, we need to choose the minimum chain length N (below which we veriy every header) and maximum K verification batch size such as (1/K)^(N/K) &lt;= Pn holds. Calculating this for various {N, K} pairs is pretty straighforward, a simple and lenient solution being <a href="http://play.golang.org/p/B-8sX_6Dq0">http://play.golang.org/p/B-8sX_6Dq0</a>.</p><p>我们将可忽略概率Pn定义为获得256位SHA3冲突（以太坊的Hash算法）的概率：1/2 ^ 128。 为了遵守以太坊的安全要求，我们需要选择最小链长N（在我们每个块都验证之前），最大K验证批量大小如（1 / K）^（N / K）&lt;= Pn。 对各种{N，K}对进行计算是非常直接的，一个简单和宽松的解决方案是<a href="http://play.golang.org/p/B-8sX_6Dq0%E3%80%82">http://play.golang.org/p/B-8sX_6Dq0。</a></p><table><thead><tr><th>N</th><th>K</th><th>N</th><th>K</th><th>N</th><th>K</th><th>N</th><th>K</th></tr></thead><tbody><tr><td>1024</td><td>43</td><td>1792</td><td>91</td><td>2560</td><td>143</td><td>3328</td><td>198</td></tr><tr><td>1152</td><td>51</td><td>1920</td><td>99</td><td>2688</td><td>152</td><td>3456</td><td>207</td></tr><tr><td>1280</td><td>58</td><td>2048</td><td>108</td><td>2816</td><td>161</td><td>3584</td><td>217</td></tr><tr><td>1408</td><td>66</td><td>2176</td><td>116</td><td>2944</td><td>170</td><td>3712</td><td>226</td></tr><tr><td>1536</td><td>74</td><td>2304</td><td>128</td><td>3072</td><td>179</td><td>3840</td><td>236</td></tr><tr><td>1664</td><td>82</td><td>2432</td><td>134</td><td>3200</td><td>189</td><td>3968</td><td>246</td></tr></tbody></table><p>The above table should be interpreted in such a way, that if we verify every K-th header, after N headers the probability of a forgery is smaller than the probability of an attacker producing a SHA3 collision. It also means, that if a forgery is indeed detected, the last N headers should be discarded as not safe enough. Any {N, K} pair may be chosen from the above table, and to keep the numbers reasonably looking, we chose N=2048, K=100. This will be fine tuned later after being able to observe network bandwidth/latency effects and possibly behavior on more CPU limited devices.</p><p>上面的表格应该这样解释：如果我们每隔K个区块头验证一次区块头，在N个区块头之后，伪造的概率小于攻击者产生SHA3冲突的概率。 这也意味着，如果确实发现了伪造，那么最后的N个头部应该被丢弃，因为不够安全。 可以从上表中选择任何{N，K}对，为了选择一个看起来好看点的数字，我们选择N = 2048，K = 100。 后续可能会根据网络带宽/延迟影响以及可能在一些CPU性能比较受限的设备上运行的情况来进行调整。</p><p>Using this caveat however would mean, that the pivot point can be considered secure only after N headers have been imported after the pivot itself. To prove the pivot safe faster, we stop the “gapped verificatios” X headers before the pivot point, and verify every single header onward, including an additioanl X headers post-pivot before accepting the pivot’s state. Given the above N and K numbers, we chose X=24 as a safe number.</p><p>然而，使用这个特性意味着，只有导入N个区块之后再导入pivot节点才被认为是安全的。 为了更快地证明pivot的安全性，我们在距离pivot节点X距离的地方停止隔块验证的行为,对随后出现的每一个块进行验证直到pivot。 鉴于上述N和K数字，我们选择X = 24作为安全数字。</p><p>With this caveat calculated, the fast sync should be modified so that up to the pivoting point - X, only every K=100-th header should be verified (at random), after which all headers up to pivot point + X should be fully verified before starting state database downloading. Note: if a sync fails due to header verification the last N headers must be discarded as they cannot be trusted enough.</p><p>通过计算caveat，快速同步需要修改为pivoting point - X,每隔100个区块头随机挑选其中的一个来进行验证，之后的每一个块都需要在状态数据库下载完成之后完全验证，如果因为区块头验证失败导致的同步失败，那么最后的N个区块头都需要被丢弃，应为他们达不到信任标准。</p><h2 id="缺点-Weakness"><a href="#缺点-Weakness" class="headerlink" title="缺点 Weakness"></a>缺点 Weakness</h2><p>Blockchain protocols in general (i.e. Bitcoin, Ethereum, and the others) are susceptible to Sybil attacks, where an attacker tries to completely isolate a node from the rest of the network, making it believe a false truth as to what the state of the real network is. This permits the attacker to spend certain funds in both the real network and this “fake bubble”. However, the attacker can only maintain this state as long as it’s feeding new valid blocks it itself is forging; and to successfully shadow the real network, it needs to do this with a chain height and difficulty close to the real network. In short, to pull off a successful Sybil attack, the attacker needs to match the network’s hash rate, so it’s a very expensive attack.</p><p>常见的区块链(比如比特币，以太坊以及其他)是比较容易受女巫攻击的影响，攻击者试图把被攻击者从主网络上完全隔离开，让被攻击者接收一个虚假的状态。这就允许攻击者在真实的网络同时这个虚假的网络上花费同一笔资金。然而这个需要攻击者提供真实的自己锻造的区块，而且需要成功的影响真实的网络，就需要在区块高度和难度上接近真实的网络。简单来说，为了成功的实施女巫攻击，攻击者需要接近主网络的hash rate，所以是一个非常昂贵的攻击。</p><p>Compared to the classical Sybil attack, fast sync provides such an attacker with an extra ability, that of feeding a node a view of the network that’s not only different from the real network, but also that might go around the EVM mechanics. The Ethereum protocol only validates state root hashes by processing all the transactions against the previous state root. But by skipping the transaction processing, we cannot prove that the state root contained within the fast sync pivot point is valid or not, so as long as an attacker can maintain a fake blockchain that’s on par with the real network, it could create an invalid view of the network’s state.</p><p>与传统的女巫攻击相比，快速同步为攻击者提供了一种额外的能力，即为节点提供一个不仅与真实网络不同的网络视图，而且还可能绕过EVM机制。 以太坊协议只通过处理所有事务与以前的状态根来验证状态根散列。 但是通过跳过事务处理，我们无法证明快速同步pivot point中包含的state root是否有效，所以只要攻击者能够保持与真实网络相同的假区块链，就可以创造一个无效的网络状态视图。</p><p>To avoid opening up nodes to this extra attacker ability, fast sync (beside being solely opt-in) will only ever run during an initial sync (i.e. when the node’s own blockchain is empty). After a node managed to successfully sync with the network, fast sync is forever disabled. This way anybody can quickly catch up with the network, but after the node caught up, the extra attack vector is plugged in. This feature permits users to safely use the fast sync flag (–fast), without having to worry about potential state root attacks happening to them in the future. As an additional safety feature, if a fast sync fails close to or after the random pivot point, fast sync is disabled as a safety precaution and the node reverts to full, block-processing based synchronization.</p><p>为了避免将节点开放给这个额外的攻击者能力，快速同步(特别指定)将只在初始同步期间运行(节点的本地区块链是空的)。 在一个节点成功与网络同步后，快速同步永远被禁用。 这样任何人都可以快速地赶上网络，但是在节点追上之后，额外的攻击矢量就被插入了。这个特性允许用户安全地使用快速同步标志（–fast），而不用担心潜在的状态 在未来发生的根攻击。 作为附加的安全功能，如果快速同步在随机 pivot point附近或之后失败，则作为安全预防措施禁用快速同步，并且节点恢复到基于块处理的完全同步。</p><h2 id="性能-Performance"><a href="#性能-Performance" class="headerlink" title="性能 Performance"></a>性能 Performance</h2><p>To benchmark the performance of the new algorithm, four separate tests were run: full syncing from scrath on Frontier and Olympic, using both the classical sync as well as the new sync mechanism. In all scenarios there were two nodes running on a single machine: a seed node featuring a fully synced database, and a leech node with only the genesis block pulling the data. In all test scenarios the seed node had a fast-synced database (smaller, less disk contention) and both nodes were given 1GB database cache (–cache=1024).</p><p>为了对新算法的性能进行基准测试，运行了四个单独的测试：使用经典同步以及新的同步机制，从Frontier和Olympic上的scrath完全同步。 在所有情况下，在一台机器上运行两个节点：具有完全同步的数据库的种子节点，以及只有起始块拉动数据的水蛭节点。 在所有测试场景中，种子节点都有一个快速同步的数据库（更小，更少的磁盘争用），两个节点都有1GB的数据库缓存（–cache = 1024）。</p><p>The machine running the tests was a Zenbook Pro, Core i7 4720HQ, 12GB RAM, 256GB m.2 SSD, Ubuntu 15.04.</p><p>运行测试的机器是Zenbook Pro，Core i7 4720HQ，12GB RAM，256GB m.2 SSD，Ubuntu 15.04。</p><table><thead><tr><th>Dataset (blocks, states)</th><th align="center">Normal sync (time, db)</th><th align="right">Fast sync (time, db)</th></tr></thead><tbody><tr><td>Frontier, 357677 blocks, 42.4K states</td><td align="center">12:21 mins, 1.6 GB</td><td align="right">2:49 mins, 235.2 MB</td></tr><tr><td>Olympic, 837869 blocks, 10.2M states</td><td align="center">4:07:55 hours, 21 GB</td><td align="right">31:32 mins, 3.8 GB</td></tr></tbody></table><p>The resulting databases contain the entire blockchain (all blocks, all uncles, all transactions), every transaction receipt and generated logs, and the entire state trie of the head 1024 blocks. This allows a fast synced node to act as a full archive node from all intents and purposes.</p><p>结果数据库包含整个区块链（所有区块，所有的区块，所有的交易），每个交易收据和生成的日志，以及头1024块的整个状态树。 这使得一个快速的同步节点可以充当所有意图和目的的完整归档节点。</p><h2 id="结束语-Closing-remarks"><a href="#结束语-Closing-remarks" class="headerlink" title="结束语 Closing remarks"></a>结束语 Closing remarks</h2><p>The fast sync algorithm requires the functionality defined by eth/63. Because of this, testing in the live network requires for at least a handful of discoverable peers to update their nodes to eth/63. On the same note, verifying that the implementation is truly correct will also entail waiting for the wider deployment of eth/63.</p><p>快速同步算法需要由eth / 63定义的功能。 正因为如此，现网中的测试至少需要少数几个可发现的对等节点将其节点更新到eth / 63。 同样的说明，验证这个实施是否真正正确还需要等待eth / 63的更广泛部署。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-以太坊测试网络Clique_PoA介绍</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9CClique_PoA%E4%BB%8B%E7%BB%8D/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9CClique_PoA%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p><a href="https://github.com/ethereum/EIPs/issues/225">https://github.com/ethereum/EIPs/issues/225</a></p><p>Clique的模式下，用户是无法获取以太币的，因为无法挖矿，所以如果需要以太币， 需要通过特殊的途径来获取。</p><p>可以通过这个网站获取ether</p><p><a href="https://faucet.rinkeby.io/">https://faucet.rinkeby.io/</a></p><p>需要有google+账号，facebook或者twitter账号才能获取， 详细的获取办法参考上面的网站。</p><p>Clique 是以太坊的一个Power of authority 的实现， 现在主要在Rinkeby 测试网络使用。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>以太坊的第一个官方测试网是Morden。它从2015年7月到2016年11月，由于Geth和Parity之间累积的垃圾和一些testnet的共识问题，最终决定停止重新启动testnet。</p><p>Ropsten就这样诞生了，清理掉了所有的垃圾，从一个干净的石板开始。这一运行状况一直持续到2017年2月底，当时恶意行为者决定滥用Pow，并逐步将GasLimit从正常的470万提高到90亿，此时发送巨大的交易损害整个网络。甚至在此之前，攻击者尝试了多次非常长的区块链重组，导致不同客户端之间的网络分裂，甚至是不同的版本。</p><p>这些攻击的根本原因在于PoW网络的安全性与它背后的计算能力一样安全。从零开始重新启动一个新的测试网络并不能解决任何问题，因为攻击者可以反复安装相同的攻击。Parity 团队决定采取一个紧急的解决办法，回滚大量的区块，制定一个不允许GasLimit超过一定门槛的软交叉。</p><p>虽然这个解决方案可能在短期内工作：</p><p>这并不高雅：以太坊应该有动态的限制<br>这不是可移植的：其他客户需要自己实现新的fork逻辑<br>它与同步模式不兼容：fast sync和轻客户端都运气不佳<br>这只是延长了攻击的时间：垃圾依然可以在无尽的情况下稳步推进<br>Parity的解决方案虽然不完美，但仍然可行。我想提出一个更长期的替代解决方案，涉及更多，但应该足够简单，以便能够在合理的时间内推出。</p><h2 id="标准化的PoA"><a href="#标准化的PoA" class="headerlink" title="标准化的PoA"></a>标准化的PoA</h2><p>如上所述，在没有价值的网络中，Pow不能安全地工作。 以太坊有以Casper为基础的长期PoS目标，但是这是一个繁琐的研究，所以我们不能很快依靠这个来解决今天的问题。 然而，一种解决方案很容易实施，而且足够有效地正确地修复测试网络，即权威证明方案（proof-of-authority scheme）。</p><p>注意，Parity确实有PoA的实现，虽然看起来比需要的更复杂，没有太多的协议文档，但是很难看到它可以和其他客户一起玩。 我欢迎他们基于他们的经验来给我的这个提案更多的反馈。</p><p>这里描述的PoA协议的主要设计目标是实现和嵌入任何现有的以太坊客户端应该是非常简单的，同时允许使用现有的同步技术（快速，轻松，扭曲），而不需要客户端开发者添加 定制逻辑到关键软件。</p><h2 id="PoA101"><a href="#PoA101" class="headerlink" title="PoA101"></a>PoA101</h2><p>对于那些没有意识到PoA如何运作的人来说，这是一个非常简单的协议，而不是矿工们为了解决一个困难的问题而竞相争夺，授权签署者可以随时自行决定是否创建新的块。</p><p>挑战围绕着如何控制挖矿频率，如何在不同的签名者之间分配负载（和机会）以及如何动态调整签名者列表。 下一节定义一个处理所有这些场景的建议协议。</p><h2 id="Rinkeby-proof-of-authority"><a href="#Rinkeby-proof-of-authority" class="headerlink" title="Rinkeby proof-of-authority"></a>Rinkeby proof-of-authority</h2><p>总体来说，有两种同步区块链的方法：</p><ul><li>传统的方法是把所有的事务一个接一个地进行起始块和紧缩。这种方式尝试过而且已经被证明在以太坊这种复杂的网络中非常耗费计算资源。<br>另一种是只下载区块链头并验证它们的有效性，此后可以从网络上下载一个任意的最近的状态并检查最近的header。</li><li>PoA方案基于这样的想法，即块可能只能由可信签署人完成。 因此，客户端看到的每个块（或header）都可以与可信任的签名者列表进行匹配。 这里面临的挑战是如何维护一个可以及时更改的授权签名者列表？ 明显的答案（将其存储在以太坊合同中）也是错误的答案：在快速同步期间是无法访问状态的。</li></ul><p><strong>维护授权签名者列表的协议必须完全包含在块头中。</strong></p><p>下一个显而易见的想法是改变块标题的结构，这样就可以放弃PoW的概念，并引入新的字段来迎合投票机制。 这也是错误的答案：在多个实现中更改这样一个核心数据结构将是一个开发，维护和安全的噩梦。</p><p><strong>维护授权签名者列表的协议必须完全适合当前的数据模型。</strong></p><p>所以，根据以上所述，我们不能使用EVM进行投票，而是不得不求助于区块头。 而且我们不能改变区块头字段，而不得不求助于当前可用的字段。 没有太多的选择。</p><h3 id="把区块头的一些其他字段用来实现投票和签名"><a href="#把区块头的一些其他字段用来实现投票和签名" class="headerlink" title="把区块头的一些其他字段用来实现投票和签名"></a>把区块头的一些其他字段用来实现投票和签名</h3><p>当前仅用作有趣元数据的最明显的字段是块头中的32字节的ExtraData部分。 矿工们通常把他们的客户端和版本放在那里，但是有些人用另外的“信息”填充它们。 该协议将扩展此字段以增加65字节用来存放矿工的KEC签名。 这将允许任何获得一个区块的人员根据授权签名者的名单对其进行验证。 同时它也使得区块头中的矿工地址的字段作废。</p><p>请注意，更改区块头的长度是非侵入性操作，因为所有代码（例如RLP编码，哈希）都不可知，所以客户端不需要定制逻辑。</p><p>以上就足以验证一个链，但我们如何更新一个动态的签名者列表。 答案是，我们可以重新使用新近过时的矿工字段beneficiary和PoA废弃的nonce字段来创建投票协议：</p><ul><li>在常规块中，这两个字段都将被设置为零。</li><li>如果签名者希望对授权签名人列表进行更改，则会：<ul><li>将矿工字段<strong>beneficiary</strong>设置为希望投票的签署者</li><li>将<strong>nonce</strong>设置为0或0xff … f来投票赞成添加或踢出</li></ul></li></ul><p>任何同步链的客户端都可以在数据块处理过程中“统计”选票，并通过普通投票保持授权签名者的动态变化列表。 初始的一组签名者通过创世区块的参数提供（以避免在起始状态中部署“最初选民名单”合同的复杂性）。</p><p>为了避免有一个无限的窗口来统计票数，并且允许定期清除陈旧的提议，我们可以重新使用ethash的概念 epoch，每个epoch 转换都会刷新所有未决的投票。 此外，这些epoch 转换还可以作为包含头部额外数据内的当前授权签名者列表的无状态检查点。 这允许客户端仅基于检查点散列进行同步，而不必重播在链上进行的所有投票。 它同样允许用包含了初始签名者的创世区块来完全定义区块链</p><h3 id="攻击媒介：恶意签名者"><a href="#攻击媒介：恶意签名者" class="headerlink" title="攻击媒介：恶意签名者"></a>攻击媒介：恶意签名者</h3><p>可能发生恶意用户被添加到签名者列表中，或者签名者密钥/机器受到威胁。 在这种情况下，协议需要能够抵御重组和垃圾邮件。 所提出的解决方案是，给定N个授权签名者的列表，任何签名者可能只在每个K中填充1个块。这确保损害是有限的，其余的矿工可以投出恶意用户。</p><h2 id="攻击媒介：审查签名者"><a href="#攻击媒介：审查签名者" class="headerlink" title="攻击媒介：审查签名者"></a>攻击媒介：审查签名者</h2><p>另一个有趣的攻击媒介是如果一个签名者（或者一组签名者）试图检查出从授权列表中删除它们的块。 为了解决这个问题，我们限制了签名者允许的最小频率为N / 2。 这确保了恶意签名者需要控制至少51％的签名帐户，在这种情况下，游戏就是无论如何也无法进行下去了。</p><h2 id="攻击媒介：垃圾邮件签名者"><a href="#攻击媒介：垃圾邮件签名者" class="headerlink" title="攻击媒介：垃圾邮件签名者"></a>攻击媒介：垃圾邮件签名者</h2><p>最后的小型攻击媒介就是恶意签署者在每一个块内注入新的投票建议。 由于节点需要统计所有投票来创建授权签名者的实际列表，所以他们需要通过时间跟踪所有投票。 没有限制投票窗口，这可能会慢慢增长，但却是无限的。 解决方法是放置一个W块的移动窗口，之后投票被认为是陈旧的。 一个理智的窗户可能是1-2个时代。 我们将这称为一个时代。</p><h2 id="攻击媒介：并发块"><a href="#攻击媒介：并发块" class="headerlink" title="攻击媒介：并发块"></a>攻击媒介：并发块</h2><p>如果授权签名者的数量是N，并且我们允许每个签名者在K中填充1个块，那么在任何时间N-K个矿工都被允许为Mint。 为了避免这些争夺块，每个签名者将添加一个小的随机“抵消”，以释放一个新的块。 这确保了小叉子是罕见的，但偶尔还会发生（如在主网上）。 如果一个签名者被滥用权威而引起混乱，那么这个签名就可以被投票出去。</p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><h3 id="这是否表明建议我们使用一个被审查testnet？"><a href="#这是否表明建议我们使用一个被审查testnet？" class="headerlink" title="这是否表明建议我们使用一个被审查testnet？"></a>这是否表明建议我们使用一个被审查testnet？</h3><p>该提议表明，考虑到某些行为者的恶意性质，并且鉴于“垄断资金”网络中PoW计划的弱点，最好是建立一个网络，使其具有一定的垃圾过滤功能，开发人员可以依靠它来测试其程序。</p><p>为什么规范PoA？</p><p>不同的客户在不同的情况下会更好。 Go可能在服务器端环境中很棒，但CPP可能更适合在RPI Zero上运行。</p><p>手动投票是不是很麻烦？</p><p>这是一个实现细节，但是签名者可以利用基于合同的投票策略，利用EVM的全部功能，只将结果推送到平均节点的头部进行验证。</p><h2 id="澄清和反馈"><a href="#澄清和反馈" class="headerlink" title="澄清和反馈"></a>澄清和反馈</h2><ul><li><p>这个建议并不排除客户端运行基于PoW的测试网络，无论是Ropsten还是基于它的新的测试网络。理想的情况是客户提供一种连接PoW以及基于PoA的测试网络的方法（＃225（评论））。</p></li><li><p>协议参数尽管可以在客户端实施者的破坏中进行配置，但Rinkeby网络应该尽可能地靠近主网络。这包括动态GasLimit，15秒左右的可变区块时间，GasPrice等（＃225（评论））。</p></li><li><p>该方案要求至少有K个签名者随时上网，因为这是确保“最小化”多样性所需的最少人数。这意味着如果超过K，则网络停止。这应该通过确保签名者是高运行时间的机器来解决，并且在发生太多故障之前及时地将失败的机器投票出去（＃225（评论））。</p></li><li><p>该提案并没有解决“合法的”垃圾邮件问题，就像在攻击者有效地使用testnet以创建垃圾一样，但是如果没有PoW挖掘，攻击者可能无法获得无限的ether来攻击。一种可能性是以有限的方式（例如每天10次）（＃225（评论）），以GitHub（或其他任何方式）帐户为基础提供一个获取ether的途径。</p></li><li><p>有人建议为当时包含授权签名者列表的每个epoch创建checkpoint block。这将允许稍后的轻客户说“从这里同步”，而不需要从起源开始。这可以在签名之前作为前缀添加到extradata字段（＃225（comment））。</p></li></ul><h2 id="Clique-PoA-一致性协议-Clique-proof-of-authority-consensus-protocol"><a href="#Clique-PoA-一致性协议-Clique-proof-of-authority-consensus-protocol" class="headerlink" title="Clique PoA 一致性协议 (Clique proof-of-authority consensus protocol )"></a>Clique PoA 一致性协议 (Clique proof-of-authority consensus protocol )</h2><p>我们定义下面的常量：</p><ul><li>EPOCH_LENGTH：检查点并重置未决投票的块数。<ul><li>建议30000，以便和主网络的ethhash epoch类似</li></ul></li><li>BLOCK_PERIOD：两个连续块的时间戳之间的最小差异。<ul><li>建议15，以便和主网络的ethhash epoch类似</li></ul></li><li>EXTRA_VANITY：固定数量的ExtraData前缀字节为签名者vanity保留。<ul><li>建议的32个字节以便和当前的ExtraData的长度相同。</li></ul></li><li>EXTRA_SEAL：为签名者印章保留的固定数量的额外数据后缀字节。<ul><li>保存签名的65个字节，基于标准secp256k1曲线。</li></ul></li><li>NONCE_AUTH：魔术随机数字0xffffffffffffffff投票添加一个新的签名者。</li><li>NONCE_DROP：魔术随机数字0x0000000000000000对移除签名者进行投票。</li><li>UNCLE_HASH：始终Keccak256（RLP（[]））作为Uncles在PoW之外没有任何意义。</li><li>DIFF_NOTURN：如果当前没有轮到你签名，那么你签名的区块的难度就是这个难度。<ul><li>建议1，因为它只需要是一个任意的基线常数。</li></ul></li><li>DIFF_INTURN：如果当前轮到你签名，那么你签名的难度。<ul><li>建议2， 这样就比没有轮到的签名者难度要高。</li></ul></li></ul><p>我们还定义了以下每块的常量：</p><ul><li>BLOCK_NUMBER：链中的块高度，创世区块的高度是0。</li><li>SIGNER_COUNT：在区块链中中特定实例上有效的授权签名者的数量。</li><li>SIGNER_INDEX：当前授权签名者的排序列表中的索引。</li><li>SIGNER_LIMIT：每隔这么多块，签名者只能签署一块。<ul><li>必须有floor(SIGNER_COUNT / 2）+1 这么多签名者同意才能达成某项决议。</li></ul></li></ul><p>我们重新调整区块头字段的用途，如下所示：</p><ul><li>beneficiary：建议修改授权签名人名单的地址。<ul><li>应该正常填写零，只有投票时修改。</li><li>尽管如此，仍然允许任意值（甚至是无意义的值，例如投出非签名者），以避免增加围绕投票机制的额外复杂性。</li><li>必须在检查点（即epoch转换）块填充零。</li></ul></li><li>nonce：Signer关于受益人字段中定义的账户的建议。<ul><li>NONCE_DROP 提议取消授权受益人作为现有签名者。</li><li>NONCE_AUTH 提出授权受益人作为新的签名者。</li><li>必须在检查点块填充零。</li><li>除了上述两者（现在）之外，不得采用任何其他值。</li></ul></li><li>extraData： vanity, checkpointing and signer signatures的组合字段。<ul><li>第一个EXTRA_VANITY字节（固定长度）可以包含任意签名者vanity data。</li><li>最后一个EXTRA_SEAL字节（固定长度）是密封标题的签名者签名。</li><li>检查点块必须包含一个签名者列表（N * 20字节），否则省略。</li><li>检查点块附加数据部分中的签署者列表必须按升序排序。</li></ul></li><li>mixHash：为了分叉保留。类似于Dao的额外数据<ul><li>在正常操作期间必须填入零。</li></ul></li><li>ommersHash：必须是UNCLE_HASH，因为在PoW之外，Uncles叔没有任何意义。</li><li>timestamp：必须至少为父区块的时间戳 + BLOCK_PERIOD。</li><li>difficulty：包含块的独立得分 来推导链的质量。 <ul><li>如果BLOCK_NUMBER％SIGNER_COUNT！= SIGNER_INDEX，则必须为DIFF_NOTURN</li><li>如果BLOCK_NUMBER％SIGNER_COUNT == SIGNER_INDEX，则必须为DIFF_INTURN</li></ul></li></ul><h3 id="Authorizing-a-block"><a href="#Authorizing-a-block" class="headerlink" title="Authorizing a block"></a>Authorizing a block</h3><p>为了给网络授权一个块，签名者需要签署包含除签名本身以外的所有内容。 这意味着哈希包含区块头的每个字段（包括nonce和mixDigest），还有除了65字节签名后缀外的extraData。 这些字段按照其在黄皮书中定义的顺序进行hash。</p><p>该散列使用标准的secp256k1曲线进行签名，得到的65字节签名（R，S，V，其中V为0或1）作为尾随的65字节后缀嵌入到extraData中。</p><p>为了确保恶意签名者（签名密钥丢失）不能在网络上受到破坏，每位签名者都可以在SIGNER_LIMIT连续块中签最多一个。 顺序不是固定的，不过（DIFF_INTURN）的签名者签出的区块难度要比（DIFF_NOTURN）高</p><h4 id="授权策略"><a href="#授权策略" class="headerlink" title="授权策略"></a>授权策略</h4><p>只要签名者符合上述规范，他们可以授权和分配他们认为合适的块， 下面的建议策略会减少网络流量和分叉，所以这是一个建议的功能：</p><ul><li>如果签署者被允许签署一个区块（在授权清单上并且最近没有签署）。<ul><li>计算下一个块的最佳签名时间（父+ BLOCK_PERIOD）。</li><li>如果轮到了，等待准确的时间到达，立即签字和播放。</li><li>如果没有轮到，则延迟 rand（SIGNER_COUNT * 500ms）这么久的时间签名。<br>这个小小的策略将确保当前轮到的签名者（谁的块更重）对签名和传播与外转签名者有稍微的优势。 此外，该方案允许随着签名者数目的增加而具有一定规模。</li></ul></li></ul><h3 id="投票签署者"><a href="#投票签署者" class="headerlink" title="投票签署者"></a>投票签署者</h3><p>每个epoch转换（包括创世区块）作为一个无状态的检查点，有能力的客户端应该能够同步而不需要任何以前的状态。 这意味着新epoch header不得包含投票，所有未落实的投票都将被丢弃，并从头开始计数。</p><p>对于所有非epoch 转换块：</p><ul><li>签名者可以使用自己签署的区块投一票，以提出对授权列表的更改。</li><li>对每一个提案只保留最新的一个投票。</li><li>随着链条的进展，投票也会生效（允许同时提交提案）。</li><li>达成多数人意见的提案SIGNER_LIMIT立即生效。</li><li>对于客户端实现的简单性，无效的提议不会受到惩罚。</li></ul><p><strong>生效的提案意味着放弃对该提案的所有未决投票（无论是赞成还是反对），并从一个清晰的名单开始。</strong></p><h3 id="级联投票"><a href="#级联投票" class="headerlink" title="级联投票"></a>级联投票</h3><p>签名者取消授权期间可能会出现复杂的案例。如果先前授权的签署者被撤销，则批准提案所需的签名者数量可能会减少一个。这可能会导致一个或多个未决的提案达成共识，执行这些提案可能会进一步影响新的提案。</p><p>当多个相冲突的提议同时通过时（例如，添加新的签名者vs删除现有的提案者），处理这种情况并不明显，评估顺序可能会彻底改变最终授权列表的结果。由于签名者可能会在他们自己的每一个区块中反转他们自己的投票，所以哪一个提案将是“第一”并不那么明显。</p><p>为了避免级联执行所带来的缺陷，解决的办法是明确禁止级联效应。换句话说：只有当前标题/投票的受益人可以被添加到授权列表或从授权列表中删除。如果这导致其他建议达成共识，那么当他们各自的受益者再次“触发”时，这些建议将被执行（因为大多数人的共识仍然在这一点上）。</p><h3 id="投票策略"><a href="#投票策略" class="headerlink" title="投票策略"></a>投票策略</h3><p>由于区块链可以有很小的reorgs，所以“cast-and-forget”的天真投票机制可能不是最优的，因为包含singleton投票的区块可能不会在最终的链中结束。</p><p>一个简单但工作的策略是允许用户在签名者上配置“提案”（例如“add 0x …”，“drop 0x …”）。 签署的代码，然后可以选择一个随机的建议，每块它签署和注入。 这确保了多个并发提案以及reorgs最终在链上被注意到。</p><p>这个列表可能在一定数量的块/epoch后过期，但重要的是要认识到“看”一个提案通过并不意味着它不会被重新组合，所以当提案通过时不应该立即放弃。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-以太坊随机数生成方式</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E9%9A%8F%E6%9C%BA%E6%95%B0%E7%94%9F%E6%88%90%E6%96%B9%E5%BC%8F/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E4%BB%A5%E5%A4%AA%E5%9D%8A%E9%9A%8F%E6%9C%BA%E6%95%B0%E7%94%9F%E6%88%90%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>最近考虑一个基于以太坊的去中心化赌场的实现， 赌场如果需要实现，那么随机数是必须的。 然后研究了一下以太坊里面的随机数生成，发现并不容易。</p><p>以太坊里面生成随机数的几种方式。</p><h1 id="oraclize"><a href="#oraclize" class="headerlink" title="oraclize"></a>oraclize</h1><p>Oraclize定位为去中心化应用的数据搬运工，它作为Web APIs和DApp的可靠链接。有了Oraclize，就不需要建立额外的信任链，因为我们的行为已经被强制加密验证。Oraclize是一个可证明的诚实的预言机服务，可以让智能合约访问互联网。Oraclize是平台无关的，为所有主流的智能合约平台提供一种虚拟的接口。可以想像，通过Oraclize投入大量有意义的数据到区块链中，可以使得智能合约产业更加繁荣，让更多有价值的应用呈现更大的生命力。</p><p>Oraclize的使用方式可以参考下面的<a href="https://github.com/oraclize/ethereum-examples/blob/master/solidity/random-datasource/randomExample.sol">代码</a></p><p>在update方法里面调用oraclize_newRandomDSQuery方法来调用Oracle的智能合约的代码，<br>Oracle根据请求来生成对应的数据， 然后把结果通过回调__callback来传入。</p><pre><code>/*   Oraclize random-datasource example   This contract uses the random-datasource to securely generate off-chain N random bytes*/pragma solidity ^0.4.11;import "github.com/oraclize/ethereum-api/oraclizeAPI.sol";contract RandomExample is usingOraclize {        event newRandomNumber_bytes(bytes);    event newRandomNumber_uint(uint);    function RandomExample() {        oraclize_setProof(proofType_Ledger); // sets the Ledger authenticity proof in the constructor        update(); // let's ask for N random bytes immediately when the contract is created!    }        // the callback function is called by Oraclize when the result is ready    // the oraclize_randomDS_proofVerify modifier prevents an invalid proof to execute this function code:    // the proof validity is fully verified on-chain    function __callback(bytes32 _queryId, string _result, bytes _proof)    {         // if we reach this point successfully, it means that the attached authenticity proof has passed!        if (msg.sender != oraclize_cbAddress()) throw;                if (oraclize_randomDS_proofVerify__returnCode(_queryId, _result, _proof) != 0) {            // the proof verification has failed, do we need to take any action here? (depends on the use case)        } else {            // the proof verification has passed            // now that we know that the random number was safely generated, let's use it..                        newRandomNumber_bytes(bytes(_result)); // this is the resulting random number (bytes)                        // for simplicity of use, let's also convert the random bytes to uint if we need            uint maxRange = 2**(8* 7); // this is the highest uint we want to get. It should never be greater than 2^(8*N), where N is the number of random bytes we had asked the datasource to return            uint randomNumber = uint(sha3(_result)) % maxRange; // this is an efficient way to get the uint out in the [0, maxRange] range                        newRandomNumber_uint(randomNumber); // this is the resulting random number (uint)        }    }        function update() payable {         uint N = 7; // number of random bytes we want the datasource to return        uint delay = 0; // number of seconds to wait before the execution takes place        uint callbackGas = 200000; // amount of gas we want Oraclize to set for the callback function        bytes32 queryId = oraclize_newRandomDSQuery(delay, N, callbackGas); // this function internally generates the correct oraclize_query and returns its queryId    }    }</code></pre><p>考虑一个提供打赌的智能合约。<br>用户调用打赌的接口，这个接口会把用户的请求存储起来，然后调用Oracle随机数生成服务。<br>然后通过Oracle回调服务，判断随机数是否大于某个值，如果成立，那么用户成功，否则用户失败。</p><p>这就是典型的Oracle的使用案例。</p><h1 id="RANDAO-A-DAO-working-as-RNG-of-Ethereum"><a href="#RANDAO-A-DAO-working-as-RNG-of-Ethereum" class="headerlink" title="RANDAO: A DAO working as RNG of Ethereum"></a>RANDAO: A DAO working as RNG of Ethereum</h1><p><a href="https://github.com/randao/randao">randao</a>是一个生成以太坊随机数的去中心化组织，</p><p><strong>Random number in programming is very important!</strong></p><p><strong>RNG in a deterministic system is very difficult</strong></p><p><strong>Miners can’t be trusted!</strong></p><p>随机数在编程中是非常重要的。<br>RNG 在一个确定性的系统中是非常难的。<br>不能相信矿工</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>Solutions</p><p>A DAO (decentralised autonomous organisation) that anyone can participate in, and the random number is generated by all participants together! First of all, we need to create a RANDAO contract in the blockchain, which defines the participation rules. Then the basic process of generating a random number can be divided into three phases:</p><p>一个DAO(去中心化的匿名组织)允许任何人加入，随机数是被所有的参与者一起合作生成的。首先，我们需要在区块链上创建一个RANDAO的智能合约，合约定义了参与规则。然后生成随机数的基本过程可以分为下面三个步骤：</p><p><strong>The first phase: collecting valid sha3(s)</strong></p><p>Anyone who want to participate in the random number generation needs to send a transaction to the contract C with m ETH as pledge in a specified time period (e.g, 6 block period, approximately 72s), accompanied by the result of sha3(s), s is the secret number respective picked by participant.</p><p><strong>第一步：收集有效的sha3(s)</strong><br>参与随机数生成的参与者首先需要在一个指定的时间区间(比如，6个区块的区间，大约72秒)发送m ETH作为抵押到智能合约 C,同时发送一个sha3(s)的值到智能合约C ，s是一个只有参与者自己知道的数字.</p><p><strong>The second phase: collecting valid s</strong></p><p>After the first phase, anyone who submitted sha3(s) successfully needs to send a transaction with the secret number s in the first stage to contract C within a specified time period. Contract C will check if s is valid by running sha3 against s and comparing the result with previous committed data. Valid s will be saved to the collection of seeds to finally generate the random number.</p><p><strong>第二步:收集有效的s</strong></p><p>在第一步结束后，那些提交了sha3(s)的参与者需要在指定的时间区间内发送s到智能合约C. 智能合约C会检查sha3(s)和之前提交的值是否相同。 相同的s会被保存到种子集合用来最终生成随机数。</p><p><strong>The third phase: calculating a random number, refund pledged ETH and bonus</strong></p><ul><li>After all secret numbers have been successfully collected, contract C will calculate the random number from the function f(s1,s2,…,sn), the result will be written to the storage of C, and the result will be sent to all other contracts that requested the random number before.</li><li>Contract C will send back the pledge to the participants in the first phase, and the profit is divided into equal parts and sent to all participants as an additional bonus. The profit comes from the fees that is paid by other contracts that consume the random number.</li></ul><p><strong>第三步:计算随机数，退回抵押和奖金</strong></p><ul><li>在所有的秘密数字s被成功收集后,智能合约C会使用函数f(s1,s2,…,sn)来计算随机数，随机数的结果会写入智能合约的存储，而且结果会被发送到所有之前请求随机数的其他智能合约上面。</li><li>智能合约C会把第一阶段的抵押返回给参与者，然后奖金会被分成同等分发送给所有的参与者。奖金来源于请求随机值的其他智能合约。</li></ul><h2 id="Additional-rules"><a href="#Additional-rules" class="headerlink" title="Additional rules"></a>Additional rules</h2><p>In order to ensure the RNG can’t be manipulated, as well as for safety and efficiency, the contract C has the following additional rules:</p><ul><li><p>The first phase, if two or more of the same sha3(s) are submitted in sequence, only the first one is accepted.</p></li><li><p>The first phase, there is a requirement for minimum number of participants, if it fails to collect enough sha3(s) within the time period, then RNG at this block height will fail.</p></li><li><p>If a participant submits the sha3(s) and it is accepted by contract C, he must reveal the s in the second phase.</p><ul><li><p>If the participant fails to reveal s in the second phase, then the m ETH sent in the first phase will be confiscated without providing a return.</p></li><li><p>If one or more s isn’t revealed in the second phase, RNG at this block height will fail. Confiscated ETHs will be divided equally and send to other participants who revealed s at the second phase. The fees paid by other contracts will be refunded.</p></li></ul></li></ul><p>补充规则</p><p>为了确保RNG不能被操控，以及为了安全和效率，智能合约C有以下的补充规则：</p><ul><li>在第一步中，如果有两个或更多个的同样的sha3(s)被提交上来，那么只有第一个会被接受。</li><li>在第一步中，对于参与者有最低要求，如果在指定的时间区间内没有收集到足够多的sha3(s)的值，那么RNG在这个区块高度会失败。</li><li>如果参与者提交了sha3(s),那么他必须在第二步提交s<ul><li>如果参与者在第二步没有提交s，那么第一阶段提供的m ETH会被没收而且没有奖励。</li><li>如果一个或者多个s没有在第二步被提交，RNG在这个区块高度会失败。没收的ETH会被分成同等分发送给提交了s的其他参与者。其他申请随机数的其他合约的费用会被退回。</li></ul></li></ul><h2 id="Incentive"><a href="#Incentive" class="headerlink" title="Incentive"></a>Incentive</h2><p>The RNG cycle is very short, and could be for example 20 cycles in one hour, if one cycle’s profit is 0.001% , the monthly rate of return is up to 0.00001 * 20 * 24 * 30 = 0.144. Targeting to 14.4% monthly rate of return, and RNG has n participants on average, the running costs of contract is n * 3 * 500 * gasPrice + Ccost. (Ccost is gas consumed by contract internally, including computing and storage, etc. ) Assuming each random numbers has r time requests on average, the call price is p ETH, the income is r * p. So each participant will get (rp - 1500n * gasPrice - Ccost) / n from one time participation. The current gasPrice is 10 szabo, and estimate of contract consumption is 1500n gas, so estimate of net income is (rp / n - 0.03) ETH. Assuming each RNG has 10 participation, and the pledge is 1000ETH, the minimum required income is 0.4 ETH, which over 0.001% profit in this case. So if the RNG is requested only once, the service price is 0.4 ETH, and if it is requested 10 times, the price is just 0.04 ETH for each request.</p><p>激励</p><p>RNG的周期非常短，例如一个小时20个生成周期，如果没有周期的利润是0.001%,一个月的盈利会达到0.00001 * 20 * 24 * 30 = 0.144。 为了达到14.4%每个月的盈利，并且RNG平均有n个参与者，运行智能合约C的费用为  n * 3 * 500 * gasPrice + Ccost.（CCost是合约内部的gas消费，包括计算和存储）假设每个随机值平均有r个请求，每个请求的费用是 p ETH, 那么收入是 r*p. 所以每个参与者每一次参与会收到rp - 1500n * gasPrice - Ccost) / n。当前的gasPrice是10 szabo, 合约的消费大概是1500n gas， 所以大概的净收入是(rp/n-0.03）ETH. 假设每个RNG有10个参与者，并且抵押是1000ETH，所以如果RNG如果只请求一次，那么一次的费用是0.4 ETH, 如果请求是10次，那么一次请求的价格会被降到0.04ETH</p><p>The RANDAO acts as an infrastructure in the Ethereum system. It is called by other contracts. Contracts for different purposes require different random numbers: some need high security, such as lottery; some need steady responses and the request should be responded immediately, these contracts are normally low-value; some need a callback, they want to receive a notification with random numbers when numbers are ready.</p><p>Obviously it’s impossible to meet different requirements in various scenarios with only one RNG contract, so a lot of contracts will be created with different initial parameters, but the basic rules are the same.</p><p>RANDAO作为以太坊系统的基础设施。被其他的合约调用。不同的合约因为有不同的目的所以需要不同的随机值：有些需要高度加密的，比如说抽奖;有些需要稳定的回应，并且要求立即作出回应,这些合约本身的价值不高;有些需要回调函数，当随机值已经生成的时候需要接收到通知。</p><p>很明显通过单一的RNG合约不可能满足所有的不同的请求，所以使用了不同的初始值创建了很多智能合约，不过他们基本的规则是相同的。</p><p>For example, if we need high security, we can substantially increase the pledge of the first phase. Thus, the cost of leading to failure of RNG process by not revealing s is greatly increased. And for the contracts without much interest involved, the minimum number of participants and the pledge can be lower.</p><p>Let’s look at an example of a dApp betting on odd or even numbers, we’ll show how to adjust the contract’s parameters to meet the desired security level, by making the cost of cheating higher than expected earnings. Assuming the bet is 1000 ETH, the betting contract calls a RNG contract C1, if C1 failed to generate a random number at requested block height, then betting contract waits for the next random number of C1, until there is one generated.</p><p>比如，如果你需要高度安全，我们可以大大的增加第一阶段的抵押。这样不提供s的导致失败的概率会大大降低。对于那么资金不是很充足的合约，那么参与者的最小个数和抵押都可以降低。</p><p>让我们看一个dapp的例子，这个例子用来赌数的奇数和偶数，我们会显示如何调整合约的参数来匹配适合的安全程度，通过让造假的成本大大高于收益。假设打赌是1000ETH，这个打赌的合约调用了RNG的合约C1, 如果C1在请求的区块高度生成随机数失败了，打赌的合约会等待C1的下一个随机数，直到有一个生成成功。</p><p>Let’s build the RNG contract C1, and set the pledged ETH of C1 to 2000. The gambler G plays the betting dApp but also participates in the contract. When he finds himself in a disadvantageous position before he reveals his secret number, he can choose not to reveal s, so that the RNG failed and he got another chance. But he will lose the 2000 pledged ETH, so although he can get 1000 ETH expected return, it is still a bad deal. However, G can reduce his losses on C1 by some means, such as participating in C1 using two accounts, sending two sha3(s). if in a disadvantageous position, G will keep only one account’s secret, and if only one participant expect G participate to in C1, G will only lose 1000 ETH in C1, but G will get 1000 ETH as expected return, which is a worthy try.</p><p>让我们构建RNG智能合约C1, 并且设置抵押的值是2000。 赌徒G参与了dApp的赌注，同时参与了RNG的智能合约。在他提交s之前，发现自己处在不利的状态。他可以选择不提交自己的s，这样RNG会失败，他会得到下一个机会。 但是他会损失2000ETH的抵押，尽管他可以得到1000ETH的赌注，所以这样并不是一个好的交易。然而赌徒G可以使用其他的方式来减少损失，比如G可以使用两个账号参与RNG，发送两个sha3(s).如果在不利的状态，G会让一个账号不提交s，这样如果除了G之外只有另外一个其他的账号，G只会在G1上面损失1000ETH，但是G如果赌赢了可以得到1000ETH，所以也值得一试。</p><p>This issue can be fixed by confiscating the pledged ETH, and not return them to participants as bonus. so a contract with 1000 pledged ETH will meet the requirement of the betting dApp.</p><p>这种情况可以通过没收所有抵押来修复，不会把他们作为奖励返回。所以一个1000抵押的合约会符合赌博的要求。</p><p>Besides confiscation, another scheme can prevent such attacks by introducing an additional system: RANDAO membership. To become a member you must pay dues, anyone paid their dues is a member. Members have different levels according to the dues they paid. Membership does not belong to a contract, but instead functions like a passport to participate in some RANDAO contracts. If a breach of any contract happens, that person’s membership will be ended and the dues will be confiscated. Now we can add an additional agreement to C1, C1 will only accept numbers committed by members whose level of investment is high enough (membership dues over 1000 ETH). This will ensure that nobody has a financial motive to try an attack.</p><p>除了没收，还有一个方案可以阻止这种攻击，那就是 RANDAO membership。 为了成为成员，你必须缴纳成员费用。根据成员缴纳的费用的多少把成员分成不同的等级， 成员系统不属于智能合约，而是作为一种类似护照的形式来参与一些RANDAO合约。 如果发生违约情况，这个成员的会员资格会被终止，成员会用会被没收。现在我们可以给智能合约C1增加一个额外的协议，C1只接受会员会用大于一定值的成员来参与。 这样来保证没有任何人会有财务动机来发动攻击。</p><h2 id="QA-Quest-and-Answer"><a href="#QA-Quest-and-Answer" class="headerlink" title="QA: Quest and Answer"></a>QA: Quest and Answer</h2><p>Q: Why not let the miners participate in RNG? Why not use tx hash, nonce and other blockchain data? A: Miners have the ability to manipulate these blockchain data, and thus can indirectly affect RNG. If RNG contains blockchain data, it will give the miners capacity to construct random numbers in their favor.</p><p>Q: 为什么不让矿工来参与到RNG中？ 为什么不使用txhash,nonce或者其他区块链数据?  A:矿工有能力才操纵这些区块链数据，而这些会对RNG产生影响。如果RNG包含了区块链数据，会给予矿工按照自己的行为构造随机数的能力。</p><p>Q: the miners can ignore certain transactions that contain random number they dislike, how to deal with that? A: That’s why we need a time window period. A reasonable period should be greater than 6 blocks, we believe that nobody can produce 6 blocks in succession. So if the participant is honest, and he send numbers immediately as long as each time window open, he doesn’t need to worry about being excluded.</p><p>Q: 矿工有能力忽略特定的包含了随机数的交易，如何处理这种情况？ A: 这就是为什么我们需要时间间隔。 一个合理的时间间隔会大于6个区块，我们任务没有人能连续生成6个区块。 所以如果参与者是忠诚的，而且在时间窗口内发送了那个数字， 那么他不同担心会被矿工排除在外。</p><p>Q: Why use all numbers of all participants, rather than a subset? A: The rule to pick a subset is deterministic, so participants will try to take specified position of the collection by various means, if they succeed, they will know in advance what the random number is generating from subsets. If the rule to pick a subset is randomised, then we still have the problem of true randomisation.</p><p>Q: 为什么使用所有的参与者的所有的值，而不是其子集？ A: 选择一个子集的规则是确定性的，所以参与者将尝试通过各种方式来采集指定的集合位置，如果它们成功，他们将事先知道从子集中产生的随机数。 如果选择一个子集的规则是随机的，那么我们仍然存在真正的随机化问题。</p><p>Q: Where does pledged dues go? A: It will be donated to a charity, or RANDAO to maintain funding. Q: 没收的费用去哪了。 会捐献给慈善机构，或者是RANDAO会维护一个基金。</p><p>Note: f(s1, s2, …, sn) is a function with multiple inputs, for example r = s1 xor s2 xor s3 … xor sn, or r = sha3(sn + sha3(sn-1 + … (sha3(s2 + s1))))</p>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-bloombits源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-bloombits%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-bloombits%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="scheduler-go"><a href="#scheduler-go" class="headerlink" title="scheduler.go"></a>scheduler.go</h2><p>scheduler是基于section的布隆过滤器的单个bit值检索的调度。 除了调度检索操作之外，这个结构还可以对请求进行重复数据删除并缓存结果，从而即使在复杂的过滤情况下也可以将网络/数据库开销降至最低。</p><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>request表示一个bloom检索任务，以便优先从本地数据库中或从网络中剪检索。 section 表示区块段号，每段4096个区块， bit代表检索的是布隆过滤器的哪一位(一共有2048位)。这个在之前的(eth-bloombits和filter源码分析.md)中有介绍。</p><pre><code>// request represents a bloom retrieval task to prioritize and pull from the local// database or remotely from the network.type request struct {    section uint64 // Section index to retrieve the a bit-vector from    bit     uint   // Bit index within the section to retrieve the vector of}</code></pre><p>response当前调度的请求的状态。 没发送一个请求，会生成一个response对象来最终这个请求的状态。<br>cached用来缓存这个section的结果。 </p><pre><code>// response represents the state of a requested bit-vector through a scheduler.type response struct {    cached []byte        // Cached bits to dedup multiple requests    done   chan struct{} // Channel to allow waiting for completion}</code></pre><p>scheduler</p><pre><code>// scheduler handles the scheduling of bloom-filter retrieval operations for// entire section-batches belonging to a single bloom bit. Beside scheduling the// retrieval operations, this struct also deduplicates the requests and caches// the results to minimize network/database overhead even in complex filtering// scenarios.type scheduler struct {    bit       uint                 // Index of the bit in the bloom filter this scheduler is responsible for 布隆过滤器的哪一个bit位(0-2047)    responses map[uint64]*response // Currently pending retrieval requests or already cached responses 当前正在进行的请求或者是已经缓存的结果。    lock      sync.Mutex           // Lock protecting the responses from concurrent access}</code></pre><h3 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h3><p>newScheduler和reset方法</p><pre><code>// newScheduler creates a new bloom-filter retrieval scheduler for a specific// bit index.func newScheduler(idx uint) *scheduler {    return &amp;scheduler{        bit:       idx,        responses: make(map[uint64]*response),    }}// reset cleans up any leftovers from previous runs. This is required before a// restart to ensure the no previously requested but never delivered state will// cause a lockup.reset用法用来清理之前的所有任何请求。func (s *scheduler) reset() {    s.lock.Lock()    defer s.lock.Unlock()    for section, res := range s.responses {        if res.cached == nil {            delete(s.responses, section)        }    }}</code></pre><h3 id="运行-run方法"><a href="#运行-run方法" class="headerlink" title="运行 run方法"></a>运行 run方法</h3><p>run方法创建了一个流水线， 从sections channel来接收需要请求的sections，通过done channel来按照请求的顺序返回结果。 并发的运行同样的scheduler是可以的，这样会导致任务重复。</p><pre><code>// run creates a retrieval pipeline, receiving section indexes from sections and// returning the results in the same order through the done channel. Concurrent// runs of the same scheduler are allowed, leading to retrieval task deduplication.func (s *scheduler) run(sections chan uint64, dist chan *request, done chan []byte, quit chan struct{}, wg *sync.WaitGroup) {    // sections 通道类型 这个是用来传递需要检索的section的通道，输入参数    // dist     通道类型， 属于输出通道(可能是网络发送或者是本地检索)，往这个通道上发送请求， 然后在done上获取回应。    // done  用来传递检索结果的通道， 可以理解为返回值通道。    // Create a forwarder channel between requests and responses of the same size as    // the distribution channel (since that will block the pipeline anyway).    在请求和响应之间创建一个与分发通道大小相同的转发器通道（因为这样会阻塞管道）    pend := make(chan uint64, cap(dist))    // Start the pipeline schedulers to forward between user -&gt; distributor -&gt; user    wg.Add(2)    go s.scheduleRequests(sections, dist, pend, quit, wg)    go s.scheduleDeliveries(pend, done, quit, wg)}</code></pre><h3 id="scheduler的流程图"><a href="#scheduler的流程图" class="headerlink" title="scheduler的流程图"></a>scheduler的流程图</h3><p><img src="/images/ethereum/source_analysis/chainindexer_2.png" alt="image"><br>图中椭圆代表了goroutine. 矩形代表了channel. 三角形代表外部的方法调用。</p><ol><li>scheduleRequests goroutine从sections接收到section消息</li><li>scheduleRequests把接收到的section组装成requtest发送到dist channel，并构建对象response[section]</li><li>scheduleRequests把上一部的section发送给pend队列。scheduleDelivers接收到pend消息，阻塞在response[section].done上面</li><li>外部调用deliver方法，把seciton的request请求结果写入response[section].cached.并关闭response[section].done channel</li><li>scheduleDelivers接收到response[section].done 信息。 把response[section].cached 发送到done channel</li></ol><h3 id="scheduleRequests"><a href="#scheduleRequests" class="headerlink" title="scheduleRequests"></a>scheduleRequests</h3><pre><code>// scheduleRequests reads section retrieval requests from the input channel,// deduplicates the stream and pushes unique retrieval tasks into the distribution// channel for a database or network layer to honour.func (s *scheduler) scheduleRequests(reqs chan uint64, dist chan *request, pend chan uint64, quit chan struct{}, wg *sync.WaitGroup) {    // Clean up the goroutine and pipeline when done    defer wg.Done()    defer close(pend)    // Keep reading and scheduling section requests    for {        select {        case &lt;-quit:            return        case section, ok := &lt;-reqs:            // New section retrieval requested            if !ok {                return            }            // Deduplicate retrieval requests            unique := false            s.lock.Lock()            if s.responses[section] == nil {                s.responses[section] = &amp;response{                    done: make(chan struct{}),                }                unique = true            }            s.lock.Unlock()            // Schedule the section for retrieval and notify the deliverer to expect this section            if unique {                select {                case &lt;-quit:                    return                case dist &lt;- &amp;request{bit: s.bit, section: section}:                }            }            select {            case &lt;-quit:                return            case pend &lt;- section:            }        }    }}</code></pre><h2 id="generator-go"><a href="#generator-go" class="headerlink" title="generator.go"></a>generator.go</h2><p>generator用来产生基于section的布隆过滤器索引数据的对象。 generator内部主要的数据结构是 bloom[2048][4096]bit 的数据结构。  输入是4096个header.logBloom数据。  比如第20个header的logBloom存储在  bloom[0:2048][20]</p><p>数据结构：</p><pre><code>// Generator takes a number of bloom filters and generates the rotated bloom bits// to be used for batched filtering.type Generator struct {    blooms   [types.BloomBitLength][]byte // Rotated blooms for per-bit matching    sections uint                         // Number of sections to batch together  //一个section包含的区块头的数量。  默认是4096    nextBit  uint                         // Next bit to set when adding a bloom 当增加一个bloom的时候，需要设置哪个bit位置}</code></pre><p>构造：</p><pre><code>// NewGenerator creates a rotated bloom generator that can iteratively fill a// batched bloom filter's bits.// func NewGenerator(sections uint) (*Generator, error) {    if sections%8 != 0 {        return nil, errors.New("section count not multiple of 8")    }    b := &amp;Generator{sections: sections}    for i := 0; i &lt; types.BloomBitLength; i++ { //BloomBitLength=2048        b.blooms[i] = make([]byte, sections/8)  // 除以8是因为一个byte是8个bit    }    return b, nil}</code></pre><p>AddBloom增加一个区块头的logsBloom</p><pre><code>// AddBloom takes a single bloom filter and sets the corresponding bit column// in memory accordingly.func (b *Generator) AddBloom(index uint, bloom types.Bloom) error {    // Make sure we're not adding more bloom filters than our capacity    if b.nextBit &gt;= b.sections { //超过了section的最大数量        return errSectionOutOfBounds    }    if b.nextBit != index {  //index是bloom在section中的下标        return errors.New("bloom filter with unexpected index")    }    // Rotate the bloom and insert into our collection    byteIndex := b.nextBit / 8  // 查找到对应的byte，需要设置这个byte位置    bitMask := byte(1) &lt;&lt; byte(7-b.nextBit%8) // 找到需要设置值的bit在byte的下标    for i := 0; i &lt; types.BloomBitLength; i++ {        bloomByteIndex := types.BloomByteLength - 1 - i/8        bloomBitMask := byte(1) &lt;&lt; byte(i%8)        if (bloom[bloomByteIndex] &amp; bloomBitMask) != 0 {            b.blooms[i][byteIndex] |= bitMask        }    }    b.nextBit++    return nil}</code></pre><p>Bitset返回</p><pre><code>// Bitset returns the bit vector belonging to the given bit index after all// blooms have been added.// 在所有的Blooms被添加之后，Bitset返回属于给定位索引的数据。func (b *Generator) Bitset(idx uint) ([]byte, error) {    if b.nextBit != b.sections {        return nil, errors.New("bloom not fully generated yet")    }    if idx &gt;= b.sections {        return nil, errSectionOutOfBounds    }    return b.blooms[idx], nil}</code></pre><h2 id="matcher-go"><a href="#matcher-go" class="headerlink" title="matcher.go"></a>matcher.go</h2><p>Matcher是一个流水线系统的调度器和逻辑匹配器，它们对比特流执行二进制与/或操作，创建一个潜在块的流来检查数据内容。</p><p>数据结构</p><pre><code>// partialMatches with a non-nil vector represents a section in which some sub-// matchers have already found potential matches. Subsequent sub-matchers will// binary AND their matches with this vector. If vector is nil, it represents a// section to be processed by the first sub-matcher.// partialMatches代表了部分匹配的结果。 比入有三个需要过滤的条件 addr1, addr2, addr3 ，需要找到同时匹配这三个条件的数据。 那么我们启动包含了匹配这三个条件的流水线。// 第一个匹配的结果会送给第二个，第二个把第一个的结果和自己的结果执行bit与操作，然后作为匹配的结果送给第三个处理。type partialMatches struct {    section uint64    bitset  []byte}// Retrieval represents a request for retrieval task assignments for a given// bit with the given number of fetch elements, or a response for such a request.// It can also have the actual results set to be used as a delivery data struct.// Retrieval 代表了 一次区块布隆过滤器索引的检索工作， 这个对象被发送给 eth/bloombits.go 里面的 startBloomHandlers来处理， 这个方法从数据库来加载布隆过滤器索引然后放在Bitsets里面返回。type Retrieval struct {    Bit      uint    Sections []uint64    Bitsets  [][]byte}// Matcher is a pipelined system of schedulers and logic matchers which perform// binary AND/OR operations on the bit-streams, creating a stream of potential// blocks to inspect for data content.type Matcher struct {    sectionSize uint64 // Size of the data batches to filter on    filters    [][]bloomIndexes    // Filter the system is matching for    schedulers map[uint]*scheduler // Retrieval schedulers for loading bloom bits     retrievers chan chan uint       // Retriever processes waiting for bit allocations  用来传递 检索任务的通道    counters   chan chan uint       // Retriever processes waiting for task count reports  用来返回当前所有的任务数量    retrievals chan chan *Retrieval // Retriever processes waiting for task allocations  用来传递 检索任务的分配    deliveries chan *Retrieval      // Retriever processes waiting for task response deliveries  检索完成的结果传递到这个通道    running uint32 // Atomic flag whether a session is live or not}</code></pre><p>matcher的大体流程图片，途中椭圆代表goroutine. 矩形代表channel。 三角形代表方法调用。</p><p><img src="/images/ethereum/source_analysis/matcher_1.png" alt="image"></p><ol><li>首先Matcher根据传入的filter的个数 创建了对应个数的 subMatch 。 每一个subMatch对应了一个filter对象。 每一个subMatch会把自己的查找结果和上一个查找结果按照位与的方式得到新的结果。 如果新的结果所有的bit位都有置位，就会把这个查找结果传递给下一个。 这是实现对所有的filter的结果求与的短路算法。  如果前面的计算已经不能匹配任何东西，那么就不用进行下面的条件的匹配了。</li><li>Matcher会根据fiters的布隆过滤器的组合下标的个数来启动对应个数的schedule。</li><li>subMatch会把请求发送给对应的schedule。</li><li>schedule会把请求调度后通过dist发送给distributor， 在distributor中管理起来。</li><li>会启动多个(16)Multiplex线程，从distributor中获取请求，然后把请求发送给bloomRequests队列, startBloomHandlers会访问数据库，拿到数据然后返回给Multiplex。</li><li>Multiplex通过deliveries通道把回答告诉distributor。</li><li>distributor调用schedule的deliver方法，把结果发送给schedule</li><li>schedule把结果返回给subMatch。</li><li>subMatch把结果进行计算后发送给下一个subMatch进行处理。如果是最后一个subMatch，那么结果会进行处理后发送给results通道。</li></ol><p>matcher</p><pre><code>filter := New(backend, 0, -1, []common.Address{addr}, [][]common.Hash{{hash1, hash2, hash3, hash4}}) 组间是与的关系 组内是或的关系。  (addr &amp;&amp; hash1) ||(addr &amp;&amp; hash2)||(addr &amp;&amp; hash3)||(addr &amp;&amp; hash4)</code></pre><p>构造函数， 需要特别注意的是输入的filters这个参数。 这个参数是一个三维度的数组  [][]bloomIndexes === [第一维度][第二维度][3] 。 </p><pre><code>// 这个是filter.go里面的代码，对于理解filters这个参数比较有用。 filter.go是Matcher的调用者。 // 可以看到无论有多少个addresses，在filters里面也只占一个位置。 filters[0]=addresses// filters[1] = topics[0] = 多个topic// filters[2] = topics[1] = 多个topic// filters[n] = topics[n] = 多个topic// filter 的参数addresses 和 topics 的过滤算法是， (含有addresses中任意一个address) 并且 (含有topics[0]里面的任意一个topic) 并且 (含有topics[1]里面任意一个topic) 并且 (含有topics[n]里面的任意一个topic)// 可以看到 对于filter 实行的是  对第一维的数据 执行 与操作， 对于第二维度的数据， 执行或操作。// 而在NewMatcher方法中，把第三维的具体数据转换成 布隆过滤器的指定三个位置。 所以在filter.go里面的var filters [][][]byte 在Matcher里面的filters变成了 [][][3]func New(backend Backend, begin, end int64, addresses []common.Address, topics [][]common.Hash) *Filter {    // Flatten the address and topic filter clauses into a single bloombits filter    // system. Since the bloombits are not positional, nil topics are permitted,    // which get flattened into a nil byte slice.    var filters [][][]byte    if len(addresses) &gt; 0 {        filter := make([][]byte, len(addresses))        for i, address := range addresses {            filter[i] = address.Bytes()        }        filters = append(filters, filter)    }    for _, topicList := range topics {        filter := make([][]byte, len(topicList))        for i, topic := range topicList {            filter[i] = topic.Bytes()        }        filters = append(filters, filter)    }// NewMatcher creates a new pipeline for retrieving bloom bit streams and doing// address and topic filtering on them. Setting a filter component to `nil` is// allowed and will result in that filter rule being skipped (OR 0x11...1).func NewMatcher(sectionSize uint64, filters [][][]byte) *Matcher {    // Create the matcher instance    m := &amp;Matcher{        sectionSize: sectionSize,        schedulers:  make(map[uint]*scheduler),        retrievers:  make(chan chan uint),        counters:    make(chan chan uint),        retrievals:  make(chan chan *Retrieval),        deliveries:  make(chan *Retrieval),    }    // Calculate the bloom bit indexes for the groups we're interested in    m.filters = nil    for _, filter := range filters {        // Gather the bit indexes of the filter rule, special casing the nil filter        if len(filter) == 0 {            continue        }        bloomBits := make([]bloomIndexes, len(filter))        for i, clause := range filter {            if clause == nil {                bloomBits = nil                break            }             // clause 对应了输入的第三维度的数据，可能是一个address或者是一个topic            // calcBloomIndexes计算了这个数据对应的(0-2048)的布隆过滤器中的三个下标， 就是说如果在布隆过滤器中对应的三位都为1，那么clause这个数据就有可能在这里。            bloomBits[i] = calcBloomIndexes(clause)        }        // Accumulate the filter rules if no nil rule was within        // 在计算中 如果bloomBits中只要其中的一条能够找到。那么就认为整个成立。        if bloomBits != nil {            // 不同的bloomBits 需要同时成立，整个结果才能成立。            m.filters = append(m.filters, bloomBits)        }    }    // For every bit, create a scheduler to load/download the bit vectors    for _, bloomIndexLists := range m.filters {        for _, bloomIndexList := range bloomIndexLists {            for _, bloomIndex := range bloomIndexList {                // 对于所有可能出现的下标。 我们都生成一个scheduler来进行对应位置的                // 布隆过滤数据的检索。                m.addScheduler(bloomIndex)            }        }    }    return m}</code></pre><p>Start 启动</p><pre><code>// Start starts the matching process and returns a stream of bloom matches in// a given range of blocks. If there are no more matches in the range, the result// channel is closed.func (m *Matcher) Start(begin, end uint64, results chan uint64) (*MatcherSession, error) {    // Make sure we're not creating concurrent sessions    if atomic.SwapUint32(&amp;m.running, 1) == 1 {        return nil, errors.New("matcher already running")    }    defer atomic.StoreUint32(&amp;m.running, 0)    // Initiate a new matching round    // 启动了一个session，作为返回值，管理查找的生命周期。    session := &amp;MatcherSession{        matcher: m,        quit:    make(chan struct{}),        kill:    make(chan struct{}),    }    for _, scheduler := range m.schedulers {        scheduler.reset()    }    // 这个运行会建立起流程，返回了一个partialMatches类型的管道表示查询的部分结果。    sink := m.run(begin, end, cap(results), session)    // Read the output from the result sink and deliver to the user    session.pend.Add(1)    go func() {        defer session.pend.Done()        defer close(results)        for {            select {            case &lt;-session.quit:                return            case res, ok := &lt;-sink:                // New match result found                // 找到返回结果 因为返回值是 section和 section中哪些区块可能有值的bitmap                // 所以需要遍历这个bitmap，找到那些被置位的区块，把区块号返回回去。                if !ok {                    return                }                // Calculate the first and last blocks of the section                sectionStart := res.section * m.sectionSize                first := sectionStart                if begin &gt; first {                    first = begin                }                last := sectionStart + m.sectionSize - 1                if end &lt; last {                    last = end                }                // Iterate over all the blocks in the section and return the matching ones                for i := first; i &lt;= last; i++ {                    // Skip the entire byte if no matches are found inside                    next := res.bitset[(i-sectionStart)/8]                    if next == 0 {                        i += 7                        continue                    }                    // Some bit it set, do the actual submatching                    if bit := 7 - i%8; next&amp;(1&lt;&lt;bit) != 0 {                        select {                        case &lt;-session.quit:                            return                        case results &lt;- i:                        }                    }                }            }        }    }()    return session, nil}</code></pre><p>run方法</p><pre><code>// run creates a daisy-chain of sub-matchers, one for the address set and one// for each topic set, each sub-matcher receiving a section only if the previous// ones have all found a potential match in one of the blocks of the section,// then binary AND-ing its own matches and forwaring the result to the next one.//  创建一个子匹配器的流水线，一个用于地址集，一个用于每个主题集，每个子匹配器只有在先前的所有子块都在该部分的一个块中找到可能的匹配时才接收一个部分，然后把接收到的和自己的匹配，并将结果转交给下一个。// The method starts feeding the section indexes into the first sub-matcher on a// new goroutine and returns a sink channel receiving the results.该方法开始section indexer送到第一个子匹配器，并返回接收结果的接收器通道。func (m *Matcher) run(begin, end uint64, buffer int, session *MatcherSession) chan *partialMatches {    // Create the source channel and feed section indexes into    source := make(chan *partialMatches, buffer)    session.pend.Add(1)    go func() {        defer session.pend.Done()        defer close(source)        for i := begin / m.sectionSize; i &lt;= end/m.sectionSize; i++ {            // 这个for循环 构造了subMatch的第一个输入源，剩下的subMatch把上一个的结果作为自己的源            // 这个源的bitset字段都是0xff，代表完全的匹配，它将和我们这一步的匹配进行与操作，得到这一步匹配的结果。            select {            case &lt;-session.quit:                return            case source &lt;- &amp;partialMatches{i, bytes.Repeat([]byte{0xff}, int(m.sectionSize/8))}:            }        }    }()    // Assemble the daisy-chained filtering pipeline    next := source    dist := make(chan *request, buffer)    for _, bloom := range m.filters {  //构建流水线， 前一个的输出作为下一个subMatch的输入。        next = m.subMatch(next, dist, bloom, session)    }    // Start the request distribution    session.pend.Add(1)    // 启动distributor线程。     go m.distributor(dist, session)    return next}</code></pre><p>subMatch函数</p><pre><code>// subMatch creates a sub-matcher that filters for a set of addresses or topics, binary OR-s those matches, then// binary AND-s the result to the daisy-chain input (source) and forwards it to the daisy-chain output.// The matches of each address/topic are calculated by fetching the given sections of the three bloom bit indexes belonging to// that address/topic, and binary AND-ing those vectors together.// subMatch创建一个子匹配器，用于过滤一组地址或主题，对这些主题进行bit位或操作，然后将上一个结果与当前过滤结果进行位与操作，如果结果不全位空，就把结果传递给下一个子匹配器。 每个地址/题目的匹配是通过获取属于该地址/题目的三个布隆过滤器位索引的给定部分以及将这些向量二进制AND并在一起来计算的。subMatch是最重要的一个函数， 把filters [][][3]的 第一维度的与，第二维度的或， 第三维度的与操作 结合在一起。 func (m *Matcher) subMatch(source chan *partialMatches, dist chan *request, bloom []bloomIndexes, session *MatcherSession) chan *partialMatches {    // Start the concurrent schedulers for each bit required by the bloom filter    // 传入的bloom []bloomIndexes参数是filters的第二,第三维度  [][3]      sectionSources := make([][3]chan uint64, len(bloom))    sectionSinks := make([][3]chan []byte, len(bloom))    for i, bits := range bloom { // i代表了第二维度的数量        for j, bit := range bits {  //j 代表了布隆过滤器的下标 肯定只有三个 取值(0-2048)            sectionSources[i][j] = make(chan uint64, cap(source)) // 创建scheduler的输入channel            sectionSinks[i][j] = make(chan []byte, cap(source)) // 创建 scheduler的输出channel            // 对这个bit发起调度请求， 通过sectionSources[i][j]传递需要查询的section            // 通过sectionSinks[i][j]来接收结果            // dist 是scheduler传递请求的通道。 这个在scheduler的介绍里面有。            m.schedulers[bit].run(sectionSources[i][j], dist, sectionSinks[i][j], session.quit, &amp;session.pend)        }    }    process := make(chan *partialMatches, cap(source)) // entries from source are forwarded here after fetches have been initiated  中间channel    results := make(chan *partialMatches, cap(source)) // 返回值channel    session.pend.Add(2)    go func() {        // Tear down the goroutine and terminate all source channels        defer session.pend.Done()        defer close(process)        defer func() {            for _, bloomSources := range sectionSources {                for _, bitSource := range bloomSources {                    close(bitSource)                }            }        }()        // Read sections from the source channel and multiplex into all bit-schedulers        // 从source channel读取sections 并把这些数据通过sectionSources传递给scheduler        for {            select {            case &lt;-session.quit:                return            case subres, ok := &lt;-source:                // New subresult from previous link                if !ok {                    return                }                // Multiplex the section index to all bit-schedulers                for _, bloomSources := range sectionSources {                    for _, bitSource := range bloomSources {                        // 传递给上面的所有的scheduler的输入通道。 申请对这些                        // section 的指定bit进行查找。 结果会发送给sectionSinks[i][j]                        select {                        case &lt;-session.quit:                            return                        case bitSource &lt;- subres.section:                        }                    }                }                // Notify the processor that this section will become available                select {                case &lt;-session.quit:                    return                case process &lt;- subres: //等到所有的请求都递交给scheduler 给process发送消息。                }            }        }    }()    go func() {        // Tear down the goroutine and terminate the final sink channel        defer session.pend.Done()        defer close(results)        // Read the source notifications and collect the delivered results        for {            select {            case &lt;-session.quit:                return            case subres, ok := &lt;-process:                 // 这里有个问题。 有没有可能乱序。 因为通道都是有缓存的。 可能查询得快慢导致                // 查看了scheduler的实现， scheduler是保证顺序的。怎么进来，就会怎么出去。                // Notified of a section being retrieved                if !ok {                    return                }                // Gather all the sub-results and merge them together                var orVector []byte                for _, bloomSinks := range sectionSinks {                    var andVector []byte                    for _, bitSink := range bloomSinks { // 这里可以接收到三个值 每个代表了对应下标的 布隆过滤器的值,对这三个值进行与操作，                    就可以得到那些区块可能存在对应的值。                        var data []byte                        select {                        case &lt;-session.quit:                            return                        case data = &lt;-bitSink:                        }                        if andVector == nil {                            andVector = make([]byte, int(m.sectionSize/8))                            copy(andVector, data)                        } else {                            bitutil.ANDBytes(andVector, andVector, data)                        }                    }                    if orVector == nil { 对第一维度的数据执行 Or操作。                        orVector = andVector                    } else {                        bitutil.ORBytes(orVector, orVector, andVector)                    }                }                if orVector == nil { //可能通道被关闭了。 没有查询到任何值                    orVector = make([]byte, int(m.sectionSize/8))                }                if subres.bitset != nil {                    // 和输入的上一次的结果进行与操作。 记得最开始这个值被初始化为全1                    bitutil.ANDBytes(orVector, orVector, subres.bitset)                }                if bitutil.TestBytes(orVector) { // 如果不全为0 那么添加到结果。可能会给下一个匹配。或者是返回。                    select {                    case &lt;-session.quit:                        return                    case results &lt;- &amp;partialMatches{subres.section, orVector}:                    }                }            }        }    }()    return results}</code></pre><p>distributor,接受来自scheduler的请求，并把他们放到一个set里面。 然后把这些任务指派给retrievers来填充他们。</p><pre><code>// distributor receives requests from the schedulers and queues them into a set// of pending requests, which are assigned to retrievers wanting to fulfil them.func (m *Matcher) distributor(dist chan *request, session *MatcherSession) {    defer session.pend.Done()    var (        requests   = make(map[uint][]uint64) // Per-bit list of section requests, ordered by section number        unallocs   = make(map[uint]struct{}) // Bits with pending requests but not allocated to any retriever        retrievers chan chan uint            // Waiting retrievers (toggled to nil if unallocs is empty)    )    var (        allocs   int            // Number of active allocations to handle graceful shutdown requests        shutdown = session.quit // Shutdown request channel, will gracefully wait for pending requests    )    // assign is a helper method fo try to assign a pending bit an an actively    // listening servicer, or schedule it up for later when one arrives.    assign := func(bit uint) {        select {        case fetcher := &lt;-m.retrievers:            allocs++            fetcher &lt;- bit        default:            // No retrievers active, start listening for new ones            retrievers = m.retrievers            unallocs[bit] = struct{}{}        }    }    for {        select {        case &lt;-shutdown:            // Graceful shutdown requested, wait until all pending requests are honoured            if allocs == 0 {                return            }            shutdown = nil        case &lt;-session.kill:            // Pending requests not honoured in time, hard terminate            return        case req := &lt;-dist: // scheduler发送来的请求 添加到指定bit位置的queue里面            // New retrieval request arrived to be distributed to some fetcher process            queue := requests[req.bit]            index := sort.Search(len(queue), func(i int) bool { return queue[i] &gt;= req.section })            requests[req.bit] = append(queue[:index], append([]uint64{req.section}, queue[index:]...)...)            // If it's a new bit and we have waiting fetchers, allocate to them            // 如果这个bit是一个新的。 还没有被指派，那么我们把他指派给等待的fetchers            if len(queue) == 0 {                assign(req.bit)            }        case fetcher := &lt;-retrievers:            // New retriever arrived, find the lowest section-ed bit to assign            // 如果新的retrievers进来了， 那么我们查看是否有任务没有指派            bit, best := uint(0), uint64(math.MaxUint64)            for idx := range unallocs {                if requests[idx][0] &lt; best {                    bit, best = idx, requests[idx][0]                }            }            // Stop tracking this bit (and alloc notifications if no more work is available)            delete(unallocs, bit)            if len(unallocs) == 0 { //如果所有任务都被指派。那么停止关注retrievers                retrievers = nil            }            allocs++            fetcher &lt;- bit        case fetcher := &lt;-m.counters:            // New task count request arrives, return number of items            // 来了新的请求，访问request的指定bit的数量。            fetcher &lt;- uint(len(requests[&lt;-fetcher]))        case fetcher := &lt;-m.retrievals:            // New fetcher waiting for tasks to retrieve, assign            // 有人来领取任务。            task := &lt;-fetcher            if want := len(task.Sections); want &gt;= len(requests[task.Bit]) {                task.Sections = requests[task.Bit]                delete(requests, task.Bit)            } else {                task.Sections = append(task.Sections[:0], requests[task.Bit][:want]...)                requests[task.Bit] = append(requests[task.Bit][:0], requests[task.Bit][want:]...)            }            fetcher &lt;- task            // If anything was left unallocated, try to assign to someone else            // 如果还有任务没有分派完。 尝试分配给其他人。            if len(requests[task.Bit]) &gt; 0 {                assign(task.Bit)            }        case result := &lt;-m.deliveries:            // New retrieval task response from fetcher, split out missing sections and            // deliver complete ones            // 收到了任务的结果。             var (                sections = make([]uint64, 0, len(result.Sections))                bitsets  = make([][]byte, 0, len(result.Bitsets))                missing  = make([]uint64, 0, len(result.Sections))            )            for i, bitset := range result.Bitsets {                if len(bitset) == 0 { //如果任务结果有缺失，记录下来                    missing = append(missing, result.Sections[i])                    continue                }                sections = append(sections, result.Sections[i])                bitsets = append(bitsets, bitset)            }            // 投递结果            m.schedulers[result.Bit].deliver(sections, bitsets)            allocs--            // Reschedule missing sections and allocate bit if newly available            if len(missing) &gt; 0 { //如果有缺失， 那么重新生成新的任务。                queue := requests[result.Bit]                for _, section := range missing {                    index := sort.Search(len(queue), func(i int) bool { return queue[i] &gt;= section })                    queue = append(queue[:index], append([]uint64{section}, queue[index:]...)...)                }                requests[result.Bit] = queue                if len(queue) == len(missing) {                    assign(result.Bit)                }            }            // If we're in the process of shutting down, terminate            if allocs == 0 &amp;&amp; shutdown == nil {                return            }        }    }}</code></pre><p>任务领取AllocateRetrieval。 任务领取了一个任务。 会返回指定的bit的检索任务。</p><pre><code>// AllocateRetrieval assigns a bloom bit index to a client process that can either// immediately reuest and fetch the section contents assigned to this bit or wait// a little while for more sections to be requested.func (s *MatcherSession) AllocateRetrieval() (uint, bool) {    fetcher := make(chan uint)    select {    case &lt;-s.quit:        return 0, false    case s.matcher.retrievers &lt;- fetcher:        bit, ok := &lt;-fetcher        return bit, ok    }}</code></pre><p>AllocateSections,领取指定bit的section查询任务。</p><pre><code>// AllocateSections assigns all or part of an already allocated bit-task queue// to the requesting process.func (s *MatcherSession) AllocateSections(bit uint, count int) []uint64 {    fetcher := make(chan *Retrieval)    select {    case &lt;-s.quit:        return nil    case s.matcher.retrievals &lt;- fetcher:        task := &amp;Retrieval{            Bit:      bit,            Sections: make([]uint64, count),        }        fetcher &lt;- task        return (&lt;-fetcher).Sections    }}</code></pre><p>DeliverSections，把结果投递给deliveries 通道。</p><pre><code>// DeliverSections delivers a batch of section bit-vectors for a specific bloom// bit index to be injected into the processing pipeline.func (s *MatcherSession) DeliverSections(bit uint, sections []uint64, bitsets [][]byte) {    select {    case &lt;-s.kill:        return    case s.matcher.deliveries &lt;- &amp;Retrieval{Bit: bit, Sections: sections, Bitsets: bitsets}:    }}</code></pre><p>任务的执行Multiplex,Multiplex函数不断的领取任务，把任务投递给bloomRequest队列。从队列获取结果。然后投递给distributor。 完成了整个过程。</p><pre><code>// Multiplex polls the matcher session for rerieval tasks and multiplexes it into// the reuested retrieval queue to be serviced together with other sessions.//// This method will block for the lifetime of the session. Even after termination// of the session, any request in-flight need to be responded to! Empty responses// are fine though in that case.func (s *MatcherSession) Multiplex(batch int, wait time.Duration, mux chan chan *Retrieval) {    for {        // Allocate a new bloom bit index to retrieve data for, stopping when done        bit, ok := s.AllocateRetrieval()        if !ok {            return        }        // Bit allocated, throttle a bit if we're below our batch limit        if s.PendingSections(bit) &lt; batch {            select {            case &lt;-s.quit:                // Session terminating, we can't meaningfully service, abort                s.AllocateSections(bit, 0)                s.DeliverSections(bit, []uint64{}, [][]byte{})                return            case &lt;-time.After(wait):                // Throttling up, fetch whatever's available            }        }        // Allocate as much as we can handle and request servicing        sections := s.AllocateSections(bit, batch)        request := make(chan *Retrieval)        select {        case &lt;-s.quit:            // Session terminating, we can't meaningfully service, abort            s.DeliverSections(bit, sections, make([][]byte, len(sections)))            return        case mux &lt;- request:            // Retrieval accepted, something must arrive before we're aborting            request &lt;- &amp;Retrieval{Bit: bit, Sections: sections}            result := &lt;-request            s.DeliverSections(result.Bit, result.Sections, result.Bitsets)        }    }}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-core-txpool交易池源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-txpool%E4%BA%A4%E6%98%93%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-core-txpool%E4%BA%A4%E6%98%93%E6%B1%A0%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>txpool主要用来存放当前提交的等待写入区块的交易，有远端和本地的。</p><p>txpool里面的交易分为两种，</p><ol><li>提交但是还不能执行的，放在queue里面等待能够执行(比如说nonce太高)。</li><li>等待执行的，放在pending里面等待执行。</li></ol><p>从txpool的测试案例来看，txpool主要功能有下面几点。</p><ol><li>交易验证的功能，包括余额不足，Gas不足，Nonce太低, value值是合法的，不能为负数。</li><li>能够缓存Nonce比当前本地账号状态高的交易。 存放在queue字段。 如果是能够执行的交易存放在pending字段</li><li>相同用户的相同Nonce的交易只会保留一个GasPrice最大的那个。 其他的插入不成功。</li><li>如果账号没有钱了，那么queue和pending中对应账号的交易会被删除。</li><li>如果账号的余额小于一些交易的额度，那么对应的交易会被删除，同时有效的交易会从pending移动到queue里面。防止被广播。</li><li>txPool支持一些限制PriceLimit(remove的最低GasPrice限制)，PriceBump(替换相同Nonce的交易的价格的百分比) AccountSlots(每个账户的pending的槽位的最小值) GlobalSlots(全局pending队列的最大值)AccountQueue(每个账户的queueing的槽位的最小值) GlobalQueue(全局queueing的最大值) Lifetime(在queue队列的最长等待时间)</li><li>有限的资源情况下按照GasPrice的优先级进行替换。</li><li>本地的交易会使用journal的功能存放在磁盘上，重启之后会重新导入。 远程的交易不会。</li></ol><p>数据结构</p><pre><code>// TxPool contains all currently known transactions. Transactions// enter the pool when they are received from the network or submitted// locally. They exit the pool when they are included in the blockchain.// TxPool 包含了当前知的交易， 当前网络接收到交易，或者本地提交的交易会加入到TxPool。// 当他们已经被添加到区块链的时候被移除。// The pool separates processable transactions (which can be applied to the// current state) and future transactions. Transactions move between those// two states over time as they are received and processed.// TxPool分为可执行的交易(可以应用到当前的状态)和未来的交易。 交易在这两种状态之间转换，type TxPool struct {    config       TxPoolConfig    chainconfig  *params.ChainConfig    chain        blockChain    gasPrice     *big.Int             //最低的GasPrice限制    txFeed       event.Feed              //通过txFeed来订阅TxPool的消息    scope        event.SubscriptionScope    chainHeadCh  chan ChainHeadEvent  // 订阅了区块头的消息，当有了新的区块头生成的时候会在这里收到通知    chainHeadSub event.Subscription   // 区块头消息的订阅器。    signer       types.Signer          // 封装了事务签名处理。    mu           sync.RWMutex    currentState  *state.StateDB      // Current state in the blockchain head    pendingState  *state.ManagedState // Pending state tracking virtual nonces    currentMaxGas *big.Int            // Current gas limit for transaction caps 目前交易上限的GasLimit    locals  *accountSet // Set of local transaction to exepmt from evicion rules  本地交易免除驱逐规则    journal *txJournal  // Journal of local transaction to back up to disk 本地交易会写入磁盘    pending map[common.Address]*txList         // All currently processable transactions 所有当前可以处理的交易    queue   map[common.Address]*txList         // Queued but non-processable transactions 当前还不能处理的交易    beats   map[common.Address]time.Time       // Last heartbeat from each known account 每一个已知账号的最后一次心跳信息的时间    all     map[common.Hash]*types.Transaction // All transactions to allow lookups 可以查找到所有交易    priced  *txPricedList                      // All transactions sorted by price 按照价格排序的交易    wg sync.WaitGroup // for shutdown sync    homestead bool  // 家园版本}</code></pre><p>构建</p><pre><code>// NewTxPool creates a new transaction pool to gather, sort and filter inbound// trnsactions from the network.func NewTxPool(config TxPoolConfig, chainconfig *params.ChainConfig, chain blockChain) *TxPool {    // Sanitize the input to ensure no vulnerable gas prices are set    config = (&amp;config).sanitize()    // Create the transaction pool with its initial settings    pool := &amp;TxPool{        config:      config,        chainconfig: chainconfig,        chain:       chain,        signer:      types.NewEIP155Signer(chainconfig.ChainId),        pending:     make(map[common.Address]*txList),        queue:       make(map[common.Address]*txList),        beats:       make(map[common.Address]time.Time),        all:         make(map[common.Hash]*types.Transaction),        chainHeadCh: make(chan ChainHeadEvent, chainHeadChanSize),        gasPrice:    new(big.Int).SetUint64(config.PriceLimit),    }    pool.locals = newAccountSet(pool.signer)    pool.priced = newTxPricedList(&amp;pool.all)    pool.reset(nil, chain.CurrentBlock().Header())    // If local transactions and journaling is enabled, load from disk    // 如果本地交易被允许,而且配置的Journal目录不为空,那么从指定的目录加载日志.    // 然后rotate交易日志. 因为老的交易可能已经失效了, 所以调用add方法之后再把被接收的交易写入日志.    //     if !config.NoLocals &amp;&amp; config.Journal != "" {        pool.journal = newTxJournal(config.Journal)        if err := pool.journal.load(pool.AddLocal); err != nil {            log.Warn("Failed to load transaction journal", "err", err)        }        if err := pool.journal.rotate(pool.local()); err != nil {            log.Warn("Failed to rotate transaction journal", "err", err)        }    }    // Subscribe events from blockchain 从区块链订阅事件。    pool.chainHeadSub = pool.chain.SubscribeChainHeadEvent(pool.chainHeadCh)    // Start the event loop and return    pool.wg.Add(1)    go pool.loop()    return pool}</code></pre><p>reset方法检索区块链的当前状态并且确保事务池的内容关于当前的区块链状态是有效的。主要功能包括：</p><ol><li>因为更换了区块头，所以原有的区块中有一些交易因为区块头的更换而作废，这部分交易需要重新加入到txPool里面等待插入新的区块</li><li>生成新的currentState和pendingState</li><li>因为状态的改变。将pending中的部分交易移到queue里面</li><li>因为状态的改变，将queue里面的交易移入到pending里面。</li></ol><p>reset代码</p><pre><code>// reset retrieves the current state of the blockchain and ensures the content// of the transaction pool is valid with regard to the chain state.func (pool *TxPool) reset(oldHead, newHead *types.Header) {    // If we're reorging an old state, reinject all dropped transactions    var reinject types.Transactions    if oldHead != nil &amp;&amp; oldHead.Hash() != newHead.ParentHash {        // If the reorg is too deep, avoid doing it (will happen during fast sync)        oldNum := oldHead.Number.Uint64()        newNum := newHead.Number.Uint64()        if depth := uint64(math.Abs(float64(oldNum) - float64(newNum))); depth &gt; 64 { //如果老的头和新的头差距太远, 那么取消重建            log.Warn("Skipping deep transaction reorg", "depth", depth)        } else {            // Reorg seems shallow enough to pull in all transactions into memory            var discarded, included types.Transactions            var (                rem = pool.chain.GetBlock(oldHead.Hash(), oldHead.Number.Uint64())                add = pool.chain.GetBlock(newHead.Hash(), newHead.Number.Uint64())            )            // 如果老的高度大于新的.那么需要把多的全部删除.            for rem.NumberU64() &gt; add.NumberU64() {                discarded = append(discarded, rem.Transactions()...)                if rem = pool.chain.GetBlock(rem.ParentHash(), rem.NumberU64()-1); rem == nil {                    log.Error("Unrooted old chain seen by tx pool", "block", oldHead.Number, "hash", oldHead.Hash())                    return                }            }            // 如果新的高度大于老的, 那么需要增加.            for add.NumberU64() &gt; rem.NumberU64() {                included = append(included, add.Transactions()...)                if add = pool.chain.GetBlock(add.ParentHash(), add.NumberU64()-1); add == nil {                    log.Error("Unrooted new chain seen by tx pool", "block", newHead.Number, "hash", newHead.Hash())                    return                }            }            // 高度相同了.如果hash不同,那么需要往后找,一直找到他们相同hash根的节点.            for rem.Hash() != add.Hash() {                discarded = append(discarded, rem.Transactions()...)                if rem = pool.chain.GetBlock(rem.ParentHash(), rem.NumberU64()-1); rem == nil {                    log.Error("Unrooted old chain seen by tx pool", "block", oldHead.Number, "hash", oldHead.Hash())                    return                }                included = append(included, add.Transactions()...)                if add = pool.chain.GetBlock(add.ParentHash(), add.NumberU64()-1); add == nil {                    log.Error("Unrooted new chain seen by tx pool", "block", newHead.Number, "hash", newHead.Hash())                    return                }            }            // 找出所有存在discard里面,但是不在included里面的值.            // 需要等下把这些交易重新插入到pool里面。            reinject = types.TxDifference(discarded, included)        }    }    // Initialize the internal state to the current head    if newHead == nil {        newHead = pool.chain.CurrentBlock().Header() // Special case during testing    }    statedb, err := pool.chain.StateAt(newHead.Root)    if err != nil {        log.Error("Failed to reset txpool state", "err", err)        return    }    pool.currentState = statedb    pool.pendingState = state.ManageState(statedb)    pool.currentMaxGas = newHead.GasLimit    // Inject any transactions discarded due to reorgs    log.Debug("Reinjecting stale transactions", "count", len(reinject))    pool.addTxsLocked(reinject, false)    // validate the pool of pending transactions, this will remove    // any transactions that have been included in the block or    // have been invalidated because of another transaction (e.g.    // higher gas price)    // 验证pending transaction池里面的交易， 会移除所有已经存在区块链里面的交易，或者是因为其他交易导致不可用的交易(比如有一个更高的gasPrice)    // demote 降级 将pending中的一些交易降级到queue里面。    pool.demoteUnexecutables()    // Update all accounts to the latest known pending nonce    // 根据pending队列的nonce更新所有账号的nonce    for addr, list := range pool.pending {        txs := list.Flatten() // Heavy but will be cached and is needed by the miner anyway        pool.pendingState.SetNonce(addr, txs[len(txs)-1].Nonce()+1)    }    // Check the queue and move transactions over to the pending if possible    // or remove those that have become invalid    // 检查队列并尽可能地将事务移到pending，或删除那些已经失效的事务    // promote 升级     pool.promoteExecutables(nil)}</code></pre><p>addTx </p><pre><code>// addTx enqueues a single transaction into the pool if it is valid.func (pool *TxPool) addTx(tx *types.Transaction, local bool) error {    pool.mu.Lock()    defer pool.mu.Unlock()    // Try to inject the transaction and update any state    replace, err := pool.add(tx, local)    if err != nil {        return err    }    // If we added a new transaction, run promotion checks and return    if !replace {        from, _ := types.Sender(pool.signer, tx) // already validated        pool.promoteExecutables([]common.Address{from})    }    return nil}</code></pre><p>addTxsLocked</p><pre><code>// addTxsLocked attempts to queue a batch of transactions if they are valid,// whilst assuming the transaction pool lock is already held.// addTxsLocked尝试把有效的交易放入queue队列，调用这个函数的时候假设已经获取到锁func (pool *TxPool) addTxsLocked(txs []*types.Transaction, local bool) error {    // Add the batch of transaction, tracking the accepted ones    dirty := make(map[common.Address]struct{})    for _, tx := range txs {        if replace, err := pool.add(tx, local); err == nil {            if !replace { // replace 是替换的意思， 如果不是替换，那么就说明状态有更新，有可以下一步处理的可能。                from, _ := types.Sender(pool.signer, tx) // already validated                dirty[from] = struct{}{}            }        }    }    // Only reprocess the internal state if something was actually added    if len(dirty) &gt; 0 {        addrs := make([]common.Address, 0, len(dirty))        for addr, _ := range dirty {            addrs = append(addrs, addr)        }            // 传入了被修改的地址，        pool.promoteExecutables(addrs)    }    return nil}</code></pre><p>demoteUnexecutables 从pending删除无效的或者是已经处理过的交易，其他的不可执行的交易会被移动到future queue中。</p><pre><code>// demoteUnexecutables removes invalid and processed transactions from the pools// executable/pending queue and any subsequent transactions that become unexecutable// are moved back into the future queue.func (pool *TxPool) demoteUnexecutables() {    // Iterate over all accounts and demote any non-executable transactions    for addr, list := range pool.pending {        nonce := pool.currentState.GetNonce(addr)        // Drop all transactions that are deemed too old (low nonce)        // 删除所有小于当前地址的nonce的交易，并从pool.all删除。        for _, tx := range list.Forward(nonce) {            hash := tx.Hash()            log.Trace("Removed old pending transaction", "hash", hash)            delete(pool.all, hash)            pool.priced.Removed()        }        // Drop all transactions that are too costly (low balance or out of gas), and queue any invalids back for later        // 删除所有的太昂贵的交易。 用户的balance可能不够用。或者是out of gas        drops, invalids := list.Filter(pool.currentState.GetBalance(addr), pool.currentMaxGas)        for _, tx := range drops {            hash := tx.Hash()            log.Trace("Removed unpayable pending transaction", "hash", hash)            delete(pool.all, hash)            pool.priced.Removed()            pendingNofundsCounter.Inc(1)        }        for _, tx := range invalids {            hash := tx.Hash()            log.Trace("Demoting pending transaction", "hash", hash)            pool.enqueueTx(hash, tx)        }        // If there's a gap in front, warn (should never happen) and postpone all transactions        // 如果存在一个空洞(nonce空洞)， 那么需要把所有的交易都放入future queue。        // 这一步确实应该不可能发生，因为Filter已经把 invalids的都处理了。 应该不存在invalids的交易，也就是不存在空洞的。        if list.Len() &gt; 0 &amp;&amp; list.txs.Get(nonce) == nil {            for _, tx := range list.Cap(0) {                hash := tx.Hash()                log.Error("Demoting invalidated transaction", "hash", hash)                pool.enqueueTx(hash, tx)            }        }        // Delete the entire queue entry if it became empty.        if list.Empty() {             delete(pool.pending, addr)            delete(pool.beats, addr)        }    }}</code></pre><p>enqueueTx 把一个新的交易插入到future queue。 这个方法假设已经获取了池的锁。</p><pre><code>// enqueueTx inserts a new transaction into the non-executable transaction queue.//// Note, this method assumes the pool lock is held!func (pool *TxPool) enqueueTx(hash common.Hash, tx *types.Transaction) (bool, error) {    // Try to insert the transaction into the future queue    from, _ := types.Sender(pool.signer, tx) // already validated    if pool.queue[from] == nil {        pool.queue[from] = newTxList(false)    }    inserted, old := pool.queue[from].Add(tx, pool.config.PriceBump)    if !inserted {        // An older transaction was better, discard this        queuedDiscardCounter.Inc(1)        return false, ErrReplaceUnderpriced    }    // Discard any previous transaction and mark this    if old != nil {        delete(pool.all, old.Hash())        pool.priced.Removed()        queuedReplaceCounter.Inc(1)    }    pool.all[hash] = tx    pool.priced.Put(tx)    return old != nil, nil}</code></pre><p>promoteExecutables方法把 已经变得可以执行的交易从future queue 插入到pending queue。通过这个处理过程，所有的无效的交易(nonce太低，余额不足)会被删除。</p><pre><code>// promoteExecutables moves transactions that have become processable from the// future queue to the set of pending transactions. During this process, all// invalidated transactions (low nonce, low balance) are deleted.func (pool *TxPool) promoteExecutables(accounts []common.Address) {    // Gather all the accounts potentially needing updates    // accounts存储了所有潜在需要更新的账户。 如果账户传入为nil，代表所有已知的账户。    if accounts == nil {        accounts = make([]common.Address, 0, len(pool.queue))        for addr, _ := range pool.queue {            accounts = append(accounts, addr)        }    }    // Iterate over all accounts and promote any executable transactions    for _, addr := range accounts {        list := pool.queue[addr]        if list == nil {            continue // Just in case someone calls with a non existing account        }        // Drop all transactions that are deemed too old (low nonce)        // 删除所有的nonce太低的交易        for _, tx := range list.Forward(pool.currentState.GetNonce(addr)) {            hash := tx.Hash()            log.Trace("Removed old queued transaction", "hash", hash)            delete(pool.all, hash)            pool.priced.Removed()        }        // Drop all transactions that are too costly (low balance or out of gas)        // 删除所有余额不足的交易。        drops, _ := list.Filter(pool.currentState.GetBalance(addr), pool.currentMaxGas)        for _, tx := range drops {            hash := tx.Hash()            log.Trace("Removed unpayable queued transaction", "hash", hash)            delete(pool.all, hash)            pool.priced.Removed()            queuedNofundsCounter.Inc(1)        }        // Gather all executable transactions and promote them        // 得到所有的可以执行的交易，并promoteTx加入pending        for _, tx := range list.Ready(pool.pendingState.GetNonce(addr)) {            hash := tx.Hash()            log.Trace("Promoting queued transaction", "hash", hash)            pool.promoteTx(addr, hash, tx)        }        // Drop all transactions over the allowed limit        // 删除所有超过限制的交易。        if !pool.locals.contains(addr) {            for _, tx := range list.Cap(int(pool.config.AccountQueue)) {                hash := tx.Hash()                delete(pool.all, hash)                pool.priced.Removed()                queuedRateLimitCounter.Inc(1)                log.Trace("Removed cap-exceeding queued transaction", "hash", hash)            }        }        // Delete the entire queue entry if it became empty.        if list.Empty() {            delete(pool.queue, addr)        }    }    // If the pending limit is overflown, start equalizing allowances    pending := uint64(0)    for _, list := range pool.pending {        pending += uint64(list.Len())    }    // 如果pending的总数超过系统的配置。     if pending &gt; pool.config.GlobalSlots {                pendingBeforeCap := pending        // Assemble a spam order to penalize large transactors first        spammers := prque.New()        for addr, list := range pool.pending {            // Only evict transactions from high rollers            // 首先把所有大于AccountSlots最小值的账户记录下来， 会从这些账户里面剔除一些交易。            // 注意spammers是一个优先级队列，也就是说是按照交易的多少从大到小排序的。            if !pool.locals.contains(addr) &amp;&amp; uint64(list.Len()) &gt; pool.config.AccountSlots {                spammers.Push(addr, float32(list.Len()))            }        }        // Gradually drop transactions from offenders        offenders := []common.Address{}        for pending &gt; pool.config.GlobalSlots &amp;&amp; !spammers.Empty() {            /*                模拟一下offenders队列的账户交易数量的变化情况。                 第一次循环   [10]    循环结束  [10]                第二次循环   [10, 9] 循环结束  [9,9]                第三次循环   [9, 9, 7] 循环结束 [7, 7, 7]                第四次循环   [7, 7 , 7 ,2] 循环结束 [2, 2 ,2, 2]            */            // Retrieve the next offender if not local address            offender, _ := spammers.Pop()            offenders = append(offenders, offender.(common.Address))            // Equalize balances until all the same or below threshold            if len(offenders) &gt; 1 { // 第一次进入这个循环的时候， offenders队列里面有交易数量最大的两个账户                // Calculate the equalization threshold for all current offenders                // 把最后加入的账户的交易数量当成本次的阈值                threshold := pool.pending[offender.(common.Address)].Len()                // Iteratively reduce all offenders until below limit or threshold reached                // 遍历直到pending有效，或者是倒数第二个的交易数量等于最后一个的交易数量                for pending &gt; pool.config.GlobalSlots &amp;&amp; pool.pending[offenders[len(offenders)-2]].Len() &gt; threshold {                    // 遍历除了最后一个账户以外的所有账户， 把他们的交易数量减去1.                    for i := 0; i &lt; len(offenders)-1; i++ {                        list := pool.pending[offenders[i]]                        for _, tx := range list.Cap(list.Len() - 1) {                            // Drop the transaction from the global pools too                            hash := tx.Hash()                            delete(pool.all, hash)                            pool.priced.Removed()                            // Update the account nonce to the dropped transaction                            if nonce := tx.Nonce(); pool.pendingState.GetNonce(offenders[i]) &gt; nonce {                                pool.pendingState.SetNonce(offenders[i], nonce)                            }                            log.Trace("Removed fairness-exceeding pending transaction", "hash", hash)                        }                        pending--                    }                }            }        }        // If still above threshold, reduce to limit or min allowance        // 经过上面的循环，所有的超过AccountSlots的账户的交易数量都变成了之前的最小值。        // 如果还是超过阈值，那么在继续从offenders里面每次删除一个。        if pending &gt; pool.config.GlobalSlots &amp;&amp; len(offenders) &gt; 0 {            for pending &gt; pool.config.GlobalSlots &amp;&amp; uint64(pool.pending[offenders[len(offenders)-1]].Len()) &gt; pool.config.AccountSlots {                for _, addr := range offenders {                    list := pool.pending[addr]                    for _, tx := range list.Cap(list.Len() - 1) {                        // Drop the transaction from the global pools too                        hash := tx.Hash()                        delete(pool.all, hash)                        pool.priced.Removed()                        // Update the account nonce to the dropped transaction                        if nonce := tx.Nonce(); pool.pendingState.GetNonce(addr) &gt; nonce {                            pool.pendingState.SetNonce(addr, nonce)                        }                        log.Trace("Removed fairness-exceeding pending transaction", "hash", hash)                    }                    pending--                }            }        }        pendingRateLimitCounter.Inc(int64(pendingBeforeCap - pending))    }  //end if pending &gt; pool.config.GlobalSlots {    // If we've queued more transactions than the hard limit, drop oldest ones    // 我们处理了pending的限制， 下面需要处理future queue的限制了。    queued := uint64(0)    for _, list := range pool.queue {        queued += uint64(list.Len())    }    if queued &gt; pool.config.GlobalQueue {        // Sort all accounts with queued transactions by heartbeat        addresses := make(addresssByHeartbeat, 0, len(pool.queue))        for addr := range pool.queue {            if !pool.locals.contains(addr) { // don't drop locals                addresses = append(addresses, addressByHeartbeat{addr, pool.beats[addr]})            }        }        sort.Sort(addresses)        // Drop transactions until the total is below the limit or only locals remain        // 从后往前，也就是心跳越新的就越会被删除。        for drop := queued - pool.config.GlobalQueue; drop &gt; 0 &amp;&amp; len(addresses) &gt; 0; {            addr := addresses[len(addresses)-1]            list := pool.queue[addr.address]            addresses = addresses[:len(addresses)-1]            // Drop all transactions if they are less than the overflow            if size := uint64(list.Len()); size &lt;= drop {                for _, tx := range list.Flatten() {                    pool.removeTx(tx.Hash())                }                drop -= size                queuedRateLimitCounter.Inc(int64(size))                continue            }            // Otherwise drop only last few transactions            txs := list.Flatten()            for i := len(txs) - 1; i &gt;= 0 &amp;&amp; drop &gt; 0; i-- {                pool.removeTx(txs[i].Hash())                drop--                queuedRateLimitCounter.Inc(1)            }        }    }}</code></pre><p>promoteTx把某个交易加入到pending 队列. 这个方法假设已经获取到了锁.</p><pre><code>// promoteTx adds a transaction to the pending (processable) list of transactions.//// Note, this method assumes the pool lock is held!func (pool *TxPool) promoteTx(addr common.Address, hash common.Hash, tx *types.Transaction) {    // Try to insert the transaction into the pending queue    if pool.pending[addr] == nil {        pool.pending[addr] = newTxList(true)    }    list := pool.pending[addr]    inserted, old := list.Add(tx, pool.config.PriceBump)    if !inserted { // 如果不能替换, 已经存在一个老的交易了. 删除.        // An older transaction was better, discard this        delete(pool.all, hash)        pool.priced.Removed()        pendingDiscardCounter.Inc(1)        return    }    // Otherwise discard any previous transaction and mark this    if old != nil {         delete(pool.all, old.Hash())        pool.priced.Removed()        pendingReplaceCounter.Inc(1)    }    // Failsafe to work around direct pending inserts (tests)    if pool.all[hash] == nil {        pool.all[hash] = tx        pool.priced.Put(tx)    }    // Set the potentially new pending nonce and notify any subsystems of the new tx    // 把交易加入到队列,并发送消息告诉所有的订阅者, 这个订阅者在eth协议内部. 会接收这个消息并把这个消息通过网路广播出去.    pool.beats[addr] = time.Now()    pool.pendingState.SetNonce(addr, tx.Nonce()+1)    go pool.txFeed.Send(TxPreEvent{tx})}</code></pre><p>removeTx，删除某个交易， 并把所有后续的交易移动到future queue</p><pre><code>// removeTx removes a single transaction from the queue, moving all subsequent// transactions back to the future queue.func (pool *TxPool) removeTx(hash common.Hash) {    // Fetch the transaction we wish to delete    tx, ok := pool.all[hash]    if !ok {        return    }    addr, _ := types.Sender(pool.signer, tx) // already validated during insertion    // Remove it from the list of known transactions    delete(pool.all, hash)    pool.priced.Removed()    // Remove the transaction from the pending lists and reset the account nonce    // 把交易从pending删除， 并把因为这个交易的删除而变得无效的交易放到future queue    // 然后更新pendingState的状态    if pending := pool.pending[addr]; pending != nil {        if removed, invalids := pending.Remove(tx); removed {            // If no more transactions are left, remove the list            if pending.Empty() {                delete(pool.pending, addr)                delete(pool.beats, addr)            } else {                // Otherwise postpone any invalidated transactions                for _, tx := range invalids {                    pool.enqueueTx(tx.Hash(), tx)                }            }            // Update the account nonce if needed            if nonce := tx.Nonce(); pool.pendingState.GetNonce(addr) &gt; nonce {                pool.pendingState.SetNonce(addr, nonce)            }            return        }    }    // Transaction is in the future queue    // 把交易从future queue删除.    if future := pool.queue[addr]; future != nil {        future.Remove(tx)        if future.Empty() {            delete(pool.queue, addr)        }    }}</code></pre><p>loop是txPool的一个goroutine.也是主要的事件循环.等待和响应外部区块链事件以及各种报告和交易驱逐事件。</p><pre><code>// loop is the transaction pool's main event loop, waiting for and reacting to// outside blockchain events as well as for various reporting and transaction// eviction events.func (pool *TxPool) loop() {    defer pool.wg.Done()    // Start the stats reporting and transaction eviction tickers    var prevPending, prevQueued, prevStales int    report := time.NewTicker(statsReportInterval)    defer report.Stop()    evict := time.NewTicker(evictionInterval)    defer evict.Stop()    journal := time.NewTicker(pool.config.Rejournal)    defer journal.Stop()    // Track the previous head headers for transaction reorgs    head := pool.chain.CurrentBlock()    // Keep waiting for and reacting to the various events    for {        select {        // Handle ChainHeadEvent        // 监听到区块头的事件, 获取到新的区块头.        // 调用reset方法        case ev := &lt;-pool.chainHeadCh:            if ev.Block != nil {                pool.mu.Lock()                if pool.chainconfig.IsHomestead(ev.Block.Number()) {                    pool.homestead = true                }                pool.reset(head.Header(), ev.Block.Header())                head = ev.Block                pool.mu.Unlock()            }        // Be unsubscribed due to system stopped        case &lt;-pool.chainHeadSub.Err():            return        // Handle stats reporting ticks 报告就是打印了一些日志        case &lt;-report.C:            pool.mu.RLock()            pending, queued := pool.stats()            stales := pool.priced.stales            pool.mu.RUnlock()            if pending != prevPending || queued != prevQueued || stales != prevStales {                log.Debug("Transaction pool status report", "executable", pending, "queued", queued, "stales", stales)                prevPending, prevQueued, prevStales = pending, queued, stales            }        // Handle inactive account transaction eviction        // 处理超时的交易信息,        case &lt;-evict.C:            pool.mu.Lock()            for addr := range pool.queue {                // Skip local transactions from the eviction mechanism                if pool.locals.contains(addr) {                    continue                }                // Any non-locals old enough should be removed                if time.Since(pool.beats[addr]) &gt; pool.config.Lifetime {                    for _, tx := range pool.queue[addr].Flatten() {                        pool.removeTx(tx.Hash())                    }                }            }            pool.mu.Unlock()        // Handle local transaction journal rotation 处理定时写交易日志的信息.        case &lt;-journal.C:            if pool.journal != nil {                pool.mu.Lock()                if err := pool.journal.rotate(pool.local()); err != nil {                    log.Warn("Failed to rotate local tx journal", "err", err)                }                pool.mu.Unlock()            }        }    }}</code></pre><p>add 方法, 验证交易并将其插入到future queue. 如果这个交易是替换了当前存在的某个交易,那么会返回之前的那个交易,这样外部就不用调用promote方法. 如果某个新增加的交易被标记为local, 那么它的发送账户会进入白名单,这个账户的关联的交易将不会因为价格的限制或者其他的一些限制被删除.</p><pre><code>// add validates a transaction and inserts it into the non-executable queue for// later pending promotion and execution. If the transaction is a replacement for// an already pending or queued one, it overwrites the previous and returns this// so outer code doesn't uselessly call promote.//// If a newly added transaction is marked as local, its sending account will be// whitelisted, preventing any associated transaction from being dropped out of// the pool due to pricing constraints.func (pool *TxPool) add(tx *types.Transaction, local bool) (bool, error) {    // If the transaction is already known, discard it    hash := tx.Hash()    if pool.all[hash] != nil {        log.Trace("Discarding already known transaction", "hash", hash)        return false, fmt.Errorf("known transaction: %x", hash)    }    // If the transaction fails basic validation, discard it    // 如果交易不能通过基本的验证,那么丢弃它    if err := pool.validateTx(tx, local); err != nil {        log.Trace("Discarding invalid transaction", "hash", hash, "err", err)        invalidTxCounter.Inc(1)        return false, err    }    // If the transaction pool is full, discard underpriced transactions    // 如果交易池满了. 那么删除一些低价的交易.    if uint64(len(pool.all)) &gt;= pool.config.GlobalSlots+pool.config.GlobalQueue {        // If the new transaction is underpriced, don't accept it        // 如果新交易本身就是低价的.那么不接收它        if pool.priced.Underpriced(tx, pool.locals) {            log.Trace("Discarding underpriced transaction", "hash", hash, "price", tx.GasPrice())            underpricedTxCounter.Inc(1)            return false, ErrUnderpriced        }        // New transaction is better than our worse ones, make room for it        // 否则删除低价值的给他腾空间.        drop := pool.priced.Discard(len(pool.all)-int(pool.config.GlobalSlots+pool.config.GlobalQueue-1), pool.locals)        for _, tx := range drop {            log.Trace("Discarding freshly underpriced transaction", "hash", tx.Hash(), "price", tx.GasPrice())            underpricedTxCounter.Inc(1)            pool.removeTx(tx.Hash())        }    }    // If the transaction is replacing an already pending one, do directly    from, _ := types.Sender(pool.signer, tx) // already validated    if list := pool.pending[from]; list != nil &amp;&amp; list.Overlaps(tx) {        // Nonce already pending, check if required price bump is met        // 如果交易对应的Nonce已经在pending队列了,那么产看是否能够替换.        inserted, old := list.Add(tx, pool.config.PriceBump)        if !inserted {            pendingDiscardCounter.Inc(1)            return false, ErrReplaceUnderpriced        }        // New transaction is better, replace old one        if old != nil {            delete(pool.all, old.Hash())            pool.priced.Removed()            pendingReplaceCounter.Inc(1)        }        pool.all[tx.Hash()] = tx        pool.priced.Put(tx)        pool.journalTx(from, tx)        log.Trace("Pooled new executable transaction", "hash", hash, "from", from, "to", tx.To())        return old != nil, nil    }    // New transaction isn't replacing a pending one, push into queue    // 新交易不能替换pending里面的任意一个交易,那么把他push到futuren 队列里面.    replace, err := pool.enqueueTx(hash, tx)    if err != nil {        return false, err    }    // Mark local addresses and journal local transactions    if local {        pool.locals.add(from)    }    // 如果是本地的交易,会被记录进入journalTx    pool.journalTx(from, tx)    log.Trace("Pooled new future transaction", "hash", hash, "from", from, "to", tx.To())    return replace, nil}</code></pre><p>validateTx 使用一致性规则来检查一个交易是否有效,并采用本地节点的一些启发式的限制.</p><pre><code>// validateTx checks whether a transaction is valid according to the consensus// rules and adheres to some heuristic limits of the local node (price and size).func (pool *TxPool) validateTx(tx *types.Transaction, local bool) error {    // Heuristic limit, reject transactions over 32KB to prevent DOS attacks    if tx.Size() &gt; 32*1024 {        return ErrOversizedData    }    // Transactions can't be negative. This may never happen using RLP decoded    // transactions but may occur if you create a transaction using the RPC.    if tx.Value().Sign() &lt; 0 {        return ErrNegativeValue    }    // Ensure the transaction doesn't exceed the current block limit gas.    if pool.currentMaxGas.Cmp(tx.Gas()) &lt; 0 {        return ErrGasLimit    }    // Make sure the transaction is signed properly    // 确保交易被正确签名.    from, err := types.Sender(pool.signer, tx)    if err != nil {        return ErrInvalidSender    }    // Drop non-local transactions under our own minimal accepted gas price    local = local || pool.locals.contains(from) // account may be local even if the transaction arrived from the network    // 如果不是本地的交易,并且GasPrice低于我们的设置,那么也不会接收.    if !local &amp;&amp; pool.gasPrice.Cmp(tx.GasPrice()) &gt; 0 {        return ErrUnderpriced    }    // Ensure the transaction adheres to nonce ordering    // 确保交易遵守了Nonce的顺序    if pool.currentState.GetNonce(from) &gt; tx.Nonce() {        return ErrNonceTooLow    }    // Transactor should have enough funds to cover the costs    // cost == V + GP * GL    // 确保用户有足够的余额来支付.    if pool.currentState.GetBalance(from).Cmp(tx.Cost()) &lt; 0 {        return ErrInsufficientFunds    }    intrGas := IntrinsicGas(tx.Data(), tx.To() == nil, pool.homestead)    // 如果交易是一个合约创建或者调用. 那么看看是否有足够的 初始Gas.    if tx.Gas().Cmp(intrGas) &lt; 0 {        return ErrIntrinsicGas    }    return nil}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-eth-downloader源码分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth-downloader%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>downloader主要负责区块链最开始的同步工作，当前的同步有两种模式，一种是传统的fullmode,这种模式通过下载区块头，和区块体来构建区块链，同步的过程就和普通的区块插入的过程一样，包括区块头的验证，交易的验证，交易执行，账户状态的改变等操作，这其实是一个比较消耗CPU和磁盘的一个过程。 另一种模式就是 快速同步的fast sync模式， 这种模式有专门的文档来描述。请参考fast sync的文档。简单的说 fast sync的模式会下载区块头，区块体和收据， 插入的过程不会执行交易，然后在一个区块高度(最高的区块高度 - 1024)的时候同步所有的账户状态，后面的1024个区块会采用fullmode的方式来构建。 这种模式会加区块的插入时间，同时不会产生大量的历史的账户信息。会相对节约磁盘， 但是对于网络的消耗会更高。 因为需要下载收据和状态。</p><h2 id="downloader-数据结构"><a href="#downloader-数据结构" class="headerlink" title="downloader 数据结构"></a>downloader 数据结构</h2><pre><code>type Downloader struct {    mode SyncMode       // Synchronisation mode defining the strategy used (per sync cycle)    mux  *event.TypeMux // Event multiplexer to announce sync operation events    // queue 对象用来调度 区块头，交易，和收据的下载，以及下载完之后的组装    queue   *queue   // Scheduler for selecting the hashes to download    // 对端的集合    peers   *peerSet // Set of active peers from which download can proceed    stateDB ethdb.Database    // fast sync 中的 Pivot point区块的头    fsPivotLock  *types.Header // Pivot header on critical section entry (cannot change between retries)    fsPivotFails uint32        // Number of subsequent fast sync failures in the critical section    // 下载的往返时延    rttEstimate   uint64 // Round trip time to target for download requests    rttConfidence uint64 // Confidence in the estimated RTT (unit: millionths to allow atomic ops)  估计RTT的信心(单位：允许原子操作的百万分之一)    // Statistics 统计信息，     syncStatsChainOrigin uint64 // Origin block number where syncing started at    syncStatsChainHeight uint64 // Highest block number known when syncing started    syncStatsState       stateSyncStats    syncStatsLock        sync.RWMutex // Lock protecting the sync stats fields    lightchain LightChain    blockchain BlockChain    // Callbacks    dropPeer peerDropFn // Drops a peer for misbehaving    // Status    synchroniseMock func(id string, hash common.Hash) error // Replacement for synchronise during testing    synchronising   int32    notified        int32    // Channels    headerCh      chan dataPack        // [eth/62] Channel receiving inbound block headers  header的输入通道，从网络下载的header会被送到这个通道    bodyCh        chan dataPack        // [eth/62] Channel receiving inbound block bodies   bodies的输入通道，从网络下载的bodies会被送到这个通道    receiptCh     chan dataPack        // [eth/63] Channel receiving inbound receipts       receipts的输入通道，从网络下载的receipts会被送到这个通道    bodyWakeCh    chan bool            // [eth/62] Channel to signal the block body fetcher of new tasks    用来传输body fetcher新任务的通道    receiptWakeCh chan bool            // [eth/63] Channel to signal the receipt fetcher of new tasks       用来传输receipt fetcher 新任务的通道    headerProcCh  chan []*types.Header // [eth/62] Channel to feed the header processor new tasks        通道为header处理者提供新的任务    // for stateFetcher    stateSyncStart chan *stateSync   //用来启动新的 state fetcher    trackStateReq  chan *stateReq     // TODO    stateCh        chan dataPack // [eth/63] Channel receiving inbound node state data       state的输入通道，从网络下载的state会被送到这个通道                    // Cancellation and termination    cancelPeer string        // Identifier of the peer currently being used as the master (cancel on drop)    cancelCh   chan struct{} // Channel to cancel mid-flight syncs    cancelLock sync.RWMutex  // Lock to protect the cancel channel and peer in delivers    quitCh   chan struct{} // Quit channel to signal termination    quitLock sync.RWMutex  // Lock to prevent double closes    // Testing hooks    syncInitHook     func(uint64, uint64)  // Method to call upon initiating a new sync run    bodyFetchHook    func([]*types.Header) // Method to call upon starting a block body fetch    receiptFetchHook func([]*types.Header) // Method to call upon starting a receipt fetch    chainInsertHook  func([]*fetchResult)  // Method to call upon inserting a chain of blocks (possibly in multiple invocations)}</code></pre><p>构造方法</p><pre><code>// New creates a new downloader to fetch hashes and blocks from remote peers.func New(mode SyncMode, stateDb ethdb.Database, mux *event.TypeMux, chain BlockChain, lightchain LightChain, dropPeer peerDropFn) *Downloader {    if lightchain == nil {        lightchain = chain    }    dl := &amp;Downloader{        mode:           mode,        stateDB:        stateDb,        mux:            mux,        queue:          newQueue(),        peers:          newPeerSet(),        rttEstimate:    uint64(rttMaxEstimate),        rttConfidence:  uint64(1000000),        blockchain:     chain,        lightchain:     lightchain,        dropPeer:       dropPeer,        headerCh:       make(chan dataPack, 1),        bodyCh:         make(chan dataPack, 1),        receiptCh:      make(chan dataPack, 1),        bodyWakeCh:     make(chan bool, 1),        receiptWakeCh:  make(chan bool, 1),        headerProcCh:   make(chan []*types.Header, 1),        quitCh:         make(chan struct{}),        stateCh:        make(chan dataPack),        stateSyncStart: make(chan *stateSync),        trackStateReq:  make(chan *stateReq),    }    go dl.qosTuner()  //简单 主要用来计算rttEstimate和rttConfidence    go dl.stateFetcher() //启动stateFetcher的任务监听，但是这个时候还没有生成state fetcher的任务。    return dl}</code></pre><h2 id="同步下载"><a href="#同步下载" class="headerlink" title="同步下载"></a>同步下载</h2><p>Synchronise试图和一个peer来同步，如果同步过程中遇到一些错误，那么会删除掉Peer。然后会被重试。</p><pre><code>// Synchronise tries to sync up our local block chain with a remote peer, both// adding various sanity checks as well as wrapping it with various log entries.func (d *Downloader) Synchronise(id string, head common.Hash, td *big.Int, mode SyncMode) error {    err := d.synchronise(id, head, td, mode)    switch err {    case nil:    case errBusy:    case errTimeout, errBadPeer, errStallingPeer,        errEmptyHeaderSet, errPeersUnavailable, errTooOld,        errInvalidAncestor, errInvalidChain:        log.Warn("Synchronisation failed, dropping peer", "peer", id, "err", err)        d.dropPeer(id)    default:        log.Warn("Synchronisation failed, retrying", "err", err)    }    return err}</code></pre><p>synchronise</p><pre><code>// synchronise will select the peer and use it for synchronising. If an empty string is given// it will use the best peer possible and synchronize if it's TD is higher than our own. If any of the// checks fail an error will be returned. This method is synchronousfunc (d *Downloader) synchronise(id string, hash common.Hash, td *big.Int, mode SyncMode) error {    // Mock out the synchronisation if testing    if d.synchroniseMock != nil {        return d.synchroniseMock(id, hash)    }    // Make sure only one goroutine is ever allowed past this point at once    // 这个方法同时只能运行一个， 检查是否正在运行。    if !atomic.CompareAndSwapInt32(&amp;d.synchronising, 0, 1) {        return errBusy    }    defer atomic.StoreInt32(&amp;d.synchronising, 0)    // Post a user notification of the sync (only once per session)    if atomic.CompareAndSwapInt32(&amp;d.notified, 0, 1) {        log.Info("Block synchronisation started")    }    // Reset the queue, peer set and wake channels to clean any internal leftover state    // 重置queue和peer的状态。    d.queue.Reset()    d.peers.Reset()    // 清空d.bodyWakeCh, d.receiptWakeCh    for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {        select {        case &lt;-ch:        default:        }    }    // 清空d.headerCh, d.bodyCh, d.receiptCh    for _, ch := range []chan dataPack{d.headerCh, d.bodyCh, d.receiptCh} {        for empty := false; !empty; {            select {            case &lt;-ch:            default:                empty = true            }        }    }    // 清空headerProcCh    for empty := false; !empty; {        select {        case &lt;-d.headerProcCh:        default:            empty = true        }    }    // Create cancel channel for aborting mid-flight and mark the master peer    d.cancelLock.Lock()    d.cancelCh = make(chan struct{})    d.cancelPeer = id    d.cancelLock.Unlock()    defer d.Cancel() // No matter what, we can't leave the cancel channel open    // Set the requested sync mode, unless it's forbidden    d.mode = mode    if d.mode == FastSync &amp;&amp; atomic.LoadUint32(&amp;d.fsPivotFails) &gt;= fsCriticalTrials {        d.mode = FullSync    }    // Retrieve the origin peer and initiate the downloading process    p := d.peers.Peer(id)    if p == nil {        return errUnknownPeer    }    return d.syncWithPeer(p, hash, td)}</code></pre><p>syncWithPeer</p><pre><code>// syncWithPeer starts a block synchronization based on the hash chain from the// specified peer and head hash.func (d *Downloader) syncWithPeer(p *peerConnection, hash common.Hash, td *big.Int) (err error) {    ...    // Look up the sync boundaries: the common ancestor and the target block    // 使用hash指来获取区块头，这个方法里面会访问网络    latest, err := d.fetchHeight(p)    if err != nil {        return err    }    height := latest.Number.Uint64()    // findAncestor试图来获取大家共同的祖先，以便找到一个开始同步的点。    origin, err := d.findAncestor(p, height)    if err != nil {        return err    }    d.syncStatsLock.Lock()    if d.syncStatsChainHeight &lt;= origin || d.syncStatsChainOrigin &gt; origin {        d.syncStatsChainOrigin = origin    }    d.syncStatsChainHeight = height    d.syncStatsLock.Unlock()    // Initiate the sync using a concurrent header and content retrieval algorithm    pivot := uint64(0)    switch d.mode {    case LightSync:        pivot = height    case FastSync:        // Calculate the new fast/slow sync pivot point        // 如果pivot这个点没有被锁定。        if d.fsPivotLock == nil {            pivotOffset, err := rand.Int(rand.Reader, big.NewInt(int64(fsPivotInterval)))            if err != nil {                panic(fmt.Sprintf("Failed to access crypto random source: %v", err))            }            if height &gt; uint64(fsMinFullBlocks)+pivotOffset.Uint64() {                pivot = height - uint64(fsMinFullBlocks) - pivotOffset.Uint64()            }        } else { // 如过这个点已经被锁定了。那么就使用这个点            // Pivot point locked in, use this and do not pick a new one!            pivot = d.fsPivotLock.Number.Uint64()        }        // If the point is below the origin, move origin back to ensure state download        if pivot &lt; origin {            if pivot &gt; 0 {                origin = pivot - 1            } else {                origin = 0            }        }        log.Debug("Fast syncing until pivot block", "pivot", pivot)    }    d.queue.Prepare(origin+1, d.mode, pivot, latest)    if d.syncInitHook != nil {        d.syncInitHook(origin, height)    }    // 启动几个fetcher 分别负责header,bodies,receipts,处理headers    fetchers := []func() error{        func() error { return d.fetchHeaders(p, origin+1) }, // Headers are always retrieved        func() error { return d.fetchBodies(origin + 1) },   // Bodies are retrieved during normal and fast sync        func() error { return d.fetchReceipts(origin + 1) }, // Receipts are retrieved during fast sync        func() error { return d.processHeaders(origin+1, td) },    }    if d.mode == FastSync {  //根据模式的不同，增加新的处理逻辑        fetchers = append(fetchers, func() error { return d.processFastSyncContent(latest) })    } else if d.mode == FullSync {        fetchers = append(fetchers, d.processFullSyncContent)    }    err = d.spawnSync(fetchers)    if err != nil &amp;&amp; d.mode == FastSync &amp;&amp; d.fsPivotLock != nil {        // If sync failed in the critical section, bump the fail counter.        atomic.AddUint32(&amp;d.fsPivotFails, 1)    }    return err}</code></pre><p>spawnSync给每个fetcher启动一个goroutine, 然后阻塞的等待fetcher出错。 </p><pre><code>// spawnSync runs d.process and all given fetcher functions to completion in// separate goroutines, returning the first error that appears.func (d *Downloader) spawnSync(fetchers []func() error) error {    var wg sync.WaitGroup    errc := make(chan error, len(fetchers))    wg.Add(len(fetchers))    for _, fn := range fetchers {        fn := fn        go func() { defer wg.Done(); errc &lt;- fn() }()    }    // Wait for the first error, then terminate the others.    var err error    for i := 0; i &lt; len(fetchers); i++ {        if i == len(fetchers)-1 {            // Close the queue when all fetchers have exited.            // This will cause the block processor to end when            // it has processed the queue.            d.queue.Close()        }        if err = &lt;-errc; err != nil {            break        }    }    d.queue.Close()    d.Cancel()    wg.Wait()    return err}</code></pre><h2 id="headers的处理"><a href="#headers的处理" class="headerlink" title="headers的处理"></a>headers的处理</h2><p>fetchHeaders方法用来获取header。 然后根据获取的header去获取body和receipt等信息。</p><pre><code>// fetchHeaders keeps retrieving headers concurrently from the number// requested, until no more are returned, potentially throttling on the way. To// facilitate concurrency but still protect against malicious nodes sending bad// headers, we construct a header chain skeleton using the "origin" peer we are// syncing with, and fill in the missing headers using anyone else. Headers from// other peers are only accepted if they map cleanly to the skeleton. If no one// can fill in the skeleton - not even the origin peer - it's assumed invalid and// the origin is dropped.fetchHeaders不断的重复这样的操作，发送header请求，等待所有的返回。直到完成所有的header请求。 为了提高并发性，同时仍然能够防止恶意节点发送错误的header，我们使用我们正在同步的“origin”peer构造一个头文件链骨架，并使用其他人填充缺失的header。 其他peer的header只有在干净地映射到骨架上时才被接受。 如果没有人能够填充骨架 - 甚至origin peer也不能填充 - 它被认为是无效的，并且origin peer也被丢弃。func (d *Downloader) fetchHeaders(p *peerConnection, from uint64) error {    p.log.Debug("Directing header downloads", "origin", from)    defer p.log.Debug("Header download terminated")    // Create a timeout timer, and the associated header fetcher    skeleton := true            // Skeleton assembly phase or finishing up    request := time.Now()       // time of the last skeleton fetch request    timeout := time.NewTimer(0) // timer to dump a non-responsive active peer    &lt;-timeout.C                 // timeout channel should be initially empty    defer timeout.Stop()    var ttl time.Duration    getHeaders := func(from uint64) {        request = time.Now()        ttl = d.requestTTL()        timeout.Reset(ttl)        if skeleton { //填充骨架            p.log.Trace("Fetching skeleton headers", "count", MaxHeaderFetch, "from", from)            go p.peer.RequestHeadersByNumber(from+uint64(MaxHeaderFetch)-1, MaxSkeletonSize, MaxHeaderFetch-1, false)        } else { // 直接请求            p.log.Trace("Fetching full headers", "count", MaxHeaderFetch, "from", from)            go p.peer.RequestHeadersByNumber(from, MaxHeaderFetch, 0, false)        }    }    // Start pulling the header chain skeleton until all is done    getHeaders(from)    for {        select {        case &lt;-d.cancelCh:            return errCancelHeaderFetch        case packet := &lt;-d.headerCh: //网络上返回的header会投递到headerCh这个通道            // Make sure the active peer is giving us the skeleton headers            if packet.PeerId() != p.id {                log.Debug("Received skeleton from incorrect peer", "peer", packet.PeerId())                break            }            headerReqTimer.UpdateSince(request)            timeout.Stop()            // If the skeleton's finished, pull any remaining head headers directly from the origin            if packet.Items() == 0 &amp;&amp; skeleton {                skeleton = false                getHeaders(from)                continue            }            // If no more headers are inbound, notify the content fetchers and return            // 如果没有更多的返回了。 那么告诉headerProcCh通道            if packet.Items() == 0 {                p.log.Debug("No more headers available")                select {                case d.headerProcCh &lt;- nil:                    return nil                case &lt;-d.cancelCh:                    return errCancelHeaderFetch                }            }            headers := packet.(*headerPack).headers            // If we received a skeleton batch, resolve internals concurrently            if skeleton { // 如果是需要填充骨架，那么在这个方法里面填充好                filled, proced, err := d.fillHeaderSkeleton(from, headers)                if err != nil {                    p.log.Debug("Skeleton chain invalid", "err", err)                    return errInvalidChain                }                headers = filled[proced:]                // proced代表已经处理完了多少个了。  所以只需要proced:后面的headers了                from += uint64(proced)            }            // Insert all the new headers and fetch the next batch            if len(headers) &gt; 0 {                p.log.Trace("Scheduling new headers", "count", len(headers), "from", from)                //投递到headerProcCh 然后继续循环。                select {                case d.headerProcCh &lt;- headers:                case &lt;-d.cancelCh:                    return errCancelHeaderFetch                }                from += uint64(len(headers))            }            getHeaders(from)        case &lt;-timeout.C:            // Header retrieval timed out, consider the peer bad and drop            p.log.Debug("Header request timed out", "elapsed", ttl)            headerTimeoutMeter.Mark(1)            d.dropPeer(p.id)            // Finish the sync gracefully instead of dumping the gathered data though            for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {                select {                case ch &lt;- false:                case &lt;-d.cancelCh:                }            }            select {            case d.headerProcCh &lt;- nil:            case &lt;-d.cancelCh:            }            return errBadPeer        }    }}</code></pre><p>processHeaders方法，这个方法从headerProcCh通道来获取header。并把获取到的header丢入到queue来进行调度，这样body fetcher或者是receipt fetcher就可以领取到fetch任务。</p><pre><code>// processHeaders takes batches of retrieved headers from an input channel and// keeps processing and scheduling them into the header chain and downloader's// queue until the stream ends or a failure occurs.// processHeaders批量的获取headers， 处理他们，并通过downloader的queue对象来调度他们。 直到错误发生或者处理结束。func (d *Downloader) processHeaders(origin uint64, td *big.Int) error {    // Calculate the pivoting point for switching from fast to slow sync    pivot := d.queue.FastSyncPivot()    // Keep a count of uncertain headers to roll back    // rollback 用来处理这种逻辑，如果某个点失败了。那么之前插入的2048个节点都要回滚。因为安全性达不到要求， 可以详细参考fast sync的文档。    rollback := []*types.Header{}    defer func() { // 这个函数用来错误退出的时候进行回滚。 TODO        if len(rollback) &gt; 0 {            // Flatten the headers and roll them back            hashes := make([]common.Hash, len(rollback))            for i, header := range rollback {                hashes[i] = header.Hash()            }            lastHeader, lastFastBlock, lastBlock := d.lightchain.CurrentHeader().Number, common.Big0, common.Big0            if d.mode != LightSync {                lastFastBlock = d.blockchain.CurrentFastBlock().Number()                lastBlock = d.blockchain.CurrentBlock().Number()            }            d.lightchain.Rollback(hashes)            curFastBlock, curBlock := common.Big0, common.Big0            if d.mode != LightSync {                curFastBlock = d.blockchain.CurrentFastBlock().Number()                curBlock = d.blockchain.CurrentBlock().Number()            }            log.Warn("Rolled back headers", "count", len(hashes),                "header", fmt.Sprintf("%d-&gt;%d", lastHeader, d.lightchain.CurrentHeader().Number),                "fast", fmt.Sprintf("%d-&gt;%d", lastFastBlock, curFastBlock),                "block", fmt.Sprintf("%d-&gt;%d", lastBlock, curBlock))            // If we're already past the pivot point, this could be an attack, thread carefully            if rollback[len(rollback)-1].Number.Uint64() &gt; pivot {                // If we didn't ever fail, lock in the pivot header (must! not! change!)                if atomic.LoadUint32(&amp;d.fsPivotFails) == 0 {                    for _, header := range rollback {                        if header.Number.Uint64() == pivot {                            log.Warn("Fast-sync pivot locked in", "number", pivot, "hash", header.Hash())                            d.fsPivotLock = header                        }                    }                }            }        }    }()    // Wait for batches of headers to process    gotHeaders := false    for {        select {        case &lt;-d.cancelCh:            return errCancelHeaderProcessing        case headers := &lt;-d.headerProcCh:            // Terminate header processing if we synced up            if len(headers) == 0 { //处理完成                // Notify everyone that headers are fully processed                for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {                    select {                    case ch &lt;- false:                    case &lt;-d.cancelCh:                    }                }                // If no headers were retrieved at all, the peer violated it's TD promise that it had a                // better chain compared to ours. The only exception is if it's promised blocks were                // already imported by other means (e.g. fecher):                //                // R &lt;remote peer&gt;, L &lt;local node&gt;: Both at block 10                // R: Mine block 11, and propagate it to L                // L: Queue block 11 for import                // L: Notice that R's head and TD increased compared to ours, start sync                // L: Import of block 11 finishes                // L: Sync begins, and finds common ancestor at 11                // L: Request new headers up from 11 (R's TD was higher, it must have something)                // R: Nothing to give                if d.mode != LightSync { // 对方的TD比我们大，但是没有获取到任何东西。 那么认为对方是错误的对方。 会断开和对方的联系                    if !gotHeaders &amp;&amp; td.Cmp(d.blockchain.GetTdByHash(d.blockchain.CurrentBlock().Hash())) &gt; 0 {                        return errStallingPeer                    }                }                // If fast or light syncing, ensure promised headers are indeed delivered. This is                // needed to detect scenarios where an attacker feeds a bad pivot and then bails out                // of delivering the post-pivot blocks that would flag the invalid content.                //                // This check cannot be executed "as is" for full imports, since blocks may still be                // queued for processing when the header download completes. However, as long as the                // peer gave us something useful, we're already happy/progressed (above check).                if d.mode == FastSync || d.mode == LightSync {                    if td.Cmp(d.lightchain.GetTdByHash(d.lightchain.CurrentHeader().Hash())) &gt; 0 {                        return errStallingPeer                    }                }                // Disable any rollback and return                rollback = nil                return nil            }            // Otherwise split the chunk of headers into batches and process them            gotHeaders = true            for len(headers) &gt; 0 {                // Terminate if something failed in between processing chunks                select {                case &lt;-d.cancelCh:                    return errCancelHeaderProcessing                default:                }                // Select the next chunk of headers to import                limit := maxHeadersProcess                if limit &gt; len(headers) {                    limit = len(headers)                }                chunk := headers[:limit]                // In case of header only syncing, validate the chunk immediately                if d.mode == FastSync || d.mode == LightSync { //如果是快速同步模式，或者是轻量级同步模式(只下载区块头)                    // Collect the yet unknown headers to mark them as uncertain                    unknown := make([]*types.Header, 0, len(headers))                    for _, header := range chunk {                        if !d.lightchain.HasHeader(header.Hash(), header.Number.Uint64()) {                            unknown = append(unknown, header)                        }                    }                    // If we're importing pure headers, verify based on their recentness                    // 每隔多少个区块验证一次                    frequency := fsHeaderCheckFrequency                    if chunk[len(chunk)-1].Number.Uint64()+uint64(fsHeaderForceVerify) &gt; pivot {                        frequency = 1                    }                    // lightchain默认是等于chain的。 插入区块头。如果失败那么需要回滚。                    if n, err := d.lightchain.InsertHeaderChain(chunk, frequency); err != nil {                        // If some headers were inserted, add them too to the rollback list                        if n &gt; 0 {                            rollback = append(rollback, chunk[:n]...)                        }                        log.Debug("Invalid header encountered", "number", chunk[n].Number, "hash", chunk[n].Hash(), "err", err)                        return errInvalidChain                    }                    // All verifications passed, store newly found uncertain headers                    rollback = append(rollback, unknown...)                    if len(rollback) &gt; fsHeaderSafetyNet {                        rollback = append(rollback[:0], rollback[len(rollback)-fsHeaderSafetyNet:]...)                    }                }                // If we're fast syncing and just pulled in the pivot, make sure it's the one locked in                if d.mode == FastSync &amp;&amp; d.fsPivotLock != nil &amp;&amp; chunk[0].Number.Uint64() &lt;= pivot &amp;&amp; chunk[len(chunk)-1].Number.Uint64() &gt;= pivot { //如果PivotLock,检查一下Hash是否相同。                    if pivot := chunk[int(pivot-chunk[0].Number.Uint64())]; pivot.Hash() != d.fsPivotLock.Hash() {                        log.Warn("Pivot doesn't match locked in one", "remoteNumber", pivot.Number, "remoteHash", pivot.Hash(), "localNumber", d.fsPivotLock.Number, "localHash", d.fsPivotLock.Hash())                        return errInvalidChain                    }                }                // Unless we're doing light chains, schedule the headers for associated content retrieval                // 如果我们处理完轻量级链。 调度header来进行相关数据的获取。body，receipts                if d.mode == FullSync || d.mode == FastSync {                    // If we've reached the allowed number of pending headers, stall a bit                    // 如果当前queue的容量容纳不下了。那么等待。                    for d.queue.PendingBlocks() &gt;= maxQueuedHeaders || d.queue.PendingReceipts() &gt;= maxQueuedHeaders {                        select {                        case &lt;-d.cancelCh:                            return errCancelHeaderProcessing                        case &lt;-time.After(time.Second):                        }                    }                    // Otherwise insert the headers for content retrieval                    // 调用Queue进行调度，下载body和receipts                    inserts := d.queue.Schedule(chunk, origin)                    if len(inserts) != len(chunk) {                        log.Debug("Stale headers")                        return errBadPeer                    }                }                headers = headers[limit:]                origin += uint64(limit)            }            // Signal the content downloaders of the availablility of new tasks            // 给通道d.bodyWakeCh, d.receiptWakeCh发送消息，唤醒处理线程。            for _, ch := range []chan bool{d.bodyWakeCh, d.receiptWakeCh} {                select {                case ch &lt;- true:                default:                }            }        }    }}</code></pre><h2 id="bodies处理"><a href="#bodies处理" class="headerlink" title="bodies处理"></a>bodies处理</h2><p>fetchBodies函数定义了一些闭包函数，然后调用了fetchParts函数</p><pre><code>// fetchBodies iteratively downloads the scheduled block bodies, taking any// available peers, reserving a chunk of blocks for each, waiting for delivery// and also periodically checking for timeouts.// fetchBodies 持续的下载区块体，中间会使用到任何可以用的链接，为每一个链接保留一部分的区块体，等待区块被交付，并定期的检查是否超时。func (d *Downloader) fetchBodies(from uint64) error {    log.Debug("Downloading block bodies", "origin", from)    var (        deliver = func(packet dataPack) (int, error) { //下载完的区块体的交付函数            pack := packet.(*bodyPack)            return d.queue.DeliverBodies(pack.peerId, pack.transactions, pack.uncles)        }        expire   = func() map[string]int { return d.queue.ExpireBodies(d.requestTTL()) }  //超时        fetch    = func(p *peerConnection, req *fetchRequest) error { return p.FetchBodies(req) }  // fetch函数        capacity = func(p *peerConnection) int { return p.BlockCapacity(d.requestRTT()) } // 对端的吞吐量        setIdle  = func(p *peerConnection, accepted int) { p.SetBodiesIdle(accepted) } // 设置peer为idle    )    err := d.fetchParts(errCancelBodyFetch, d.bodyCh, deliver, d.bodyWakeCh, expire,        d.queue.PendingBlocks, d.queue.InFlightBlocks, d.queue.ShouldThrottleBlocks, d.queue.ReserveBodies,        d.bodyFetchHook, fetch, d.queue.CancelBodies, capacity, d.peers.BodyIdlePeers, setIdle, "bodies")    log.Debug("Block body download terminated", "err", err)    return err}</code></pre><p>fetchParts</p><pre><code>// fetchParts iteratively downloads scheduled block parts, taking any available// peers, reserving a chunk of fetch requests for each, waiting for delivery and// also periodically checking for timeouts.// fetchParts迭代地下载预定的块部分，取得任何可用的对等体，为每个部分预留大量的提取请求，等待交付并且还定期检查超时。// As the scheduling/timeout logic mostly is the same for all downloaded data// types, this method is used by each for data gathering and is instrumented with// various callbacks to handle the slight differences between processing them.// 由于调度/超时逻辑对于所有下载的数据类型大部分是相同的，所以这个方法被用于不同的区块类型的下载，并且用各种回调函数来处理它们之间的细微差别。// The instrumentation parameters://  - errCancel:   error type to return if the fetch operation is cancelled (mostly makes logging nicer) 如果fetch操作被取消，会在这个通道上发送数据//  - deliveryCh:  channel from which to retrieve downloaded data packets (merged from all concurrent peers) 数据被下载完成后投递的目的地//  - deliver:     processing callback to deliver data packets into type specific download queues (usually within `queue`) 处理完成后数据被投递到哪个队列//  - wakeCh:      notification channel for waking the fetcher when new tasks are available (or sync completed) 用来通知fetcher 新的任务到来，或者是同步完成//  - expire:      task callback method to abort requests that took too long and return the faulty peers (traffic shaping)  因为超时来终止请求的回调函数。//  - pending:     task callback for the number of requests still needing download (detect completion/non-completability) 还需要下载的任务的数量。//  - inFlight:    task callback for the number of in-progress requests (wait for all active downloads to finish) 正在处理过程中的请求数量//  - throttle:    task callback to check if the processing queue is full and activate throttling (bound memory use) 用来检查处理队列是否满的回调函数。//  - reserve:     task callback to reserve new download tasks to a particular peer (also signals partial completions)  用来为某个peer来预定任务的回调函数//  - fetchHook:   tester callback to notify of new tasks being initiated (allows testing the scheduling logic) //  - fetch:       network callback to actually send a particular download request to a physical remote peer //发送网络请求的回调函数//  - cancel:      task callback to abort an in-flight download request and allow rescheduling it (in case of lost peer)  用来取消正在处理的任务的回调函数//  - capacity:    network callback to retrieve the estimated type-specific bandwidth capacity of a peer (traffic shaping) 网络容量或者是带宽。//  - idle:        network callback to retrieve the currently (type specific) idle peers that can be assigned tasks  peer是否空闲的回调函数//  - setIdle:     network callback to set a peer back to idle and update its estimated capacity (traffic shaping)  设置peer为空闲的回调函数//  - kind:        textual label of the type being downloaded to display in log mesages   下载类型，用于日志func (d *Downloader) fetchParts(errCancel error, deliveryCh chan dataPack, deliver func(dataPack) (int, error), wakeCh chan bool,    expire func() map[string]int, pending func() int, inFlight func() bool, throttle func() bool, reserve func(*peerConnection, int) (*fetchRequest, bool, error),    fetchHook func([]*types.Header), fetch func(*peerConnection, *fetchRequest) error, cancel func(*fetchRequest), capacity func(*peerConnection) int,    idle func() ([]*peerConnection, int), setIdle func(*peerConnection, int), kind string) error {    // Create a ticker to detect expired retrieval tasks    ticker := time.NewTicker(100 * time.Millisecond)    defer ticker.Stop()    update := make(chan struct{}, 1)    // Prepare the queue and fetch block parts until the block header fetcher's done    finished := false    for {        select {        case &lt;-d.cancelCh:            return errCancel        case packet := &lt;-deliveryCh:            // If the peer was previously banned and failed to deliver it's pack            // in a reasonable time frame, ignore it's message.            // 如果peer在之前被禁止而且没有在合适的时间deliver它的数据，那么忽略这个数据            if peer := d.peers.Peer(packet.PeerId()); peer != nil {                // Deliver the received chunk of data and check chain validity                accepted, err := deliver(packet)                if err == errInvalidChain {                    return err                }                // Unless a peer delivered something completely else than requested (usually                // caused by a timed out request which came through in the end), set it to                // idle. If the delivery's stale, the peer should have already been idled.                if err != errStaleDelivery {                    setIdle(peer, accepted)                }                // Issue a log to the user to see what's going on                switch {                case err == nil &amp;&amp; packet.Items() == 0:                    peer.log.Trace("Requested data not delivered", "type", kind)                case err == nil:                    peer.log.Trace("Delivered new batch of data", "type", kind, "count", packet.Stats())                default:                    peer.log.Trace("Failed to deliver retrieved data", "type", kind, "err", err)                }            }            // Blocks assembled, try to update the progress            select {            case update &lt;- struct{}{}:            default:            }        case cont := &lt;-wakeCh:            // The header fetcher sent a continuation flag, check if it's done            // 当所有的任务完成的时候会写入这个队列。            if !cont {                finished = true            }            // Headers arrive, try to update the progress            select {            case update &lt;- struct{}{}:            default:            }        case &lt;-ticker.C:            // Sanity check update the progress            select {            case update &lt;- struct{}{}:            default:            }        case &lt;-update:            // Short circuit if we lost all our peers            if d.peers.Len() == 0 {                return errNoPeers            }            // Check for fetch request timeouts and demote the responsible peers            for pid, fails := range expire() {                if peer := d.peers.Peer(pid); peer != nil {                    // If a lot of retrieval elements expired, we might have overestimated the remote peer or perhaps                    // ourselves. Only reset to minimal throughput but don't drop just yet. If even the minimal times                    // out that sync wise we need to get rid of the peer.                    //如果很多检索元素过期，我们可能高估了远程对象或者我们自己。 只能重置为最小的吞吐量，但不要丢弃。 如果即使最小的同步任然超时，我们需要删除peer。                    // The reason the minimum threshold is 2 is because the downloader tries to estimate the bandwidth                    // and latency of a peer separately, which requires pushing the measures capacity a bit and seeing                    // how response times reacts, to it always requests one more than the minimum (i.e. min 2).                    // 最小阈值为2的原因是因为下载器试图分别估计对等体的带宽和等待时间，这需要稍微推动测量容量并且看到响应时间如何反应，总是要求比最小值（即，最小值2）。                    if fails &gt; 2 {                        peer.log.Trace("Data delivery timed out", "type", kind)                        setIdle(peer, 0)                    } else {                        peer.log.Debug("Stalling delivery, dropping", "type", kind)                        d.dropPeer(pid)                    }                }            }            // If there's nothing more to fetch, wait or terminate            // 任务全部完成。 那么退出            if pending() == 0 { //如果没有等待分配的任务， 那么break。不用执行下面的代码了。                if !inFlight() &amp;&amp; finished {                    log.Debug("Data fetching completed", "type", kind)                    return nil                }                break            }            // Send a download request to all idle peers, until throttled            progressed, throttled, running := false, false, inFlight()            idles, total := idle()            for _, peer := range idles {                // Short circuit if throttling activated                if throttle() {                    throttled = true                    break                }                // Short circuit if there is no more available task.                if pending() == 0 {                    break                }                // Reserve a chunk of fetches for a peer. A nil can mean either that                // no more headers are available, or that the peer is known not to                // have them.                // 为某个peer请求分配任务。                request, progress, err := reserve(peer, capacity(peer))                if err != nil {                    return err                }                if progress {                    progressed = true                }                if request == nil {                    continue                }                if request.From &gt; 0 {                    peer.log.Trace("Requesting new batch of data", "type", kind, "from", request.From)                } else if len(request.Headers) &gt; 0 {                    peer.log.Trace("Requesting new batch of data", "type", kind, "count", len(request.Headers), "from", request.Headers[0].Number)                } else {                    peer.log.Trace("Requesting new batch of data", "type", kind, "count", len(request.Hashes))                }                // Fetch the chunk and make sure any errors return the hashes to the queue                if fetchHook != nil {                    fetchHook(request.Headers)                }                if err := fetch(peer, request); err != nil {                    // Although we could try and make an attempt to fix this, this error really                    // means that we've double allocated a fetch task to a peer. If that is the                    // case, the internal state of the downloader and the queue is very wrong so                    // better hard crash and note the error instead of silently accumulating into                    // a much bigger issue.                    panic(fmt.Sprintf("%v: %s fetch assignment failed", peer, kind))                }                running = true            }            // Make sure that we have peers available for fetching. If all peers have been tried            // and all failed throw an error            if !progressed &amp;&amp; !throttled &amp;&amp; !running &amp;&amp; len(idles) == total &amp;&amp; pending() &gt; 0 {                return errPeersUnavailable            }        }    }}</code></pre><h2 id="receipt的处理"><a href="#receipt的处理" class="headerlink" title="receipt的处理"></a>receipt的处理</h2><p>receipt的处理和body类似。</p><pre><code>// fetchReceipts iteratively downloads the scheduled block receipts, taking any// available peers, reserving a chunk of receipts for each, waiting for delivery// and also periodically checking for timeouts.func (d *Downloader) fetchReceipts(from uint64) error {    log.Debug("Downloading transaction receipts", "origin", from)    var (        deliver = func(packet dataPack) (int, error) {            pack := packet.(*receiptPack)            return d.queue.DeliverReceipts(pack.peerId, pack.receipts)        }        expire   = func() map[string]int { return d.queue.ExpireReceipts(d.requestTTL()) }        fetch    = func(p *peerConnection, req *fetchRequest) error { return p.FetchReceipts(req) }        capacity = func(p *peerConnection) int { return p.ReceiptCapacity(d.requestRTT()) }        setIdle  = func(p *peerConnection, accepted int) { p.SetReceiptsIdle(accepted) }    )    err := d.fetchParts(errCancelReceiptFetch, d.receiptCh, deliver, d.receiptWakeCh, expire,        d.queue.PendingReceipts, d.queue.InFlightReceipts, d.queue.ShouldThrottleReceipts, d.queue.ReserveReceipts,        d.receiptFetchHook, fetch, d.queue.CancelReceipts, capacity, d.peers.ReceiptIdlePeers, setIdle, "receipts")    log.Debug("Transaction receipt download terminated", "err", err)    return err}</code></pre><h2 id="processFastSyncContent-和-processFullSyncContent"><a href="#processFastSyncContent-和-processFullSyncContent" class="headerlink" title="processFastSyncContent 和 processFullSyncContent"></a>processFastSyncContent 和 processFullSyncContent</h2><pre><code>// processFastSyncContent takes fetch results from the queue and writes them to the// database. It also controls the synchronisation of state nodes of the pivot block.func (d *Downloader) processFastSyncContent(latest *types.Header) error {    // Start syncing state of the reported head block.    // This should get us most of the state of the pivot block.    // 启动状态同步    stateSync := d.syncState(latest.Root)    defer stateSync.Cancel()    go func() {        if err := stateSync.Wait(); err != nil {            d.queue.Close() // wake up WaitResults        }    }()    pivot := d.queue.FastSyncPivot()    for {        results := d.queue.WaitResults() // 等待队列输出处理完成的区块        if len(results) == 0 {            return stateSync.Cancel()        }        if d.chainInsertHook != nil {            d.chainInsertHook(results)        }        P, beforeP, afterP := splitAroundPivot(pivot, results)        // 插入fast sync的数据        if err := d.commitFastSyncData(beforeP, stateSync); err != nil {            return err        }        if P != nil {            // 如果已经达到了 pivot point 那么等待状态同步完成，            stateSync.Cancel()            if err := d.commitPivotBlock(P); err != nil {                return err            }        }        // 对于pivot point 之后的所有节点，都需要按照完全的处理。        if err := d.importBlockResults(afterP); err != nil {            return err        }    }}</code></pre><p>processFullSyncContent,比较简单。 从队列里面获取区块然后插入。</p><pre><code>// processFullSyncContent takes fetch results from the queue and imports them into the chain.func (d *Downloader) processFullSyncContent() error {    for {        results := d.queue.WaitResults()        if len(results) == 0 {            return nil        }        if d.chainInsertHook != nil {            d.chainInsertHook(results)        }        if err := d.importBlockResults(results); err != nil {            return err        }    }}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-eth以太坊协议分析</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth%E4%BB%A5%E5%A4%AA%E5%9D%8A%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-eth%E4%BB%A5%E5%A4%AA%E5%9D%8A%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>node中的服务的定义， eth其实就是实现了一个服务。</p><pre><code>type Service interface {    // Protocols retrieves the P2P protocols the service wishes to start.    Protocols() []p2p.Protocol    // APIs retrieves the list of RPC descriptors the service provides    APIs() []rpc.API    // Start is called after all services have been constructed and the networking    // layer was also initialized to spawn any goroutines required by the service.    Start(server *p2p.Server) error    // Stop terminates all goroutines belonging to the service, blocking until they    // are all terminated.    Stop() error}</code></pre><p>go ethereum 的eth目录是以太坊服务的实现。 以太坊协议是通过node的Register方法注入的。</p><pre><code>// RegisterEthService adds an Ethereum client to the stack.func RegisterEthService(stack *node.Node, cfg *eth.Config) {    var err error    if cfg.SyncMode == downloader.LightSync {        err = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) {            return les.New(ctx, cfg)        })    } else {        err = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) {            fullNode, err := eth.New(ctx, cfg)            if fullNode != nil &amp;&amp; cfg.LightServ &gt; 0 {                ls, _ := les.NewLesServer(fullNode, cfg)                fullNode.AddLesServer(ls)            }            return fullNode, err        })    }    if err != nil {        Fatalf("Failed to register the Ethereum service: %v", err)    }}</code></pre><p>以太坊协议的数据结构</p><pre><code>// Ethereum implements the Ethereum full node service.type Ethereum struct {    config      *Config                    配置    chainConfig *params.ChainConfig        链配置    // Channel for shutting down the service    shutdownChan  chan bool    // Channel for shutting down the ethereum    stopDbUpgrade func() error // stop chain db sequential key upgrade    // Handlers    txPool          *core.TxPool            交易池    blockchain      *core.BlockChain        区块链    protocolManager *ProtocolManager        协议管理    lesServer       LesServer                轻量级客户端服务器    // DB interfaces    chainDb ethdb.Database // Block chain database    区块链数据库    eventMux       *event.TypeMux    engine         consensus.Engine                一致性引擎。 应该是Pow部分    accountManager *accounts.Manager            账号管理    bloomRequests chan chan *bloombits.Retrieval // Channel receiving bloom data retrieval requests    接收bloom过滤器数据请求的通道    bloomIndexer  *core.ChainIndexer             // Bloom indexer operating during block imports  //在区块import的时候执行Bloom indexer操作 暂时不清楚是什么    ApiBackend *EthApiBackend        //提供给RPC服务使用的API后端    miner     *miner.Miner            //矿工    gasPrice  *big.Int                //节点接收的gasPrice的最小值。 比这个值更小的交易会被本节点拒绝    etherbase common.Address        //矿工地址    networkId     uint64            //网络ID  testnet是0 mainnet是1     netRPCService *ethapi.PublicNetAPI    //RPC的服务    lock sync.RWMutex // Protects the variadic fields (e.g. gas price and etherbase)}</code></pre><p>以太坊协议的创建New. 暂时先不涉及core的内容。 只是大概介绍一下。 core里面的内容后续会分析。</p><pre><code>// New creates a new Ethereum object (including the// initialisation of the common Ethereum object)func New(ctx *node.ServiceContext, config *Config) (*Ethereum, error) {    if config.SyncMode == downloader.LightSync {        return nil, errors.New("can't run eth.Ethereum in light sync mode, use les.LightEthereum")    }    if !config.SyncMode.IsValid() {        return nil, fmt.Errorf("invalid sync mode %d", config.SyncMode)    }    // 创建leveldb。 打开或者新建 chaindata目录    chainDb, err := CreateDB(ctx, config, "chaindata")    if err != nil {        return nil, err    }    // 数据库格式升级    stopDbUpgrade := upgradeDeduplicateData(chainDb)    // 设置创世区块。 如果数据库里面已经有创世区块那么从数据库里面取出(私链)。或者是从代码里面获取默认值。    chainConfig, genesisHash, genesisErr := core.SetupGenesisBlock(chainDb, config.Genesis)    if _, ok := genesisErr.(*params.ConfigCompatError); genesisErr != nil &amp;&amp; !ok {        return nil, genesisErr    }    log.Info("Initialised chain configuration", "config", chainConfig)    eth := &amp;Ethereum{        config:         config,        chainDb:        chainDb,        chainConfig:    chainConfig,        eventMux:       ctx.EventMux,        accountManager: ctx.AccountManager,        engine:         CreateConsensusEngine(ctx, config, chainConfig, chainDb), // 一致性引擎。 这里我理解是Pow        shutdownChan:   make(chan bool),        stopDbUpgrade:  stopDbUpgrade,        networkId:      config.NetworkId,  // 网络ID用来区别网路。 测试网络是0.主网是1        gasPrice:       config.GasPrice,   // 可以通过配置 --gasprice 客户端接纳的交易的gasprice最小值。如果小于这个值那么会被节点丢弃。         etherbase:      config.Etherbase,  //挖矿的受益者        bloomRequests:  make(chan chan *bloombits.Retrieval),  //bloom的请求        bloomIndexer:   NewBloomIndexer(chainDb, params.BloomBitsBlocks),    }    log.Info("Initialising Ethereum protocol", "versions", ProtocolVersions, "network", config.NetworkId)    if !config.SkipBcVersionCheck { // 检查数据库里面存储的BlockChainVersion和客户端的BlockChainVersion的版本是否一致        bcVersion := core.GetBlockChainVersion(chainDb)        if bcVersion != core.BlockChainVersion &amp;&amp; bcVersion != 0 {            return nil, fmt.Errorf("Blockchain DB version mismatch (%d / %d). Run geth upgradedb.\n", bcVersion, core.BlockChainVersion)        }        core.WriteBlockChainVersion(chainDb, core.BlockChainVersion)    }    vmConfig := vm.Config{EnablePreimageRecording: config.EnablePreimageRecording}    // 使用数据库创建了区块链    eth.blockchain, err = core.NewBlockChain(chainDb, eth.chainConfig, eth.engine, vmConfig)    if err != nil {        return nil, err    }    // Rewind the chain in case of an incompatible config upgrade.    if compat, ok := genesisErr.(*params.ConfigCompatError); ok {        log.Warn("Rewinding chain to upgrade configuration", "err", compat)        eth.blockchain.SetHead(compat.RewindTo)        core.WriteChainConfig(chainDb, genesisHash, chainConfig)    }    // bloomIndexer 暂时不知道是什么东西 这里面涉及得也不是很多。 暂时先不管了    eth.bloomIndexer.Start(eth.blockchain.CurrentHeader(), eth.blockchain.SubscribeChainEvent)    if config.TxPool.Journal != "" {        config.TxPool.Journal = ctx.ResolvePath(config.TxPool.Journal)    }    // 创建交易池。 用来存储本地或者在网络上接收到的交易。    eth.txPool = core.NewTxPool(config.TxPool, eth.chainConfig, eth.blockchain)    // 创建协议管理器    if eth.protocolManager, err = NewProtocolManager(eth.chainConfig, config.SyncMode, config.NetworkId, eth.eventMux, eth.txPool, eth.engine, eth.blockchain, chainDb); err != nil {        return nil, err    }    // 创建矿工    eth.miner = miner.New(eth, eth.chainConfig, eth.EventMux(), eth.engine)    eth.miner.SetExtra(makeExtraData(config.ExtraData))    // ApiBackend 用于给RPC调用提供后端支持    eth.ApiBackend = &amp;EthApiBackend{eth, nil}    // gpoParams GPO Gas Price Oracle 的缩写。 GasPrice预测。 通过最近的交易来预测当前的GasPrice的值。这个值可以作为之后发送交易的费用的参考。    gpoParams := config.GPO    if gpoParams.Default == nil {        gpoParams.Default = config.GasPrice    }    eth.ApiBackend.gpo = gasprice.NewOracle(eth.ApiBackend, gpoParams)    return eth, nil}</code></pre><p>ApiBackend 定义在 api_backend.go文件中。 封装了一些函数。</p><pre><code>// EthApiBackend implements ethapi.Backend for full nodestype EthApiBackend struct {    eth *Ethereum    gpo *gasprice.Oracle}func (b *EthApiBackend) SetHead(number uint64) {    b.eth.protocolManager.downloader.Cancel()    b.eth.blockchain.SetHead(number)}</code></pre><p>New方法中除了core中的一些方法， 有一个ProtocolManager的对象在以太坊协议中比较重要， 以太坊本来是一个协议。ProtocolManager中又可以管理多个以太坊的子协议。</p><pre><code>// NewProtocolManager returns a new ethereum sub protocol manager. The Ethereum sub protocol manages peers capable// with the ethereum network.func NewProtocolManager(config *params.ChainConfig, mode downloader.SyncMode, networkId uint64, mux *event.TypeMux, txpool txPool, engine consensus.Engine, blockchain *core.BlockChain, chaindb ethdb.Database) (*ProtocolManager, error) {    // Create the protocol manager with the base fields    manager := &amp;ProtocolManager{        networkId:   networkId,        eventMux:    mux,        txpool:      txpool,        blockchain:  blockchain,        chaindb:     chaindb,        chainconfig: config,        peers:       newPeerSet(),        newPeerCh:   make(chan *peer),        noMorePeers: make(chan struct{}),        txsyncCh:    make(chan *txsync),        quitSync:    make(chan struct{}),    }    // Figure out whether to allow fast sync or not    if mode == downloader.FastSync &amp;&amp; blockchain.CurrentBlock().NumberU64() &gt; 0 {        log.Warn("Blockchain not empty, fast sync disabled")        mode = downloader.FullSync    }    if mode == downloader.FastSync {        manager.fastSync = uint32(1)    }    // Initiate a sub-protocol for every implemented version we can handle    manager.SubProtocols = make([]p2p.Protocol, 0, len(ProtocolVersions))    for i, version := range ProtocolVersions {        // Skip protocol version if incompatible with the mode of operation        if mode == downloader.FastSync &amp;&amp; version &lt; eth63 {            continue        }        // Compatible; initialise the sub-protocol        version := version // Closure for the run        manager.SubProtocols = append(manager.SubProtocols, p2p.Protocol{            Name:    ProtocolName,            Version: version,            Length:  ProtocolLengths[i],            // 还记得p2p里面的Protocol么。 p2p的peer连接成功之后会调用Run方法            Run: func(p *p2p.Peer, rw p2p.MsgReadWriter) error {                peer := manager.newPeer(int(version), p, rw)                select {                case manager.newPeerCh &lt;- peer:                    manager.wg.Add(1)                    defer manager.wg.Done()                    return manager.handle(peer)                case &lt;-manager.quitSync:                    return p2p.DiscQuitting                }            },            NodeInfo: func() interface{} {                return manager.NodeInfo()            },            PeerInfo: func(id discover.NodeID) interface{} {                if p := manager.peers.Peer(fmt.Sprintf("%x", id[:8])); p != nil {                    return p.Info()                }                return nil            },        })    }    if len(manager.SubProtocols) == 0 {        return nil, errIncompatibleConfig    }    // Construct the different synchronisation mechanisms    // downloader是负责从其他的peer来同步自身数据。    // downloader是全链同步工具    manager.downloader = downloader.New(mode, chaindb, manager.eventMux, blockchain, nil, manager.removePeer)    // validator 是使用一致性引擎来验证区块头的函数    validator := func(header *types.Header) error {        return engine.VerifyHeader(blockchain, header, true)    }    // 返回区块高度的函数    heighter := func() uint64 {        return blockchain.CurrentBlock().NumberU64()    }    // 如果fast sync开启了。 那么不会调用inserter。    inserter := func(blocks types.Blocks) (int, error) {        // If fast sync is running, deny importing weird blocks        if atomic.LoadUint32(&amp;manager.fastSync) == 1 {            log.Warn("Discarded bad propagated block", "number", blocks[0].Number(), "hash", blocks[0].Hash())            return 0, nil        }        // 设置开始接收交易        atomic.StoreUint32(&amp;manager.acceptTxs, 1) // Mark initial sync done on any fetcher import        // 插入区块        return manager.blockchain.InsertChain(blocks)    }    // 生成一个fetcher     // Fetcher负责积累来自各个peer的区块通知并安排进行检索。    manager.fetcher = fetcher.New(blockchain.GetBlockByHash, validator, manager.BroadcastBlock, heighter, inserter, manager.removePeer)    return manager, nil}</code></pre><p>服务的APIs()方法会返回服务暴露的RPC方法。</p><pre><code>// APIs returns the collection of RPC services the ethereum package offers.// NOTE, some of these services probably need to be moved to somewhere else.func (s *Ethereum) APIs() []rpc.API {    apis := ethapi.GetAPIs(s.ApiBackend)    // Append any APIs exposed explicitly by the consensus engine    apis = append(apis, s.engine.APIs(s.BlockChain())...)    // Append all the local APIs and return    return append(apis, []rpc.API{        {            Namespace: "eth",            Version:   "1.0",            Service:   NewPublicEthereumAPI(s),            Public:    true,        },        ...        , {            Namespace: "net",            Version:   "1.0",            Service:   s.netRPCService,            Public:    true,        },    }...)}</code></pre><p>服务的Protocols方法会返回服务提供了那些p2p的Protocol。 返回协议管理器里面的所有SubProtocols. 如果有lesServer那么还提供lesServer的Protocol。可以看到。所有的网络功能都是通过Protocol的方式提供出来的。</p><pre><code>// Protocols implements node.Service, returning all the currently configured// network protocols to start.func (s *Ethereum) Protocols() []p2p.Protocol {    if s.lesServer == nil {        return s.protocolManager.SubProtocols    }    return append(s.protocolManager.SubProtocols, s.lesServer.Protocols()...)}</code></pre><p>Ethereum服务在创建之后，会被调用服务的Start方法。下面我们来看看Start方法</p><pre><code>// Start implements node.Service, starting all internal goroutines needed by the// Ethereum protocol implementation.func (s *Ethereum) Start(srvr *p2p.Server) error {    // Start the bloom bits servicing goroutines    // 启动布隆过滤器请求处理的goroutine TODO    s.startBloomHandlers()    // Start the RPC service    // 创建网络的API net    s.netRPCService = ethapi.NewPublicNetAPI(srvr, s.NetVersion())    // Figure out a max peers count based on the server limits    maxPeers := srvr.MaxPeers    if s.config.LightServ &gt; 0 {        maxPeers -= s.config.LightPeers        if maxPeers &lt; srvr.MaxPeers/2 {            maxPeers = srvr.MaxPeers / 2        }    }    // Start the networking layer and the light server if requested    // 启动协议管理器    s.protocolManager.Start(maxPeers)    if s.lesServer != nil {        // 如果lesServer不为nil 启动它。        s.lesServer.Start(srvr)    }    return nil}</code></pre><p>协议管理器的数据结构</p><pre><code>type ProtocolManager struct {    networkId uint64    fastSync  uint32 // Flag whether fast sync is enabled (gets disabled if we already have blocks)    acceptTxs uint32 // Flag whether we're considered synchronised (enables transaction processing)    txpool      txPool    blockchain  *core.BlockChain    chaindb     ethdb.Database    chainconfig *params.ChainConfig    maxPeers    int    downloader *downloader.Downloader    fetcher    *fetcher.Fetcher    peers      *peerSet    SubProtocols []p2p.Protocol    eventMux      *event.TypeMux    txCh          chan core.TxPreEvent    txSub         event.Subscription    minedBlockSub *event.TypeMuxSubscription    // channels for fetcher, syncer, txsyncLoop    newPeerCh   chan *peer    txsyncCh    chan *txsync    quitSync    chan struct{}    noMorePeers chan struct{}    // wait group is used for graceful shutdowns during downloading    // and processing    wg sync.WaitGroup}</code></pre><p>协议管理器的Start方法。这个方法里面启动了大量的goroutine用来处理各种事务，可以推测，这个类应该是以太坊服务的主要实现类。</p><pre><code>func (pm *ProtocolManager) Start(maxPeers int) {    pm.maxPeers = maxPeers        // broadcast transactions    // 广播交易的通道。 txCh会作为txpool的TxPreEvent订阅通道。txpool有了这种消息会通知给这个txCh。 广播交易的goroutine会把这个消息广播出去。    pm.txCh = make(chan core.TxPreEvent, txChanSize)    // 订阅的回执    pm.txSub = pm.txpool.SubscribeTxPreEvent(pm.txCh)    // 启动广播的goroutine    go pm.txBroadcastLoop()    // broadcast mined blocks    // 订阅挖矿消息。当新的Block被挖出来的时候会产生消息。 这个订阅和上面的那个订阅采用了两种不同的模式，这种是标记为Deprecated的订阅方式。    pm.minedBlockSub = pm.eventMux.Subscribe(core.NewMinedBlockEvent{})    // 挖矿广播 goroutine 当挖出来的时候需要尽快的广播到网络上面去。    go pm.minedBroadcastLoop()    // start sync handlers    // 同步器负责周期性地与网络同步，下载散列和块以及处理通知处理程序。    go pm.syncer()    // txsyncLoop负责每个新连接的初始事务同步。 当新的peer出现时，我们转发所有当前待处理的事务。 为了最小化出口带宽使用，我们一次只发送一个小包。    go pm.txsyncLoop()}</code></pre><p>当p2p的server启动的时候，会主动的找节点去连接，或者被其他的节点连接。 连接的过程是首先进行加密信道的握手，然后进行协议的握手。 最后为每个协议启动goroutine 执行Run方法来把控制交给最终的协议。 这个run方法首先创建了一个peer对象，然后调用了handle方法来处理这个peer</p><pre><code>Run: func(p *p2p.Peer, rw p2p.MsgReadWriter) error {                    peer := manager.newPeer(int(version), p, rw)                    select {                    case manager.newPeerCh &lt;- peer:  //把peer发送到newPeerCh通道                        manager.wg.Add(1)                        defer manager.wg.Done()                        return manager.handle(peer)  // 调用handlo方法                    case &lt;-manager.quitSync:                        return p2p.DiscQuitting                    }                },</code></pre><p>handle方法,</p><pre><code>// handle is the callback invoked to manage the life cycle of an eth peer. When// this function terminates, the peer is disconnected.// handle是一个回调方法，用来管理eth的peer的生命周期管理。 当这个方法退出的时候，peer的连接也会断开。func (pm *ProtocolManager) handle(p *peer) error {    if pm.peers.Len() &gt;= pm.maxPeers {        return p2p.DiscTooManyPeers    }    p.Log().Debug("Ethereum peer connected", "name", p.Name())    // Execute the Ethereum handshake    td, head, genesis := pm.blockchain.Status()    // td是total difficult, head是当前的区块头，genesis是创世区块的信息。 只有创世区块相同才能握手成功。    if err := p.Handshake(pm.networkId, td, head, genesis); err != nil {        p.Log().Debug("Ethereum handshake failed", "err", err)        return err    }    if rw, ok := p.rw.(*meteredMsgReadWriter); ok {        rw.Init(p.version)    }    // Register the peer locally    // 把peer注册到本地    if err := pm.peers.Register(p); err != nil {        p.Log().Error("Ethereum peer registration failed", "err", err)        return err    }    defer pm.removePeer(p.id)    // Register the peer in the downloader. If the downloader considers it banned, we disconnect    // 把peer注册给downloader. 如果downloader认为这个peer被禁，那么断开连接。    if err := pm.downloader.RegisterPeer(p.id, p.version, p); err != nil {        return err    }    // Propagate existing transactions. new transactions appearing    // after this will be sent via broadcasts.    // 把当前pending的交易发送给对方，这个只在连接刚建立的时候发生    pm.syncTransactions(p)    // If we're DAO hard-fork aware, validate any remote peer with regard to the hard-fork    // 验证peer的DAO硬分叉    if daoBlock := pm.chainconfig.DAOForkBlock; daoBlock != nil {        // Request the peer's DAO fork header for extra-data validation        if err := p.RequestHeadersByNumber(daoBlock.Uint64(), 1, 0, false); err != nil {            return err        }        // Start a timer to disconnect if the peer doesn't reply in time        // 如果15秒内没有接收到回应。那么断开连接。        p.forkDrop = time.AfterFunc(daoChallengeTimeout, func() {            p.Log().Debug("Timed out DAO fork-check, dropping")            pm.removePeer(p.id)        })        // Make sure it's cleaned up if the peer dies off        defer func() {            if p.forkDrop != nil {                p.forkDrop.Stop()                p.forkDrop = nil            }        }()    }    // main loop. handle incoming messages.    // 主循环。 处理进入的消息。    for {        if err := pm.handleMsg(p); err != nil {            p.Log().Debug("Ethereum message handling failed", "err", err)            return err        }    }}</code></pre><p>Handshake</p><pre><code>// Handshake executes the eth protocol handshake, negotiating version number,// network IDs, difficulties, head and genesis blocks.func (p *peer) Handshake(network uint64, td *big.Int, head common.Hash, genesis common.Hash) error {    // Send out own handshake in a new thread    // error的channel的大小是2， 就是为了一次性处理下面的两个goroutine方法    errc := make(chan error, 2)    var status statusData // safe to read after two values have been received from errc    go func() {        errc &lt;- p2p.Send(p.rw, StatusMsg, &amp;statusData{            ProtocolVersion: uint32(p.version),            NetworkId:       network,            TD:              td,            CurrentBlock:    head,            GenesisBlock:    genesis,        })    }()    go func() {        errc &lt;- p.readStatus(network, &amp;status, genesis)    }()    timeout := time.NewTimer(handshakeTimeout)    defer timeout.Stop()    // 如果接收到任何一个错误(发送，接收),或者是超时， 那么就断开连接。    for i := 0; i &lt; 2; i++ {        select {        case err := &lt;-errc:            if err != nil {                return err            }        case &lt;-timeout.C:            return p2p.DiscReadTimeout        }    }    p.td, p.head = status.TD, status.CurrentBlock    return nil}</code></pre><p>readStatus，检查对端返回的各种情况，</p><pre><code>func (p *peer) readStatus(network uint64, status *statusData, genesis common.Hash) (err error) {    msg, err := p.rw.ReadMsg()    if err != nil {        return err    }    if msg.Code != StatusMsg {        return errResp(ErrNoStatusMsg, "first msg has code %x (!= %x)", msg.Code, StatusMsg)    }    if msg.Size &gt; ProtocolMaxMsgSize {        return errResp(ErrMsgTooLarge, "%v &gt; %v", msg.Size, ProtocolMaxMsgSize)    }    // Decode the handshake and make sure everything matches    if err := msg.Decode(&amp;status); err != nil {        return errResp(ErrDecode, "msg %v: %v", msg, err)    }    if status.GenesisBlock != genesis {        return errResp(ErrGenesisBlockMismatch, "%x (!= %x)", status.GenesisBlock[:8], genesis[:8])    }    if status.NetworkId != network {        return errResp(ErrNetworkIdMismatch, "%d (!= %d)", status.NetworkId, network)    }    if int(status.ProtocolVersion) != p.version {        return errResp(ErrProtocolVersionMismatch, "%d (!= %d)", status.ProtocolVersion, p.version)    }    return nil}</code></pre><p>Register 简单的把peer加入到自己的peers的map</p><pre><code>// Register injects a new peer into the working set, or returns an error if the// peer is already known.func (ps *peerSet) Register(p *peer) error {    ps.lock.Lock()    defer ps.lock.Unlock()    if ps.closed {        return errClosed    }    if _, ok := ps.peers[p.id]; ok {        return errAlreadyRegistered    }    ps.peers[p.id] = p    return nil}</code></pre><p>经过一系列的检查和握手之后， 循环的调用了handleMsg方法来处理事件循环。 这个方法很长，主要是处理接收到各种消息之后的应对措施。</p><pre><code>// handleMsg is invoked whenever an inbound message is received from a remote// peer. The remote connection is turn down upon returning any error.func (pm *ProtocolManager) handleMsg(p *peer) error {    // Read the next message from the remote peer, and ensure it's fully consumed    msg, err := p.rw.ReadMsg()    if err != nil {        return err    }    if msg.Size &gt; ProtocolMaxMsgSize {        return errResp(ErrMsgTooLarge, "%v &gt; %v", msg.Size, ProtocolMaxMsgSize)    }    defer msg.Discard()    // Handle the message depending on its contents    switch {    case msg.Code == StatusMsg:        // Status messages should never arrive after the handshake        // StatusMsg应该在HandleShake阶段接收到。 经过了HandleShake之后是不应该接收到这种消息的。        return errResp(ErrExtraStatusMsg, "uncontrolled status message")    // Block header query, collect the requested headers and reply    // 接收到请求区块头的消息， 会根据请求返回区块头信息。    case msg.Code == GetBlockHeadersMsg:        // Decode the complex header query        var query getBlockHeadersData        if err := msg.Decode(&amp;query); err != nil {            return errResp(ErrDecode, "%v: %v", msg, err)        }        hashMode := query.Origin.Hash != (common.Hash{})        // Gather headers until the fetch or network limits is reached        var (            bytes   common.StorageSize            headers []*types.Header            unknown bool        )        for !unknown &amp;&amp; len(headers) &lt; int(query.Amount) &amp;&amp; bytes &lt; softResponseLimit &amp;&amp; len(headers) &lt; downloader.MaxHeaderFetch {            // Retrieve the next header satisfying the query            var origin *types.Header            if hashMode {                origin = pm.blockchain.GetHeaderByHash(query.Origin.Hash)            } else {                origin = pm.blockchain.GetHeaderByNumber(query.Origin.Number)            }            if origin == nil {                break            }            number := origin.Number.Uint64()            headers = append(headers, origin)            bytes += estHeaderRlpSize            // Advance to the next header of the query            switch {            case query.Origin.Hash != (common.Hash{}) &amp;&amp; query.Reverse:                // Hash based traversal towards the genesis block                // 从Hash指定的开始朝创世区块移动。 也就是反向移动。  通过hash查找                for i := 0; i &lt; int(query.Skip)+1; i++ {                    if header := pm.blockchain.GetHeader(query.Origin.Hash, number); header != nil {// 通过hash和number获取前一个区块头                                            query.Origin.Hash = header.ParentHash                        number--                    } else {                        unknown = true                        break //break是跳出switch。 unknow用来跳出循环。                    }                }            case query.Origin.Hash != (common.Hash{}) &amp;&amp; !query.Reverse:                // Hash based traversal towards the leaf block                // 通过hash来查找                var (                    current = origin.Number.Uint64()                    next    = current + query.Skip + 1                )                if next &lt;= current { //正向， 但是next比当前还小，防备整数溢出攻击。                    infos, _ := json.MarshalIndent(p.Peer.Info(), "", "  ")                    p.Log().Warn("GetBlockHeaders skip overflow attack", "current", current, "skip", query.Skip, "next", next, "attacker", infos)                    unknown = true                } else {                    if header := pm.blockchain.GetHeaderByNumber(next); header != nil {                        if pm.blockchain.GetBlockHashesFromHash(header.Hash(), query.Skip+1)[query.Skip] == query.Origin.Hash {                            // 如果可以找到这个header，而且这个header和origin在同一个链上。                            query.Origin.Hash = header.Hash()                        } else {                            unknown = true                        }                    } else {                        unknown = true                    }                }            case query.Reverse:        // 通过number查找                // Number based traversal towards the genesis block                //  query.Origin.Hash == (common.Hash{})                 if query.Origin.Number &gt;= query.Skip+1 {                    query.Origin.Number -= (query.Skip + 1)                } else {                    unknown = true                }            case !query.Reverse:     //通过number查找                // Number based traversal towards the leaf block                query.Origin.Number += (query.Skip + 1)            }        }        return p.SendBlockHeaders(headers)    case msg.Code == BlockHeadersMsg: //接收到了GetBlockHeadersMsg的回答。        // A batch of headers arrived to one of our previous requests        var headers []*types.Header        if err := msg.Decode(&amp;headers); err != nil {            return errResp(ErrDecode, "msg %v: %v", msg, err)        }        // If no headers were received, but we're expending a DAO fork check, maybe it's that        // 如果对端没有返回任何的headers,而且forkDrop不为空，那么应该是我们的DAO检查的请求，我们之前在HandShake发送了DAO header的请求。        if len(headers) == 0 &amp;&amp; p.forkDrop != nil {            // Possibly an empty reply to the fork header checks, sanity check TDs            verifyDAO := true            // If we already have a DAO header, we can check the peer's TD against it. If            // the peer's ahead of this, it too must have a reply to the DAO check            if daoHeader := pm.blockchain.GetHeaderByNumber(pm.chainconfig.DAOForkBlock.Uint64()); daoHeader != nil {                if _, td := p.Head(); td.Cmp(pm.blockchain.GetTd(daoHeader.Hash(), daoHeader.Number.Uint64())) &gt;= 0 {                    //这个时候检查对端的total difficult 是否已经超过了DAO分叉区块的td值， 如果超过了，说明对端应该存在这个区块头， 但是返回的空白的，那么这里验证失败。 这里什么都没有做。 如果对端还不发送，那么会被超时退出。                    verifyDAO = false                }            }            // If we're seemingly on the same chain, disable the drop timer            if verifyDAO { // 如果验证成功，那么删除掉计时器，然后返回。                p.Log().Debug("Seems to be on the same side of the DAO fork")                p.forkDrop.Stop()                p.forkDrop = nil                return nil            }        }        // Filter out any explicitly requested headers, deliver the rest to the downloader        // 过滤出任何非常明确的请求， 然后把剩下的投递给downloader        // 如果长度是1 那么filter为true        filter := len(headers) == 1        if filter {            // If it's a potential DAO fork check, validate against the rules            if p.forkDrop != nil &amp;&amp; pm.chainconfig.DAOForkBlock.Cmp(headers[0].Number) == 0 {  //DAO检查                // Disable the fork drop timer                p.forkDrop.Stop()                p.forkDrop = nil                // Validate the header and either drop the peer or continue                if err := misc.VerifyDAOHeaderExtraData(pm.chainconfig, headers[0]); err != nil {                    p.Log().Debug("Verified to be on the other side of the DAO fork, dropping")                    return err                }                p.Log().Debug("Verified to be on the same side of the DAO fork")                return nil            }            // Irrelevant of the fork checks, send the header to the fetcher just in case            // 如果不是DAO的请求，交给过滤器进行过滤。过滤器会返回需要继续处理的headers，这些headers会被交给downloader进行分发。            headers = pm.fetcher.FilterHeaders(p.id, headers, time.Now())        }        if len(headers) &gt; 0 || !filter {            err := pm.downloader.DeliverHeaders(p.id, headers)            if err != nil {                log.Debug("Failed to deliver headers", "err", err)            }        }    case msg.Code == GetBlockBodiesMsg:        //  Block Body的请求 这个比较简单。 从blockchain里面获取body返回就行。        // Decode the retrieval message        msgStream := rlp.NewStream(msg.Payload, uint64(msg.Size))        if _, err := msgStream.List(); err != nil {            return err        }        // Gather blocks until the fetch or network limits is reached        var (            hash   common.Hash            bytes  int            bodies []rlp.RawValue        )        for bytes &lt; softResponseLimit &amp;&amp; len(bodies) &lt; downloader.MaxBlockFetch {            // Retrieve the hash of the next block            if err := msgStream.Decode(&amp;hash); err == rlp.EOL {                break            } else if err != nil {                return errResp(ErrDecode, "msg %v: %v", msg, err)            }            // Retrieve the requested block body, stopping if enough was found            if data := pm.blockchain.GetBodyRLP(hash); len(data) != 0 {                bodies = append(bodies, data)                bytes += len(data)            }        }        return p.SendBlockBodiesRLP(bodies)    case msg.Code == BlockBodiesMsg:        // A batch of block bodies arrived to one of our previous requests        var request blockBodiesData        if err := msg.Decode(&amp;request); err != nil {            return errResp(ErrDecode, "msg %v: %v", msg, err)        }        // Deliver them all to the downloader for queuing        trasactions := make([][]*types.Transaction, len(request))        uncles := make([][]*types.Header, len(request))        for i, body := range request {            trasactions[i] = body.Transactions            uncles[i] = body.Uncles        }        // Filter out any explicitly requested bodies, deliver the rest to the downloader        // 过滤掉任何显示的请求， 剩下的交给downloader        filter := len(trasactions) &gt; 0 || len(uncles) &gt; 0        if filter {            trasactions, uncles = pm.fetcher.FilterBodies(p.id, trasactions, uncles, time.Now())        }        if len(trasactions) &gt; 0 || len(uncles) &gt; 0 || !filter {            err := pm.downloader.DeliverBodies(p.id, trasactions, uncles)            if err != nil {                log.Debug("Failed to deliver bodies", "err", err)            }        }    case p.version &gt;= eth63 &amp;&amp; msg.Code == GetNodeDataMsg:        // 对端的版本是eth63 而且是请求NodeData        // Decode the retrieval message        msgStream := rlp.NewStream(msg.Payload, uint64(msg.Size))        if _, err := msgStream.List(); err != nil {            return err        }        // Gather state data until the fetch or network limits is reached        var (            hash  common.Hash            bytes int            data  [][]byte        )        for bytes &lt; softResponseLimit &amp;&amp; len(data) &lt; downloader.MaxStateFetch {            // Retrieve the hash of the next state entry            if err := msgStream.Decode(&amp;hash); err == rlp.EOL {                break            } else if err != nil {                return errResp(ErrDecode, "msg %v: %v", msg, err)            }            // Retrieve the requested state entry, stopping if enough was found            // 请求的任何hash值都会返回给对方。             if entry, err := pm.chaindb.Get(hash.Bytes()); err == nil {                data = append(data, entry)                bytes += len(entry)            }        }        return p.SendNodeData(data)    case p.version &gt;= eth63 &amp;&amp; msg.Code == NodeDataMsg:        // A batch of node state data arrived to one of our previous requests        var data [][]byte        if err := msg.Decode(&amp;data); err != nil {            return errResp(ErrDecode, "msg %v: %v", msg, err)        }        // Deliver all to the downloader        // 数据交给downloader        if err := pm.downloader.DeliverNodeData(p.id, data); err != nil {            log.Debug("Failed to deliver node state data", "err", err)        }    case p.version &gt;= eth63 &amp;&amp; msg.Code == GetReceiptsMsg:        // 请求收据        // Decode the retrieval message        msgStream := rlp.NewStream(msg.Payload, uint64(msg.Size))        if _, err := msgStream.List(); err != nil {            return err        }        // Gather state data until the fetch or network limits is reached        var (            hash     common.Hash            bytes    int            receipts []rlp.RawValue        )        for bytes &lt; softResponseLimit &amp;&amp; len(receipts) &lt; downloader.MaxReceiptFetch {            // Retrieve the hash of the next block            if err := msgStream.Decode(&amp;hash); err == rlp.EOL {                break            } else if err != nil {                return errResp(ErrDecode, "msg %v: %v", msg, err)            }            // Retrieve the requested block's receipts, skipping if unknown to us            results := core.GetBlockReceipts(pm.chaindb, hash, core.GetBlockNumber(pm.chaindb, hash))            if results == nil {                if header := pm.blockchain.GetHeaderByHash(hash); header == nil || header.ReceiptHash != types.EmptyRootHash {                    continue                }            }            // If known, encode and queue for response packet            if encoded, err := rlp.EncodeToBytes(results); err != nil {                log.Error("Failed to encode receipt", "err", err)            } else {                receipts = append(receipts, encoded)                bytes += len(encoded)            }        }        return p.SendReceiptsRLP(receipts)    case p.version &gt;= eth63 &amp;&amp; msg.Code == ReceiptsMsg:        // A batch of receipts arrived to one of our previous requests        var receipts [][]*types.Receipt        if err := msg.Decode(&amp;receipts); err != nil {            return errResp(ErrDecode, "msg %v: %v", msg, err)        }        // Deliver all to the downloader        if err := pm.downloader.DeliverReceipts(p.id, receipts); err != nil {            log.Debug("Failed to deliver receipts", "err", err)        }    case msg.Code == NewBlockHashesMsg:        // 接收到BlockHashesMsg消息        var announces newBlockHashesData        if err := msg.Decode(&amp;announces); err != nil {            return errResp(ErrDecode, "%v: %v", msg, err)        }        // Mark the hashes as present at the remote node        for _, block := range announces {            p.MarkBlock(block.Hash)        }        // Schedule all the unknown hashes for retrieval        unknown := make(newBlockHashesData, 0, len(announces))        for _, block := range announces {            if !pm.blockchain.HasBlock(block.Hash, block.Number) {                unknown = append(unknown, block)            }        }        for _, block := range unknown {            // 通知fetcher有一个潜在的block需要下载            pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies)        }    case msg.Code == NewBlockMsg:        // Retrieve and decode the propagated block        var request newBlockData        if err := msg.Decode(&amp;request); err != nil {            return errResp(ErrDecode, "%v: %v", msg, err)        }        request.Block.ReceivedAt = msg.ReceivedAt        request.Block.ReceivedFrom = p        // Mark the peer as owning the block and schedule it for import        p.MarkBlock(request.Block.Hash())        pm.fetcher.Enqueue(p.id, request.Block)        // Assuming the block is importable by the peer, but possibly not yet done so,        // calculate the head hash and TD that the peer truly must have.        var (            trueHead = request.Block.ParentHash()            trueTD   = new(big.Int).Sub(request.TD, request.Block.Difficulty())        )        // Update the peers total difficulty if better than the previous        if _, td := p.Head(); trueTD.Cmp(td) &gt; 0 {            // 如果peer的真实的TD和head和我们这边记载的不同， 设置peer真实的head和td，            p.SetHead(trueHead, trueTD)            // Schedule a sync if above ours. Note, this will not fire a sync for a gap of            // a singe block (as the true TD is below the propagated block), however this            // scenario should easily be covered by the fetcher.            // 如果真实的TD比我们的TD大，那么请求和这个peer同步。            currentBlock := pm.blockchain.CurrentBlock()            if trueTD.Cmp(pm.blockchain.GetTd(currentBlock.Hash(), currentBlock.NumberU64())) &gt; 0 {                go pm.synchronise(p)            }        }    case msg.Code == TxMsg:        // Transactions arrived, make sure we have a valid and fresh chain to handle them        // 交易信息返回。 在我们没用同步完成之前不会接收交易信息。        if atomic.LoadUint32(&amp;pm.acceptTxs) == 0 {            break        }        // Transactions can be processed, parse all of them and deliver to the pool        var txs []*types.Transaction        if err := msg.Decode(&amp;txs); err != nil {            return errResp(ErrDecode, "msg %v: %v", msg, err)        }        for i, tx := range txs {            // Validate and mark the remote transaction            if tx == nil {                return errResp(ErrDecode, "transaction %d is nil", i)            }            p.MarkTransaction(tx.Hash())        }        // 添加到txpool        pm.txpool.AddRemotes(txs)    default:        return errResp(ErrInvalidMsgCode, "%v", msg.Code)    }    return nil}</code></pre><p>几种同步synchronise, 之前发现对方的节点比自己节点要更新的时候会调用这个方法synchronise，</p><pre><code>// synchronise tries to sync up our local block chain with a remote peer.// synchronise 尝试 让本地区块链跟远端同步。func (pm *ProtocolManager) synchronise(peer *peer) {    // Short circuit if no peers are available    if peer == nil {        return    }    // Make sure the peer's TD is higher than our own    currentBlock := pm.blockchain.CurrentBlock()    td := pm.blockchain.GetTd(currentBlock.Hash(), currentBlock.NumberU64())    pHead, pTd := peer.Head()    if pTd.Cmp(td) &lt;= 0 {        return    }    // Otherwise try to sync with the downloader    mode := downloader.FullSync    if atomic.LoadUint32(&amp;pm.fastSync) == 1 { //如果显式申明是fast        // Fast sync was explicitly requested, and explicitly granted        mode = downloader.FastSync    } else if currentBlock.NumberU64() == 0 &amp;&amp; pm.blockchain.CurrentFastBlock().NumberU64() &gt; 0 {  //如果数据库是空白的        // The database seems empty as the current block is the genesis. Yet the fast        // block is ahead, so fast sync was enabled for this node at a certain point.        // The only scenario where this can happen is if the user manually (or via a        // bad block) rolled back a fast sync node below the sync point. In this case        // however it's safe to reenable fast sync.        atomic.StoreUint32(&amp;pm.fastSync, 1)        mode = downloader.FastSync    }    // Run the sync cycle, and disable fast sync if we've went past the pivot block    err := pm.downloader.Synchronise(peer.id, pHead, pTd, mode)    if atomic.LoadUint32(&amp;pm.fastSync) == 1 {        // Disable fast sync if we indeed have something in our chain        if pm.blockchain.CurrentBlock().NumberU64() &gt; 0 {            log.Info("Fast sync complete, auto disabling")            atomic.StoreUint32(&amp;pm.fastSync, 0)        }    }    if err != nil {        return    }    atomic.StoreUint32(&amp;pm.acceptTxs, 1) // Mark initial sync done    // 同步完成 开始接收交易。    if head := pm.blockchain.CurrentBlock(); head.NumberU64() &gt; 0 {        // We've completed a sync cycle, notify all peers of new state. This path is        // essential in star-topology networks where a gateway node needs to notify        // all its out-of-date peers of the availability of a new block. This failure        // scenario will most often crop up in private and hackathon networks with        // degenerate connectivity, but it should be healthy for the mainnet too to        // more reliably update peers or the local TD state.        // 我们告诉所有的peer我们的状态。        go pm.BroadcastBlock(head, false)    }}</code></pre><p>交易广播。txBroadcastLoop 在start的时候启动的goroutine。  txCh在txpool接收到一条合法的交易的时候会往这个上面写入事件。 然后把交易广播给所有的peers</p><pre><code>func (self *ProtocolManager) txBroadcastLoop() {    for {        select {        case event := &lt;-self.txCh:            self.BroadcastTx(event.Tx.Hash(), event.Tx)        // Err() channel will be closed when unsubscribing.        case &lt;-self.txSub.Err():            return        }    }}</code></pre><p>挖矿广播。当收到订阅的事件的时候把新挖到的矿广播出去。</p><pre><code>// Mined broadcast loopfunc (self *ProtocolManager) minedBroadcastLoop() {    // automatically stops if unsubscribe    for obj := range self.minedBlockSub.Chan() {        switch ev := obj.Data.(type) {        case core.NewMinedBlockEvent:            self.BroadcastBlock(ev.Block, true)  // First propagate block to peers            self.BroadcastBlock(ev.Block, false) // Only then announce to the rest        }    }}</code></pre><p>syncer负责定期和网络同步，</p><pre><code>// syncer is responsible for periodically synchronising with the network, both// downloading hashes and blocks as well as handling the announcement handler.//同步器负责周期性地与网络同步，下载散列和块以及处理通知处理程序。func (pm *ProtocolManager) syncer() {    // Start and ensure cleanup of sync mechanisms    pm.fetcher.Start()    defer pm.fetcher.Stop()    defer pm.downloader.Terminate()    // Wait for different events to fire synchronisation operations    forceSync := time.NewTicker(forceSyncCycle)    defer forceSync.Stop()    for {        select {        case &lt;-pm.newPeerCh: //当有新的Peer增加的时候 会同步。 这个时候还可能触发区块广播。            // Make sure we have peers to select from, then sync            if pm.peers.Len() &lt; minDesiredPeerCount {                break            }            go pm.synchronise(pm.peers.BestPeer())        case &lt;-forceSync.C:            // 定时触发 10秒一次            // Force a sync even if not enough peers are present            // BestPeer() 选择总难度最大的节点。            go pm.synchronise(pm.peers.BestPeer())        case &lt;-pm.noMorePeers: // 退出信号            return        }    }}</code></pre><p>txsyncLoop负责把pending的交易发送给新建立的连接。</p><pre><code>// txsyncLoop takes care of the initial transaction sync for each new// connection. When a new peer appears, we relay all currently pending// transactions. In order to minimise egress bandwidth usage, we send// the transactions in small packs to one peer at a time.txsyncLoop负责每个新连接的初始事务同步。 当新的对等体出现时，我们转发所有当前待处理的事务。 为了最小化出口带宽使用，我们一次将一个小包中的事务发送给一个对等体。func (pm *ProtocolManager) txsyncLoop() {    var (        pending = make(map[discover.NodeID]*txsync)        sending = false               // whether a send is active        pack    = new(txsync)         // the pack that is being sent        done    = make(chan error, 1) // result of the send    )    // send starts a sending a pack of transactions from the sync.    send := func(s *txsync) {        // Fill pack with transactions up to the target size.        size := common.StorageSize(0)        pack.p = s.p        pack.txs = pack.txs[:0]        for i := 0; i &lt; len(s.txs) &amp;&amp; size &lt; txsyncPackSize; i++ {            pack.txs = append(pack.txs, s.txs[i])            size += s.txs[i].Size()        }        // Remove the transactions that will be sent.        s.txs = s.txs[:copy(s.txs, s.txs[len(pack.txs):])]        if len(s.txs) == 0 {            delete(pending, s.p.ID())        }        // Send the pack in the background.        s.p.Log().Trace("Sending batch of transactions", "count", len(pack.txs), "bytes", size)        sending = true        go func() { done &lt;- pack.p.SendTransactions(pack.txs) }()    }    // pick chooses the next pending sync.    // 随机挑选一个txsync来发送。    pick := func() *txsync {        if len(pending) == 0 {            return nil        }        n := rand.Intn(len(pending)) + 1        for _, s := range pending {            if n--; n == 0 {                return s            }        }        return nil    }    for {        select {        case s := &lt;-pm.txsyncCh: //从这里接收txsyncCh消息。            pending[s.p.ID()] = s            if !sending {                send(s)            }        case err := &lt;-done:            sending = false            // Stop tracking peers that cause send failures.            if err != nil {                pack.p.Log().Debug("Transaction send failed", "err", err)                delete(pending, pack.p.ID())            }            // Schedule the next send.            if s := pick(); s != nil {                send(s)            }        case &lt;-pm.quitSync:            return        }    }}</code></pre><p>txsyncCh队列的生产者，syncTransactions是在handle方法里面调用的。 在新链接刚刚创建的时候会被调用一次。</p><pre><code>// syncTransactions starts sending all currently pending transactions to the given peer.func (pm *ProtocolManager) syncTransactions(p *peer) {    var txs types.Transactions    pending, _ := pm.txpool.Pending()    for _, batch := range pending {        txs = append(txs, batch...)    }    if len(txs) == 0 {        return    }    select {    case pm.txsyncCh &lt;- &amp;txsync{p, txs}:    case &lt;-pm.quitSync:    }}</code></pre><p>总结一下。 我们现在的一些大的流程。</p><p>区块同步</p><ol><li>如果是自己挖的矿。通过goroutine minedBroadcastLoop()来进行广播。</li><li>如果是接收到其他人的区块广播，(NewBlockHashesMsg/NewBlockMsg),是否fetcher会通知的peer？ TODO</li><li>goroutine syncer()中会定时的同BestPeer()来同步信息。</li></ol><p>交易同步</p><ol><li>新建立连接。 把pending的交易发送给他。</li><li>本地发送了一个交易，或者是接收到别人发来的交易信息。 txpool会产生一条消息，消息被传递到txCh通道。 然后被goroutine txBroadcastLoop()处理， 发送给其他不知道这个交易的peer。</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-miner挖矿部分源码分析CPU挖矿</title>
      <link href="/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-miner%E6%8C%96%E7%9F%BF%E9%83%A8%E5%88%86%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90CPU%E6%8C%96%E7%9F%BF/"/>
      <url>/2021/05/17/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-miner%E6%8C%96%E7%9F%BF%E9%83%A8%E5%88%86%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90CPU%E6%8C%96%E7%9F%BF/</url>
      
        <content type="html"><![CDATA[<h2 id="agent"><a href="#agent" class="headerlink" title="agent"></a>agent</h2><p>agent 是具体执行挖矿的对象。 它执行的流程就是，接受计算好了的区块头， 计算mixhash和nonce， 把挖矿好的区块头返回。</p><p>构造CpuAgent, 一般情况下不会使用CPU来进行挖矿，一般来说挖矿都是使用的专门的GPU进行挖矿， GPU挖矿的代码不会在这里体现。</p><pre><code>type CpuAgent struct {    mu sync.Mutex    workCh        chan *Work       // 接受挖矿任务的通道    stop          chan struct{}    quitCurrentOp chan struct{}    returnCh      chan&lt;- *Result   // 挖矿完成后的返回channel    chain  consensus.ChainReader // 获取区块链的信息    engine consensus.Engine      // 一致性引擎，这里指的是Pow引擎    isMining int32 // isMining indicates whether the agent is currently mining}func NewCpuAgent(chain consensus.ChainReader, engine consensus.Engine) *CpuAgent {    miner := &amp;CpuAgent{        chain:  chain,        engine: engine,        stop:   make(chan struct{}, 1),        workCh: make(chan *Work, 1),    }    return miner}</code></pre><p>设置返回值channel和得到Work的channel， 方便外界传值和得到返回信息。</p><pre><code>func (self *CpuAgent) Work() chan&lt;- *Work            { return self.workCh }func (self *CpuAgent) SetReturnCh(ch chan&lt;- *Result) { self.returnCh = ch }</code></pre><p>启动和消息循环，如果已经启动挖矿，那么直接退出， 否则启动update 这个goroutine<br>update 从workCh接受任务，进行挖矿，或者是接受退出信息，退出。</p><pre><code>func (self *CpuAgent) Start() {    if !atomic.CompareAndSwapInt32(&amp;self.isMining, 0, 1) {        return // agent already started    }    go self.update()}func (self *CpuAgent) update() {out:    for {        select {        case work := &lt;-self.workCh:            self.mu.Lock()            if self.quitCurrentOp != nil {                close(self.quitCurrentOp)            }            self.quitCurrentOp = make(chan struct{})            go self.mine(work, self.quitCurrentOp)            self.mu.Unlock()        case &lt;-self.stop:            self.mu.Lock()            if self.quitCurrentOp != nil {                close(self.quitCurrentOp)                self.quitCurrentOp = nil            }            self.mu.Unlock()            break out        }    }}</code></pre><p>mine, 挖矿，调用一致性引擎进行挖矿， 如果挖矿成功，把消息发送到returnCh上面。</p><pre><code>func (self *CpuAgent) mine(work *Work, stop &lt;-chan struct{}) {    if result, err := self.engine.Seal(self.chain, work.Block, stop); result != nil {        log.Info("Successfully sealed new block", "number", result.Number(), "hash", result.Hash())        self.returnCh &lt;- &amp;Result{work, result}    } else {        if err != nil {            log.Warn("Block sealing failed", "err", err)        }        self.returnCh &lt;- nil    }}</code></pre><p>GetHashRate， 这个函数返回当前的HashRate。</p><pre><code>func (self *CpuAgent) GetHashRate() int64 {    if pow, ok := self.engine.(consensus.PoW); ok {        return int64(pow.Hashrate())    }    return 0}</code></pre><h2 id="remote-agent"><a href="#remote-agent" class="headerlink" title="remote_agent"></a>remote_agent</h2><p>remote_agent 提供了一套RPC接口，可以实现远程矿工进行采矿的功能。 比如我有一个矿机，矿机内部没有运行以太坊节点，矿机首先从remote_agent获取当前的任务，然后进行挖矿计算，当挖矿完成后，提交计算结果，完成挖矿。 </p><p>数据结构和构造</p><pre><code>type RemoteAgent struct {    mu sync.Mutex    quitCh   chan struct{}    workCh   chan *Work          // 接受任务    returnCh chan&lt;- *Result        // 结果返回    chain       consensus.ChainReader    engine      consensus.Engine    currentWork *Work    //当前的任务    work        map[common.Hash]*Work // 当前还没有提交的任务，正在计算    hashrateMu sync.RWMutex    hashrate   map[common.Hash]hashrate  // 正在计算的任务的hashrate    running int32 // running indicates whether the agent is active. Call atomically}func NewRemoteAgent(chain consensus.ChainReader, engine consensus.Engine) *RemoteAgent {    return &amp;RemoteAgent{        chain:    chain,        engine:   engine,        work:     make(map[common.Hash]*Work),        hashrate: make(map[common.Hash]hashrate),    }}</code></pre><p>启动和停止</p><pre><code>func (a *RemoteAgent) Start() {    if !atomic.CompareAndSwapInt32(&amp;a.running, 0, 1) {        return    }    a.quitCh = make(chan struct{})    a.workCh = make(chan *Work, 1)    go a.loop(a.workCh, a.quitCh)}func (a *RemoteAgent) Stop() {    if !atomic.CompareAndSwapInt32(&amp;a.running, 1, 0) {        return    }    close(a.quitCh)    close(a.workCh)}</code></pre><p>得到输入输出的channel，这个和agent.go一样。</p><pre><code>func (a *RemoteAgent) Work() chan&lt;- *Work {    return a.workCh}func (a *RemoteAgent) SetReturnCh(returnCh chan&lt;- *Result) {    a.returnCh = returnCh}</code></pre><p>loop方法,和agent.go里面做的工作比较类似， 当接收到任务的时候，就存放在currentWork字段里面。 如果84秒还没有完成一个工作，那么就删除这个工作， 如果10秒没有收到hashrate的报告，那么删除这个追踪/。</p><pre><code>// loop monitors mining events on the work and quit channels, updating the internal// state of the rmeote miner until a termination is requested.//// Note, the reason the work and quit channels are passed as parameters is because// RemoteAgent.Start() constantly recreates these channels, so the loop code cannot// assume data stability in these member fields.func (a *RemoteAgent) loop(workCh chan *Work, quitCh chan struct{}) {    ticker := time.NewTicker(5 * time.Second)    defer ticker.Stop()    for {        select {        case &lt;-quitCh:            return        case work := &lt;-workCh:            a.mu.Lock()            a.currentWork = work            a.mu.Unlock()        case &lt;-ticker.C:            // cleanup            a.mu.Lock()            for hash, work := range a.work {                if time.Since(work.createdAt) &gt; 7*(12*time.Second) {                    delete(a.work, hash)                }            }            a.mu.Unlock()            a.hashrateMu.Lock()            for id, hashrate := range a.hashrate {                if time.Since(hashrate.ping) &gt; 10*time.Second {                    delete(a.hashrate, id)                }            }            a.hashrateMu.Unlock()        }    }}</code></pre><p>GetWork，这个方法由远程矿工调用，获取当前的挖矿任务。</p><pre><code>func (a *RemoteAgent) GetWork() ([3]string, error) {    a.mu.Lock()    defer a.mu.Unlock()    var res [3]string    if a.currentWork != nil {        block := a.currentWork.Block        res[0] = block.HashNoNonce().Hex()        seedHash := ethash.SeedHash(block.NumberU64())        res[1] = common.BytesToHash(seedHash).Hex()        // Calculate the "target" to be returned to the external miner        n := big.NewInt(1)        n.Lsh(n, 255)        n.Div(n, block.Difficulty())        n.Lsh(n, 1)        res[2] = common.BytesToHash(n.Bytes()).Hex()        a.work[block.HashNoNonce()] = a.currentWork        return res, nil    }    return res, errors.New("No work available yet, don't panic.")}</code></pre><p>SubmitWork, 远程矿工会调用这个方法提交挖矿的结果。 对结果进行验证之后提交到returnCh</p><pre><code>// SubmitWork tries to inject a pow solution into the remote agent, returning// whether the solution was accepted or not (not can be both a bad pow as well as// any other error, like no work pending).func (a *RemoteAgent) SubmitWork(nonce types.BlockNonce, mixDigest, hash common.Hash) bool {    a.mu.Lock()    defer a.mu.Unlock()    // Make sure the work submitted is present    work := a.work[hash]    if work == nil {        log.Info("Work submitted but none pending", "hash", hash)        return false    }    // Make sure the Engine solutions is indeed valid    result := work.Block.Header()    result.Nonce = nonce    result.MixDigest = mixDigest    if err := a.engine.VerifySeal(a.chain, result); err != nil {        log.Warn("Invalid proof-of-work submitted", "hash", hash, "err", err)        return false    }    block := work.Block.WithSeal(result)    // Solutions seems to be valid, return to the miner and notify acceptance    a.returnCh &lt;- &amp;Result{work, block}    delete(a.work, hash)    return true}</code></pre><p>SubmitHashrate, 提交hash算力</p><pre><code>func (a *RemoteAgent) SubmitHashrate(id common.Hash, rate uint64) {    a.hashrateMu.Lock()    defer a.hashrateMu.Unlock()    a.hashrate[id] = hashrate{time.Now(), rate}}</code></pre><h2 id="unconfirmed"><a href="#unconfirmed" class="headerlink" title="unconfirmed"></a>unconfirmed</h2><p>unconfirmed是一个数据结构，用来跟踪用户本地的挖矿信息的，比如挖出了一个块，那么等待足够的后续区块确认之后(5个)，再查看本地挖矿的区块是否包含在规范的区块链内部。</p><p>数据结构</p><pre><code>// headerRetriever is used by the unconfirmed block set to verify whether a previously// mined block is part of the canonical chain or not.// headerRetriever由未确认的块组使用，以验证先前挖掘的块是否是规范链的一部分。type headerRetriever interface {    // GetHeaderByNumber retrieves the canonical header associated with a block number.    GetHeaderByNumber(number uint64) *types.Header}// unconfirmedBlock is a small collection of metadata about a locally mined block// that is placed into a unconfirmed set for canonical chain inclusion tracking.// unconfirmedBlock 是本地挖掘区块的一个小的元数据的集合，用来放入未确认的集合用来追踪本地挖掘的区块是否被包含进入规范的区块链type unconfirmedBlock struct {    index uint64    hash  common.Hash}// unconfirmedBlocks implements a data structure to maintain locally mined blocks// have have not yet reached enough maturity to guarantee chain inclusion. It is// used by the miner to provide logs to the user when a previously mined block// has a high enough guarantee to not be reorged out of te canonical chain.    // unconfirmedBlocks 实现了一个数据结构，用来管理本地挖掘的区块，这些区块还没有达到足够的信任度来证明他们已经被规范的区块链接受。 它用来给矿工提供信息，以便他们了解他们之前挖到的区块是否被包含进入了规范的区块链。type unconfirmedBlocks struct {    chain  headerRetriever // Blockchain to verify canonical status through 需要验证的区块链 用这个接口来获取当前的规范的区块头信息    depth  uint            // Depth after which to discard previous blocks 经过多少个区块之后丢弃之前的区块    blocks *ring.Ring      // Block infos to allow canonical chain cross checks // 区块信息，以允许规范链交叉检查    lock   sync.RWMutex    // Protects the fields from concurrent access}// newUnconfirmedBlocks returns new data structure to track currently unconfirmed blocks.func newUnconfirmedBlocks(chain headerRetriever, depth uint) *unconfirmedBlocks {    return &amp;unconfirmedBlocks{        chain: chain,        depth: depth,    }}</code></pre><p>插入跟踪区块, 当矿工挖到一个区块的时候调用， index是区块的高度， hash是区块的hash值。</p><pre><code>// Insert adds a new block to the set of unconfirmed ones.func (set *unconfirmedBlocks) Insert(index uint64, hash common.Hash) {    // If a new block was mined locally, shift out any old enough blocks    // 如果一个本地的区块挖到了，那么移出已经超过depth的区块    set.Shift(index)    // Create the new item as its own ring    // 循环队列的操作。    item := ring.New(1)    item.Value = &amp;unconfirmedBlock{        index: index,        hash:  hash,    }    // Set as the initial ring or append to the end    set.lock.Lock()    defer set.lock.Unlock()    if set.blocks == nil {        set.blocks = item    } else {        // 移动到循环队列的最后一个元素插入item        set.blocks.Move(-1).Link(item)    }    // Display a log for the user to notify of a new mined block unconfirmed    log.Info("🔨 mined potential block", "number", index, "hash", hash)}</code></pre><p>Shift方法会删除那些index超过传入的index-depth的区块，并检查他们是否在规范的区块链中。</p><pre><code>// Shift drops all unconfirmed blocks from the set which exceed the unconfirmed sets depth// allowance, checking them against the canonical chain for inclusion or staleness// report.func (set *unconfirmedBlocks) Shift(height uint64) {    set.lock.Lock()    defer set.lock.Unlock()    for set.blocks != nil {        // Retrieve the next unconfirmed block and abort if too fresh        // 因为blocks中的区块都是按顺序排列的。排在最开始的肯定是最老的区块。        // 所以每次只需要检查最开始的那个区块，如果处理完了，就从循环队列里面摘除。        next := set.blocks.Value.(*unconfirmedBlock)        if next.index+uint64(set.depth) &gt; height { // 如果足够老了。            break        }        // Block seems to exceed depth allowance, check for canonical status        // 查询 那个区块高度的区块头        header := set.chain.GetHeaderByNumber(next.index)        switch {        case header == nil:            log.Warn("Failed to retrieve header of mined block", "number", next.index, "hash", next.hash)        case header.Hash() == next.hash: // 如果区块头就等于我们自己，            log.Info("🔗 block reached canonical chain", "number", next.index, "hash", next.hash)        default: // 否则说明我们在侧链上面。            log.Info("⑂ block  became a side fork", "number", next.index, "hash", next.hash)        }        // Drop the block out of the ring        // 从循环队列删除        if set.blocks.Value == set.blocks.Next().Value {            // 如果当前的值就等于我们自己，说明只有循环队列只有一个元素，那么设置未nil            set.blocks = nil        } else {            // 否则移动到最后，然后删除一个，再移动到最前。            set.blocks = set.blocks.Move(-1)            set.blocks.Unlink(1)            set.blocks = set.blocks.Move(1)        }    }}</code></pre><h2 id="worker-go"><a href="#worker-go" class="headerlink" title="worker.go"></a>worker.go</h2><p>worker 内部包含了很多agent，可以包含之前提到的agent和remote_agent。 worker同时负责构建区块和对象。同时把任务提供给agent。</p><p>数据结构：</p><p>Agent接口</p><pre><code>// Agent can register themself with the workertype Agent interface {    Work() chan&lt;- *Work    SetReturnCh(chan&lt;- *Result)    Stop()    Start()    GetHashRate() int64}</code></pre><p>Work结构，Work存储了工作者的当时的环境，并且持有所有的暂时的状态信息。</p><pre><code>// Work is the workers current environment and holds// all of the current state informationtype Work struct {    config *params.ChainConfig    signer types.Signer            // 签名者    state     *state.StateDB // apply state changes here 状态数据库    ancestors *set.Set       // ancestor set (used for checking uncle parent validity)  祖先集合，用来检查祖先是否有效    family    *set.Set       // family set (used for checking uncle invalidity) 家族集合，用来检查祖先的无效性    uncles    *set.Set       // uncle set  uncles集合    tcount    int            // tx count in cycle 这个周期的交易数量    Block *types.Block // the new block  //新的区块    header   *types.Header            // 区块头    txs      []*types.Transaction   // 交易    receipts []*types.Receipt          // 收据    createdAt time.Time             // 创建时间}type Result struct {  //结果    Work  *Work    Block *types.Block}</code></pre><p>worker</p><pre><code>// worker is the main object which takes care of applying messages to the new state// 工作者是负责将消息应用到新状态的主要对象type worker struct {    config *params.ChainConfig    engine consensus.Engine    mu sync.Mutex    // update loop    mux          *event.TypeMux    txCh         chan core.TxPreEvent        // 用来接受txPool里面的交易的通道    txSub        event.Subscription            // 用来接受txPool里面的交易的订阅器    chainHeadCh  chan core.ChainHeadEvent    // 用来接受区块头的通道    chainHeadSub event.Subscription    chainSideCh  chan core.ChainSideEvent    // 用来接受一个区块链从规范区块链移出的通道    chainSideSub event.Subscription    wg           sync.WaitGroup    agents map[Agent]struct{}                // 所有的agent    recv   chan *Result                        // agent会把结果发送到这个通道    eth     Backend                            // eth的协议    chain   *core.BlockChain                // 区块链    proc    core.Validator                    // 区块链验证器    chainDb ethdb.Database                    // 区块链数据库    coinbase common.Address                    // 挖矿者的地址    extra    []byte                            //         snapshotMu    sync.RWMutex                // 快照 RWMutex（快照读写锁）    snapshotBlock *types.Block                // 快照 Block    snapshotState *state.StateDB                // 快照 StateDB        currentMu sync.Mutex    current   *Work    uncleMu        sync.Mutex    possibleUncles map[common.Hash]*types.Block    //可能的叔父节点    unconfirmed *unconfirmedBlocks // set of locally mined blocks pending canonicalness confirmations    // atomic status counters    mining int32    atWork int32}</code></pre><p>构造</p><pre><code>func newWorker(config *params.ChainConfig, engine consensus.Engine, coinbase common.Address, eth Backend, mux *event.TypeMux) *worker {    worker := &amp;worker{        config:         config,        engine:         engine,        eth:            eth,        mux:            mux,        txCh:           make(chan core.TxPreEvent, txChanSize), // 4096        chainHeadCh:    make(chan core.ChainHeadEvent, chainHeadChanSize), // 10        chainSideCh:    make(chan core.ChainSideEvent, chainSideChanSize), // 10        chainDb:        eth.ChainDb(),        recv:           make(chan *Result, resultQueueSize), // 10        chain:          eth.BlockChain(),        proc:           eth.BlockChain().Validator(),        possibleUncles: make(map[common.Hash]*types.Block),        coinbase:       coinbase,        agents:         make(map[Agent]struct{}),        unconfirmed:    newUnconfirmedBlocks(eth.BlockChain(), miningLogAtDepth),    }    // Subscribe TxPreEvent for tx pool    worker.txSub = eth.TxPool().SubscribeTxPreEvent(worker.txCh)    // Subscribe events for blockchain    worker.chainHeadSub = eth.BlockChain().SubscribeChainHeadEvent(worker.chainHeadCh)    worker.chainSideSub = eth.BlockChain().SubscribeChainSideEvent(worker.chainSideCh)    go worker.update()    go worker.wait()    worker.commitNewWork()    return worker}</code></pre><p>update</p><pre><code>func (self *worker) update() {    defer self.txSub.Unsubscribe()    defer self.chainHeadSub.Unsubscribe()    defer self.chainSideSub.Unsubscribe()    for {        // A real event arrived, process interesting content        select {        // Handle ChainHeadEvent 当接收到一个区块头的信息的时候，马上开启挖矿服务。        case &lt;-self.chainHeadCh:            self.commitNewWork()        // Handle ChainSideEvent 接收不在规范的区块链的区块，加入到潜在的叔父集合        case ev := &lt;-self.chainSideCh:            self.uncleMu.Lock()            self.possibleUncles[ev.Block.Hash()] = ev.Block            self.uncleMu.Unlock()        // Handle TxPreEvent 接收到txPool里面的交易信息的时候。        case ev := &lt;-self.txCh:            // Apply transaction to the pending state if we're not mining            // 如果当前没有挖矿， 那么把交易应用到当前的状态上，以便马上开启挖矿任务。            if atomic.LoadInt32(&amp;self.mining) == 0 {                self.currentMu.Lock()                acc, _ := types.Sender(self.current.signer, ev.Tx)                txs := map[common.Address]types.Transactions{acc: {ev.Tx}}                txset := types.NewTransactionsByPriceAndNonce(self.current.signer, txs)                self.current.commitTransactions(self.mux, txset, self.chain, self.coinbase)                self.currentMu.Unlock()            }        // System stopped        case &lt;-self.txSub.Err():            return        case &lt;-self.chainHeadSub.Err():            return        case &lt;-self.chainSideSub.Err():            return        }    }}</code></pre><p>commitNewWork 提交新的任务</p><pre><code>func (self *worker) commitNewWork() {    self.mu.Lock()    defer self.mu.Unlock()    self.uncleMu.Lock()    defer self.uncleMu.Unlock()    self.currentMu.Lock()    defer self.currentMu.Unlock()    tstart := time.Now()    parent := self.chain.CurrentBlock()    tstamp := tstart.Unix()    if parent.Time().Cmp(new(big.Int).SetInt64(tstamp)) &gt;= 0 { // 不能出现比parent的时间还少的情况        tstamp = parent.Time().Int64() + 1    }    // this will ensure we're not going off too far in the future    // 我们的时间不要超过现在的时间太远， 那么等待一段时间，     // 感觉这个功能完全是为了测试实现的， 如果是真实的挖矿程序，应该不会等待。    if now := time.Now().Unix(); tstamp &gt; now+1 {        wait := time.Duration(tstamp-now) * time.Second        log.Info("Mining too far in the future", "wait", common.PrettyDuration(wait))        time.Sleep(wait)    }    num := parent.Number()    header := &amp;types.Header{        ParentHash: parent.Hash(),        Number:     num.Add(num, common.Big1),        GasLimit:   core.CalcGasLimit(parent),        GasUsed:    new(big.Int),        Extra:      self.extra,        Time:       big.NewInt(tstamp),    }    // Only set the coinbase if we are mining (avoid spurious block rewards)    // 只有当我们挖矿的时候才设置coinbase(避免虚假的块奖励？ TODO 没懂)    if atomic.LoadInt32(&amp;self.mining) == 1 {        header.Coinbase = self.coinbase    }    if err := self.engine.Prepare(self.chain, header); err != nil {        log.Error("Failed to prepare header for mining", "err", err)        return    }    // If we are care about TheDAO hard-fork check whether to override the extra-data or not    // 根据我们是否关心DAO硬分叉来决定是否覆盖额外的数据。    if daoBlock := self.config.DAOForkBlock; daoBlock != nil {        // Check whether the block is among the fork extra-override range        // 检查区块是否在 DAO硬分叉的范围内   [daoblock,daoblock+limit]        limit := new(big.Int).Add(daoBlock, params.DAOForkExtraRange)        if header.Number.Cmp(daoBlock) &gt;= 0 &amp;&amp; header.Number.Cmp(limit) &lt; 0 {            // Depending whether we support or oppose the fork, override differently            if self.config.DAOForkSupport { // 如果我们支持DAO 那么设置保留的额外的数据                header.Extra = common.CopyBytes(params.DAOForkBlockExtra)            } else if bytes.Equal(header.Extra, params.DAOForkBlockExtra) {                header.Extra = []byte{} // If miner opposes, don't let it use the reserved extra-data // 否则不使用保留的额外数据            }        }    }    // Could potentially happen if starting to mine in an odd state.    err := self.makeCurrent(parent, header) // 用新的区块头来设置当前的状态    if err != nil {        log.Error("Failed to create mining context", "err", err)        return    }    // Create the current work task and check any fork transitions needed    work := self.current    if self.config.DAOForkSupport &amp;&amp; self.config.DAOForkBlock != nil &amp;&amp; self.config.DAOForkBlock.Cmp(header.Number) == 0 {        misc.ApplyDAOHardFork(work.state)  // 把DAO里面的资金转移到指定的账户。    }    pending, err := self.eth.TxPool().Pending() //得到阻塞的资金    if err != nil {        log.Error("Failed to fetch pending transactions", "err", err)        return    }    // 创建交易。 这个方法后续介绍    txs := types.NewTransactionsByPriceAndNonce(self.current.signer, pending)    // 提交交易 这个方法后续介绍        work.commitTransactions(self.mux, txs, self.chain, self.coinbase)    // compute uncles for the new block.    var (        uncles    []*types.Header        badUncles []common.Hash    )    for hash, uncle := range self.possibleUncles {        if len(uncles) == 2 {            break        }        if err := self.commitUncle(work, uncle.Header()); err != nil {            log.Trace("Bad uncle found and will be removed", "hash", hash)            log.Trace(fmt.Sprint(uncle))            badUncles = append(badUncles, hash)        } else {            log.Debug("Committing new uncle to block", "hash", hash)            uncles = append(uncles, uncle.Header())        }    }    for _, hash := range badUncles {        delete(self.possibleUncles, hash)    }    // Create the new block to seal with the consensus engine    // 使用给定的状态来创建新的区块，Finalize会进行区块奖励等操作    if work.Block, err = self.engine.Finalize(self.chain, header, work.state, work.txs, uncles, work.receipts); err != nil {        log.Error("Failed to finalize block for sealing", "err", err)        return    }    // We only care about logging if we're actually mining.    //     if atomic.LoadInt32(&amp;self.mining) == 1 {        log.Info("Commit new mining work", "number", work.Block.Number(), "txs", work.tcount, "uncles", len(uncles), "elapsed", common.PrettyDuration(time.Since(tstart)))        self.unconfirmed.Shift(work.Block.NumberU64() - 1)    }    self.push(work)}</code></pre><p>push方法，如果我们没有在挖矿，那么直接返回，否则把任务送给每一个agent</p><pre><code>// push sends a new work task to currently live miner agents.func (self *worker) push(work *Work) {    if atomic.LoadInt32(&amp;self.mining) != 1 {        return    }    for agent := range self.agents {        atomic.AddInt32(&amp;self.atWork, 1)        if ch := agent.Work(); ch != nil {            ch &lt;- work        }    }}</code></pre><p>makeCurrent，未当前的周期创建一个新的环境。</p><pre><code>// makeCurrent creates a new environment for the current cycle.// func (self *worker) makeCurrent(parent *types.Block, header *types.Header) error {    state, err := self.chain.StateAt(parent.Root())    if err != nil {        return err    }    work := &amp;Work{        config:    self.config,        signer:    types.NewEIP155Signer(self.config.ChainId),        state:     state,        ancestors: set.New(),        family:    set.New(),        uncles:    set.New(),        header:    header,        createdAt: time.Now(),    }    // when 08 is processed ancestors contain 07 (quick block)    for _, ancestor := range self.chain.GetBlocksFromHash(parent.Hash(), 7) {        for _, uncle := range ancestor.Uncles() {            work.family.Add(uncle.Hash())        }        work.family.Add(ancestor.Hash())        work.ancestors.Add(ancestor.Hash())    }    // Keep track of transactions which return errors so they can be removed    work.tcount = 0    self.current = work    return nil}</code></pre><p>commitTransactions</p><pre><code>func (env *Work) commitTransactions(mux *event.TypeMux, txs *types.TransactionsByPriceAndNonce, bc *core.BlockChain, coinbase common.Address) {    // 由于是打包新的区块中交易，所以将总 gasPool 初始化为 env.header.GasLimit    if env.gasPool == nil {        env.gasPool = new(core.GasPool).AddGas(env.header.GasLimit)    }    var coalescedLogs []*types.Log    for {        // If we don't have enough gas for any further transactions then we're done        // 如果当前区块中所有 Gas 消耗已经使用完，则退出打包交易        if env.gasPool.Gas() &lt; params.TxGas {            log.Trace("Not enough gas for further transactions", "have", env.gasPool, "want", params.TxGas)            break        }                        // Retrieve the next transaction and abort if all done        // 检索下一笔交易，如果交易集合为空则退出 commit        tx := txs.Peek()        if tx == nil {            break        }        // Error may be ignored here. The error has already been checked        // during transaction acceptance is the transaction pool.        //        // We use the eip155 signer regardless of the current hf.        from, _ := types.Sender(env.signer, tx)        // Check whether the tx is replay protected. If we're not in the EIP155 hf        // phase, start ignoring the sender until we do.        // 请参考 https://github.com/ethereum/EIPs/blob/master/EIPS/eip-155.md        // DAO事件发生后，以太坊分裂为ETH和ETC,因为两个链上的东西一摸一样，所以在ETC        // 上面发生的交易可以拿到ETH上面进行重放， 反之亦然。 所以Vitalik提出了EIP155来避免这种情况。        if tx.Protected() &amp;&amp; !env.config.IsEIP155(env.header.Number) {            log.Trace("Ignoring reply protected transaction", "hash", tx.Hash(), "eip155", env.config.EIP155Block)            txs.Pop()            continue        }        // Start executing the transaction        env.state.Prepare(tx.Hash(), common.Hash{}, env.tcount)        // 执行交易        err, logs := env.commitTransaction(tx, bc, coinbase, gp)        switch err {        case core.ErrGasLimitReached:            // Pop the current out-of-gas transaction without shifting in the next from the account            // 弹出整个账户的所有交易， 不处理用户的下一个交易。            log.Trace("Gas limit exceeded for current block", "sender", from)            txs.Pop()        case core.ErrNonceTooLow:            // New head notification data race between the transaction pool and miner, shift            // 移动到用户的下一个交易            log.Trace("Skipping transaction with low nonce", "sender", from, "nonce", tx.Nonce())            txs.Shift()        case core.ErrNonceTooHigh:            // Reorg notification data race between the transaction pool and miner, skip account =            // 跳过这个账户            log.Trace("Skipping account with hight nonce", "sender", from, "nonce", tx.Nonce())            txs.Pop()        case nil:            // Everything ok, collect the logs and shift in the next transaction from the same account            coalescedLogs = append(coalescedLogs, logs...)            env.tcount++            txs.Shift()        default:            // Strange error, discard the transaction and get the next in line (note, the            // nonce-too-high clause will prevent us from executing in vain).            // 其他奇怪的错误，跳过这个交易。            log.Debug("Transaction failed, account skipped", "hash", tx.Hash(), "err", err)            txs.Shift()        }    }    if len(coalescedLogs) &gt; 0 || env.tcount &gt; 0 {        // make a copy, the state caches the logs and these logs get "upgraded" from pending to mined        // logs by filling in the block hash when the block was mined by the local miner. This can        // cause a race condition if a log was "upgraded" before the PendingLogsEvent is processed.        // 因为需要把log发送出去，而这边在挖矿完成后需要对log进行修改，所以拷贝一份发送出去，避免争用。        cpy := make([]*types.Log, len(coalescedLogs))        for i, l := range coalescedLogs {            cpy[i] = new(types.Log)            *cpy[i] = *l        }        go func(logs []*types.Log, tcount int) {            if len(logs) &gt; 0 {                mux.Post(core.PendingLogsEvent{Logs: logs})            }            if tcount &gt; 0 {                mux.Post(core.PendingStateEvent{})            }        }(cpy, env.tcount)    }}</code></pre><p>commitTransaction执行ApplyTransaction</p><pre><code>func (env *Work) commitTransaction(tx *types.Transaction, bc *core.BlockChain, coinbase common.Address, gp *core.GasPool) (error, []*types.Log) {    snap := env.state.Snapshot()    receipt, _, err := core.ApplyTransaction(env.config, bc, &amp;coinbase, gp, env.state, env.header, tx, env.header.GasUsed, vm.Config{})    if err != nil {        env.state.RevertToSnapshot(snap)        return err, nil    }    env.txs = append(env.txs, tx)    env.receipts = append(env.receipts, receipt)    return nil, receipt.Logs}</code></pre><p>wait函数用来接受挖矿的结果然后写入本地区块链，同时通过eth协议广播出去。</p><pre><code>func (self *worker) wait() {    for {        mustCommitNewWork := true        for result := range self.recv {            atomic.AddInt32(&amp;self.atWork, -1)            if result == nil {                continue            }            block := result.Block            work := result.Work            // Update the block hash in all logs since it is now available and not when the            // receipt/log of individual transactions were created.            for _, r := range work.receipts {                for _, l := range r.Logs {                    l.BlockHash = block.Hash()                }            }            for _, log := range work.state.Logs() {                log.BlockHash = block.Hash()            }            stat, err := self.chain.WriteBlockAndState(block, work.receipts, work.state)            if err != nil {                log.Error("Failed writing block to chain", "err", err)                continue            }            // check if canon block and write transactions            if stat == core.CanonStatTy { // 说明已经插入到规范的区块链                // implicit by posting ChainHeadEvent                // 因为这种状态下，会发送ChainHeadEvent，会触发上面的update里面的代码，这部分代码会commitNewWork，所以在这里就不需要commit了。                mustCommitNewWork = false            }                // Broadcast the block and announce chain insertion event            // 广播区块，并且申明区块链插入事件。            self.mux.Post(core.NewMinedBlockEvent{Block: block})            var (                events []interface{}                logs   = work.state.Logs()            )            events = append(events, core.ChainEvent{Block: block, Hash: block.Hash(), Logs: logs})            if stat == core.CanonStatTy {                events = append(events, core.ChainHeadEvent{Block: block})            }            self.chain.PostChainEvents(events, logs)            // Insert the block into the set of pending ones to wait for confirmations            // 插入本地跟踪列表， 查看后续的确认状态。            self.unconfirmed.Insert(block.NumberU64(), block.Hash())            if mustCommitNewWork { // TODO ?                 self.commitNewWork()            }        }    }}</code></pre><h2 id="miner"><a href="#miner" class="headerlink" title="miner"></a>miner</h2><p>miner用来对worker进行管理， 订阅外部事件，控制worker的启动和停止。</p><p>数据结构</p><pre><code>// Backend wraps all methods required for mining.type Backend interface {    AccountManager() *accounts.Manager    BlockChain() *core.BlockChain    TxPool() *core.TxPool    ChainDb() ethdb.Database}// Miner creates blocks and searches for proof-of-work values.type Miner struct {    mux *event.TypeMux    worker *worker    coinbase common.Address    mining   int32    eth      Backend    engine   consensus.Engine    canStart    int32 // can start indicates whether we can start the mining operation    shouldStart int32 // should start indicates whether we should start after sync}</code></pre><p>构造, 创建了一个CPU agent 启动了miner的update goroutine</p><pre><code>func New(eth Backend, config *params.ChainConfig, mux *event.TypeMux, engine consensus.Engine) *Miner {    miner := &amp;Miner{        eth:      eth,        mux:      mux,        engine:   engine,        worker:   newWorker(config, engine, common.Address{}, eth, mux),        canStart: 1,    }    miner.Register(NewCpuAgent(eth.BlockChain(), engine))    go miner.update()    return miner}</code></pre><p>update订阅了downloader的事件， 注意这个goroutine是一个一次性的循环， 只要接收到一次downloader的downloader.DoneEvent或者 downloader.FailedEvent事件， 就会设置canStart为1. 并退出循环， 这是为了避免黑客恶意的 DOS攻击，让你不断的处于异常状态</p><pre><code>// update keeps track of the downloader events. Please be aware that this is a one shot type of update loop.// It's entered once and as soon as `Done` or `Failed` has been broadcasted the events are unregistered and// the loop is exited. This to prevent a major security vuln where external parties can DOS you with blocks// and halt your mining operation for as long as the DOS continues.func (self *Miner) update() {    events := self.mux.Subscribe(downloader.StartEvent{}, downloader.DoneEvent{}, downloader.FailedEvent{})out:    for ev := range events.Chan() {        switch ev.Data.(type) {        case downloader.StartEvent:            atomic.StoreInt32(&amp;self.canStart, 0)            if self.Mining() {                self.Stop()                atomic.StoreInt32(&amp;self.shouldStart, 1)                log.Info("Mining aborted due to sync")            }        case downloader.DoneEvent, downloader.FailedEvent:            shouldStart := atomic.LoadInt32(&amp;self.shouldStart) == 1            atomic.StoreInt32(&amp;self.canStart, 1)            atomic.StoreInt32(&amp;self.shouldStart, 0)            if shouldStart {                self.Start(self.coinbase)            }            // unsubscribe. we're only interested in this event once            events.Unsubscribe()            // stop immediately and ignore all further pending events            break out        }    }}</code></pre><p>Start</p><pre><code>func (self *Miner) Start(coinbase common.Address) {    atomic.StoreInt32(&amp;self.shouldStart, 1)  // shouldStart 是是否应该启动    self.worker.setEtherbase(coinbase)             self.coinbase = coinbase    if atomic.LoadInt32(&amp;self.canStart) == 0 {  // canStart是否能够启动，        log.Info("Network syncing, will start miner afterwards")        return    }    atomic.StoreInt32(&amp;self.mining, 1)    log.Info("Starting mining operation")    self.worker.start()  // 启动worker 开始挖矿    self.worker.commitNewWork()  //提交新的挖矿任务。}</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>以太坊源码分析-RLP源码分析</title>
      <link href="/2021/04/14/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-RLP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
      <url>/2021/04/14/blockchain/ethereum/source_analysis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-RLP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="版本说明"><a href="#版本说明" class="headerlink" title="版本说明"></a>版本说明</h1><p>源码分析使用的版本为：<a href="https://github.com/ethereum/go-ethereum/tree/v1.10.3">v1.10.3</a></p><h1 id="RLP源码解析"><a href="#RLP源码解析" class="headerlink" title="RLP源码解析"></a>RLP源码解析</h1><h2 id="一、介绍RLP"><a href="#一、介绍RLP" class="headerlink" title="一、介绍RLP"></a>一、介绍RLP</h2><p>RLP是Recursive Length Prefix的简写。是以太坊中的序列化方法，以太坊的所有对象都会使用RLP方法序列化为字节数组。这里我希望先从黄皮书来形式化上了解RLP方法， 然后通过代码来分析实际的实现。<br>RLP把所有的数据看成两类数据的组合， 一类是字节数组， 一类是类似于List的数据结构。 我理解这两类基本包含了所有的数据结构。 比如用得比较多的struct。 可以看成是一个很多不同类型的字段组成的List</p><h2 id="二、分析RLP源文件"><a href="#二、分析RLP源文件" class="headerlink" title="二、分析RLP源文件"></a>二、分析RLP源文件</h2><p><img src="https://img-blog.csdnimg.cn/20210612115632564.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>RLP的源码不是很多：</p><pre><code>decode.go            解码器，把RLP数据解码为go的数据结构decode_tail_test.go        解码器测试代码decode_test.go            解码器测试代码    doc.go                文档代码encode.go            编码器，把GO的数据结构序列化为字节数组encode_test.go            编码器测试encode_example_test.goraw.go                未解码的RLP数据raw_test.gosafe.go     并未使用typecache.go            类型缓存， 类型缓存记录了类型-&gt;(编码器|解码器)的内容unsafe.go</code></pre><h3 id="1-根据类型找到对应的编码器和解码器：typecache-go"><a href="#1-根据类型找到对应的编码器和解码器：typecache-go" class="headerlink" title="1.  根据类型找到对应的编码器和解码器：typecache.go"></a>1.  根据类型找到对应的编码器和解码器：typecache.go</h3><p>在C++或者Java等支持重载的语言中， 可以通过不同的类型重载同一个函数名称来实现方法针对不同类型的分派,比如， 也可以通过泛型来实现函数的分派。但是GO语言本身不支持重载， 也没有泛型，所以函数的分派就需要自己实现了。 typecache.go主要是实现这个目的， 通过自身的类型来快速的找到自己的编码器函数和解码器函数。</p><p>我们首先看看核心数据结构</p><pre><code class="go">type typeCache struct {    cur atomic.Value    // This lock synchronizes writers.    mu   sync.Mutex    next map[typekey]*typeinfo}// typekey is the key of a type in typeCache. It includes the struct tags because// they might generate a different decoder.type typekey struct {    reflect.Type    tags}//存储了编码器和解码器函数// typeinfo is an entry in the type cache.type typeinfo struct {    decoder    decoder    decoderErr error // error from makeDecoder    writer     writer    writerErr  error // error from makeWriter}</code></pre><p>核心数据结构就是typeCache这个Map， Map的key是类型，value是对应的编码和解码器。</p><p>下面是用户如何获取编码器和解码器的函数</p><pre><code class="go">// 解码函数func cachedDecoder(typ reflect.Type) (decoder, error) {    info := theTC.info(typ)    return info.decoder, info.decoderErr}// 编码函数func cachedWriter(typ reflect.Type) (writer, error) {    info := theTC.info(typ)    return info.writer, info.writerErr}func (c *typeCache) info(typ reflect.Type) *typeinfo {    key := typekey{Type: typ}    if info := c.cur.Load().(map[typekey]*typeinfo)[key]; info != nil {        return info    }    // Not in the cache, need to generate info for this type.    return c.generate(typ, tags{})}func (c *typeCache) generate(typ reflect.Type, tags tags) *typeinfo {    c.mu.Lock()    defer c.mu.Unlock()    cur := c.cur.Load().(map[typekey]*typeinfo)    if info := cur[typekey{typ, tags}]; info != nil {        return info    }    // Copy cur to next.    c.next = make(map[typekey]*typeinfo, len(cur)+1)    for k, v := range cur {        c.next[k] = v    }    // Generate.    info := c.infoWhileGenerating(typ, tags)    // next -&gt; cur    c.cur.Store(c.next)    c.next = nil    return info}func (c *typeCache) infoWhileGenerating(typ reflect.Type, tags tags) *typeinfo {    key := typekey{typ, tags}    if info := c.next[key]; info != nil {        return info    }    // Put a dummy value into the cache before generating.    // If the generator tries to lookup itself, it will get    // the dummy value and won't call itself recursively.    info := new(typeinfo)    c.next[key] = info    info.generate(typ, tags)    return info}</code></pre><p>对于结构体类型的处理还是挺有意思的，而且这部分详细的处理逻辑在黄皮书上面也是找不到的。</p><pre><code class="go">type field struct {    index    int    info     *typeinfo    optional bool}// structFields resolves the typeinfo of all public fields in a struct type.func structFields(typ reflect.Type) (fields []field, err error) {    var (        lastPublic  = lastPublicField(typ)        anyOptional = false    )    for i := 0; i &lt; typ.NumField(); i++ {        if f := typ.Field(i); f.PkgPath == "" { // exported            tags, err := parseStructTag(typ, i, lastPublic)            if err != nil {                return nil, err            }            // Skip rlp:"-" fields.            if tags.ignored {                continue            }            // If any field has the "optional" tag, subsequent fields must also have it.            if tags.optional || tags.tail {                anyOptional = true            } else if anyOptional {                return nil, fmt.Errorf(`rlp: struct field %v.%s needs "optional" tag`, typ, f.Name)            }            info := theTC.infoWhileGenerating(f.Type, tags)            fields = append(fields, field{i, info, tags.optional})        }    }    return fields, nil}// anyOptionalFields returns the index of the first field with "optional" tag.func firstOptionalField(fields []field) int {    for i, f := range fields {        if f.optional {            return i        }    }    return len(fields)}</code></pre><h3 id="2-编码器：encode-go"><a href="#2-编码器：encode-go" class="headerlink" title="2. 编码器：encode.go"></a>2. 编码器：encode.go</h3><p>首先定义了空字符串和空List的值，分别是 0x80和0xC0。 注意，整形的0值的对应值也是0x80。这个在黄皮书上面是没有看到有定义的。 然后定义了一个接口类型给别的类型实现 EncodeRLP</p><pre><code class="go">var (    // Common encoded values.    // These are useful when implementing EncodeRLP.    EmptyString = []byte{0x80}    EmptyList   = []byte{0xC0})// Encoder is implemented by types that require custom// encoding rules or want to encode private fields.type Encoder interface {    // EncodeRLP should write the RLP encoding of its receiver to w.    // If the implementation is a pointer method, it may also be    // called for nil pointers.    //    // Implementations should generate valid RLP. The data written is    // not verified at the moment, but a future version might. It is    // recommended to write only a single value but writing multiple    // values or no value at all is also permitted.    EncodeRLP(io.Writer) error}</code></pre><p>然后定义了一个最重要的方法， 大部分的EncodeRLP方法都是直接调用了这个方法Encode方法。这个方法首先获取了一个encbuf对象。 然后调用这个对象的encode方法。encode方法中，首先获取了对象的反射类型，根据反射类型获取它的编码器，然后调用编码器的writer方法。 这个就跟上面谈到的typecache联系到一起了。</p><pre><code class="go">func Encode(w io.Writer, val interface{}) error {    if outer, ok := w.(*encbuf); ok {        // Encode was called by some type's EncodeRLP.        // Avoid copying by writing to the outer encbuf directly.        return outer.encode(val)    }    eb := encbufPool.Get().(*encbuf)    defer encbufPool.Put(eb)    eb.reset()    if err := eb.encode(val); err != nil {        return err    }    return eb.toWriter(w)}func (w *encbuf) encode(val interface{}) error {    rval := reflect.ValueOf(val)    ti, err := cachedTypeInfo(rval.Type(), tags{})    if err != nil {        return err    }    return ti.writer(rval, w)}</code></pre><p>encbuf的介绍<br>encbuf是encode buffer的简写(我猜的)。encbuf出现在Encode方法，和很多Writer方法中。顾名思义，这个是在encode的过程中充当buffer的作用。下面先看看encbuf的定义。</p><pre><code class="go">type encbuf struct {    str     []byte      // string data, contains everything except list headers    lheads  []*listhead // all list headers    lhsize  int         // sum of sizes of all encoded list headers    sizebuf []byte      // 9-byte auxiliary buffer for uint encoding}type listhead struct {    offset int // index of this header in string data    size   int // total size of encoded data (including list headers)}</code></pre><p>从注释可以看到， str字段包含了所有的内容，除了列表的头部。 列表的头部记录在lheads字段中。 lhsize字段记录了lheads的长度， sizebuf是9个字节大小的辅助buffer，专门用来处理uint的编码的。 listhead由两个字段组成， offset字段记录了列表数据在str字段的哪个位置， size字段记录了包含列表头的编码后的数据的总长度。可以看到下面的图。</p><p><img src="https://img-blog.csdnimg.cn/20210614111346666.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70"></p><p>对于普通的类型，比如字符串，整形，bool型等数据，就是直接往str字段里面填充就行了。 但是对于结构体类型的处理， 就需要特殊的处理方式了。可以看看上面提到过的makeStructWriter方法。</p><pre><code class="go">func makeStructWriter(typ reflect.Type) (writer, error) {        fields, err := structFields(typ)        if err != nil {        return nil, err    }    for _, f := range fields {        if f.info.writerErr != nil {            return nil, structFieldError{typ, f.index, f.info.writerErr}        }    }    var writer writer    firstOptionalField := firstOptionalField(fields)    if firstOptionalField == len(fields) {        // This is the writer function for structs without any optional fields.        writer = func(val reflect.Value, w *encbuf) error {            lh := w.list()            for _, f := range fields {                if err := f.info.writer(val.Field(f.index), w); err != nil {                    return err                }            }            w.listEnd(lh)            return nil        }    } else {        // If there are any "optional" fields, the writer needs to perform additional        // checks to determine the output list length.        writer = func(val reflect.Value, w *encbuf) error {            lastField := len(fields) - 1            for ; lastField &gt;= firstOptionalField; lastField-- {                if !val.Field(fields[lastField].index).IsZero() {                    break                }            }            lh := w.list()            for i := 0; i &lt;= lastField; i++ {                if err := fields[i].info.writer(val.Field(fields[i].index), w); err != nil {                    return err                }            }            w.listEnd(lh)            return nil        }    }    return writer, nil}</code></pre><p>可以看到上面的代码中体现了处理结构体数据的特殊处理方法，就是首先调用w.list()方法，处理完毕之后再调用listEnd(lh)方法。 采用这种方式的原因是我们在刚开始处理结构体的时候，并不知道处理后的结构体的长度有多长，因为需要根据结构体的长度来决定头的处理方式(回忆一下黄皮书里面结构体的处理方式)，所以我们在处理前记录好str的位置，然后开始处理每个字段，处理完之后在看一下str的数据增加了多少就知道处理后的结构体长度有多长了。</p><pre><code class="go">// list adds a new list header to the header stack. It returns the index// of the header. The caller must call listEnd with this index after encoding// the content of the list.func (w *encbuf) list() int {    w.lheads = append(w.lheads, listhead{offset: len(w.str), size: w.lhsize})    return len(w.lheads) - 1}func (w *encbuf) listEnd(index int) {    lh := &amp;w.lheads[index]    lh.size = w.size() - lh.offset - lh.size    if lh.size &lt; 56 {        w.lhsize++ // length encoded into kind tag    } else {        w.lhsize += 1 + intsize(uint64(lh.size))    }}func (w *encbuf) size() int {    return len(w.str) + w.lhsize}</code></pre><p>然后我们可以看看encbuf最后的处理逻辑，会对listhead进行处理，组装成完整的RLP数据</p><pre><code class="go">func (w *encbuf) toBytes() []byte {    out := make([]byte, w.size())    strpos := 0    pos := 0    for _, head := range w.lheads {        // write string data before header        n := copy(out[pos:], w.str[strpos:head.offset])        pos += n        strpos += n        // write the header        enc := head.encode(out[pos:])        pos += len(enc)    }    // copy string data after the last list header    copy(out[pos:], w.str[strpos:])    return out}</code></pre><p>writer介绍<br>剩下的流程其实比较简单了。 就是根据黄皮书针把每种不同的数据填充到encbuf里面去。</p><pre><code class="go">func writeBool(val reflect.Value, w *encbuf) error {    if val.Bool() {        w.str = append(w.str, 0x01)    } else {        w.str = append(w.str, 0x80)    }    return nil}func writeString(val reflect.Value, w *encbuf) error {    s := val.String()    if len(s) == 1 &amp;&amp; s[0] &lt;= 0x7f {        // fits single byte, no string header        w.str = append(w.str, s[0])    } else {        w.encodeStringHeader(len(s))        w.str = append(w.str, s...)    }    return nil}</code></pre><h3 id="3-解码器：decode-go"><a href="#3-解码器：decode-go" class="headerlink" title="3. 解码器：decode.go"></a>3. 解码器：decode.go</h3><p>解码器的大致流程和编码器差不多，理解了编码器的大致流程，也就知道了解码器的大致流程。</p><pre><code class="go">// Decode decodes a value and stores the result in the value pointed// to by val. Please see the documentation for the Decode function// to learn about the decoding rules.func (s *Stream) Decode(val interface{}) error {    if val == nil {        return errDecodeIntoNil    }    rval := reflect.ValueOf(val)    rtyp := rval.Type()    if rtyp.Kind() != reflect.Ptr {        return errNoPointer    }    if rval.IsNil() {        return errDecodeIntoNil    }    decoder, err := cachedDecoder(rtyp.Elem())    if err != nil {        return err    }    err = decoder(s, rval.Elem())    if decErr, ok := err.(*decodeError); ok &amp;&amp; len(decErr.ctx) &gt; 0 {        // Add decode target type to error so context has more meaning.        decErr.ctx = append(decErr.ctx, fmt.Sprint("(", rtyp.Elem(), ")"))    }    return err}func cachedDecoder(typ reflect.Type) (decoder, error) {    info := theTC.info(typ)    return info.decoder, info.decoderErr}func makeDecoder(typ reflect.Type, tags tags) (dec decoder, err error) {    kind := typ.Kind()    switch {    case typ == rawValueType:        return decodeRawValue, nil    case typ.AssignableTo(reflect.PtrTo(bigInt)):        return decodeBigInt, nil    case typ.AssignableTo(bigInt):        return decodeBigIntNoPtr, nil    case kind == reflect.Ptr:        return makePtrDecoder(typ, tags)    case reflect.PtrTo(typ).Implements(decoderInterface):        return decodeDecoder, nil    case isUint(kind):        return decodeUint, nil    case kind == reflect.Bool:        return decodeBool, nil    case kind == reflect.String:        return decodeString, nil    case kind == reflect.Slice || kind == reflect.Array:        return makeListDecoder(typ, tags)    case kind == reflect.Struct:        return makeStructDecoder(typ)    case kind == reflect.Interface:        return decodeInterface, nil    default:        return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ)    }}</code></pre><p>我们同样通过结构体类型的解码过程来查看具体的解码过程。跟编码过程差不多，首先通过structFields获取需要解码的所有字段，然后每个字段进行解码。 跟编码过程差不多有一个List()和ListEnd()的操作，不过这里的处理流程和编码过程不一样，后续章节会详细介绍。</p><pre><code class="go">func makeStructDecoder(typ reflect.Type) (decoder, error) {    fields, err := structFields(typ)    if err != nil {        return nil, err    }    for _, f := range fields {        if f.info.decoderErr != nil {            return nil, structFieldError{typ, f.index, f.info.decoderErr}        }    }    dec := func(s *Stream, val reflect.Value) (err error) {        if _, err := s.List(); err != nil {            return wrapStreamError(err, typ)        }        for i, f := range fields {            err := f.info.decoder(s, val.Field(f.index))            if err == EOL {                if f.optional {                    // The field is optional, so reaching the end of the list before                    // reaching the last field is acceptable. All remaining undecoded                    // fields are zeroed.                    zeroFields(val, fields[i:])                    break                }                return &amp;decodeError{msg: "too few elements", typ: typ}            } else if err != nil {                return addErrorContext(err, "."+typ.Field(f.index).Name)            }        }        return wrapStreamError(s.ListEnd(), typ)    }    return dec, nil}</code></pre><p>下面在看字符串的解码过程，因为不同长度的字符串有不同方式的编码，我们可以通过前缀的不同来获取字符串的类型， 这里我们通过s.Kind()方法获取当前需要解析的类型和长度，如果是Byte类型，那么直接返回Byte的值， 如果是String类型那么读取指定长度的值然后返回。 这就是kind()方法的用途。</p><pre><code class="go">// Bytes reads an RLP string and returns its contents as a byte slice.// If the input does not contain an RLP string, the returned// error will be ErrExpectedString.func (s *Stream) Bytes() ([]byte, error) {    kind, size, err := s.Kind()    if err != nil {        return nil, err    }    switch kind {    case Byte:        s.kind = -1 // rearm Kind        return []byte{s.byteval}, nil    case String:        b := make([]byte, size)        if err = s.readFull(b); err != nil {            return nil, err        }        if size == 1 &amp;&amp; b[0] &lt; 128 {            return nil, ErrCanonSize        }        return b, nil    default:        return nil, ErrExpectedString    }}</code></pre><h3 id="4-Stream-结构分析"><a href="#4-Stream-结构分析" class="headerlink" title="4. Stream 结构分析"></a>4. Stream 结构分析</h3><p>解码器的其他代码和编码器的结构差不多， 但是有一个特殊的结构是编码器里面没有的。那就是Stream。 这个是用来读取用流式的方式来解码RLP的一个辅助类。 前面我们讲到了大致的解码流程就是首先通过Kind()方法获取需要解码的对象的类型和长度,然后根据长度和类型进行数据的解码。 那么我们如何处理结构体的字段又是结构体的数据呢， 回忆我们对结构体进行处理的时候，首先调用s.List()方法，然后对每个字段进行解码，最后调用s.EndList()方法。 技巧就在这两个方法里面， 下面我们看看这两个方法。</p><pre><code class="go">// Stream can be used for piecemeal decoding of an input stream. This// is useful if the input is very large or if the decoding rules for a// type depend on the input structure. Stream does not keep an// internal buffer. After decoding a value, the input reader will be// positioned just before the type information for the next value.//// When decoding a list and the input position reaches the declared// length of the list, all operations will return error EOL.// The end of the list must be acknowledged using ListEnd to continue// reading the enclosing list.//// Stream is not safe for concurrent use.type Stream struct {    r ByteReader    remaining uint64   // number of bytes remaining to be read from r    size      uint64   // size of value ahead    kinderr   error    // error from last readKind    stack     []uint64 // list sizes    uintbuf   [8]byte  // auxiliary buffer for integer decoding    kind      Kind     // kind of value ahead    byteval   byte     // value of single byte in type tag    limited   bool     // true if input limit is in effect}</code></pre><p>Stream的List方法，当调用List方法的时候。我们先调用Kind方法获取类型和长度，如果类型不匹配那么就抛出错误，然后我们把一个listpos对象压入到堆栈，这个对象是关键。 这个对象的pos字段记录了当前这个list已经读取了多少字节的数据， 所以刚开始的时候肯定是0. size字段记录了这个list对象一共需要读取多少字节数据。这样我在处理后续的每一个字段的时候，每读取一些字节，就会增加pos这个字段的值，处理到最后会对比pos字段和size字段是否相等，如果不相等，那么会抛出异常。</p><pre><code class="go">// List starts decoding an RLP list. If the input does not contain a// list, the returned error will be ErrExpectedList. When the list's// end has been reached, any Stream operation will return EOL.func (s *Stream) List() (size uint64, err error) {    kind, size, err := s.Kind()    if err != nil {        return 0, err    }    if kind != List {        return 0, ErrExpectedList    }    // Remove size of inner list from outer list before pushing the new size    // onto the stack. This ensures that the remaining outer list size will    // be correct after the matching call to ListEnd.    if inList, limit := s.listLimit(); inList {        s.stack[len(s.stack)-1] = limit - size    }    s.stack = append(s.stack, size)    s.kind = -1    s.size = 0    return size, nil}</code></pre><p>Stream的ListEnd方法，如果当前读取的数据数量pos不等于声明的数据长度size，抛出异常，然后对堆栈进行pop操作，如果当前堆栈不为空，那么就在堆栈的栈顶的pos加上当前处理完毕的数据长度(用来处理这种情况–结构体的字段又是结构体， 这种递归的结构)</p><pre><code class="go">// ListEnd returns to the enclosing list.// The input reader must be positioned at the end of a list.func (s *Stream) ListEnd() error {    // Ensure that no more data is remaining in the current list.    if inList, listLimit := s.listLimit(); !inList {        return errNotInList    } else if listLimit &gt; 0 {        return errNotAtEOL    }    s.stack = s.stack[:len(s.stack)-1] // pop    s.kind = -1    s.size = 0    return nil}</code></pre><h1 id="参考资料地址"><a href="#参考资料地址" class="headerlink" title="参考资料地址"></a>参考资料地址</h1><ul><li><a href="https://ethereum.org/en/whitepaper">以太坊白皮书</a></li><li><a href="https://ethereum.github.io/yellowpaper/paper.pdf">以太坊黄皮书（英文版）</a></li><li><a href="https://github.com/wanshan1024/ethereum_yellowpaper/blob/master/ethereum_yellow_paper_cn.pdf">以太坊黄皮书（中文版）</a></li><li><a href="https://github.com/ZtesoftCS/go-ethereum-code-analysis">分析参考资料</a></li><li><a href="https://segmentfault.com/a/1190000016050921">博客参考资料</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Ethereum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu安装Redis</title>
      <link href="/1900/01/01/other/Ubuntu%E5%AE%89%E8%A3%85Redis/"/>
      <url>/1900/01/01/other/Ubuntu%E5%AE%89%E8%A3%85Redis/</url>
      
        <content type="html"><![CDATA[<h1 id="Ubuntu安装Redis"><a href="#Ubuntu安装Redis" class="headerlink" title="Ubuntu安装Redis"></a>Ubuntu安装Redis</h1><h2 id="一、前提条件"><a href="#一、前提条件" class="headerlink" title="一、前提条件"></a>一、前提条件</h2><p>需要连接互联网，然后执行sudo apt-get update更新软件包</p><h2 id="二、执行安装命令"><a href="#二、执行安装命令" class="headerlink" title="二、执行安装命令"></a>二、执行安装命令</h2><p>sudo  apt-get install redis-server 执行后如下图所示，我们输入y 确认安装并使用空间</p><p><img src="https://img-blog.csdnimg.cn/20200809101003516.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>接下来会执行完成，我们可以看到包括redis的版本信息等，执行service  redis status 可以查看redis服务的状态为running，说明安装完成系统自动启动了服务<br><img src="https://img-blog.csdnimg.cn/2020080910101782.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="三、配置redis服务"><a href="#三、配置redis服务" class="headerlink" title="三、配置redis服务"></a>三、配置redis服务</h2><p>3.1：开启远程连接<br>找到/etc/redis/redis.conf文件修改如下:</p><p>注释掉  127.0.0.1   #bind 127.0.0.1，如果不需要远程连接redis则不需要这个操作<br><img src="https://img-blog.csdnimg.cn/20200809101128860.png" alt="在这里插入图片描述"></p><p>3.2：设置密码<br>找到/etc/redis/redis.conf文件修改如下:</p><p>添加  requirepass kingredis（密码设置为kingredis）</p><p><img src="https://img-blog.csdnimg.cn/20200809101317268.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MjU0Njk5,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="四、测试redis服务（可选）"><a href="#四、测试redis服务（可选）" class="headerlink" title="四、测试redis服务（可选）"></a>四、测试redis服务（可选）</h2><p>步骤三的操作完成后，重启redis服务</p><pre><code>$ redis-server       # 启动服务$ redis-cli          # 启动客户端$ redis-cli shutdown # 关闭服务</code></pre><p>如果出现以上命令无法关闭redis-server的情况下解决办法如下：</p><p>使用以下命令启动重启和关闭</p><p>$ /etc/init.d/redis-server stop     # 停止<br>$ /etc/init.d/redis-server start    # 启动<br>$ /etc/init.d/redis-server restart  # 重启<br>我的安装情况是默认安装后保护模式和后台启动模式均为开启状态，根据需要配置为关闭。<br>查看下面的简单配置。<br><img src="https://img-blog.csdnimg.cn/20200809103047400.png" alt="在这里插入图片描述"></p><p>4.1：测试密码设置成功</p><p>执行redis-cli命令打开redis客户端  set操作    的时候要求输入密码，说明密码设置成功，执行auth 密码验证密码后，可以执行set操作<br>auth 你的密码</p><p>4.2：测试远程登录</p><p>使用Redis连接工具进行远程连接，例如使用RedisInsight(<a href="https://redis.com/redis-enterprise/redis-insight">点我下载</a>)</p>]]></content>
      
      
      
        <tags>
            
            <tag> 部署文档 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker操作Fabric常用命令</title>
      <link href="/1900/01/01/blockchain/fabric/Docker%E6%93%8D%E4%BD%9CFabric%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/1900/01/01/blockchain/fabric/Docker%E6%93%8D%E4%BD%9CFabric%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Enter password to read.">    <label for="pass">Enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 部署文档 </tag>
            
            <tag> Fabric </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于区块链的档案分发系统介绍</title>
      <link href="/1900/01/01/blockchain/fabric/%E5%9F%BA%E4%BA%8E%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9A%84%E6%A1%A3%E6%A1%88%E5%88%86%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"/>
      <url>/1900/01/01/blockchain/fabric/%E5%9F%BA%E4%BA%8E%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9A%84%E6%A1%A3%E6%A1%88%E5%88%86%E5%8F%91%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>推荐使用云服务器:</strong><br><a href="https://curl.qcloud.com/uAWpwwiE">【腾讯云】轻量新用户上云福利，2核2G4M 低至 50 元/年 起， 抓住上云好时机！</a></p></blockquote><blockquote><p><strong>解决问题步骤:</strong><br>遇到问题请先看文章最后的常见问题以及评论区<br>无法解决可以先百度/谷歌尝试解决<br>依旧无法解决可以将问题集中汇总联系我，并在最后通过评论方式记录到对应文章以便他人查看</p></blockquote><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>有很多同学也需要搭建这个系统希望我能帮他们搭建，但是我确实太忙了（打工人的无奈），所以只能抛砖引玉尽我所能提供思路吧。</p><p>这篇博客是我对”基于区块链的档案分发管理系统”项目的总结：</p><p>“基于区块链的档案分发管理系统“演示视频：<a href="https://www.bilibili.com/video/bv13y4y137kF">https://www.bilibili.com/video/bv13y4y137kF</a></p><p>Fabric区块链环境问题、代码启动报错问题我可以提供帮助，其他的SpringBoot相关问题、代码改造问题、智能合约编写问题等请百度或查看我赠送的视频课程。</p><h2 id="二、原理和涉及技术点"><a href="#二、原理和涉及技术点" class="headerlink" title="二、原理和涉及技术点"></a>二、原理和涉及技术点</h2><h3 id="1-原理"><a href="#1-原理" class="headerlink" title="1. 原理"></a>1. 原理</h3><p>三层架构：</p><ul><li>区块链网络：存放数据，使用Fabric搭建。所以在运行过程中需要保证虚拟机中的Fabric网络一直启动</li><li>缓存层：Redis，将常用的数据存于Redis，以此加快查询速度</li><li>DAPP：使用Java开发，前后端使用技术为SpringBoot、Thymeleaf、<a href="https://startbootstrap.com/theme/sb-admin-2">SB-Admin2</a> ,在Java代码中通过FabricSDK与Fabric网络进行交互（触发链码等）</li></ul><h3 id="2-技术点"><a href="#2-技术点" class="headerlink" title="2. 技术点"></a>2. 技术点</h3><ul><li>【必须】Linux：搭建Fabric网络需要使用Linux命令</li><li>【非必须】JavaWeb、SpringBoot、Thymeleaf、HTML、CSS、JS：如果不需要修改代码那么只需要了解SpringBoot启动方式即可，需要修改代码最好熟悉这些</li><li>【非必须】Go：Fabric的智能合约运行在容器中，可以使用Go、Java、Node.js语言开发。如果需要重新开发合约需要会用Go，简单看看教程就可以</li><li>【非必须】区块链基础、Fabric</li><li>【非必须】Docker：Fabric网络在Docker中运行</li><li>【非必须】Redis：搭建起来即可</li></ul><p>说明：以上技术并不是要求都掌握，只是说掌握的越好做起来可能越容易。</p><h2 id="三、环境介绍"><a href="#三、环境介绍" class="headerlink" title="三、环境介绍"></a>三、环境介绍</h2><h3 id="1-硬件环境"><a href="#1-硬件环境" class="headerlink" title="1. 硬件环境"></a>1. 硬件环境</h3><ul><li>Ubuntu16.04服务器（版本要求不必须，18.04、20.04亦可）</li></ul><h3 id="2-软件环境"><a href="#2-软件环境" class="headerlink" title="2. 软件环境"></a>2. 软件环境</h3><ul><li>Fabric：Fabric<font color="red"><strong>1.4.0</strong></font>作为区块链框架</li><li>Java：运行SpringBoot项目</li><li>Maven：项目使用Maven仓库</li><li>Redis、Redis Desktop Manager</li><li>XShell：与Ubuntu连接使用</li><li>XFTP：与Ubuntu传输文件使用</li><li>IntelliJ IDEA：代码编辑器</li></ul><h2 id="四、环境搭建步骤和程序使用方式"><a href="#四、环境搭建步骤和程序使用方式" class="headerlink" title="四、环境搭建步骤和程序使用方式"></a>四、环境搭建步骤和程序使用方式</h2><p><font color="red"><strong>在进行此步骤之前最好先看视频课程</strong></font></p><h3 id="1-Ubuntu上准备基础环境"><a href="#1-Ubuntu上准备基础环境" class="headerlink" title="1. Ubuntu上准备基础环境"></a>1. Ubuntu上准备基础环境</h3><ul><li>Ubuntu系统：安装VMware虚拟机和Ubuntu16.04 64位系统（或18.04、20.04）</li><li>Fabric网络：搭建Fabric单机并运行启动（重难点，多机部署更合适，因为区块链不该是一个节点，作为学习一个节点够了）。参考博客：<a href="/1900/01/01/blockchain/fabric/%E9%83%A8%E7%BD%B2Fabric-v1-4-0%E2%80%94%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2/" title="搭建Fabric环境并启动">搭建Fabric环境并启动</a></li><li>Redis环境：搭建过程参考博客：<a href="/1900/01/01/other/Ubuntu%E5%AE%89%E8%A3%85Redis/" title="Ubuntu安装Redis">Ubuntu安装Redis</a></li></ul><h3 id="2-代码运行机器上准备开发环境"><a href="#2-代码运行机器上准备开发环境" class="headerlink" title="2. 代码运行机器上准备开发环境"></a>2. 代码运行机器上准备开发环境</h3><ul><li>IntelliJ IDEA：运行代码的编辑器</li><li>XShell：远程连接Ubuntu</li><li>XFTP：与Ubuntu进行文件传输</li><li>Java环境：在运行代码的机器上安装JDK<font color="red"><strong>1.8</strong></font></li><li>Maven环境：在运行代码的机器上安装Maven，同时<font color="red">配置使用国内源</font></li></ul><h3 id="3-启动程序"><a href="#3-启动程序" class="headerlink" title="3. 启动程序"></a>3. 启动程序</h3><p>i) 准备证书文件</p><p><font color="red">使用root用户</font>将区块链服务器上的证书文件copy到本地项目中以便使用：<br>从<code>/home/ubuntu/gopath/src/github.com/hyperledger/fabric-samples/first-network/crypto-config</code><br>复制到：<code>src/main/resources/file/fabric/crypto-config</code>目录</p><p>ii) 配置host</p><p>修改代码所在机器（不是Fabric所在机器）的host映射区块链网络的域名example.com</p><pre><code class="bash"># 192.168.31.131 为搭建区块链的服务器的地址，需要根据实际情况修改192.168.31.131      orderer.example.com peer0.org1.example.com peer1.org1.example.com peer0.org2.example.com peer1.org2.example.com</code></pre><p>iii) 检查Redis状态</p><p>执行service redis status 可以查看redis服务的状态为running，说明安装完成系统自动启动了服务。否则执行命令<code>/etc/init.d/redis-server start</code></p><p>iv) 修改Java配置文件</p><ul><li>按着注释修改文件：</li></ul><p><code>src/main/java/com/springboot/config/PathConf.java</code>的<code>org1KeyFileName</code>和<code>org2KeyFileName</code></p><ul><li>修改<code>src/main/resources/application.yml</code>文件中的TODO注释部分（redis账号和密码）</li></ul><p>v) 启动代码</p><p>这里提前看一下SpringBoot+Maven项目如何启动，求求项目启动问题就别再问我了～</p><ul><li>打开ys-file-manage文件夹，项目结构：</li></ul><p><img src="/../images/fabric/image-20220320144055288.png" alt="image-20220320144055288"></p><ul><li><p>将pom.xml添加到maven项目然后点击刷新按钮导入依赖包（如果已操作忽略该步骤）</p><p><img src="/../images/fabric/image-20220320144304432.png" alt="image-20220320144304432"></p><p><img src="/../images/fabric/image-20220320144719203.png" alt="image-20220320144719203"></p></li><li><p>运行<code>src/main/java/com/springboot/SpringBootFileManageApplication.java</code>代码启动服务</p></li></ul><p><img src="/../images/fabric/springboot-startup.png" alt="image-20220317172522948"></p><p>vi) 安装、实例化链码</p><p>如果修改了智能合约不可使用此方式部署，请使用命令行方式：<a href="/1900/01/01/blockchain/fabric/Docker%E6%93%8D%E4%BD%9CFabric%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" title="Docker操作Fabric常用命令">Docker操作Fabric常用命令</a></p><p>链接：<a href="http://localhost:8089/FileManage/admin/chaincodeView">http://localhost:8089/FileManage/admin/chaincodeView</a></p><p><img src="/../images/fabric/image-20220328192236825.png" alt="image-20220328192236825"></p><p>依次输入链码名和链码版本，然后依次点击安装合约、实例化合约等待弹窗返回提示结果</p><p>vii) 注册系统管理员</p><p>链接：<a href="http://localhost:8089/FileManage/admin/insertAdminInfoView">http://localhost:8089/FileManage/admin/insertAdminInfoView</a></p><p>注册成功后会返回登陆ID，使用此ID作为用户名，设置的密码作为登陆密码进行登录</p><p>提示：代码健壮性不强，所以最好所有输入框都要输入内容，否则可能会有想不到的bug</p><p>档案管理员登录地址：<a href="http://localhost:8089/FileManage/admin/adminLoginView">http://localhost:8089/FileManage/admin/adminLoginView</a></p><h2 id="五、部分代码介绍"><a href="#五、部分代码介绍" class="headerlink" title="五、部分代码介绍"></a>五、部分代码介绍</h2><h3 id="1-使用Fabric-Java-SDK连接区块链"><a href="#1-使用Fabric-Java-SDK连接区块链" class="headerlink" title="1. 使用Fabric-Java SDK连接区块链"></a>1. 使用Fabric-Java SDK连接区块链</h3><p>参考博客：<a href="/1900/01/01/blockchain/fabric/%E5%8C%BA%E5%9D%97%E9%93%BEFabric-sdk-java%E7%9A%84%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4/" title="如何使用SDK连接区块链网络">如何使用SDK连接区块链网络</a> </p><p>参考代码：<a href="https://gitee.com/hbuzzs/FabricSDK/tree/master">Fabric-Java SDK代码</a></p><h3 id="2-编写并部署智能合约"><a href="#2-编写并部署智能合约" class="headerlink" title="2. 编写并部署智能合约"></a>2. 编写并部署智能合约</h3><p>Go开发智能合约：<a href="https://gitee.com/hbuzzs/FileManageChainCode">智能合约代码</a></p><h2 id="六、常见问题"><a href="#六、常见问题" class="headerlink" title="六、常见问题"></a>六、常见问题</h2><h3 id="1-注意要创建超级管理员账号，否则无法登陆"><a href="#1-注意要创建超级管理员账号，否则无法登陆" class="headerlink" title="1. 注意要创建超级管理员账号，否则无法登陆"></a>1. 注意要创建超级管理员账号，否则无法登陆</h3><p>注册系统管理员（超级管理员）链接：<a href="http://localhost:8089/FileManage/admin/insertAdminInfoView">http://localhost:8089/FileManage/admin/insertAdminInfoView</a></p><h3 id="2-使用XShell或XFTP连接Ubuntu失败"><a href="#2-使用XShell或XFTP连接Ubuntu失败" class="headerlink" title="2. 使用XShell或XFTP连接Ubuntu失败"></a>2. 使用XShell或XFTP连接Ubuntu失败</h3><p>可能原因：</p><ul><li>远程连接IP错误</li><li>远程连接密码错误</li><li>远程连接端口错误，应使用22</li><li>Ubuntu上没有安装SSH服务<pre><code class="shell"># 首先在服务器上安装ssh的服务器端sudo apt-get install openssh-server# 启动ssh-server/etc/init.d/ssh restart# 确认ssh-server已经正常工作netstat -tlp# 看到 tcp6 0 0 *:ssh *:* LISTEN - 输出说明ssh-server已经在运行了</code></pre></li><li>Ubuntu没有允许登录用户远程登录（例如未允许root远程登录）<pre><code class="shell"># 编辑/etc/ssh/sshd_config文件；sudo vim /etc/ssh/sshd_config# 找到配置参数：PermitRootLogin 将该参数后面的值修改为yes即可；# 按“esc键” :wq  回车，  保存退出；# 给root用户设置密码；sudo passwd root# 输入两遍密码；（给root用户设置了密码后，就已经可以使用root用户登陆到系统中了）# 重启ssh服务sudo  systemctl  restart  ssh</code></pre></li></ul><h3 id="3-提示证书认证失败"><a href="#3-提示证书认证失败" class="headerlink" title="3. 提示证书认证失败"></a>3. 提示证书认证失败</h3><p>检查Fabric中的证书文件和代码中的证书文件是否一致</p><h3 id="4-Redis连接异常"><a href="#4-Redis连接异常" class="headerlink" title="4. Redis连接异常"></a>4. Redis连接异常</h3><p><img src="/../images/fabric/image-20220328191741714.png" alt="image-20220328191741714"></p><p>可能原因：</p><ul><li>代码所在机器是否不可以连接到Redis（可以ping命令测试）</li><li>代码配置文件中的Redis的IP和密码不正确</li><li>Redis没有开启远程连接（搭建Redis博客中有相关介绍）</li><li>Redis没有设置密码</li></ul><h3 id="5-使用XFTP拷贝文件不完整，缺少密钥文件"><a href="#5-使用XFTP拷贝文件不完整，缺少密钥文件" class="headerlink" title="5. 使用XFTP拷贝文件不完整，缺少密钥文件"></a>5. 使用XFTP拷贝文件不完整，缺少密钥文件</h3><p>可能原因：未使用root用户传输文件，密钥文件是root用户才可以传输的。</p><h3 id="6-项目启动后安装链码报错"><a href="#6-项目启动后安装链码报错" class="headerlink" title="6. 项目启动后安装链码报错"></a>6. 项目启动后安装链码报错</h3><p><img src="/../images/fabric/image-20220429193102060.png" alt="image-20220429193102060"></p><p>可能原因：</p><ul><li>文件证书路径不正确，是否修改了<code>src/main/java/com/springboot/config/PathConf.java</code>的<code>org1KeyFileName</code>和<code>org2KeyFileName</code></li><li>检查项目结构是否如下：<img src="/../images/fabric/image-20220320144055288.png" alt="image-20220320144055288"></li></ul><p>如果两种可能都不是，那么检查一下那个路径有没有那个文件：</p><p><img src="/../images/fabric/image-20220429193457444.png" alt="image-20220429193457444"></p><h3 id="7-与Fabric网络连接超时"><a href="#7-与Fabric网络连接超时" class="headerlink" title="7. 与Fabric网络连接超时"></a>7. 与Fabric网络连接超时</h3><p><img src="/../images/fabric/image-20220429220100251.png" alt="image-20220429220100251"></p><p>可能原因：Fabric网络所在机器性能较差，连接失败，重试或提高Fabric机器配置</p>]]></content>
      
      
      
        <tags>
            
            <tag> 部署文档 </tag>
            
            <tag> Fabric </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04安装部署Fabric v1.4.0 — 单机部署</title>
      <link href="/1900/01/01/blockchain/fabric/%E9%83%A8%E7%BD%B2Fabric-v1-4-0%E2%80%94%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2/"/>
      <url>/1900/01/01/blockchain/fabric/%E9%83%A8%E7%BD%B2Fabric-v1-4-0%E2%80%94%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2/</url>
      
        <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Enter password to read.">    <label for="pass">Enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 部署文档 </tag>
            
            <tag> Fabric </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fabric-SDK-Java的使用步骤</title>
      <link href="/1900/01/01/blockchain/fabric/%E5%8C%BA%E5%9D%97%E9%93%BEFabric-sdk-java%E7%9A%84%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4/"/>
      <url>/1900/01/01/blockchain/fabric/%E5%8C%BA%E5%9D%97%E9%93%BEFabric-sdk-java%E7%9A%84%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4/</url>
      
        <content type="html"><![CDATA[<div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Enter password to read.">    <label for="pass">Enter password to read.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
        <tags>
            
            <tag> 部署文档 </tag>
            
            <tag> Fabric </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
